{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Tacotron2.ipynb","provenance":[],"collapsed_sections":["g0ygNSquvyK9"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwco3Qsdteon","executionInfo":{"status":"ok","timestamp":1622258112012,"user_tz":-540,"elapsed":236,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}},"outputId":"db1dad57-b105-415e-b271-24d6576665ff"},"source":["# Remove this cell if you don't use google colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2RlHglHEtpHN","executionInfo":{"status":"ok","timestamp":1622258113433,"user_tz":-540,"elapsed":5,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}}},"source":["import os"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YD9QwJARtsoM","executionInfo":{"status":"ok","timestamp":1622258113672,"user_tz":-540,"elapsed":9,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}},"outputId":"fed26ce0-4f51-4aa5-c55d-2ec1d7d6acd7"},"source":["# change the path you use\n","cd '/content/drive/MyDrive/your_workspace/tacotron2'"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k8LgUO8Tt2Cx","executionInfo":{"status":"ok","timestamp":1622258114224,"user_tz":-540,"elapsed":1,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}}},"source":["%tensorflow_version 1.x"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"veQz2fH2t3nP","executionInfo":{"status":"ok","timestamp":1622258115075,"user_tz":-540,"elapsed":2,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}},"outputId":"06a9fa1e-62ea-4bb2-c50b-b86139e8efa0"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUMPQ1ydt5aw","executionInfo":{"status":"ok","timestamp":1622258123967,"user_tz":-540,"elapsed":8610,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}},"outputId":"d899fac0-e048-4250-ec78-97dfb784c8ad"},"source":["!pip install jamo\n","!pip install Unidecode"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: jamo in /usr/local/lib/python3.7/dist-packages (0.4.1)\n","Requirement already satisfied: Unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tfFO4VywHoJJ","executionInfo":{"status":"ok","timestamp":1622258131482,"user_tz":-540,"elapsed":7524,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}},"outputId":"3eb08349-2ede-446b-d4db-90482a739b2b"},"source":["# Use korean font in colab\n","%matplotlib inline  \n","\n","import matplotlib \n","import matplotlib.pyplot as plt \n","import matplotlib.font_manager as font_manager\n","\n","!apt-get update -qq\n","!apt-get install fonts-nanum* -qq\n","\n","path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' \n","font_name = font_manager.FontProperties(fname=path, size=10).get_name()\n","print(font_name)\n","plt.rc('font', family=font_name)\n","\n","font_manager._rebuild()\n","matplotlib.rcParams['axes.unicode_minus'] = False"],"execution_count":19,"outputs":[{"output_type":"stream","text":["NanumBarunGothic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZX6PLdwNdDr","executionInfo":{"status":"ok","timestamp":1622258131483,"user_tz":-540,"elapsed":30,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}},"outputId":"5ffbeb3b-df2d-4285-800f-0858757040b9"},"source":["sys_font=font_manager.findSystemFonts()\n","print(f\"sys_font number: {len(sys_font)}\")\n","print(sys_font)\n","\n","nanum_font = [f for f in sys_font if 'Nanum' in f]\n","print(f\"nanum_font number: {len(nanum_font)}\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["sys_font number: 48\n","['/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf', '/usr/share/fonts/truetype/nanum/NanumGothicEcoBold.ttf', '/usr/share/fonts/truetype/nanum/NanumSquareB.ttf', '/usr/share/fonts/truetype/nanum/NanumMyeongjo.ttf', '/usr/share/fonts/truetype/nanum/NanumSquareRoundL.ttf', '/usr/share/fonts/truetype/nanum/NanumGothic.ttf', '/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf', '/usr/share/fonts/truetype/liberation/LiberationMono-BoldItalic.ttf', '/usr/share/fonts/truetype/nanum/NanumBarunGothicBold.ttf', '/usr/share/fonts/truetype/nanum/NanumGothicCoding-Bold.ttf', '/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf', '/usr/share/fonts/truetype/nanum/NanumMyeongjoEcoBold.ttf', '/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf', '/usr/share/fonts/truetype/nanum/NanumBarunGothicUltraLight.ttf', '/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf', '/usr/share/fonts/truetype/liberation/LiberationSans-BoldItalic.ttf', '/usr/share/fonts/truetype/liberation/LiberationSans-Italic.ttf', '/usr/share/fonts/truetype/nanum/NanumBarunpenR.ttf', '/usr/share/fonts/truetype/nanum/NanumMyeongjoEcoExtraBold.ttf', '/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf', '/usr/share/fonts/truetype/nanum/NanumSquareRoundR.ttf', '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', '/usr/share/fonts/truetype/nanum/NanumSquareEB.ttf', '/usr/share/fonts/truetype/nanum/NanumMyeongjoBold.ttf', '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf', '/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Bold.ttf', '/usr/share/fonts/truetype/nanum/NanumBarunpenB.ttf', '/usr/share/fonts/truetype/nanum/NanumBarunGothicLight.ttf', '/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf', '/usr/share/fonts/truetype/liberation/LiberationSerif-BoldItalic.ttf', '/usr/share/fonts/truetype/nanum/NanumMyeongjoExtraBold.ttf', '/usr/share/fonts/truetype/nanum/NanumBrush.ttf', '/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf', '/usr/share/fonts/truetype/nanum/NanumGothicLight.ttf', '/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Italic.ttf', '/usr/share/fonts/truetype/liberation/LiberationSansNarrow-BoldItalic.ttf', '/usr/share/fonts/truetype/liberation/LiberationSerif-Italic.ttf', '/usr/share/fonts/truetype/nanum/NanumPen.ttf', '/usr/share/fonts/truetype/nanum/NanumSquareRoundEB.ttf', '/usr/share/fonts/truetype/nanum/NanumSquareL.ttf', '/usr/share/fonts/truetype/humor-sans/Humor-Sans.ttf', '/usr/share/fonts/truetype/nanum/NanumMyeongjoEco.ttf', '/usr/share/fonts/truetype/nanum/NanumSquareR.ttf', '/usr/share/fonts/truetype/liberation/LiberationMono-Italic.ttf', '/usr/share/fonts/truetype/nanum/NanumGothicEcoExtraBold.ttf', '/usr/share/fonts/truetype/nanum/NanumGothicExtraBold.ttf', '/usr/share/fonts/truetype/nanum/NanumSquareRoundB.ttf', '/usr/share/fonts/truetype/nanum/NanumGothicCoding.ttf']\n","nanum_font number: 31\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"UInvlaDHKY0S","executionInfo":{"status":"ok","timestamp":1622258132022,"user_tz":-540,"elapsed":563,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}},"outputId":"ba354972-045f-4343-bba4-c4943f90b775"},"source":["# check Korean font is printed well\n","import numpy as np\n","\n","font_manager._rebuild()\n","plt.plot(np.array([1, 2, 3, 4]))\n","plt.title('안녕하세요')"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, '안녕하세요')"]},"metadata":{"tags":[]},"execution_count":21},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"g0ygNSquvyK9"},"source":["# Tacotron2 for IU dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WMBMnH5t7fN","executionInfo":{"status":"ok","timestamp":1622258418610,"user_tz":-540,"elapsed":37604,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"}},"outputId":"60ac8a2f-fcad-414b-8189-9151552345c4"},"source":["# preprocessing (Only for the first starting. Data will be saved into the out_dir)\n","!python preprocess.py --num_workers 8 --name iu --in_dir write_your_dataset_path/iu --out_dir ./data/iu"],"execution_count":22,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Hyperparameters:\n","  adam_beta1: 0.9\n","  adam_beta2: 0.999\n","  allow_clipping_in_normalization: True\n","  attention_dim: 128\n","  attention_filters: 32\n","  attention_kernel: (31,)\n","  attention_size: 128\n","  attention_type: bah_mon_norm\n","  attention_win_size: 7\n","  cleaners: korean_cleaners\n","  clip_mels_length: True\n","  cumulative_weights: True\n","  dec_prenet_sizes: [256, 256]\n","  decoder_layers: 2\n","  decoder_lstm_units: 1024\n","  dilation_channels: 256\n","  dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n","  dropout_prob: 0.5\n","  embedding_size: 512\n","  enc_conv_channels: 512\n","  enc_conv_kernel_size: 5\n","  enc_conv_num_layers: 3\n","  encoder_lstm_units: 256\n","  fft_size: 2048\n","  filter_width: 3\n","  gc_channels: 32\n","  griffin_lim_iters: 60\n","  hop_size: 300\n","  inference_prenet_dropout: True\n","  initial_data_greedy: True\n","  initial_phase_step: 8000\n","  input_type: raw\n","  l2_regularization_strength: 0\n","  legacy: True\n","  main_data: ['']\n","  main_data_greedy_factor: 0\n","  mask_encoder: True\n","  max_abs_value: 4.0\n","  max_checkpoints: 3\n","  max_mel_frames: 1000\n","  max_n_frame: 1000\n","  min_level_db: -100\n","  min_n_frame: 150\n","  min_tokens: 30\n","  model_type: multi-speaker\n","  momentum: 0.9\n","  name: Tacotron-2\n","  num_mels: 80\n","  num_steps: 1000000\n","  optimizer: adam\n","  out_channels: 30\n","  post_bank_channel_size: 128\n","  post_bank_size: 8\n","  post_highway_depth: 4\n","  post_maxpool_width: 2\n","  post_proj_sizes: [256, 80]\n","  post_proj_width: 3\n","  post_rnn_size: 128\n","  postnet_channels: 512\n","  postnet_kernel_size: (5,)\n","  postnet_num_layers: 5\n","  power: 1.5\n","  preemphasis: 0.97\n","  preemphasize: True\n","  prenet_layers: [256, 256]\n","  prioritize_loss: False\n","  quantization_channels: 256\n","  reduction_factor: 2\n","  ref_level_db: 20\n","  rescaling: True\n","  rescaling_max: 0.999\n","  residual_channels: 128\n","  residual_legacy: True\n","  sample_rate: 24000\n","  sample_size: 9000\n","  scalar_input: True\n","  signal_normalization: True\n","  silence_threshold: 0\n","  skip_channels: 128\n","  skip_inadequate: False\n","  skip_path_filter: False\n","  smoothing: False\n","  speaker_embedding_size: 16\n","  store_metadata: False\n","  symmetric_mels: True\n","  synthesis_constraint: False\n","  synthesis_constraint_type: window\n","  tacotron_decay_learning_rate: True\n","  tacotron_decay_rate: 0.5\n","  tacotron_decay_steps: 18000\n","  tacotron_final_learning_rate: 0.0001\n","  tacotron_initial_learning_rate: 0.001\n","  tacotron_reg_weight: 1e-06\n","  tacotron_start_decay: 40000\n","  tacotron_zoneout_rate: 0.1\n","  trim_fft_size: 512\n","  trim_hop_size: 128\n","  trim_silence: True\n","  trim_top_db: 23\n","  upsample_factor: [12, 25]\n","  upsample_type: SubPixel\n","  use_biases: True\n","  use_lws: False\n","  wavenet_batch_size: 2\n","  wavenet_clip_gradients: True\n","  wavenet_decay_rate: 0.5\n","  wavenet_decay_steps: 300000\n","  wavenet_dropout: 0.05\n","  wavenet_learning_rate: 0.001\n","  win_size: 1200\n","Sampling frequency: 24000\n","100% 80/80 [00:22<00:00,  3.51it/s]\n","Write 80 utterances, 14952 mel frames, 4485600 audio timesteps, (0.05 hours)\n","Max input length (text chars): 44\n","Max mel frames length: 438\n","Max audio timesteps length: 131400\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AqCliCTrt_Sh","outputId":"8b26da10-2ab3-4e85-925a-e1acd0cf8b1d"},"source":["# train tacotron2 without loading models (checkpoint).\n","!python train_tacotron2.py --data_paths ./data/iu --batch_size 32"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","Step 2052    [1.710 sec/step, loss=0.84622, avg_loss=0.88524]\n","Generated 32 batches of size 32 in 10.818 sec\n","Step 2053    [1.751 sec/step, loss=0.72488, avg_loss=0.88379]\n","Step 2054    [1.730 sec/step, loss=0.85924, avg_loss=0.88366]\n","Step 2055    [1.721 sec/step, loss=0.92112, avg_loss=0.88376]\n","Step 2056    [1.728 sec/step, loss=0.85865, avg_loss=0.88357]\n","Step 2057    [1.723 sec/step, loss=0.88726, avg_loss=0.88325]\n","Step 2058    [1.712 sec/step, loss=0.92266, avg_loss=0.88350]\n","Step 2059    [1.705 sec/step, loss=0.89947, avg_loss=0.88350]\n","Step 2060    [1.706 sec/step, loss=0.86401, avg_loss=0.88270]\n","Step 2061    [1.706 sec/step, loss=0.87661, avg_loss=0.88272]\n","Step 2062    [1.697 sec/step, loss=0.87912, avg_loss=0.88288]\n","Step 2063    [1.693 sec/step, loss=0.92666, avg_loss=0.88340]\n","Step 2064    [1.693 sec/step, loss=0.90359, avg_loss=0.88359]\n","Step 2065    [1.690 sec/step, loss=0.87909, avg_loss=0.88351]\n","Step 2066    [1.689 sec/step, loss=0.84477, avg_loss=0.88322]\n","Step 2067    [1.702 sec/step, loss=0.87213, avg_loss=0.88310]\n","Step 2068    [1.700 sec/step, loss=0.92829, avg_loss=0.88351]\n","Step 2069    [1.691 sec/step, loss=0.88335, avg_loss=0.88337]\n","Step 2070    [1.685 sec/step, loss=0.85896, avg_loss=0.88288]\n","Step 2071    [1.721 sec/step, loss=0.73196, avg_loss=0.88175]\n","Step 2072    [1.722 sec/step, loss=0.91391, avg_loss=0.88223]\n","Step 2073    [1.729 sec/step, loss=0.87865, avg_loss=0.88193]\n","Step 2074    [1.735 sec/step, loss=0.87839, avg_loss=0.88182]\n","Step 2075    [1.755 sec/step, loss=0.87899, avg_loss=0.88216]\n","Step 2076    [1.753 sec/step, loss=0.87329, avg_loss=0.88215]\n","Step 2077    [1.765 sec/step, loss=0.89996, avg_loss=0.88234]\n","Step 2078    [1.775 sec/step, loss=0.88363, avg_loss=0.88225]\n","Step 2079    [1.771 sec/step, loss=0.86997, avg_loss=0.88231]\n","Step 2080    [1.781 sec/step, loss=0.93142, avg_loss=0.88236]\n","Step 2081    [1.782 sec/step, loss=0.90483, avg_loss=0.88218]\n","Step 2082    [1.789 sec/step, loss=0.91403, avg_loss=0.88227]\n","Step 2083    [1.758 sec/step, loss=0.90405, avg_loss=0.88422]\n","Step 2084    [1.765 sec/step, loss=0.87752, avg_loss=0.88411]\n","Generated 32 batches of size 32 in 11.146 sec\n","Step 2085    [1.770 sec/step, loss=0.86686, avg_loss=0.88387]\n","Step 2086    [1.768 sec/step, loss=0.89369, avg_loss=0.88396]\n","Step 2087    [1.740 sec/step, loss=0.88014, avg_loss=0.88391]\n","Step 2088    [1.698 sec/step, loss=0.84213, avg_loss=0.88341]\n","Step 2089    [1.693 sec/step, loss=0.85238, avg_loss=0.88303]\n","Step 2090    [1.691 sec/step, loss=0.87143, avg_loss=0.88302]\n","Step 2091    [1.690 sec/step, loss=0.90690, avg_loss=0.88289]\n","Step 2092    [1.693 sec/step, loss=0.89587, avg_loss=0.88297]\n","Step 2093    [1.684 sec/step, loss=0.86810, avg_loss=0.88286]\n","Step 2094    [1.681 sec/step, loss=0.88144, avg_loss=0.88269]\n","Step 2095    [1.686 sec/step, loss=0.87455, avg_loss=0.88259]\n","Step 2096    [1.680 sec/step, loss=0.89340, avg_loss=0.88256]\n","Step 2097    [1.677 sec/step, loss=0.85655, avg_loss=0.88262]\n","Step 2098    [1.688 sec/step, loss=0.85939, avg_loss=0.88252]\n","Step 2099    [1.684 sec/step, loss=0.87739, avg_loss=0.88242]\n","Step 2100    [1.689 sec/step, loss=0.87131, avg_loss=0.88205]\n","Writing summary at step: 2100\n","Step 2101    [1.689 sec/step, loss=0.87732, avg_loss=0.88210]\n","Step 2102    [1.646 sec/step, loss=0.88542, avg_loss=0.88361]\n","Step 2103    [1.635 sec/step, loss=0.88352, avg_loss=0.88380]\n","Step 2104    [1.645 sec/step, loss=0.87717, avg_loss=0.88346]\n","Step 2105    [1.657 sec/step, loss=0.88762, avg_loss=0.88341]\n","Step 2106    [1.650 sec/step, loss=0.86090, avg_loss=0.88356]\n","Step 2107    [1.646 sec/step, loss=0.87313, avg_loss=0.88329]\n","Step 2108    [1.639 sec/step, loss=0.89768, avg_loss=0.88357]\n","Step 2109    [1.648 sec/step, loss=0.89453, avg_loss=0.88377]\n","Step 2110    [1.645 sec/step, loss=0.84942, avg_loss=0.88315]\n","Step 2111    [1.656 sec/step, loss=0.88830, avg_loss=0.88335]\n","Step 2112    [1.661 sec/step, loss=0.90221, avg_loss=0.88330]\n","Generated 32 batches of size 32 in 10.903 sec\n","Step 2113    [1.726 sec/step, loss=0.68792, avg_loss=0.88100]\n","Step 2114    [1.743 sec/step, loss=0.86451, avg_loss=0.88066]\n","Step 2115    [1.749 sec/step, loss=0.88703, avg_loss=0.88053]\n","Step 2116    [1.731 sec/step, loss=0.88350, avg_loss=0.88018]\n","Step 2117    [1.728 sec/step, loss=0.89844, avg_loss=0.87994]\n","Step 2118    [1.713 sec/step, loss=0.89643, avg_loss=0.87983]\n","Step 2119    [1.688 sec/step, loss=0.90686, avg_loss=0.88002]\n","Step 2120    [1.691 sec/step, loss=0.87081, avg_loss=0.87966]\n","Step 2121    [1.694 sec/step, loss=0.86299, avg_loss=0.87950]\n","Step 2122    [1.696 sec/step, loss=0.87045, avg_loss=0.87895]\n","Step 2123    [1.703 sec/step, loss=0.88771, avg_loss=0.87898]\n","Step 2124    [1.691 sec/step, loss=0.91214, avg_loss=0.87922]\n","Step 2125    [1.674 sec/step, loss=0.87802, avg_loss=0.87926]\n","Step 2126    [1.669 sec/step, loss=0.86959, avg_loss=0.87902]\n","Step 2127    [1.660 sec/step, loss=0.89479, avg_loss=0.87885]\n","Step 2128    [1.658 sec/step, loss=0.84941, avg_loss=0.87840]\n","Step 2129    [1.651 sec/step, loss=0.85378, avg_loss=0.87835]\n","Step 2130    [1.663 sec/step, loss=0.87889, avg_loss=0.87855]\n","Step 2131    [1.667 sec/step, loss=0.87806, avg_loss=0.87847]\n","Step 2132    [1.665 sec/step, loss=0.87124, avg_loss=0.87843]\n","Step 2133    [1.664 sec/step, loss=0.92531, avg_loss=0.87863]\n","Step 2134    [1.665 sec/step, loss=0.87804, avg_loss=0.87848]\n","Step 2135    [1.674 sec/step, loss=0.88782, avg_loss=0.87844]\n","Step 2136    [1.679 sec/step, loss=0.86476, avg_loss=0.87821]\n","Step 2137    [1.719 sec/step, loss=0.71261, avg_loss=0.87652]\n","Step 2138    [1.723 sec/step, loss=0.88424, avg_loss=0.87623]\n","Step 2139    [1.723 sec/step, loss=0.85861, avg_loss=0.87600]\n","Step 2140    [1.717 sec/step, loss=0.87215, avg_loss=0.87606]\n","Step 2141    [1.715 sec/step, loss=0.88582, avg_loss=0.87568]\n","Step 2142    [1.716 sec/step, loss=0.87264, avg_loss=0.87578]\n","Step 2143    [1.733 sec/step, loss=0.87570, avg_loss=0.87562]\n","Step 2144    [1.736 sec/step, loss=0.87111, avg_loss=0.87543]\n","Step 2145    [1.780 sec/step, loss=0.89531, avg_loss=0.87565]\n","Generated 32 batches of size 32 in 10.532 sec\n","Step 2146    [1.787 sec/step, loss=0.87293, avg_loss=0.87523]\n","Step 2147    [1.779 sec/step, loss=0.88497, avg_loss=0.87516]\n","Step 2148    [1.755 sec/step, loss=0.86573, avg_loss=0.87482]\n","Step 2149    [1.752 sec/step, loss=0.90923, avg_loss=0.87511]\n","Step 2150    [1.742 sec/step, loss=0.84514, avg_loss=0.87478]\n","Step 2151    [1.732 sec/step, loss=0.86755, avg_loss=0.87478]\n","Step 2152    [1.729 sec/step, loss=0.87452, avg_loss=0.87506]\n","Step 2153    [1.688 sec/step, loss=0.88490, avg_loss=0.87666]\n","Step 2154    [1.689 sec/step, loss=0.89094, avg_loss=0.87698]\n","Step 2155    [1.686 sec/step, loss=0.85615, avg_loss=0.87633]\n","Step 2156    [1.676 sec/step, loss=0.85738, avg_loss=0.87632]\n","Step 2157    [1.667 sec/step, loss=0.86878, avg_loss=0.87613]\n","Step 2158    [1.674 sec/step, loss=0.86464, avg_loss=0.87555]\n","Step 2159    [1.675 sec/step, loss=0.85281, avg_loss=0.87508]\n","Step 2160    [1.702 sec/step, loss=0.86506, avg_loss=0.87509]\n","Step 2161    [1.709 sec/step, loss=0.88667, avg_loss=0.87519]\n","Step 2162    [1.739 sec/step, loss=0.77325, avg_loss=0.87414]\n","Step 2163    [1.741 sec/step, loss=0.85235, avg_loss=0.87339]\n","Step 2164    [1.739 sec/step, loss=0.87179, avg_loss=0.87307]\n","Step 2165    [1.742 sec/step, loss=0.86547, avg_loss=0.87294]\n","Step 2166    [1.756 sec/step, loss=0.87550, avg_loss=0.87325]\n","Step 2167    [1.745 sec/step, loss=0.87546, avg_loss=0.87328]\n","Step 2168    [1.747 sec/step, loss=0.87993, avg_loss=0.87280]\n","Step 2169    [1.745 sec/step, loss=0.90329, avg_loss=0.87299]\n","Step 2170    [1.741 sec/step, loss=0.87350, avg_loss=0.87314]\n","Step 2171    [1.706 sec/step, loss=0.87166, avg_loss=0.87454]\n","Step 2172    [1.715 sec/step, loss=0.86045, avg_loss=0.87400]\n","Step 2173    [1.711 sec/step, loss=0.85993, avg_loss=0.87382]\n","Step 2174    [1.695 sec/step, loss=0.84250, avg_loss=0.87346]\n","Step 2175    [1.687 sec/step, loss=0.87265, avg_loss=0.87339]\n","Step 2176    [1.686 sec/step, loss=0.84390, avg_loss=0.87310]\n","Step 2177    [1.710 sec/step, loss=0.88538, avg_loss=0.87295]\n","Generated 32 batches of size 32 in 10.496 sec\n","Step 2178    [1.724 sec/step, loss=0.87059, avg_loss=0.87282]\n","Step 2179    [1.725 sec/step, loss=0.88634, avg_loss=0.87299]\n","Step 2180    [1.711 sec/step, loss=0.87525, avg_loss=0.87242]\n","Step 2181    [1.709 sec/step, loss=0.85350, avg_loss=0.87191]\n","Step 2182    [1.707 sec/step, loss=0.88020, avg_loss=0.87157]\n","Step 2183    [1.697 sec/step, loss=0.87406, avg_loss=0.87127]\n","Step 2184    [1.684 sec/step, loss=0.87661, avg_loss=0.87126]\n","Step 2185    [1.684 sec/step, loss=0.90189, avg_loss=0.87161]\n","Step 2186    [1.681 sec/step, loss=0.87196, avg_loss=0.87140]\n","Step 2187    [1.684 sec/step, loss=0.84990, avg_loss=0.87109]\n","Step 2188    [1.695 sec/step, loss=0.85437, avg_loss=0.87122]\n","Step 2189    [1.707 sec/step, loss=0.83796, avg_loss=0.87107]\n","Step 2190    [1.710 sec/step, loss=0.87096, avg_loss=0.87107]\n","Step 2191    [1.717 sec/step, loss=0.86765, avg_loss=0.87068]\n","Step 2192    [1.711 sec/step, loss=0.82830, avg_loss=0.87000]\n","Step 2193    [1.712 sec/step, loss=0.84484, avg_loss=0.86977]\n","Step 2194    [1.711 sec/step, loss=0.88980, avg_loss=0.86985]\n","Step 2195    [1.709 sec/step, loss=0.88188, avg_loss=0.86992]\n","Step 2196    [1.713 sec/step, loss=0.87705, avg_loss=0.86976]\n","Step 2197    [1.739 sec/step, loss=0.85396, avg_loss=0.86973]\n","Step 2198    [1.762 sec/step, loss=0.64545, avg_loss=0.86760]\n","Step 2199    [1.761 sec/step, loss=0.84511, avg_loss=0.86727]\n","Step 2200    [1.760 sec/step, loss=0.87383, avg_loss=0.86730]\n","Writing summary at step: 2200\n","Step 2201    [1.756 sec/step, loss=0.90159, avg_loss=0.86754]\n","Step 2202    [1.777 sec/step, loss=0.86920, avg_loss=0.86738]\n","Step 2203    [1.780 sec/step, loss=0.88260, avg_loss=0.86737]\n","Step 2204    [1.770 sec/step, loss=0.86640, avg_loss=0.86726]\n","Step 2205    [1.762 sec/step, loss=0.86677, avg_loss=0.86705]\n","Step 2206    [1.767 sec/step, loss=0.86251, avg_loss=0.86707]\n","Step 2207    [1.779 sec/step, loss=0.87484, avg_loss=0.86709]\n","Step 2208    [1.784 sec/step, loss=0.89381, avg_loss=0.86705]\n","Step 2209    [1.792 sec/step, loss=0.84322, avg_loss=0.86653]\n","Generated 32 batches of size 32 in 10.549 sec\n","Step 2210    [1.799 sec/step, loss=0.89150, avg_loss=0.86696]\n","Step 2211    [1.790 sec/step, loss=0.84613, avg_loss=0.86653]\n","Step 2212    [1.788 sec/step, loss=0.87872, avg_loss=0.86630]\n","Step 2213    [1.721 sec/step, loss=0.86778, avg_loss=0.86810]\n","Step 2214    [1.706 sec/step, loss=0.85523, avg_loss=0.86800]\n","Step 2215    [1.711 sec/step, loss=0.88461, avg_loss=0.86798]\n","Step 2216    [1.708 sec/step, loss=0.85302, avg_loss=0.86768]\n","Step 2217    [1.700 sec/step, loss=0.90827, avg_loss=0.86777]\n","Step 2218    [1.696 sec/step, loss=0.87724, avg_loss=0.86758]\n","Step 2219    [1.711 sec/step, loss=0.83785, avg_loss=0.86689]\n","Step 2220    [1.709 sec/step, loss=0.86797, avg_loss=0.86686]\n","Step 2221    [1.715 sec/step, loss=0.85614, avg_loss=0.86679]\n","Step 2222    [1.751 sec/step, loss=0.71560, avg_loss=0.86525]\n","Step 2223    [1.748 sec/step, loss=0.88402, avg_loss=0.86521]\n","Step 2224    [1.744 sec/step, loss=0.85791, avg_loss=0.86467]\n","Step 2225    [1.741 sec/step, loss=0.83615, avg_loss=0.86425]\n","Step 2226    [1.754 sec/step, loss=0.88446, avg_loss=0.86440]\n","Step 2227    [1.754 sec/step, loss=0.85937, avg_loss=0.86404]\n","Step 2228    [1.758 sec/step, loss=0.87913, avg_loss=0.86434]\n","Step 2229    [1.759 sec/step, loss=0.89539, avg_loss=0.86476]\n","Step 2230    [1.754 sec/step, loss=0.86724, avg_loss=0.86464]\n","Step 2231    [1.752 sec/step, loss=0.86037, avg_loss=0.86446]\n","Step 2232    [1.753 sec/step, loss=0.84922, avg_loss=0.86424]\n","Step 2233    [1.752 sec/step, loss=0.87144, avg_loss=0.86370]\n","Step 2234    [1.748 sec/step, loss=0.89548, avg_loss=0.86388]\n","Step 2235    [1.739 sec/step, loss=0.85976, avg_loss=0.86360]\n","Step 2236    [1.736 sec/step, loss=0.89856, avg_loss=0.86394]\n","Step 2237    [1.700 sec/step, loss=0.86732, avg_loss=0.86548]\n","Step 2238    [1.707 sec/step, loss=0.84481, avg_loss=0.86509]\n","Step 2239    [1.744 sec/step, loss=0.85258, avg_loss=0.86503]\n","Step 2240    [1.763 sec/step, loss=0.90765, avg_loss=0.86538]\n","Generated 32 batches of size 32 in 10.821 sec\n","Step 2241    [1.764 sec/step, loss=0.88321, avg_loss=0.86536]\n","Step 2242    [1.767 sec/step, loss=0.87856, avg_loss=0.86542]\n","Step 2243    [1.758 sec/step, loss=0.88129, avg_loss=0.86547]\n","Step 2244    [1.747 sec/step, loss=0.88179, avg_loss=0.86558]\n","Step 2245    [1.703 sec/step, loss=0.88204, avg_loss=0.86545]\n","Step 2246    [1.696 sec/step, loss=0.86671, avg_loss=0.86538]\n","Step 2247    [1.695 sec/step, loss=0.83338, avg_loss=0.86487]\n","Step 2248    [1.698 sec/step, loss=0.87453, avg_loss=0.86496]\n","Step 2249    [1.701 sec/step, loss=0.87486, avg_loss=0.86461]\n","Step 2250    [1.711 sec/step, loss=0.85018, avg_loss=0.86466]\n","Step 2251    [1.710 sec/step, loss=0.85959, avg_loss=0.86458]\n","Step 2252    [1.708 sec/step, loss=0.85003, avg_loss=0.86434]\n","Step 2253    [1.709 sec/step, loss=0.85463, avg_loss=0.86404]\n","Step 2254    [1.702 sec/step, loss=0.84263, avg_loss=0.86355]\n","Step 2255    [1.700 sec/step, loss=0.88000, avg_loss=0.86379]\n","Step 2256    [1.697 sec/step, loss=0.87844, avg_loss=0.86400]\n","Step 2257    [1.705 sec/step, loss=0.86647, avg_loss=0.86398]\n","Step 2258    [1.705 sec/step, loss=0.87183, avg_loss=0.86405]\n","Step 2259    [1.743 sec/step, loss=0.69064, avg_loss=0.86243]\n","Step 2260    [1.719 sec/step, loss=0.88212, avg_loss=0.86260]\n","Step 2261    [1.720 sec/step, loss=0.85234, avg_loss=0.86226]\n","Step 2262    [1.682 sec/step, loss=0.87770, avg_loss=0.86330]\n","Step 2263    [1.686 sec/step, loss=0.87764, avg_loss=0.86355]\n","Step 2264    [1.679 sec/step, loss=0.85179, avg_loss=0.86335]\n","Step 2265    [1.677 sec/step, loss=0.85200, avg_loss=0.86322]\n","Step 2266    [1.662 sec/step, loss=0.88314, avg_loss=0.86330]\n","Step 2267    [1.663 sec/step, loss=0.87744, avg_loss=0.86331]\n","Step 2268    [1.663 sec/step, loss=0.85249, avg_loss=0.86304]\n","Step 2269    [1.661 sec/step, loss=0.87959, avg_loss=0.86280]\n","Step 2270    [1.667 sec/step, loss=0.86398, avg_loss=0.86271]\n","Step 2271    [1.677 sec/step, loss=0.85223, avg_loss=0.86251]\n","Step 2272    [1.695 sec/step, loss=0.85724, avg_loss=0.86248]\n","Generated 32 batches of size 32 in 10.816 sec\n","Step 2273    [1.728 sec/step, loss=0.85020, avg_loss=0.86238]\n","Step 2274    [1.744 sec/step, loss=0.85654, avg_loss=0.86252]\n","Step 2275    [1.732 sec/step, loss=0.85238, avg_loss=0.86232]\n","Step 2276    [1.728 sec/step, loss=0.86013, avg_loss=0.86248]\n","Step 2277    [1.697 sec/step, loss=0.86177, avg_loss=0.86225]\n","Step 2278    [1.678 sec/step, loss=0.85637, avg_loss=0.86211]\n","Step 2279    [1.681 sec/step, loss=0.88414, avg_loss=0.86208]\n","Step 2280    [1.686 sec/step, loss=0.86507, avg_loss=0.86198]\n","Step 2281    [1.686 sec/step, loss=0.84218, avg_loss=0.86187]\n","Step 2282    [1.679 sec/step, loss=0.85724, avg_loss=0.86164]\n","Step 2283    [1.686 sec/step, loss=0.89949, avg_loss=0.86189]\n","Step 2284    [1.687 sec/step, loss=0.83740, avg_loss=0.86150]\n","Step 2285    [1.681 sec/step, loss=0.87698, avg_loss=0.86125]\n","Step 2286    [1.681 sec/step, loss=0.87020, avg_loss=0.86124]\n","Step 2287    [1.678 sec/step, loss=0.84041, avg_loss=0.86114]\n","Step 2288    [1.673 sec/step, loss=0.88697, avg_loss=0.86147]\n","Step 2289    [1.661 sec/step, loss=0.83333, avg_loss=0.86142]\n","Step 2290    [1.655 sec/step, loss=0.84828, avg_loss=0.86119]\n","Step 2291    [1.648 sec/step, loss=0.86632, avg_loss=0.86118]\n","Step 2292    [1.652 sec/step, loss=0.84083, avg_loss=0.86131]\n","Step 2293    [1.654 sec/step, loss=0.92188, avg_loss=0.86208]\n","Step 2294    [1.651 sec/step, loss=0.82671, avg_loss=0.86144]\n","Step 2295    [1.645 sec/step, loss=0.87133, avg_loss=0.86134]\n","Step 2296    [1.644 sec/step, loss=0.88316, avg_loss=0.86140]\n","Step 2297    [1.618 sec/step, loss=0.85178, avg_loss=0.86138]\n","Step 2298    [1.583 sec/step, loss=0.87309, avg_loss=0.86365]\n","Step 2299    [1.600 sec/step, loss=0.86143, avg_loss=0.86382]\n","Step 2300    [1.600 sec/step, loss=0.86304, avg_loss=0.86371]\n","Writing summary at step: 2300\n","Step 2301    [1.608 sec/step, loss=0.90291, avg_loss=0.86372]\n","Step 2302    [1.618 sec/step, loss=0.87474, avg_loss=0.86378]\n","Step 2303    [1.621 sec/step, loss=0.85612, avg_loss=0.86351]\n","Step 2304    [1.640 sec/step, loss=0.86477, avg_loss=0.86350]\n","Generated 32 batches of size 32 in 11.280 sec\n","Step 2305    [1.649 sec/step, loss=0.87042, avg_loss=0.86353]\n","Step 2306    [1.649 sec/step, loss=0.91076, avg_loss=0.86402]\n","Step 2307    [1.634 sec/step, loss=0.84917, avg_loss=0.86376]\n","Step 2308    [1.634 sec/step, loss=0.88367, avg_loss=0.86366]\n","Step 2309    [1.653 sec/step, loss=0.73722, avg_loss=0.86260]\n","Step 2310    [1.653 sec/step, loss=0.83913, avg_loss=0.86207]\n","Step 2311    [1.646 sec/step, loss=0.86898, avg_loss=0.86230]\n","Step 2312    [1.640 sec/step, loss=0.87485, avg_loss=0.86226]\n","Step 2313    [1.642 sec/step, loss=0.83172, avg_loss=0.86190]\n","Step 2314    [1.643 sec/step, loss=0.89891, avg_loss=0.86234]\n","Step 2315    [1.638 sec/step, loss=0.85488, avg_loss=0.86204]\n","Step 2316    [1.644 sec/step, loss=0.86169, avg_loss=0.86213]\n","Step 2317    [1.647 sec/step, loss=0.85166, avg_loss=0.86156]\n","Step 2318    [1.652 sec/step, loss=0.85102, avg_loss=0.86130]\n","Step 2319    [1.646 sec/step, loss=0.87144, avg_loss=0.86164]\n","Step 2320    [1.647 sec/step, loss=0.86543, avg_loss=0.86161]\n","Step 2321    [1.640 sec/step, loss=0.87267, avg_loss=0.86178]\n","Step 2322    [1.609 sec/step, loss=0.83248, avg_loss=0.86295]\n","Step 2323    [1.625 sec/step, loss=0.86508, avg_loss=0.86276]\n","Step 2324    [1.627 sec/step, loss=0.88098, avg_loss=0.86299]\n","Step 2325    [1.628 sec/step, loss=0.82568, avg_loss=0.86288]\n","Step 2326    [1.616 sec/step, loss=0.85318, avg_loss=0.86257]\n","Step 2327    [1.613 sec/step, loss=0.80990, avg_loss=0.86208]\n","Step 2328    [1.613 sec/step, loss=0.85112, avg_loss=0.86180]\n","Step 2329    [1.614 sec/step, loss=0.86408, avg_loss=0.86148]\n","Step 2330    [1.609 sec/step, loss=0.85880, avg_loss=0.86140]\n","Step 2331    [1.609 sec/step, loss=0.85016, avg_loss=0.86130]\n","Step 2332    [1.623 sec/step, loss=0.81361, avg_loss=0.86094]\n","Step 2333    [1.625 sec/step, loss=0.85601, avg_loss=0.86079]\n","Step 2334    [1.631 sec/step, loss=0.85821, avg_loss=0.86041]\n","Step 2335    [1.636 sec/step, loss=0.87116, avg_loss=0.86053]\n","Step 2336    [1.636 sec/step, loss=0.84447, avg_loss=0.85999]\n","Step 2337    [1.638 sec/step, loss=0.85114, avg_loss=0.85982]\n","Generated 32 batches of size 32 in 10.907 sec\n","Step 2338    [1.646 sec/step, loss=0.85819, avg_loss=0.85996]\n","Step 2339    [1.649 sec/step, loss=0.69814, avg_loss=0.85841]\n","Step 2340    [1.638 sec/step, loss=0.88015, avg_loss=0.85814]\n","Step 2341    [1.646 sec/step, loss=0.88082, avg_loss=0.85811]\n","Step 2342    [1.637 sec/step, loss=0.83466, avg_loss=0.85768]\n","Step 2343    [1.640 sec/step, loss=0.88699, avg_loss=0.85773]\n","Step 2344    [1.677 sec/step, loss=0.67959, avg_loss=0.85571]\n","Step 2345    [1.684 sec/step, loss=0.83958, avg_loss=0.85529]\n","Step 2346    [1.690 sec/step, loss=0.84560, avg_loss=0.85508]\n","Step 2347    [1.703 sec/step, loss=0.85810, avg_loss=0.85532]\n","Step 2348    [1.698 sec/step, loss=0.84364, avg_loss=0.85501]\n","Step 2349    [1.692 sec/step, loss=0.83797, avg_loss=0.85464]\n","Step 2350    [1.688 sec/step, loss=0.86351, avg_loss=0.85478]\n","Step 2351    [1.696 sec/step, loss=0.83068, avg_loss=0.85449]\n","Step 2352    [1.697 sec/step, loss=0.84682, avg_loss=0.85446]\n","Step 2353    [1.697 sec/step, loss=0.85372, avg_loss=0.85445]\n","Step 2354    [1.715 sec/step, loss=0.86326, avg_loss=0.85465]\n","Step 2355    [1.722 sec/step, loss=0.85679, avg_loss=0.85442]\n","Step 2356    [1.721 sec/step, loss=0.85101, avg_loss=0.85415]\n","Step 2357    [1.723 sec/step, loss=0.88139, avg_loss=0.85430]\n","Step 2358    [1.719 sec/step, loss=0.84333, avg_loss=0.85401]\n","Step 2359    [1.681 sec/step, loss=0.87749, avg_loss=0.85588]\n","Step 2360    [1.677 sec/step, loss=0.88469, avg_loss=0.85591]\n","Step 2361    [1.669 sec/step, loss=0.86411, avg_loss=0.85602]\n","Step 2362    [1.668 sec/step, loss=0.81955, avg_loss=0.85544]\n","Step 2363    [1.666 sec/step, loss=0.85507, avg_loss=0.85522]\n","Step 2364    [1.668 sec/step, loss=0.84491, avg_loss=0.85515]\n","Step 2365    [1.681 sec/step, loss=0.83647, avg_loss=0.85499]\n","Step 2366    [1.699 sec/step, loss=0.85431, avg_loss=0.85470]\n","Step 2367    [1.710 sec/step, loss=0.86301, avg_loss=0.85456]\n","Step 2368    [1.713 sec/step, loss=0.86376, avg_loss=0.85467]\n","Generated 32 batches of size 32 in 10.746 sec\n","Step 2369    [1.720 sec/step, loss=0.85264, avg_loss=0.85440]\n","Step 2370    [1.713 sec/step, loss=0.85018, avg_loss=0.85427]\n","Step 2371    [1.700 sec/step, loss=0.84428, avg_loss=0.85419]\n","Step 2372    [1.676 sec/step, loss=0.88206, avg_loss=0.85443]\n","Step 2373    [1.649 sec/step, loss=0.86964, avg_loss=0.85463]\n","Step 2374    [1.638 sec/step, loss=0.81801, avg_loss=0.85424]\n","Step 2375    [1.645 sec/step, loss=0.85459, avg_loss=0.85427]\n","Step 2376    [1.678 sec/step, loss=0.76600, avg_loss=0.85332]\n","Step 2377    [1.682 sec/step, loss=0.87458, avg_loss=0.85345]\n","Step 2378    [1.677 sec/step, loss=0.84920, avg_loss=0.85338]\n","Step 2379    [1.678 sec/step, loss=0.85027, avg_loss=0.85304]\n","Step 2380    [1.670 sec/step, loss=0.84788, avg_loss=0.85287]\n","Step 2381    [1.677 sec/step, loss=0.83231, avg_loss=0.85277]\n","Step 2382    [1.675 sec/step, loss=0.85471, avg_loss=0.85275]\n","Step 2383    [1.684 sec/step, loss=0.83266, avg_loss=0.85208]\n","Step 2384    [1.686 sec/step, loss=0.87615, avg_loss=0.85246]\n","Step 2385    [1.686 sec/step, loss=0.87643, avg_loss=0.85246]\n","Step 2386    [1.683 sec/step, loss=0.82789, avg_loss=0.85204]\n","Step 2387    [1.702 sec/step, loss=0.88642, avg_loss=0.85250]\n","Step 2388    [1.697 sec/step, loss=0.85636, avg_loss=0.85219]\n","Step 2389    [1.705 sec/step, loss=0.87537, avg_loss=0.85261]\n","Step 2390    [1.701 sec/step, loss=0.87797, avg_loss=0.85291]\n","Step 2391    [1.701 sec/step, loss=0.85000, avg_loss=0.85274]\n","Step 2392    [1.699 sec/step, loss=0.86694, avg_loss=0.85301]\n","Step 2393    [1.698 sec/step, loss=0.84206, avg_loss=0.85221]\n","Step 2394    [1.703 sec/step, loss=0.87740, avg_loss=0.85271]\n","Step 2395    [1.708 sec/step, loss=0.83554, avg_loss=0.85236]\n","Step 2396    [1.717 sec/step, loss=0.83121, avg_loss=0.85184]\n","Step 2397    [1.729 sec/step, loss=0.85645, avg_loss=0.85188]\n","Step 2398    [1.734 sec/step, loss=0.87439, avg_loss=0.85190]\n","Step 2399    [1.742 sec/step, loss=0.83497, avg_loss=0.85163]\n","Generated 32 batches of size 32 in 10.230 sec\n","Step 2400    [1.756 sec/step, loss=0.84792, avg_loss=0.85148]\n","Writing summary at step: 2400\n","Step 2401    [1.751 sec/step, loss=0.86307, avg_loss=0.85108]\n","Step 2402    [1.728 sec/step, loss=0.87352, avg_loss=0.85107]\n","Step 2403    [1.722 sec/step, loss=0.83134, avg_loss=0.85082]\n","Step 2404    [1.711 sec/step, loss=0.86044, avg_loss=0.85078]\n","Step 2405    [1.699 sec/step, loss=0.80929, avg_loss=0.85017]\n","Step 2406    [1.685 sec/step, loss=0.82805, avg_loss=0.84934]\n","Step 2407    [1.684 sec/step, loss=0.87670, avg_loss=0.84962]\n","Step 2408    [1.683 sec/step, loss=0.87535, avg_loss=0.84953]\n","Step 2409    [1.657 sec/step, loss=0.83356, avg_loss=0.85050]\n","Step 2410    [1.650 sec/step, loss=0.84470, avg_loss=0.85055]\n","Step 2411    [1.650 sec/step, loss=0.82112, avg_loss=0.85007]\n","Step 2412    [1.660 sec/step, loss=0.86052, avg_loss=0.84993]\n","Step 2413    [1.666 sec/step, loss=0.85591, avg_loss=0.85017]\n","Step 2414    [1.704 sec/step, loss=0.68971, avg_loss=0.84808]\n","Step 2415    [1.706 sec/step, loss=0.86493, avg_loss=0.84818]\n","Step 2416    [1.706 sec/step, loss=0.87844, avg_loss=0.84835]\n","Step 2417    [1.707 sec/step, loss=0.86438, avg_loss=0.84847]\n","Step 2418    [1.712 sec/step, loss=0.85302, avg_loss=0.84849]\n","Step 2419    [1.705 sec/step, loss=0.88797, avg_loss=0.84866]\n","Step 2420    [1.702 sec/step, loss=0.83633, avg_loss=0.84837]\n","Step 2421    [1.701 sec/step, loss=0.86290, avg_loss=0.84827]\n","Step 2422    [1.702 sec/step, loss=0.86857, avg_loss=0.84863]\n","Step 2423    [1.684 sec/step, loss=0.81771, avg_loss=0.84816]\n","Step 2424    [1.688 sec/step, loss=0.86031, avg_loss=0.84795]\n","Step 2425    [1.693 sec/step, loss=0.86072, avg_loss=0.84830]\n","Step 2426    [1.698 sec/step, loss=0.88730, avg_loss=0.84864]\n","Step 2427    [1.707 sec/step, loss=0.88473, avg_loss=0.84939]\n","Step 2428    [1.705 sec/step, loss=0.86009, avg_loss=0.84948]\n","Step 2429    [1.708 sec/step, loss=0.83390, avg_loss=0.84918]\n","Step 2430    [1.717 sec/step, loss=0.84744, avg_loss=0.84907]\n","Step 2431    [1.724 sec/step, loss=0.84075, avg_loss=0.84897]\n","Step 2432    [1.723 sec/step, loss=0.86103, avg_loss=0.84945]\n","Generated 32 batches of size 32 in 10.697 sec\n","Step 2433    [1.727 sec/step, loss=0.83847, avg_loss=0.84927]\n","Step 2434    [1.735 sec/step, loss=0.86657, avg_loss=0.84935]\n","Step 2435    [1.739 sec/step, loss=0.87403, avg_loss=0.84938]\n","Step 2436    [1.735 sec/step, loss=0.84323, avg_loss=0.84937]\n","Step 2437    [1.728 sec/step, loss=0.85378, avg_loss=0.84940]\n","Step 2438    [1.708 sec/step, loss=0.83284, avg_loss=0.84914]\n","Step 2439    [1.665 sec/step, loss=0.81014, avg_loss=0.85026]\n","Step 2440    [1.659 sec/step, loss=0.85811, avg_loss=0.85004]\n","Step 2441    [1.655 sec/step, loss=0.85383, avg_loss=0.84977]\n","Step 2442    [1.659 sec/step, loss=0.85147, avg_loss=0.84994]\n","Step 2443    [1.655 sec/step, loss=0.85948, avg_loss=0.84967]\n","Step 2444    [1.628 sec/step, loss=0.85886, avg_loss=0.85146]\n","Step 2445    [1.619 sec/step, loss=0.83439, avg_loss=0.85141]\n","Step 2446    [1.615 sec/step, loss=0.86386, avg_loss=0.85159]\n","Step 2447    [1.605 sec/step, loss=0.87173, avg_loss=0.85173]\n","Step 2448    [1.614 sec/step, loss=0.87104, avg_loss=0.85200]\n","Step 2449    [1.619 sec/step, loss=0.86548, avg_loss=0.85227]\n","Step 2450    [1.624 sec/step, loss=0.84627, avg_loss=0.85210]\n","Step 2451    [1.628 sec/step, loss=0.81536, avg_loss=0.85195]\n","Step 2452    [1.636 sec/step, loss=0.83908, avg_loss=0.85187]\n","Step 2453    [1.634 sec/step, loss=0.81526, avg_loss=0.85149]\n","Step 2454    [1.621 sec/step, loss=0.87211, avg_loss=0.85158]\n","Step 2455    [1.616 sec/step, loss=0.85233, avg_loss=0.85153]\n","Step 2456    [1.651 sec/step, loss=0.73736, avg_loss=0.85039]\n","Step 2457    [1.643 sec/step, loss=0.85491, avg_loss=0.85013]\n","Step 2458    [1.640 sec/step, loss=0.83679, avg_loss=0.85006]\n","Step 2459    [1.643 sec/step, loss=0.86763, avg_loss=0.84997]\n","Step 2460    [1.664 sec/step, loss=0.84110, avg_loss=0.84953]\n","Step 2461    [1.672 sec/step, loss=0.82441, avg_loss=0.84913]\n","Step 2462    [1.686 sec/step, loss=0.84259, avg_loss=0.84936]\n","Step 2463    [1.699 sec/step, loss=0.83051, avg_loss=0.84912]\n","Generated 32 batches of size 32 in 10.604 sec\n","Step 2464    [1.704 sec/step, loss=0.84319, avg_loss=0.84910]\n","Step 2465    [1.709 sec/step, loss=0.82496, avg_loss=0.84899]\n","Step 2466    [1.691 sec/step, loss=0.84080, avg_loss=0.84885]\n","Step 2467    [1.679 sec/step, loss=0.86925, avg_loss=0.84891]\n","Step 2468    [1.667 sec/step, loss=0.85015, avg_loss=0.84878]\n","Step 2469    [1.663 sec/step, loss=0.81263, avg_loss=0.84838]\n","Step 2470    [1.668 sec/step, loss=0.83655, avg_loss=0.84824]\n","Step 2471    [1.667 sec/step, loss=0.81663, avg_loss=0.84796]\n","Step 2472    [1.664 sec/step, loss=0.83140, avg_loss=0.84746]\n","Step 2473    [1.655 sec/step, loss=0.82433, avg_loss=0.84700]\n","Step 2474    [1.670 sec/step, loss=0.82259, avg_loss=0.84705]\n","Step 2475    [1.668 sec/step, loss=0.85947, avg_loss=0.84710]\n","Step 2476    [1.634 sec/step, loss=0.82706, avg_loss=0.84771]\n","Step 2477    [1.634 sec/step, loss=0.83618, avg_loss=0.84733]\n","Step 2478    [1.637 sec/step, loss=0.83868, avg_loss=0.84722]\n","Step 2479    [1.634 sec/step, loss=0.83157, avg_loss=0.84703]\n","Step 2480    [1.639 sec/step, loss=0.83132, avg_loss=0.84687]\n","Step 2481    [1.637 sec/step, loss=0.82488, avg_loss=0.84679]\n","Step 2482    [1.637 sec/step, loss=0.86321, avg_loss=0.84688]\n","Step 2483    [1.627 sec/step, loss=0.86041, avg_loss=0.84716]\n","Step 2484    [1.626 sec/step, loss=0.86198, avg_loss=0.84701]\n","Step 2485    [1.625 sec/step, loss=0.81593, avg_loss=0.84641]\n","Step 2486    [1.627 sec/step, loss=0.84663, avg_loss=0.84660]\n","Step 2487    [1.619 sec/step, loss=0.87179, avg_loss=0.84645]\n","Step 2488    [1.624 sec/step, loss=0.86337, avg_loss=0.84652]\n","Step 2489    [1.621 sec/step, loss=0.83338, avg_loss=0.84610]\n","Step 2490    [1.624 sec/step, loss=0.83314, avg_loss=0.84565]\n","Step 2491    [1.658 sec/step, loss=0.74467, avg_loss=0.84460]\n","Step 2492    [1.665 sec/step, loss=0.87339, avg_loss=0.84466]\n","Step 2493    [1.678 sec/step, loss=0.84958, avg_loss=0.84474]\n","Step 2494    [1.678 sec/step, loss=0.80567, avg_loss=0.84402]\n","Step 2495    [1.699 sec/step, loss=0.83868, avg_loss=0.84405]\n","Generated 32 batches of size 32 in 10.419 sec\n","Step 2496    [1.697 sec/step, loss=0.83128, avg_loss=0.84405]\n","Step 2497    [1.704 sec/step, loss=0.85734, avg_loss=0.84406]\n","Step 2498    [1.692 sec/step, loss=0.83404, avg_loss=0.84366]\n","Step 2499    [1.676 sec/step, loss=0.82109, avg_loss=0.84352]\n","Step 2500    [1.661 sec/step, loss=0.82896, avg_loss=0.84333]\n","Writing summary at step: 2500\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Training korean : Use jamo\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12642 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12618 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50976 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51032 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49885 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54060 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53364 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47101 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47749 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52845 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50528 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45208 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12642 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12618 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50976 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51032 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49885 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54060 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53364 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47101 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47749 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52845 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50528 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45208 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/train-step-000002500-align000.png\n","100% 1/1 [00:02<00:00,  2.12s/it]\n","Test finished for step 2500.\n","  0% 0/2 [00:00<?, ?it/s]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000002500-align000.png\n"," 50% 1/2 [00:01<00:01,  1.83s/it]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000002500-align001.png\n","100% 2/2 [00:03<00:00,  1.79s/it]\n","Test finished for step 2500.\n","Step 2501    [1.655 sec/step, loss=0.82301, avg_loss=0.84293]\n","Step 2502    [1.650 sec/step, loss=0.82507, avg_loss=0.84244]\n","Step 2503    [1.656 sec/step, loss=0.84134, avg_loss=0.84254]\n","Step 2504    [1.672 sec/step, loss=0.86246, avg_loss=0.84256]\n","Step 2505    [1.668 sec/step, loss=0.83595, avg_loss=0.84283]\n","Step 2506    [1.673 sec/step, loss=0.85868, avg_loss=0.84314]\n","Step 2507    [1.679 sec/step, loss=0.87062, avg_loss=0.84308]\n","Step 2508    [1.680 sec/step, loss=0.88870, avg_loss=0.84321]\n","Step 2509    [1.672 sec/step, loss=0.81344, avg_loss=0.84301]\n","Step 2510    [1.679 sec/step, loss=0.86553, avg_loss=0.84322]\n","Step 2511    [1.687 sec/step, loss=0.85934, avg_loss=0.84360]\n","Step 2512    [1.681 sec/step, loss=0.86526, avg_loss=0.84365]\n","Step 2513    [1.672 sec/step, loss=0.82224, avg_loss=0.84331]\n","Step 2514    [1.649 sec/step, loss=0.81459, avg_loss=0.84456]\n","Step 2515    [1.645 sec/step, loss=0.83127, avg_loss=0.84422]\n","Step 2516    [1.646 sec/step, loss=0.86751, avg_loss=0.84411]\n","Step 2517    [1.643 sec/step, loss=0.81010, avg_loss=0.84357]\n","Step 2518    [1.638 sec/step, loss=0.87977, avg_loss=0.84384]\n","Step 2519    [1.648 sec/step, loss=0.84289, avg_loss=0.84339]\n","Step 2520    [1.649 sec/step, loss=0.83291, avg_loss=0.84335]\n","Step 2521    [1.654 sec/step, loss=0.86724, avg_loss=0.84340]\n","Step 2522    [1.654 sec/step, loss=0.82580, avg_loss=0.84297]\n","Step 2523    [1.667 sec/step, loss=0.82564, avg_loss=0.84305]\n","Step 2524    [1.666 sec/step, loss=0.82881, avg_loss=0.84273]\n","Step 2525    [1.683 sec/step, loss=0.85713, avg_loss=0.84270]\n","Generated 32 batches of size 32 in 10.605 sec\n","Step 2526    [1.693 sec/step, loss=0.84349, avg_loss=0.84226]\n","Step 2527    [1.723 sec/step, loss=0.70213, avg_loss=0.84043]\n","Step 2528    [1.722 sec/step, loss=0.85602, avg_loss=0.84039]\n","Step 2529    [1.716 sec/step, loss=0.80942, avg_loss=0.84015]\n","Step 2530    [1.705 sec/step, loss=0.85832, avg_loss=0.84026]\n","Step 2531    [1.696 sec/step, loss=0.85236, avg_loss=0.84037]\n","Step 2532    [1.684 sec/step, loss=0.83238, avg_loss=0.84009]\n","Step 2533    [1.684 sec/step, loss=0.83444, avg_loss=0.84005]\n","Step 2534    [1.669 sec/step, loss=0.84453, avg_loss=0.83983]\n","Step 2535    [1.661 sec/step, loss=0.84274, avg_loss=0.83951]\n","Step 2536    [1.664 sec/step, loss=0.85186, avg_loss=0.83960]\n","Step 2537    [1.671 sec/step, loss=0.82365, avg_loss=0.83930]\n","Step 2538    [1.674 sec/step, loss=0.85859, avg_loss=0.83955]\n","Step 2539    [1.716 sec/step, loss=0.68040, avg_loss=0.83826]\n","Step 2540    [1.714 sec/step, loss=0.83663, avg_loss=0.83804]\n","Step 2541    [1.706 sec/step, loss=0.82476, avg_loss=0.83775]\n","Step 2542    [1.709 sec/step, loss=0.85553, avg_loss=0.83779]\n","Step 2543    [1.718 sec/step, loss=0.83763, avg_loss=0.83757]\n","Step 2544    [1.705 sec/step, loss=0.80382, avg_loss=0.83702]\n","Step 2545    [1.711 sec/step, loss=0.84605, avg_loss=0.83714]\n","Step 2546    [1.709 sec/step, loss=0.84278, avg_loss=0.83693]\n","Step 2547    [1.727 sec/step, loss=0.83535, avg_loss=0.83657]\n","Step 2548    [1.723 sec/step, loss=0.82692, avg_loss=0.83612]\n","Step 2549    [1.717 sec/step, loss=0.86067, avg_loss=0.83608]\n","Step 2550    [1.706 sec/step, loss=0.84197, avg_loss=0.83603]\n","Step 2551    [1.701 sec/step, loss=0.85140, avg_loss=0.83639]\n","Step 2552    [1.694 sec/step, loss=0.85018, avg_loss=0.83650]\n","Step 2553    [1.697 sec/step, loss=0.83766, avg_loss=0.83673]\n","Step 2554    [1.722 sec/step, loss=0.86039, avg_loss=0.83661]\n","Step 2555    [1.732 sec/step, loss=0.85366, avg_loss=0.83662]\n","Step 2556    [1.719 sec/step, loss=0.83662, avg_loss=0.83762]\n","Generated 32 batches of size 32 in 10.630 sec\n","Step 2557    [1.727 sec/step, loss=0.84977, avg_loss=0.83757]\n","Step 2558    [1.723 sec/step, loss=0.81796, avg_loss=0.83738]\n","Step 2559    [1.718 sec/step, loss=0.81432, avg_loss=0.83684]\n","Step 2560    [1.702 sec/step, loss=0.84837, avg_loss=0.83692]\n","Step 2561    [1.697 sec/step, loss=0.81737, avg_loss=0.83685]\n","Step 2562    [1.693 sec/step, loss=0.84247, avg_loss=0.83685]\n","Step 2563    [1.674 sec/step, loss=0.80581, avg_loss=0.83660]\n","Step 2564    [1.674 sec/step, loss=0.85602, avg_loss=0.83673]\n","Step 2565    [1.662 sec/step, loss=0.78714, avg_loss=0.83635]\n","Step 2566    [1.663 sec/step, loss=0.79456, avg_loss=0.83589]\n","Step 2567    [1.670 sec/step, loss=0.84999, avg_loss=0.83569]\n","Step 2568    [1.681 sec/step, loss=0.82604, avg_loss=0.83545]\n","Step 2569    [1.678 sec/step, loss=0.82134, avg_loss=0.83554]\n","Step 2570    [1.677 sec/step, loss=0.80685, avg_loss=0.83524]\n","Step 2571    [1.686 sec/step, loss=0.82713, avg_loss=0.83535]\n","Step 2572    [1.685 sec/step, loss=0.81368, avg_loss=0.83517]\n","Step 2573    [1.686 sec/step, loss=0.83674, avg_loss=0.83529]\n","Step 2574    [1.666 sec/step, loss=0.82925, avg_loss=0.83536]\n","Step 2575    [1.682 sec/step, loss=0.82860, avg_loss=0.83505]\n","Step 2576    [1.685 sec/step, loss=0.85013, avg_loss=0.83528]\n","Step 2577    [1.682 sec/step, loss=0.87231, avg_loss=0.83564]\n","Step 2578    [1.683 sec/step, loss=0.84968, avg_loss=0.83575]\n","Step 2579    [1.694 sec/step, loss=0.85151, avg_loss=0.83595]\n","Step 2580    [1.692 sec/step, loss=0.81924, avg_loss=0.83583]\n","Step 2581    [1.683 sec/step, loss=0.80834, avg_loss=0.83567]\n","Step 2582    [1.691 sec/step, loss=0.84494, avg_loss=0.83549]\n","Step 2583    [1.687 sec/step, loss=0.84722, avg_loss=0.83535]\n","Step 2584    [1.696 sec/step, loss=0.81465, avg_loss=0.83488]\n","Step 2585    [1.739 sec/step, loss=0.67853, avg_loss=0.83351]\n","Step 2586    [1.742 sec/step, loss=0.81210, avg_loss=0.83316]\n","Step 2587    [1.759 sec/step, loss=0.84894, avg_loss=0.83293]\n","Step 2588    [1.764 sec/step, loss=0.83053, avg_loss=0.83260]\n","Step 2589    [1.769 sec/step, loss=0.81266, avg_loss=0.83240]\n","Generated 32 batches of size 32 in 10.858 sec\n","Step 2590    [1.781 sec/step, loss=0.82228, avg_loss=0.83229]\n","Step 2591    [1.751 sec/step, loss=0.81871, avg_loss=0.83303]\n","Step 2592    [1.745 sec/step, loss=0.82208, avg_loss=0.83252]\n","Step 2593    [1.733 sec/step, loss=0.85286, avg_loss=0.83255]\n","Step 2594    [1.733 sec/step, loss=0.84868, avg_loss=0.83298]\n","Step 2595    [1.723 sec/step, loss=0.78431, avg_loss=0.83243]\n","Step 2596    [1.717 sec/step, loss=0.84061, avg_loss=0.83253]\n","Step 2597    [1.698 sec/step, loss=0.83172, avg_loss=0.83227]\n","Step 2598    [1.703 sec/step, loss=0.81702, avg_loss=0.83210]\n","Step 2599    [1.695 sec/step, loss=0.85320, avg_loss=0.83242]\n","Step 2600    [1.695 sec/step, loss=0.83471, avg_loss=0.83248]\n","Writing summary at step: 2600\n","Step 2601    [1.697 sec/step, loss=0.82765, avg_loss=0.83253]\n","Step 2602    [1.695 sec/step, loss=0.84507, avg_loss=0.83273]\n","Step 2603    [1.692 sec/step, loss=0.81389, avg_loss=0.83245]\n","Step 2604    [1.668 sec/step, loss=0.80740, avg_loss=0.83190]\n","Step 2605    [1.675 sec/step, loss=0.87878, avg_loss=0.83233]\n","Step 2606    [1.676 sec/step, loss=0.84851, avg_loss=0.83223]\n","Step 2607    [1.667 sec/step, loss=0.81545, avg_loss=0.83168]\n","Step 2608    [1.699 sec/step, loss=0.73089, avg_loss=0.83010]\n","Step 2609    [1.708 sec/step, loss=0.88509, avg_loss=0.83081]\n","Step 2610    [1.708 sec/step, loss=0.86788, avg_loss=0.83084]\n","Step 2611    [1.705 sec/step, loss=0.82391, avg_loss=0.83048]\n","Step 2612    [1.700 sec/step, loss=0.83229, avg_loss=0.83015]\n","Step 2613    [1.702 sec/step, loss=0.79720, avg_loss=0.82990]\n","Step 2614    [1.687 sec/step, loss=0.81995, avg_loss=0.82996]\n","Step 2615    [1.696 sec/step, loss=0.84180, avg_loss=0.83006]\n","Step 2616    [1.689 sec/step, loss=0.87429, avg_loss=0.83013]\n","Step 2617    [1.697 sec/step, loss=0.80703, avg_loss=0.83010]\n","Step 2618    [1.716 sec/step, loss=0.82614, avg_loss=0.82956]\n","Step 2619    [1.718 sec/step, loss=0.85995, avg_loss=0.82973]\n","Generated 32 batches of size 32 in 10.373 sec\n","Step 2620    [1.747 sec/step, loss=0.86483, avg_loss=0.83005]\n","Step 2621    [1.748 sec/step, loss=0.84888, avg_loss=0.82987]\n","Step 2622    [1.739 sec/step, loss=0.78765, avg_loss=0.82949]\n","Step 2623    [1.730 sec/step, loss=0.82176, avg_loss=0.82945]\n","Step 2624    [1.728 sec/step, loss=0.81602, avg_loss=0.82932]\n","Step 2625    [1.705 sec/step, loss=0.83330, avg_loss=0.82908]\n","Step 2626    [1.704 sec/step, loss=0.83016, avg_loss=0.82895]\n","Step 2627    [1.673 sec/step, loss=0.81217, avg_loss=0.83005]\n","Step 2628    [1.675 sec/step, loss=0.84172, avg_loss=0.82991]\n","Step 2629    [1.682 sec/step, loss=0.83846, avg_loss=0.83020]\n","Step 2630    [1.680 sec/step, loss=0.81441, avg_loss=0.82976]\n","Step 2631    [1.679 sec/step, loss=0.80315, avg_loss=0.82927]\n","Step 2632    [1.678 sec/step, loss=0.83129, avg_loss=0.82926]\n","Step 2633    [1.667 sec/step, loss=0.80958, avg_loss=0.82901]\n","Step 2634    [1.667 sec/step, loss=0.83680, avg_loss=0.82893]\n","Step 2635    [1.662 sec/step, loss=0.85780, avg_loss=0.82908]\n","Step 2636    [1.661 sec/step, loss=0.85566, avg_loss=0.82912]\n","Step 2637    [1.654 sec/step, loss=0.79940, avg_loss=0.82888]\n","Step 2638    [1.652 sec/step, loss=0.83058, avg_loss=0.82860]\n","Step 2639    [1.615 sec/step, loss=0.81136, avg_loss=0.82991]\n","Step 2640    [1.610 sec/step, loss=0.79182, avg_loss=0.82946]\n","Step 2641    [1.612 sec/step, loss=0.83781, avg_loss=0.82959]\n","Step 2642    [1.646 sec/step, loss=0.66693, avg_loss=0.82770]\n","Step 2643    [1.644 sec/step, loss=0.86159, avg_loss=0.82794]\n","Step 2644    [1.651 sec/step, loss=0.83078, avg_loss=0.82821]\n","Step 2645    [1.656 sec/step, loss=0.84308, avg_loss=0.82818]\n","Step 2646    [1.655 sec/step, loss=0.82985, avg_loss=0.82805]\n","Step 2647    [1.643 sec/step, loss=0.82582, avg_loss=0.82796]\n","Step 2648    [1.643 sec/step, loss=0.83838, avg_loss=0.82807]\n","Step 2649    [1.649 sec/step, loss=0.83621, avg_loss=0.82783]\n","Step 2650    [1.665 sec/step, loss=0.82830, avg_loss=0.82769]\n","Step 2651    [1.666 sec/step, loss=0.81608, avg_loss=0.82734]\n","Step 2652    [1.691 sec/step, loss=0.81144, avg_loss=0.82695]\n","Generated 32 batches of size 32 in 10.634 sec\n","Step 2653    [1.697 sec/step, loss=0.84800, avg_loss=0.82705]\n","Step 2654    [1.673 sec/step, loss=0.85995, avg_loss=0.82705]\n","Step 2655    [1.676 sec/step, loss=0.83008, avg_loss=0.82681]\n","Step 2656    [1.660 sec/step, loss=0.85315, avg_loss=0.82698]\n","Step 2657    [1.655 sec/step, loss=0.80116, avg_loss=0.82649]\n","Step 2658    [1.668 sec/step, loss=0.83867, avg_loss=0.82670]\n","Step 2659    [1.669 sec/step, loss=0.79414, avg_loss=0.82650]\n","Step 2660    [1.673 sec/step, loss=0.82920, avg_loss=0.82631]\n","Step 2661    [1.674 sec/step, loss=0.83084, avg_loss=0.82644]\n","Step 2662    [1.671 sec/step, loss=0.84385, avg_loss=0.82645]\n","Step 2663    [1.683 sec/step, loss=0.82359, avg_loss=0.82663]\n","Step 2664    [1.680 sec/step, loss=0.82070, avg_loss=0.82628]\n","Step 2665    [1.680 sec/step, loss=0.83879, avg_loss=0.82679]\n","Step 2666    [1.680 sec/step, loss=0.79228, avg_loss=0.82677]\n","Step 2667    [1.674 sec/step, loss=0.82958, avg_loss=0.82657]\n","Step 2668    [1.662 sec/step, loss=0.81111, avg_loss=0.82642]\n","Step 2669    [1.681 sec/step, loss=0.81452, avg_loss=0.82635]\n","Step 2670    [1.683 sec/step, loss=0.82893, avg_loss=0.82657]\n","Step 2671    [1.675 sec/step, loss=0.82148, avg_loss=0.82651]\n","Step 2672    [1.682 sec/step, loss=0.84536, avg_loss=0.82683]\n","Step 2673    [1.689 sec/step, loss=0.81218, avg_loss=0.82659]\n","Step 2674    [1.694 sec/step, loss=0.82885, avg_loss=0.82658]\n","Step 2675    [1.677 sec/step, loss=0.80207, avg_loss=0.82632]\n","Step 2676    [1.672 sec/step, loss=0.78488, avg_loss=0.82566]\n","Step 2677    [1.671 sec/step, loss=0.81766, avg_loss=0.82512]\n","Step 2678    [1.704 sec/step, loss=0.65632, avg_loss=0.82318]\n","Step 2679    [1.691 sec/step, loss=0.80693, avg_loss=0.82274]\n","Step 2680    [1.693 sec/step, loss=0.85305, avg_loss=0.82308]\n","Step 2681    [1.731 sec/step, loss=0.84831, avg_loss=0.82348]\n","Step 2682    [1.749 sec/step, loss=0.83892, avg_loss=0.82342]\n","Step 2683    [1.750 sec/step, loss=0.80624, avg_loss=0.82301]\n","Generated 32 batches of size 32 in 10.567 sec\n","Step 2684    [1.744 sec/step, loss=0.79944, avg_loss=0.82285]\n","Step 2685    [1.706 sec/step, loss=0.83026, avg_loss=0.82437]\n","Step 2686    [1.703 sec/step, loss=0.83657, avg_loss=0.82462]\n","Step 2687    [1.673 sec/step, loss=0.81378, avg_loss=0.82426]\n","Step 2688    [1.667 sec/step, loss=0.84202, avg_loss=0.82438]\n","Step 2689    [1.668 sec/step, loss=0.84920, avg_loss=0.82474]\n","Step 2690    [1.660 sec/step, loss=0.81036, avg_loss=0.82463]\n","Step 2691    [1.658 sec/step, loss=0.82737, avg_loss=0.82471]\n","Step 2692    [1.660 sec/step, loss=0.81587, avg_loss=0.82465]\n","Step 2693    [1.657 sec/step, loss=0.84822, avg_loss=0.82460]\n","Step 2694    [1.656 sec/step, loss=0.81505, avg_loss=0.82427]\n","Step 2695    [1.644 sec/step, loss=0.84618, avg_loss=0.82489]\n","Step 2696    [1.648 sec/step, loss=0.82653, avg_loss=0.82475]\n","Step 2697    [1.669 sec/step, loss=0.79965, avg_loss=0.82442]\n","Step 2698    [1.665 sec/step, loss=0.81538, avg_loss=0.82441]\n","Step 2699    [1.665 sec/step, loss=0.80439, avg_loss=0.82392]\n","Step 2700    [1.662 sec/step, loss=0.85235, avg_loss=0.82410]\n","Writing summary at step: 2700\n","Step 2701    [1.663 sec/step, loss=0.81012, avg_loss=0.82392]\n","Step 2702    [1.664 sec/step, loss=0.87556, avg_loss=0.82423]\n","Step 2703    [1.670 sec/step, loss=0.85030, avg_loss=0.82459]\n","Step 2704    [1.671 sec/step, loss=0.82805, avg_loss=0.82480]\n","Step 2705    [1.670 sec/step, loss=0.81030, avg_loss=0.82411]\n","Step 2706    [1.676 sec/step, loss=0.84666, avg_loss=0.82409]\n","Step 2707    [1.676 sec/step, loss=0.80751, avg_loss=0.82401]\n","Step 2708    [1.645 sec/step, loss=0.83518, avg_loss=0.82506]\n","Step 2709    [1.650 sec/step, loss=0.83924, avg_loss=0.82460]\n","Step 2710    [1.641 sec/step, loss=0.78787, avg_loss=0.82380]\n","Step 2711    [1.645 sec/step, loss=0.85693, avg_loss=0.82413]\n","Step 2712    [1.657 sec/step, loss=0.83824, avg_loss=0.82419]\n","Generated 32 batches of size 32 in 10.299 sec\n","Step 2713    [1.733 sec/step, loss=0.70852, avg_loss=0.82330]\n","Step 2714    [1.733 sec/step, loss=0.84643, avg_loss=0.82357]\n","Step 2715    [1.724 sec/step, loss=0.80209, avg_loss=0.82317]\n","Step 2716    [1.727 sec/step, loss=0.86777, avg_loss=0.82310]\n","Step 2717    [1.722 sec/step, loss=0.86944, avg_loss=0.82373]\n","Step 2718    [1.698 sec/step, loss=0.83582, avg_loss=0.82382]\n","Step 2719    [1.695 sec/step, loss=0.85348, avg_loss=0.82376]\n","Step 2720    [1.672 sec/step, loss=0.85595, avg_loss=0.82367]\n","Step 2721    [1.671 sec/step, loss=0.81885, avg_loss=0.82337]\n","Step 2722    [1.672 sec/step, loss=0.80671, avg_loss=0.82356]\n","Step 2723    [1.666 sec/step, loss=0.80965, avg_loss=0.82344]\n","Step 2724    [1.662 sec/step, loss=0.82488, avg_loss=0.82353]\n","Step 2725    [1.665 sec/step, loss=0.81826, avg_loss=0.82338]\n","Step 2726    [1.689 sec/step, loss=0.73091, avg_loss=0.82239]\n","Step 2727    [1.683 sec/step, loss=0.82355, avg_loss=0.82250]\n","Step 2728    [1.696 sec/step, loss=0.82864, avg_loss=0.82237]\n","Step 2729    [1.695 sec/step, loss=0.87549, avg_loss=0.82274]\n","Step 2730    [1.702 sec/step, loss=0.81081, avg_loss=0.82270]\n","Step 2731    [1.709 sec/step, loss=0.85241, avg_loss=0.82320]\n","Step 2732    [1.717 sec/step, loss=0.80723, avg_loss=0.82296]\n","Step 2733    [1.718 sec/step, loss=0.83506, avg_loss=0.82321]\n","Step 2734    [1.726 sec/step, loss=0.83196, avg_loss=0.82316]\n","Step 2735    [1.726 sec/step, loss=0.81726, avg_loss=0.82276]\n","Step 2736    [1.746 sec/step, loss=0.84745, avg_loss=0.82267]\n","Step 2737    [1.747 sec/step, loss=0.82541, avg_loss=0.82293]\n","Step 2738    [1.747 sec/step, loss=0.87209, avg_loss=0.82335]\n","Step 2739    [1.745 sec/step, loss=0.82053, avg_loss=0.82344]\n","Step 2740    [1.748 sec/step, loss=0.82835, avg_loss=0.82381]\n","Step 2741    [1.750 sec/step, loss=0.85867, avg_loss=0.82401]\n","Step 2742    [1.717 sec/step, loss=0.84746, avg_loss=0.82582]\n","Step 2743    [1.704 sec/step, loss=0.80967, avg_loss=0.82530]\n","Step 2744    [1.725 sec/step, loss=0.81283, avg_loss=0.82512]\n","Step 2745    [1.746 sec/step, loss=0.82730, avg_loss=0.82496]\n","Generated 32 batches of size 32 in 10.656 sec\n","Step 2746    [1.767 sec/step, loss=0.81710, avg_loss=0.82484]\n","Step 2747    [1.762 sec/step, loss=0.76181, avg_loss=0.82420]\n","Step 2748    [1.764 sec/step, loss=0.81076, avg_loss=0.82392]\n","Step 2749    [1.758 sec/step, loss=0.83918, avg_loss=0.82395]\n","Step 2750    [1.741 sec/step, loss=0.77744, avg_loss=0.82344]\n","Step 2751    [1.735 sec/step, loss=0.81698, avg_loss=0.82345]\n","Step 2752    [1.714 sec/step, loss=0.80064, avg_loss=0.82334]\n","Step 2753    [1.716 sec/step, loss=0.85124, avg_loss=0.82337]\n","Step 2754    [1.727 sec/step, loss=0.82174, avg_loss=0.82299]\n","Step 2755    [1.710 sec/step, loss=0.82630, avg_loss=0.82295]\n","Step 2756    [1.708 sec/step, loss=0.82462, avg_loss=0.82267]\n","Step 2757    [1.705 sec/step, loss=0.82026, avg_loss=0.82286]\n","Step 2758    [1.694 sec/step, loss=0.80645, avg_loss=0.82254]\n","Step 2759    [1.697 sec/step, loss=0.83021, avg_loss=0.82290]\n","Step 2760    [1.695 sec/step, loss=0.82492, avg_loss=0.82286]\n","Step 2761    [1.692 sec/step, loss=0.79828, avg_loss=0.82253]\n","Step 2762    [1.691 sec/step, loss=0.80094, avg_loss=0.82210]\n","Step 2763    [1.682 sec/step, loss=0.82203, avg_loss=0.82209]\n","Step 2764    [1.718 sec/step, loss=0.70218, avg_loss=0.82090]\n","Step 2765    [1.714 sec/step, loss=0.83232, avg_loss=0.82084]\n","Step 2766    [1.732 sec/step, loss=0.80957, avg_loss=0.82101]\n","Step 2767    [1.732 sec/step, loss=0.81087, avg_loss=0.82082]\n","Step 2768    [1.742 sec/step, loss=0.80999, avg_loss=0.82081]\n","Step 2769    [1.727 sec/step, loss=0.80961, avg_loss=0.82076]\n","Step 2770    [1.720 sec/step, loss=0.76901, avg_loss=0.82016]\n","Step 2771    [1.722 sec/step, loss=0.81842, avg_loss=0.82013]\n","Step 2772    [1.724 sec/step, loss=0.81396, avg_loss=0.81982]\n","Step 2773    [1.726 sec/step, loss=0.80060, avg_loss=0.81970]\n","Step 2774    [1.725 sec/step, loss=0.83442, avg_loss=0.81976]\n","Step 2775    [1.721 sec/step, loss=0.80120, avg_loss=0.81975]\n","Step 2776    [1.732 sec/step, loss=0.81111, avg_loss=0.82001]\n","Step 2777    [1.749 sec/step, loss=0.83382, avg_loss=0.82017]\n","Step 2778    [1.716 sec/step, loss=0.80319, avg_loss=0.82164]\n","Step 2779    [1.730 sec/step, loss=0.83534, avg_loss=0.82193]\n","Generated 32 batches of size 32 in 11.104 sec\n","Step 2780    [1.743 sec/step, loss=0.82095, avg_loss=0.82160]\n","Step 2781    [1.714 sec/step, loss=0.81091, avg_loss=0.82123]\n","Step 2782    [1.687 sec/step, loss=0.79691, avg_loss=0.82081]\n","Step 2783    [1.684 sec/step, loss=0.80171, avg_loss=0.82077]\n","Step 2784    [1.686 sec/step, loss=0.84168, avg_loss=0.82119]\n","Step 2785    [1.700 sec/step, loss=0.80994, avg_loss=0.82098]\n","Step 2786    [1.703 sec/step, loss=0.80828, avg_loss=0.82070]\n","Step 2787    [1.705 sec/step, loss=0.80278, avg_loss=0.82059]\n","Step 2788    [1.706 sec/step, loss=0.83804, avg_loss=0.82055]\n","Step 2789    [1.699 sec/step, loss=0.83231, avg_loss=0.82038]\n","Step 2790    [1.696 sec/step, loss=0.81903, avg_loss=0.82047]\n","Step 2791    [1.697 sec/step, loss=0.81918, avg_loss=0.82039]\n","Step 2792    [1.694 sec/step, loss=0.81454, avg_loss=0.82037]\n","Step 2793    [1.693 sec/step, loss=0.78552, avg_loss=0.81975]\n","Step 2794    [1.693 sec/step, loss=0.79769, avg_loss=0.81957]\n","Step 2795    [1.730 sec/step, loss=0.66077, avg_loss=0.81772]\n","Step 2796    [1.723 sec/step, loss=0.80455, avg_loss=0.81750]\n","Step 2797    [1.701 sec/step, loss=0.80286, avg_loss=0.81753]\n","Step 2798    [1.716 sec/step, loss=0.83388, avg_loss=0.81772]\n","Step 2799    [1.718 sec/step, loss=0.81494, avg_loss=0.81782]\n","Step 2800    [1.712 sec/step, loss=0.78751, avg_loss=0.81717]\n","Writing summary at step: 2800\n","Step 2801    [1.719 sec/step, loss=0.82772, avg_loss=0.81735]\n","Step 2802    [1.724 sec/step, loss=0.81184, avg_loss=0.81671]\n","Step 2803    [1.716 sec/step, loss=0.79104, avg_loss=0.81612]\n","Step 2804    [1.719 sec/step, loss=0.79957, avg_loss=0.81584]\n","Step 2805    [1.716 sec/step, loss=0.80722, avg_loss=0.81580]\n","Step 2806    [1.705 sec/step, loss=0.80949, avg_loss=0.81543]\n","Step 2807    [1.712 sec/step, loss=0.82786, avg_loss=0.81564]\n","Step 2808    [1.717 sec/step, loss=0.80462, avg_loss=0.81533]\n","Step 2809    [1.725 sec/step, loss=0.84437, avg_loss=0.81538]\n","Step 2810    [1.750 sec/step, loss=0.87899, avg_loss=0.81629]\n","Generated 32 batches of size 32 in 10.774 sec\n","Step 2811    [1.758 sec/step, loss=0.81641, avg_loss=0.81589]\n","Step 2812    [1.743 sec/step, loss=0.82885, avg_loss=0.81579]\n","Step 2813    [1.670 sec/step, loss=0.81756, avg_loss=0.81688]\n","Step 2814    [1.676 sec/step, loss=0.84808, avg_loss=0.81690]\n","Step 2815    [1.680 sec/step, loss=0.83597, avg_loss=0.81724]\n","Step 2816    [1.690 sec/step, loss=0.79727, avg_loss=0.81653]\n","Step 2817    [1.687 sec/step, loss=0.77983, avg_loss=0.81564]\n","Step 2818    [1.691 sec/step, loss=0.80988, avg_loss=0.81538]\n","Step 2819    [1.684 sec/step, loss=0.84390, avg_loss=0.81528]\n","Step 2820    [1.683 sec/step, loss=0.82452, avg_loss=0.81497]\n","Step 2821    [1.675 sec/step, loss=0.76963, avg_loss=0.81448]\n","Step 2822    [1.677 sec/step, loss=0.81306, avg_loss=0.81454]\n","Step 2823    [1.681 sec/step, loss=0.81625, avg_loss=0.81461]\n","Step 2824    [1.685 sec/step, loss=0.83205, avg_loss=0.81468]\n","Step 2825    [1.683 sec/step, loss=0.80375, avg_loss=0.81453]\n","Step 2826    [1.648 sec/step, loss=0.82432, avg_loss=0.81547]\n","Step 2827    [1.657 sec/step, loss=0.81389, avg_loss=0.81537]\n","Step 2828    [1.643 sec/step, loss=0.81619, avg_loss=0.81525]\n","Step 2829    [1.639 sec/step, loss=0.82203, avg_loss=0.81471]\n","Step 2830    [1.642 sec/step, loss=0.86179, avg_loss=0.81522]\n","Step 2831    [1.660 sec/step, loss=0.84299, avg_loss=0.81513]\n","Step 2832    [1.662 sec/step, loss=0.84743, avg_loss=0.81553]\n","Step 2833    [1.698 sec/step, loss=0.69148, avg_loss=0.81409]\n","Step 2834    [1.689 sec/step, loss=0.80373, avg_loss=0.81381]\n","Step 2835    [1.687 sec/step, loss=0.81792, avg_loss=0.81382]\n","Step 2836    [1.667 sec/step, loss=0.79694, avg_loss=0.81331]\n","Step 2837    [1.674 sec/step, loss=0.82495, avg_loss=0.81331]\n","Step 2838    [1.675 sec/step, loss=0.84698, avg_loss=0.81306]\n","Step 2839    [1.693 sec/step, loss=0.83189, avg_loss=0.81317]\n","Step 2840    [1.708 sec/step, loss=0.83241, avg_loss=0.81321]\n","Step 2841    [1.711 sec/step, loss=0.79425, avg_loss=0.81257]\n","Step 2842    [1.722 sec/step, loss=0.83483, avg_loss=0.81244]\n","Generated 32 batches of size 32 in 10.845 sec\n","Step 2843    [1.734 sec/step, loss=0.81621, avg_loss=0.81251]\n","Step 2844    [1.709 sec/step, loss=0.83345, avg_loss=0.81271]\n","Step 2845    [1.686 sec/step, loss=0.82096, avg_loss=0.81265]\n","Step 2846    [1.665 sec/step, loss=0.83005, avg_loss=0.81278]\n","Step 2847    [1.663 sec/step, loss=0.81720, avg_loss=0.81333]\n","Step 2848    [1.656 sec/step, loss=0.78273, avg_loss=0.81305]\n","Step 2849    [1.664 sec/step, loss=0.80904, avg_loss=0.81275]\n","Step 2850    [1.667 sec/step, loss=0.82183, avg_loss=0.81319]\n","Step 2851    [1.673 sec/step, loss=0.80792, avg_loss=0.81310]\n","Step 2852    [1.672 sec/step, loss=0.82294, avg_loss=0.81333]\n","Step 2853    [1.670 sec/step, loss=0.83145, avg_loss=0.81313]\n","Step 2854    [1.657 sec/step, loss=0.81215, avg_loss=0.81303]\n","Step 2855    [1.659 sec/step, loss=0.81116, avg_loss=0.81288]\n","Step 2856    [1.651 sec/step, loss=0.79109, avg_loss=0.81255]\n","Step 2857    [1.663 sec/step, loss=0.82449, avg_loss=0.81259]\n","Step 2858    [1.663 sec/step, loss=0.80647, avg_loss=0.81259]\n","Step 2859    [1.661 sec/step, loss=0.80205, avg_loss=0.81231]\n","Step 2860    [1.664 sec/step, loss=0.81843, avg_loss=0.81224]\n","Step 2861    [1.671 sec/step, loss=0.82131, avg_loss=0.81247]\n","Step 2862    [1.710 sec/step, loss=0.68821, avg_loss=0.81135]\n","Step 2863    [1.707 sec/step, loss=0.77429, avg_loss=0.81087]\n","Step 2864    [1.683 sec/step, loss=0.79817, avg_loss=0.81183]\n","Step 2865    [1.682 sec/step, loss=0.81862, avg_loss=0.81169]\n","Step 2866    [1.680 sec/step, loss=0.83609, avg_loss=0.81196]\n","Step 2867    [1.683 sec/step, loss=0.82025, avg_loss=0.81205]\n","Step 2868    [1.681 sec/step, loss=0.80097, avg_loss=0.81196]\n","Step 2869    [1.681 sec/step, loss=0.80184, avg_loss=0.81188]\n","Step 2870    [1.682 sec/step, loss=0.78437, avg_loss=0.81204]\n","Step 2871    [1.690 sec/step, loss=0.82406, avg_loss=0.81209]\n","Step 2872    [1.692 sec/step, loss=0.78665, avg_loss=0.81182]\n","Step 2873    [1.696 sec/step, loss=0.82867, avg_loss=0.81210]\n","Step 2874    [1.710 sec/step, loss=0.82709, avg_loss=0.81203]\n","Generated 32 batches of size 32 in 11.037 sec\n","Step 2875    [1.722 sec/step, loss=0.79639, avg_loss=0.81198]\n","Step 2876    [1.720 sec/step, loss=0.80094, avg_loss=0.81188]\n","Step 2877    [1.699 sec/step, loss=0.79877, avg_loss=0.81153]\n","Step 2878    [1.700 sec/step, loss=0.81413, avg_loss=0.81164]\n","Step 2879    [1.687 sec/step, loss=0.79376, avg_loss=0.81122]\n","Step 2880    [1.676 sec/step, loss=0.81619, avg_loss=0.81117]\n","Step 2881    [1.672 sec/step, loss=0.79563, avg_loss=0.81102]\n","Step 2882    [1.685 sec/step, loss=0.81284, avg_loss=0.81118]\n","Step 2883    [1.681 sec/step, loss=0.77735, avg_loss=0.81093]\n","Step 2884    [1.680 sec/step, loss=0.82937, avg_loss=0.81081]\n","Step 2885    [1.664 sec/step, loss=0.81431, avg_loss=0.81086]\n","Step 2886    [1.662 sec/step, loss=0.78767, avg_loss=0.81065]\n","Step 2887    [1.665 sec/step, loss=0.82605, avg_loss=0.81088]\n","Step 2888    [1.666 sec/step, loss=0.81829, avg_loss=0.81068]\n","Step 2889    [1.663 sec/step, loss=0.78229, avg_loss=0.81018]\n","Step 2890    [1.670 sec/step, loss=0.82783, avg_loss=0.81027]\n","Step 2891    [1.672 sec/step, loss=0.81460, avg_loss=0.81023]\n","Step 2892    [1.673 sec/step, loss=0.80310, avg_loss=0.81011]\n","Step 2893    [1.677 sec/step, loss=0.80459, avg_loss=0.81030]\n","Step 2894    [1.676 sec/step, loss=0.80411, avg_loss=0.81037]\n","Step 2895    [1.638 sec/step, loss=0.81837, avg_loss=0.81194]\n","Step 2896    [1.640 sec/step, loss=0.80193, avg_loss=0.81192]\n","Step 2897    [1.644 sec/step, loss=0.78968, avg_loss=0.81178]\n","Step 2898    [1.628 sec/step, loss=0.80063, avg_loss=0.81145]\n","Step 2899    [1.633 sec/step, loss=0.81329, avg_loss=0.81144]\n","Step 2900    [1.653 sec/step, loss=0.81446, avg_loss=0.81171]\n","Writing summary at step: 2900\n","Step 2901    [1.645 sec/step, loss=0.80082, avg_loss=0.81144]\n","Step 2902    [1.661 sec/step, loss=0.82939, avg_loss=0.81161]\n","Step 2903    [1.680 sec/step, loss=0.78163, avg_loss=0.81152]\n","Step 2904    [1.694 sec/step, loss=0.82706, avg_loss=0.81179]\n","Step 2905    [1.699 sec/step, loss=0.78404, avg_loss=0.81156]\n","Generated 32 batches of size 32 in 11.047 sec\n","Step 2906    [1.710 sec/step, loss=0.81274, avg_loss=0.81159]\n","Step 2907    [1.715 sec/step, loss=0.81278, avg_loss=0.81144]\n","Step 2908    [1.747 sec/step, loss=0.66883, avg_loss=0.81008]\n","Step 2909    [1.723 sec/step, loss=0.77823, avg_loss=0.80942]\n","Step 2910    [1.705 sec/step, loss=0.79204, avg_loss=0.80855]\n","Step 2911    [1.692 sec/step, loss=0.81657, avg_loss=0.80856]\n","Step 2912    [1.697 sec/step, loss=0.80212, avg_loss=0.80829]\n","Step 2913    [1.733 sec/step, loss=0.69521, avg_loss=0.80706]\n","Step 2914    [1.740 sec/step, loss=0.76516, avg_loss=0.80624]\n","Step 2915    [1.734 sec/step, loss=0.80112, avg_loss=0.80589]\n","Step 2916    [1.728 sec/step, loss=0.79799, avg_loss=0.80589]\n","Step 2917    [1.730 sec/step, loss=0.79762, avg_loss=0.80607]\n","Step 2918    [1.727 sec/step, loss=0.81688, avg_loss=0.80614]\n","Step 2919    [1.723 sec/step, loss=0.77548, avg_loss=0.80546]\n","Step 2920    [1.718 sec/step, loss=0.82039, avg_loss=0.80542]\n","Step 2921    [1.725 sec/step, loss=0.82662, avg_loss=0.80599]\n","Step 2922    [1.729 sec/step, loss=0.82756, avg_loss=0.80613]\n","Step 2923    [1.745 sec/step, loss=0.80360, avg_loss=0.80600]\n","Step 2924    [1.746 sec/step, loss=0.82313, avg_loss=0.80592]\n","Step 2925    [1.745 sec/step, loss=0.79326, avg_loss=0.80581]\n","Step 2926    [1.742 sec/step, loss=0.82310, avg_loss=0.80580]\n","Step 2927    [1.738 sec/step, loss=0.82834, avg_loss=0.80594]\n","Step 2928    [1.742 sec/step, loss=0.83856, avg_loss=0.80617]\n","Step 2929    [1.746 sec/step, loss=0.79545, avg_loss=0.80590]\n","Step 2930    [1.745 sec/step, loss=0.81717, avg_loss=0.80545]\n","Step 2931    [1.724 sec/step, loss=0.80278, avg_loss=0.80505]\n","Step 2932    [1.715 sec/step, loss=0.83931, avg_loss=0.80497]\n","Step 2933    [1.678 sec/step, loss=0.78378, avg_loss=0.80589]\n","Step 2934    [1.696 sec/step, loss=0.82061, avg_loss=0.80606]\n","Step 2935    [1.721 sec/step, loss=0.81064, avg_loss=0.80599]\n","Step 2936    [1.733 sec/step, loss=0.85492, avg_loss=0.80657]\n","Generated 32 batches of size 32 in 10.484 sec\n","Step 2937    [1.738 sec/step, loss=0.83096, avg_loss=0.80663]\n","Step 2938    [1.732 sec/step, loss=0.79194, avg_loss=0.80608]\n","Step 2939    [1.711 sec/step, loss=0.76638, avg_loss=0.80542]\n","Step 2940    [1.698 sec/step, loss=0.79173, avg_loss=0.80502]\n","Step 2941    [1.694 sec/step, loss=0.79203, avg_loss=0.80500]\n","Step 2942    [1.687 sec/step, loss=0.85112, avg_loss=0.80516]\n","Step 2943    [1.677 sec/step, loss=0.80825, avg_loss=0.80508]\n","Step 2944    [1.679 sec/step, loss=0.83442, avg_loss=0.80509]\n","Step 2945    [1.678 sec/step, loss=0.82799, avg_loss=0.80516]\n","Step 2946    [1.679 sec/step, loss=0.78446, avg_loss=0.80470]\n","Step 2947    [1.678 sec/step, loss=0.79906, avg_loss=0.80452]\n","Step 2948    [1.680 sec/step, loss=0.82208, avg_loss=0.80492]\n","Step 2949    [1.672 sec/step, loss=0.78348, avg_loss=0.80466]\n","Step 2950    [1.675 sec/step, loss=0.80463, avg_loss=0.80449]\n","Step 2951    [1.664 sec/step, loss=0.83437, avg_loss=0.80475]\n","Step 2952    [1.660 sec/step, loss=0.81389, avg_loss=0.80466]\n","Step 2953    [1.655 sec/step, loss=0.81261, avg_loss=0.80447]\n","Step 2954    [1.660 sec/step, loss=0.82390, avg_loss=0.80459]\n","Step 2955    [1.662 sec/step, loss=0.80993, avg_loss=0.80458]\n","Step 2956    [1.682 sec/step, loss=0.82365, avg_loss=0.80490]\n","Step 2957    [1.676 sec/step, loss=0.81289, avg_loss=0.80479]\n","Step 2958    [1.686 sec/step, loss=0.81571, avg_loss=0.80488]\n","Step 2959    [1.687 sec/step, loss=0.80055, avg_loss=0.80487]\n","Step 2960    [1.680 sec/step, loss=0.81067, avg_loss=0.80479]\n","Step 2961    [1.675 sec/step, loss=0.82863, avg_loss=0.80486]\n","Step 2962    [1.647 sec/step, loss=0.82921, avg_loss=0.80627]\n","Step 2963    [1.649 sec/step, loss=0.76928, avg_loss=0.80622]\n","Step 2964    [1.676 sec/step, loss=0.67675, avg_loss=0.80501]\n","Step 2965    [1.685 sec/step, loss=0.82897, avg_loss=0.80511]\n","Step 2966    [1.689 sec/step, loss=0.84327, avg_loss=0.80518]\n","Step 2967    [1.706 sec/step, loss=0.82273, avg_loss=0.80521]\n","Step 2968    [1.711 sec/step, loss=0.78241, avg_loss=0.80502]\n","Step 2969    [1.710 sec/step, loss=0.80142, avg_loss=0.80502]\n","Generated 32 batches of size 32 in 11.149 sec\n","Step 2970    [1.723 sec/step, loss=0.80998, avg_loss=0.80527]\n","Step 2971    [1.714 sec/step, loss=0.80176, avg_loss=0.80505]\n","Step 2972    [1.704 sec/step, loss=0.78361, avg_loss=0.80502]\n","Step 2973    [1.696 sec/step, loss=0.82643, avg_loss=0.80500]\n","Step 2974    [1.682 sec/step, loss=0.80904, avg_loss=0.80482]\n","Step 2975    [1.674 sec/step, loss=0.81136, avg_loss=0.80497]\n","Step 2976    [1.676 sec/step, loss=0.79478, avg_loss=0.80490]\n","Step 2977    [1.678 sec/step, loss=0.78457, avg_loss=0.80476]\n","Step 2978    [1.672 sec/step, loss=0.79404, avg_loss=0.80456]\n","Step 2979    [1.679 sec/step, loss=0.82397, avg_loss=0.80486]\n","Step 2980    [1.670 sec/step, loss=0.74727, avg_loss=0.80417]\n","Step 2981    [1.668 sec/step, loss=0.77785, avg_loss=0.80400]\n","Step 2982    [1.664 sec/step, loss=0.80691, avg_loss=0.80394]\n","Step 2983    [1.666 sec/step, loss=0.80885, avg_loss=0.80425]\n","Step 2984    [1.662 sec/step, loss=0.75772, avg_loss=0.80354]\n","Step 2985    [1.679 sec/step, loss=0.78439, avg_loss=0.80324]\n","Step 2986    [1.692 sec/step, loss=0.78916, avg_loss=0.80325]\n","Step 2987    [1.688 sec/step, loss=0.76381, avg_loss=0.80263]\n","Step 2988    [1.685 sec/step, loss=0.79145, avg_loss=0.80236]\n","Step 2989    [1.690 sec/step, loss=0.81647, avg_loss=0.80270]\n","Step 2990    [1.684 sec/step, loss=0.79493, avg_loss=0.80237]\n","Step 2991    [1.679 sec/step, loss=0.81743, avg_loss=0.80240]\n","Step 2992    [1.678 sec/step, loss=0.78090, avg_loss=0.80218]\n","Step 2993    [1.674 sec/step, loss=0.79551, avg_loss=0.80209]\n","Step 2994    [1.680 sec/step, loss=0.81740, avg_loss=0.80222]\n","Step 2995    [1.681 sec/step, loss=0.80011, avg_loss=0.80204]\n","Step 2996    [1.682 sec/step, loss=0.80461, avg_loss=0.80207]\n","Step 2997    [1.682 sec/step, loss=0.81298, avg_loss=0.80230]\n","Step 2998    [1.701 sec/step, loss=0.80645, avg_loss=0.80236]\n","Step 2999    [1.721 sec/step, loss=0.85182, avg_loss=0.80274]\n","Step 3000    [1.711 sec/step, loss=0.77147, avg_loss=0.80231]\n","Writing summary at step: 3000\n","Saving audio and alignment...\n","Generated 32 batches of size 32 in 10.512 sec\n","  0% 0/1 [00:00<?, ?it/s]Training korean : Use jamo\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49512 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48127 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49900 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52824 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50506 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49512 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48127 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49900 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52824 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50506 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/train-step-000003000-align000.png\n","100% 1/1 [00:02<00:00,  2.53s/it]\n","Test finished for step 3000.\n","  0% 0/2 [00:00<?, ?it/s]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000003000-align000.png\n"," 50% 1/2 [00:09<00:09,  9.90s/it]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000003000-align001.png\n","100% 2/2 [00:19<00:00,  9.90s/it]\n","Test finished for step 3000.\n","Step 3001    [1.720 sec/step, loss=0.81049, avg_loss=0.80241]\n","Step 3002    [1.743 sec/step, loss=0.70571, avg_loss=0.80117]\n","Step 3003    [1.735 sec/step, loss=0.81985, avg_loss=0.80156]\n","Step 3004    [1.724 sec/step, loss=0.81180, avg_loss=0.80140]\n","Step 3005    [1.720 sec/step, loss=0.81100, avg_loss=0.80167]\n","Step 3006    [1.708 sec/step, loss=0.77282, avg_loss=0.80127]\n","Step 3007    [1.697 sec/step, loss=0.74946, avg_loss=0.80064]\n","Step 3008    [1.671 sec/step, loss=0.83073, avg_loss=0.80226]\n","Step 3009    [1.671 sec/step, loss=0.79024, avg_loss=0.80238]\n","Step 3010    [1.674 sec/step, loss=0.81895, avg_loss=0.80265]\n","Step 3011    [1.675 sec/step, loss=0.79925, avg_loss=0.80247]\n","Step 3012    [1.676 sec/step, loss=0.80578, avg_loss=0.80251]\n","Step 3013    [1.638 sec/step, loss=0.77123, avg_loss=0.80327]\n","Step 3014    [1.634 sec/step, loss=0.77899, avg_loss=0.80341]\n","Step 3015    [1.641 sec/step, loss=0.82748, avg_loss=0.80367]\n","Step 3016    [1.631 sec/step, loss=0.79910, avg_loss=0.80368]\n","Step 3017    [1.631 sec/step, loss=0.79942, avg_loss=0.80370]\n","Step 3018    [1.635 sec/step, loss=0.81016, avg_loss=0.80364]\n","Step 3019    [1.637 sec/step, loss=0.77241, avg_loss=0.80360]\n","Step 3020    [1.646 sec/step, loss=0.83778, avg_loss=0.80378]\n","Step 3021    [1.648 sec/step, loss=0.79474, avg_loss=0.80346]\n","Step 3022    [1.643 sec/step, loss=0.81945, avg_loss=0.80338]\n","Step 3023    [1.627 sec/step, loss=0.77990, avg_loss=0.80314]\n","Step 3024    [1.625 sec/step, loss=0.80618, avg_loss=0.80297]\n","Step 3025    [1.628 sec/step, loss=0.80318, avg_loss=0.80307]\n","Step 3026    [1.643 sec/step, loss=0.83401, avg_loss=0.80318]\n","Step 3027    [1.640 sec/step, loss=0.77921, avg_loss=0.80269]\n","Step 3028    [1.651 sec/step, loss=0.80135, avg_loss=0.80232]\n","Step 3029    [1.667 sec/step, loss=0.78396, avg_loss=0.80220]\n","Step 3030    [1.675 sec/step, loss=0.83415, avg_loss=0.80237]\n","Generated 32 batches of size 32 in 11.373 sec\n","Step 3031    [1.724 sec/step, loss=0.69221, avg_loss=0.80127]\n","Step 3032    [1.725 sec/step, loss=0.80408, avg_loss=0.80091]\n","Step 3033    [1.725 sec/step, loss=0.80364, avg_loss=0.80111]\n","Step 3034    [1.708 sec/step, loss=0.77759, avg_loss=0.80068]\n","Step 3035    [1.684 sec/step, loss=0.81325, avg_loss=0.80071]\n","Step 3036    [1.671 sec/step, loss=0.79364, avg_loss=0.80010]\n","Step 3037    [1.662 sec/step, loss=0.82119, avg_loss=0.80000]\n","Step 3038    [1.665 sec/step, loss=0.82518, avg_loss=0.80033]\n","Step 3039    [1.669 sec/step, loss=0.80157, avg_loss=0.80068]\n","Step 3040    [1.672 sec/step, loss=0.82552, avg_loss=0.80102]\n","Step 3041    [1.672 sec/step, loss=0.75502, avg_loss=0.80065]\n","Step 3042    [1.663 sec/step, loss=0.80821, avg_loss=0.80022]\n","Step 3043    [1.667 sec/step, loss=0.81646, avg_loss=0.80030]\n","Step 3044    [1.670 sec/step, loss=0.81214, avg_loss=0.80008]\n","Step 3045    [1.662 sec/step, loss=0.77945, avg_loss=0.79959]\n","Step 3046    [1.661 sec/step, loss=0.80623, avg_loss=0.79981]\n","Step 3047    [1.671 sec/step, loss=0.81971, avg_loss=0.80002]\n","Step 3048    [1.672 sec/step, loss=0.79259, avg_loss=0.79972]\n","Step 3049    [1.685 sec/step, loss=0.81682, avg_loss=0.80006]\n","Step 3050    [1.683 sec/step, loss=0.78949, avg_loss=0.79991]\n","Step 3051    [1.688 sec/step, loss=0.79629, avg_loss=0.79953]\n","Step 3052    [1.688 sec/step, loss=0.76943, avg_loss=0.79908]\n","Step 3053    [1.683 sec/step, loss=0.76226, avg_loss=0.79858]\n","Step 3054    [1.675 sec/step, loss=0.76771, avg_loss=0.79802]\n","Step 3055    [1.679 sec/step, loss=0.79769, avg_loss=0.79789]\n","Step 3056    [1.669 sec/step, loss=0.80939, avg_loss=0.79775]\n","Step 3057    [1.667 sec/step, loss=0.81651, avg_loss=0.79779]\n","Step 3058    [1.667 sec/step, loss=0.78855, avg_loss=0.79751]\n","Step 3059    [1.683 sec/step, loss=0.79519, avg_loss=0.79746]\n","Step 3060    [1.698 sec/step, loss=0.79173, avg_loss=0.79727]\n","Step 3061    [1.707 sec/step, loss=0.81103, avg_loss=0.79710]\n","Step 3062    [1.701 sec/step, loss=0.80542, avg_loss=0.79686]\n","Step 3063    [1.724 sec/step, loss=0.80682, avg_loss=0.79723]\n","Generated 32 batches of size 32 in 10.642 sec\n","Step 3064    [1.723 sec/step, loss=0.65544, avg_loss=0.79702]\n","Step 3065    [1.713 sec/step, loss=0.76542, avg_loss=0.79638]\n","Step 3066    [1.692 sec/step, loss=0.77794, avg_loss=0.79573]\n","Step 3067    [1.676 sec/step, loss=0.79670, avg_loss=0.79547]\n","Step 3068    [1.667 sec/step, loss=0.78844, avg_loss=0.79553]\n","Step 3069    [1.681 sec/step, loss=0.80432, avg_loss=0.79556]\n","Step 3070    [1.669 sec/step, loss=0.80029, avg_loss=0.79546]\n","Step 3071    [1.669 sec/step, loss=0.80189, avg_loss=0.79546]\n","Step 3072    [1.672 sec/step, loss=0.80054, avg_loss=0.79563]\n","Step 3073    [1.705 sec/step, loss=0.66288, avg_loss=0.79400]\n","Step 3074    [1.711 sec/step, loss=0.80782, avg_loss=0.79399]\n","Step 3075    [1.716 sec/step, loss=0.79408, avg_loss=0.79381]\n","Step 3076    [1.709 sec/step, loss=0.78648, avg_loss=0.79373]\n","Step 3077    [1.707 sec/step, loss=0.79816, avg_loss=0.79387]\n","Step 3078    [1.706 sec/step, loss=0.77787, avg_loss=0.79370]\n","Step 3079    [1.709 sec/step, loss=0.80542, avg_loss=0.79352]\n","Step 3080    [1.711 sec/step, loss=0.78671, avg_loss=0.79391]\n","Step 3081    [1.710 sec/step, loss=0.76156, avg_loss=0.79375]\n","Step 3082    [1.703 sec/step, loss=0.75760, avg_loss=0.79326]\n","Step 3083    [1.703 sec/step, loss=0.78865, avg_loss=0.79306]\n","Step 3084    [1.708 sec/step, loss=0.81807, avg_loss=0.79366]\n","Step 3085    [1.697 sec/step, loss=0.82665, avg_loss=0.79408]\n","Step 3086    [1.684 sec/step, loss=0.78470, avg_loss=0.79404]\n","Step 3087    [1.687 sec/step, loss=0.77531, avg_loss=0.79415]\n","Step 3088    [1.694 sec/step, loss=0.80849, avg_loss=0.79432]\n","Step 3089    [1.692 sec/step, loss=0.78420, avg_loss=0.79400]\n","Step 3090    [1.693 sec/step, loss=0.77892, avg_loss=0.79384]\n","Step 3091    [1.699 sec/step, loss=0.81002, avg_loss=0.79377]\n","Step 3092    [1.733 sec/step, loss=0.80197, avg_loss=0.79398]\n","Step 3093    [1.754 sec/step, loss=0.78979, avg_loss=0.79392]\n","Step 3094    [1.763 sec/step, loss=0.81455, avg_loss=0.79389]\n","Generated 32 batches of size 32 in 10.918 sec\n","Step 3095    [1.775 sec/step, loss=0.80409, avg_loss=0.79393]\n","Step 3096    [1.776 sec/step, loss=0.80895, avg_loss=0.79397]\n","Step 3097    [1.776 sec/step, loss=0.78668, avg_loss=0.79371]\n","Step 3098    [1.762 sec/step, loss=0.78331, avg_loss=0.79348]\n","Step 3099    [1.735 sec/step, loss=0.78403, avg_loss=0.79280]\n","Step 3100    [1.726 sec/step, loss=0.78536, avg_loss=0.79294]\n","Writing summary at step: 3100\n","Step 3101    [1.718 sec/step, loss=0.79241, avg_loss=0.79276]\n","Step 3102    [1.687 sec/step, loss=0.78913, avg_loss=0.79359]\n","Step 3103    [1.686 sec/step, loss=0.80068, avg_loss=0.79340]\n","Step 3104    [1.686 sec/step, loss=0.79379, avg_loss=0.79322]\n","Step 3105    [1.686 sec/step, loss=0.78883, avg_loss=0.79300]\n","Step 3106    [1.694 sec/step, loss=0.79313, avg_loss=0.79320]\n","Step 3107    [1.699 sec/step, loss=0.78871, avg_loss=0.79360]\n","Step 3108    [1.715 sec/step, loss=0.71910, avg_loss=0.79248]\n","Step 3109    [1.717 sec/step, loss=0.78247, avg_loss=0.79240]\n","Step 3110    [1.709 sec/step, loss=0.74821, avg_loss=0.79169]\n","Step 3111    [1.706 sec/step, loss=0.74779, avg_loss=0.79118]\n","Step 3112    [1.697 sec/step, loss=0.75423, avg_loss=0.79066]\n","Step 3113    [1.698 sec/step, loss=0.79206, avg_loss=0.79087]\n","Step 3114    [1.693 sec/step, loss=0.79117, avg_loss=0.79099]\n","Step 3115    [1.706 sec/step, loss=0.80377, avg_loss=0.79076]\n","Step 3116    [1.705 sec/step, loss=0.77525, avg_loss=0.79052]\n","Step 3117    [1.705 sec/step, loss=0.76471, avg_loss=0.79017]\n","Step 3118    [1.699 sec/step, loss=0.77895, avg_loss=0.78986]\n","Step 3119    [1.698 sec/step, loss=0.77567, avg_loss=0.78989]\n","Step 3120    [1.691 sec/step, loss=0.79732, avg_loss=0.78949]\n","Step 3121    [1.682 sec/step, loss=0.73966, avg_loss=0.78894]\n","Step 3122    [1.682 sec/step, loss=0.78042, avg_loss=0.78855]\n","Step 3123    [1.693 sec/step, loss=0.81056, avg_loss=0.78885]\n","Step 3124    [1.701 sec/step, loss=0.79237, avg_loss=0.78872]\n","Step 3125    [1.723 sec/step, loss=0.83077, avg_loss=0.78899]\n","Generated 32 batches of size 32 in 10.464 sec\n","Step 3126    [1.730 sec/step, loss=0.82076, avg_loss=0.78886]\n","Step 3127    [1.732 sec/step, loss=0.80015, avg_loss=0.78907]\n","Step 3128    [1.727 sec/step, loss=0.83577, avg_loss=0.78941]\n","Step 3129    [1.713 sec/step, loss=0.80047, avg_loss=0.78958]\n","Step 3130    [1.703 sec/step, loss=0.79882, avg_loss=0.78922]\n","Step 3131    [1.655 sec/step, loss=0.78402, avg_loss=0.79014]\n","Step 3132    [1.663 sec/step, loss=0.79757, avg_loss=0.79008]\n","Step 3133    [1.672 sec/step, loss=0.78776, avg_loss=0.78992]\n","Step 3134    [1.668 sec/step, loss=0.76373, avg_loss=0.78978]\n","Step 3135    [1.672 sec/step, loss=0.79149, avg_loss=0.78956]\n","Step 3136    [1.671 sec/step, loss=0.75299, avg_loss=0.78916]\n","Step 3137    [1.673 sec/step, loss=0.84207, avg_loss=0.78936]\n","Step 3138    [1.673 sec/step, loss=0.79884, avg_loss=0.78910]\n","Step 3139    [1.691 sec/step, loss=0.81624, avg_loss=0.78925]\n","Step 3140    [1.690 sec/step, loss=0.81478, avg_loss=0.78914]\n","Step 3141    [1.696 sec/step, loss=0.79119, avg_loss=0.78950]\n","Step 3142    [1.694 sec/step, loss=0.79122, avg_loss=0.78933]\n","Step 3143    [1.688 sec/step, loss=0.78594, avg_loss=0.78903]\n","Step 3144    [1.678 sec/step, loss=0.77439, avg_loss=0.78865]\n","Step 3145    [1.682 sec/step, loss=0.79066, avg_loss=0.78876]\n","Step 3146    [1.723 sec/step, loss=0.68679, avg_loss=0.78757]\n","Step 3147    [1.716 sec/step, loss=0.78980, avg_loss=0.78727]\n","Step 3148    [1.719 sec/step, loss=0.80185, avg_loss=0.78736]\n","Step 3149    [1.713 sec/step, loss=0.78339, avg_loss=0.78703]\n","Step 3150    [1.719 sec/step, loss=0.79111, avg_loss=0.78704]\n","Step 3151    [1.714 sec/step, loss=0.77832, avg_loss=0.78686]\n","Step 3152    [1.719 sec/step, loss=0.77342, avg_loss=0.78690]\n","Step 3153    [1.720 sec/step, loss=0.79223, avg_loss=0.78720]\n","Step 3154    [1.731 sec/step, loss=0.77704, avg_loss=0.78730]\n","Step 3155    [1.739 sec/step, loss=0.81410, avg_loss=0.78746]\n","Step 3156    [1.738 sec/step, loss=0.75757, avg_loss=0.78694]\n","Step 3157    [1.742 sec/step, loss=0.80200, avg_loss=0.78680]\n","Step 3158    [1.750 sec/step, loss=0.82829, avg_loss=0.78719]\n","Generated 32 batches of size 32 in 10.830 sec\n","Step 3159    [1.755 sec/step, loss=0.79353, avg_loss=0.78718]\n","Step 3160    [1.737 sec/step, loss=0.74659, avg_loss=0.78673]\n","Step 3161    [1.727 sec/step, loss=0.76301, avg_loss=0.78625]\n","Step 3162    [1.727 sec/step, loss=0.81542, avg_loss=0.78635]\n","Step 3163    [1.706 sec/step, loss=0.78096, avg_loss=0.78609]\n","Step 3164    [1.673 sec/step, loss=0.80083, avg_loss=0.78754]\n","Step 3165    [1.680 sec/step, loss=0.80901, avg_loss=0.78798]\n","Step 3166    [1.680 sec/step, loss=0.79482, avg_loss=0.78815]\n","Step 3167    [1.676 sec/step, loss=0.77129, avg_loss=0.78789]\n","Step 3168    [1.682 sec/step, loss=0.79034, avg_loss=0.78791]\n","Step 3169    [1.669 sec/step, loss=0.78607, avg_loss=0.78773]\n","Step 3170    [1.680 sec/step, loss=0.78441, avg_loss=0.78757]\n","Step 3171    [1.680 sec/step, loss=0.77592, avg_loss=0.78731]\n","Step 3172    [1.683 sec/step, loss=0.76906, avg_loss=0.78700]\n","Step 3173    [1.645 sec/step, loss=0.78828, avg_loss=0.78825]\n","Step 3174    [1.646 sec/step, loss=0.77485, avg_loss=0.78792]\n","Step 3175    [1.672 sec/step, loss=0.71523, avg_loss=0.78713]\n","Step 3176    [1.669 sec/step, loss=0.75053, avg_loss=0.78677]\n","Step 3177    [1.674 sec/step, loss=0.76337, avg_loss=0.78642]\n","Step 3178    [1.679 sec/step, loss=0.79929, avg_loss=0.78664]\n","Step 3179    [1.672 sec/step, loss=0.80248, avg_loss=0.78661]\n","Step 3180    [1.674 sec/step, loss=0.76411, avg_loss=0.78638]\n","Step 3181    [1.674 sec/step, loss=0.72509, avg_loss=0.78602]\n","Step 3182    [1.673 sec/step, loss=0.74950, avg_loss=0.78594]\n","Step 3183    [1.685 sec/step, loss=0.79031, avg_loss=0.78595]\n","Step 3184    [1.689 sec/step, loss=0.80734, avg_loss=0.78585]\n","Step 3185    [1.681 sec/step, loss=0.75455, avg_loss=0.78512]\n","Step 3186    [1.677 sec/step, loss=0.76103, avg_loss=0.78489]\n","Step 3187    [1.682 sec/step, loss=0.76360, avg_loss=0.78477]\n","Step 3188    [1.715 sec/step, loss=0.78650, avg_loss=0.78455]\n","Step 3189    [1.726 sec/step, loss=0.78675, avg_loss=0.78458]\n","Generated 32 batches of size 32 in 10.761 sec\n","Step 3190    [1.738 sec/step, loss=0.82801, avg_loss=0.78507]\n","Step 3191    [1.735 sec/step, loss=0.76415, avg_loss=0.78461]\n","Step 3192    [1.704 sec/step, loss=0.80980, avg_loss=0.78469]\n","Step 3193    [1.688 sec/step, loss=0.79584, avg_loss=0.78475]\n","Step 3194    [1.679 sec/step, loss=0.78022, avg_loss=0.78440]\n","Step 3195    [1.663 sec/step, loss=0.77624, avg_loss=0.78413]\n","Step 3196    [1.664 sec/step, loss=0.77848, avg_loss=0.78382]\n","Step 3197    [1.668 sec/step, loss=0.79815, avg_loss=0.78394]\n","Step 3198    [1.668 sec/step, loss=0.79457, avg_loss=0.78405]\n","Step 3199    [1.670 sec/step, loss=0.77637, avg_loss=0.78397]\n","Step 3200    [1.679 sec/step, loss=0.78583, avg_loss=0.78398]\n","Writing summary at step: 3200\n","Step 3201    [1.679 sec/step, loss=0.79130, avg_loss=0.78397]\n","Step 3202    [1.666 sec/step, loss=0.73605, avg_loss=0.78343]\n","Step 3203    [1.663 sec/step, loss=0.78956, avg_loss=0.78332]\n","Step 3204    [1.661 sec/step, loss=0.80041, avg_loss=0.78339]\n","Step 3205    [1.658 sec/step, loss=0.75257, avg_loss=0.78303]\n","Step 3206    [1.663 sec/step, loss=0.78791, avg_loss=0.78297]\n","Step 3207    [1.662 sec/step, loss=0.73635, avg_loss=0.78245]\n","Step 3208    [1.631 sec/step, loss=0.78270, avg_loss=0.78309]\n","Step 3209    [1.629 sec/step, loss=0.79221, avg_loss=0.78318]\n","Step 3210    [1.630 sec/step, loss=0.81048, avg_loss=0.78381]\n","Step 3211    [1.631 sec/step, loss=0.81664, avg_loss=0.78450]\n","Step 3212    [1.635 sec/step, loss=0.79161, avg_loss=0.78487]\n","Step 3213    [1.636 sec/step, loss=0.75793, avg_loss=0.78453]\n","Step 3214    [1.628 sec/step, loss=0.77464, avg_loss=0.78436]\n","Step 3215    [1.612 sec/step, loss=0.78921, avg_loss=0.78422]\n","Step 3216    [1.622 sec/step, loss=0.82943, avg_loss=0.78476]\n","Step 3217    [1.632 sec/step, loss=0.79687, avg_loss=0.78508]\n","Step 3218    [1.649 sec/step, loss=0.76936, avg_loss=0.78499]\n","Step 3219    [1.692 sec/step, loss=0.81299, avg_loss=0.78536]\n","Generated 32 batches of size 32 in 10.384 sec\n","Step 3220    [1.711 sec/step, loss=0.79307, avg_loss=0.78532]\n","Step 3221    [1.752 sec/step, loss=0.67755, avg_loss=0.78469]\n","Step 3222    [1.750 sec/step, loss=0.77436, avg_loss=0.78463]\n","Step 3223    [1.736 sec/step, loss=0.77907, avg_loss=0.78432]\n","Step 3224    [1.729 sec/step, loss=0.78693, avg_loss=0.78426]\n","Step 3225    [1.714 sec/step, loss=0.79654, avg_loss=0.78392]\n","Step 3226    [1.691 sec/step, loss=0.75142, avg_loss=0.78323]\n","Step 3227    [1.690 sec/step, loss=0.80486, avg_loss=0.78328]\n","Step 3228    [1.675 sec/step, loss=0.76560, avg_loss=0.78257]\n","Step 3229    [1.672 sec/step, loss=0.77945, avg_loss=0.78236]\n","Step 3230    [1.670 sec/step, loss=0.78033, avg_loss=0.78218]\n","Step 3231    [1.675 sec/step, loss=0.80314, avg_loss=0.78237]\n","Step 3232    [1.667 sec/step, loss=0.75735, avg_loss=0.78197]\n","Step 3233    [1.665 sec/step, loss=0.80380, avg_loss=0.78213]\n","Step 3234    [1.673 sec/step, loss=0.79616, avg_loss=0.78245]\n","Step 3235    [1.673 sec/step, loss=0.79906, avg_loss=0.78253]\n","Step 3236    [1.673 sec/step, loss=0.74694, avg_loss=0.78247]\n","Step 3237    [1.686 sec/step, loss=0.79267, avg_loss=0.78197]\n","Step 3238    [1.685 sec/step, loss=0.75836, avg_loss=0.78157]\n","Step 3239    [1.665 sec/step, loss=0.76528, avg_loss=0.78106]\n","Step 3240    [1.677 sec/step, loss=0.79370, avg_loss=0.78085]\n","Step 3241    [1.674 sec/step, loss=0.82038, avg_loss=0.78114]\n","Step 3242    [1.685 sec/step, loss=0.80985, avg_loss=0.78133]\n","Step 3243    [1.695 sec/step, loss=0.80023, avg_loss=0.78147]\n","Step 3244    [1.703 sec/step, loss=0.79864, avg_loss=0.78171]\n","Step 3245    [1.704 sec/step, loss=0.79711, avg_loss=0.78178]\n","Step 3246    [1.674 sec/step, loss=0.82261, avg_loss=0.78314]\n","Step 3247    [1.671 sec/step, loss=0.76360, avg_loss=0.78287]\n","Step 3248    [1.664 sec/step, loss=0.74006, avg_loss=0.78226]\n","Step 3249    [1.665 sec/step, loss=0.81405, avg_loss=0.78256]\n","Step 3250    [1.673 sec/step, loss=0.82165, avg_loss=0.78287]\n","Step 3251    [1.691 sec/step, loss=0.78862, avg_loss=0.78297]\n","Step 3252    [1.709 sec/step, loss=0.79351, avg_loss=0.78317]\n","Generated 32 batches of size 32 in 10.816 sec\n","Step 3253    [1.758 sec/step, loss=0.67315, avg_loss=0.78198]\n","Step 3254    [1.750 sec/step, loss=0.77968, avg_loss=0.78201]\n","Step 3255    [1.736 sec/step, loss=0.76604, avg_loss=0.78153]\n","Step 3256    [1.727 sec/step, loss=0.73000, avg_loss=0.78125]\n","Step 3257    [1.718 sec/step, loss=0.74356, avg_loss=0.78067]\n","Step 3258    [1.699 sec/step, loss=0.78627, avg_loss=0.78025]\n","Step 3259    [1.681 sec/step, loss=0.81657, avg_loss=0.78048]\n","Step 3260    [1.688 sec/step, loss=0.79444, avg_loss=0.78095]\n","Step 3261    [1.688 sec/step, loss=0.75708, avg_loss=0.78090]\n","Step 3262    [1.689 sec/step, loss=0.78675, avg_loss=0.78061]\n","Step 3263    [1.689 sec/step, loss=0.78082, avg_loss=0.78061]\n","Step 3264    [1.687 sec/step, loss=0.74902, avg_loss=0.78009]\n","Step 3265    [1.678 sec/step, loss=0.73227, avg_loss=0.77932]\n","Step 3266    [1.682 sec/step, loss=0.77355, avg_loss=0.77911]\n","Step 3267    [1.683 sec/step, loss=0.78933, avg_loss=0.77929]\n","Step 3268    [1.683 sec/step, loss=0.78756, avg_loss=0.77926]\n","Step 3269    [1.677 sec/step, loss=0.76050, avg_loss=0.77901]\n","Step 3270    [1.672 sec/step, loss=0.79547, avg_loss=0.77912]\n","Step 3271    [1.680 sec/step, loss=0.78513, avg_loss=0.77921]\n","Step 3272    [1.675 sec/step, loss=0.76749, avg_loss=0.77919]\n","Step 3273    [1.677 sec/step, loss=0.76576, avg_loss=0.77897]\n","Step 3274    [1.680 sec/step, loss=0.77121, avg_loss=0.77893]\n","Step 3275    [1.648 sec/step, loss=0.77921, avg_loss=0.77957]\n","Step 3276    [1.652 sec/step, loss=0.79333, avg_loss=0.78000]\n","Step 3277    [1.646 sec/step, loss=0.78099, avg_loss=0.78018]\n","Step 3278    [1.643 sec/step, loss=0.76413, avg_loss=0.77982]\n","Step 3279    [1.643 sec/step, loss=0.76330, avg_loss=0.77943]\n","Step 3280    [1.649 sec/step, loss=0.78775, avg_loss=0.77967]\n","Step 3281    [1.653 sec/step, loss=0.80073, avg_loss=0.78042]\n","Step 3282    [1.658 sec/step, loss=0.75936, avg_loss=0.78052]\n","Step 3283    [1.686 sec/step, loss=0.79523, avg_loss=0.78057]\n","Step 3284    [1.703 sec/step, loss=0.79305, avg_loss=0.78043]\n","Generated 32 batches of size 32 in 10.897 sec\n","Step 3285    [1.707 sec/step, loss=0.75476, avg_loss=0.78043]\n","Step 3286    [1.712 sec/step, loss=0.77131, avg_loss=0.78053]\n","Step 3287    [1.742 sec/step, loss=0.67466, avg_loss=0.77965]\n","Step 3288    [1.714 sec/step, loss=0.78435, avg_loss=0.77962]\n","Step 3289    [1.703 sec/step, loss=0.76372, avg_loss=0.77939]\n","Step 3290    [1.686 sec/step, loss=0.76281, avg_loss=0.77874]\n","Step 3291    [1.684 sec/step, loss=0.80561, avg_loss=0.77916]\n","Step 3292    [1.684 sec/step, loss=0.77031, avg_loss=0.77876]\n","Step 3293    [1.678 sec/step, loss=0.75502, avg_loss=0.77835]\n","Step 3294    [1.672 sec/step, loss=0.73884, avg_loss=0.77794]\n","Step 3295    [1.683 sec/step, loss=0.79358, avg_loss=0.77811]\n","Step 3296    [1.682 sec/step, loss=0.78778, avg_loss=0.77821]\n","Step 3297    [1.679 sec/step, loss=0.74922, avg_loss=0.77772]\n","Step 3298    [1.682 sec/step, loss=0.80454, avg_loss=0.77782]\n","Step 3299    [1.684 sec/step, loss=0.77860, avg_loss=0.77784]\n","Step 3300    [1.674 sec/step, loss=0.74388, avg_loss=0.77742]\n","Writing summary at step: 3300\n","Step 3301    [1.714 sec/step, loss=0.69151, avg_loss=0.77642]\n","Step 3302    [1.717 sec/step, loss=0.77051, avg_loss=0.77677]\n","Step 3303    [1.714 sec/step, loss=0.76362, avg_loss=0.77651]\n","Step 3304    [1.714 sec/step, loss=0.77125, avg_loss=0.77621]\n","Step 3305    [1.724 sec/step, loss=0.78441, avg_loss=0.77653]\n","Step 3306    [1.714 sec/step, loss=0.76501, avg_loss=0.77630]\n","Step 3307    [1.718 sec/step, loss=0.77912, avg_loss=0.77673]\n","Step 3308    [1.715 sec/step, loss=0.74917, avg_loss=0.77640]\n","Step 3309    [1.716 sec/step, loss=0.76010, avg_loss=0.77608]\n","Step 3310    [1.717 sec/step, loss=0.75675, avg_loss=0.77554]\n","Step 3311    [1.721 sec/step, loss=0.77640, avg_loss=0.77514]\n","Step 3312    [1.722 sec/step, loss=0.78806, avg_loss=0.77510]\n","Step 3313    [1.740 sec/step, loss=0.79637, avg_loss=0.77548]\n","Step 3314    [1.756 sec/step, loss=0.76356, avg_loss=0.77537]\n","Step 3315    [1.765 sec/step, loss=0.77852, avg_loss=0.77527]\n","Generated 32 batches of size 32 in 10.845 sec\n","Step 3316    [1.788 sec/step, loss=0.79467, avg_loss=0.77492]\n","Step 3317    [1.789 sec/step, loss=0.80138, avg_loss=0.77496]\n","Step 3318    [1.773 sec/step, loss=0.75667, avg_loss=0.77484]\n","Step 3319    [1.729 sec/step, loss=0.75790, avg_loss=0.77429]\n","Step 3320    [1.715 sec/step, loss=0.79687, avg_loss=0.77432]\n","Step 3321    [1.691 sec/step, loss=0.76992, avg_loss=0.77525]\n","Step 3322    [1.698 sec/step, loss=0.80764, avg_loss=0.77558]\n","Step 3323    [1.699 sec/step, loss=0.75510, avg_loss=0.77534]\n","Step 3324    [1.694 sec/step, loss=0.74004, avg_loss=0.77487]\n","Step 3325    [1.686 sec/step, loss=0.76516, avg_loss=0.77456]\n","Step 3326    [1.690 sec/step, loss=0.78205, avg_loss=0.77486]\n","Step 3327    [1.725 sec/step, loss=0.64479, avg_loss=0.77326]\n","Step 3328    [1.726 sec/step, loss=0.76866, avg_loss=0.77329]\n","Step 3329    [1.727 sec/step, loss=0.76249, avg_loss=0.77312]\n","Step 3330    [1.729 sec/step, loss=0.82750, avg_loss=0.77360]\n","Step 3331    [1.723 sec/step, loss=0.77668, avg_loss=0.77333]\n","Step 3332    [1.724 sec/step, loss=0.80077, avg_loss=0.77377]\n","Step 3333    [1.715 sec/step, loss=0.75634, avg_loss=0.77329]\n","Step 3334    [1.716 sec/step, loss=0.78042, avg_loss=0.77313]\n","Step 3335    [1.733 sec/step, loss=0.78099, avg_loss=0.77295]\n","Step 3336    [1.748 sec/step, loss=0.81191, avg_loss=0.77360]\n","Step 3337    [1.740 sec/step, loss=0.81795, avg_loss=0.77386]\n","Step 3338    [1.738 sec/step, loss=0.74150, avg_loss=0.77369]\n","Step 3339    [1.739 sec/step, loss=0.76159, avg_loss=0.77365]\n","Step 3340    [1.733 sec/step, loss=0.78639, avg_loss=0.77358]\n","Step 3341    [1.728 sec/step, loss=0.77358, avg_loss=0.77311]\n","Step 3342    [1.719 sec/step, loss=0.78082, avg_loss=0.77282]\n","Step 3343    [1.717 sec/step, loss=0.78840, avg_loss=0.77270]\n","Step 3344    [1.719 sec/step, loss=0.78821, avg_loss=0.77260]\n","Step 3345    [1.723 sec/step, loss=0.75642, avg_loss=0.77219]\n","Step 3346    [1.719 sec/step, loss=0.71976, avg_loss=0.77116]\n","Step 3347    [1.726 sec/step, loss=0.75264, avg_loss=0.77105]\n","Step 3348    [1.743 sec/step, loss=0.77902, avg_loss=0.77144]\n","Step 3349    [1.741 sec/step, loss=0.75428, avg_loss=0.77084]\n","Generated 32 batches of size 32 in 10.850 sec\n","Step 3350    [1.741 sec/step, loss=0.77933, avg_loss=0.77042]\n","Step 3351    [1.727 sec/step, loss=0.77070, avg_loss=0.77024]\n","Step 3352    [1.714 sec/step, loss=0.78022, avg_loss=0.77011]\n","Step 3353    [1.664 sec/step, loss=0.77502, avg_loss=0.77113]\n","Step 3354    [1.667 sec/step, loss=0.76244, avg_loss=0.77095]\n","Step 3355    [1.669 sec/step, loss=0.75435, avg_loss=0.77084]\n","Step 3356    [1.670 sec/step, loss=0.76027, avg_loss=0.77114]\n","Step 3357    [1.674 sec/step, loss=0.75994, avg_loss=0.77130]\n","Step 3358    [1.674 sec/step, loss=0.73143, avg_loss=0.77076]\n","Step 3359    [1.670 sec/step, loss=0.79058, avg_loss=0.77050]\n","Step 3360    [1.664 sec/step, loss=0.75306, avg_loss=0.77008]\n","Step 3361    [1.665 sec/step, loss=0.77166, avg_loss=0.77023]\n","Step 3362    [1.654 sec/step, loss=0.76360, avg_loss=0.77000]\n","Step 3363    [1.654 sec/step, loss=0.76656, avg_loss=0.76985]\n","Step 3364    [1.653 sec/step, loss=0.80897, avg_loss=0.77045]\n","Step 3365    [1.697 sec/step, loss=0.66415, avg_loss=0.76977]\n","Step 3366    [1.710 sec/step, loss=0.81270, avg_loss=0.77016]\n","Step 3367    [1.714 sec/step, loss=0.78909, avg_loss=0.77016]\n","Step 3368    [1.710 sec/step, loss=0.75830, avg_loss=0.76987]\n","Step 3369    [1.713 sec/step, loss=0.77810, avg_loss=0.77004]\n","Step 3370    [1.716 sec/step, loss=0.78143, avg_loss=0.76990]\n","Step 3371    [1.706 sec/step, loss=0.74130, avg_loss=0.76947]\n","Step 3372    [1.707 sec/step, loss=0.76730, avg_loss=0.76946]\n","Step 3373    [1.713 sec/step, loss=0.79208, avg_loss=0.76973]\n","Step 3374    [1.706 sec/step, loss=0.78361, avg_loss=0.76985]\n","Step 3375    [1.705 sec/step, loss=0.77814, avg_loss=0.76984]\n","Step 3376    [1.704 sec/step, loss=0.76776, avg_loss=0.76958]\n","Step 3377    [1.709 sec/step, loss=0.72674, avg_loss=0.76904]\n","Step 3378    [1.722 sec/step, loss=0.78423, avg_loss=0.76924]\n","Step 3379    [1.749 sec/step, loss=0.81546, avg_loss=0.76976]\n","Generated 32 batches of size 32 in 10.260 sec\n","Step 3380    [1.758 sec/step, loss=0.79081, avg_loss=0.76980]\n","Step 3381    [1.768 sec/step, loss=0.76685, avg_loss=0.76946]\n","Step 3382    [1.773 sec/step, loss=0.78001, avg_loss=0.76966]\n","Step 3383    [1.735 sec/step, loss=0.79987, avg_loss=0.76971]\n","Step 3384    [1.707 sec/step, loss=0.73552, avg_loss=0.76913]\n","Step 3385    [1.710 sec/step, loss=0.77699, avg_loss=0.76936]\n","Step 3386    [1.710 sec/step, loss=0.75584, avg_loss=0.76920]\n","Step 3387    [1.681 sec/step, loss=0.81725, avg_loss=0.77063]\n","Step 3388    [1.680 sec/step, loss=0.77906, avg_loss=0.77057]\n","Step 3389    [1.695 sec/step, loss=0.77371, avg_loss=0.77067]\n","Step 3390    [1.698 sec/step, loss=0.76963, avg_loss=0.77074]\n","Step 3391    [1.707 sec/step, loss=0.79859, avg_loss=0.77067]\n","Step 3392    [1.701 sec/step, loss=0.78658, avg_loss=0.77084]\n","Step 3393    [1.704 sec/step, loss=0.77312, avg_loss=0.77102]\n","Step 3394    [1.713 sec/step, loss=0.79494, avg_loss=0.77158]\n","Step 3395    [1.708 sec/step, loss=0.77783, avg_loss=0.77142]\n","Step 3396    [1.703 sec/step, loss=0.72395, avg_loss=0.77078]\n","Step 3397    [1.704 sec/step, loss=0.75988, avg_loss=0.77089]\n","Step 3398    [1.741 sec/step, loss=0.64647, avg_loss=0.76931]\n","Step 3399    [1.739 sec/step, loss=0.76784, avg_loss=0.76920]\n","Step 3400    [1.741 sec/step, loss=0.76036, avg_loss=0.76936]\n","Writing summary at step: 3400\n","Step 3401    [1.711 sec/step, loss=0.79105, avg_loss=0.77036]\n","Step 3402    [1.709 sec/step, loss=0.77440, avg_loss=0.77040]\n","Step 3403    [1.711 sec/step, loss=0.80560, avg_loss=0.77082]\n","Step 3404    [1.711 sec/step, loss=0.77123, avg_loss=0.77082]\n","Step 3405    [1.709 sec/step, loss=0.80173, avg_loss=0.77099]\n","Step 3406    [1.708 sec/step, loss=0.77931, avg_loss=0.77113]\n","Step 3407    [1.701 sec/step, loss=0.72023, avg_loss=0.77055]\n","Step 3408    [1.720 sec/step, loss=0.83685, avg_loss=0.77142]\n","Step 3409    [1.729 sec/step, loss=0.78952, avg_loss=0.77172]\n","Step 3410    [1.744 sec/step, loss=0.78194, avg_loss=0.77197]\n","Generated 32 batches of size 32 in 10.434 sec\n","Step 3411    [1.763 sec/step, loss=0.80344, avg_loss=0.77224]\n","Step 3412    [1.763 sec/step, loss=0.77884, avg_loss=0.77215]\n","Step 3413    [1.740 sec/step, loss=0.76993, avg_loss=0.77188]\n","Step 3414    [1.728 sec/step, loss=0.78351, avg_loss=0.77208]\n","Step 3415    [1.714 sec/step, loss=0.77551, avg_loss=0.77205]\n","Step 3416    [1.685 sec/step, loss=0.78065, avg_loss=0.77191]\n","Step 3417    [1.675 sec/step, loss=0.76457, avg_loss=0.77154]\n","Step 3418    [1.677 sec/step, loss=0.76210, avg_loss=0.77160]\n","Step 3419    [1.682 sec/step, loss=0.77939, avg_loss=0.77181]\n","Step 3420    [1.683 sec/step, loss=0.77584, avg_loss=0.77160]\n","Step 3421    [1.668 sec/step, loss=0.76561, avg_loss=0.77156]\n","Step 3422    [1.666 sec/step, loss=0.78714, avg_loss=0.77135]\n","Step 3423    [1.673 sec/step, loss=0.78272, avg_loss=0.77163]\n","Step 3424    [1.679 sec/step, loss=0.78726, avg_loss=0.77210]\n","Step 3425    [1.699 sec/step, loss=0.77855, avg_loss=0.77224]\n","Step 3426    [1.695 sec/step, loss=0.73267, avg_loss=0.77174]\n","Step 3427    [1.660 sec/step, loss=0.78727, avg_loss=0.77317]\n","Step 3428    [1.666 sec/step, loss=0.81035, avg_loss=0.77358]\n","Step 3429    [1.664 sec/step, loss=0.74761, avg_loss=0.77344]\n","Step 3430    [1.657 sec/step, loss=0.77470, avg_loss=0.77291]\n","Step 3431    [1.657 sec/step, loss=0.78724, avg_loss=0.77301]\n","Step 3432    [1.654 sec/step, loss=0.77052, avg_loss=0.77271]\n","Step 3433    [1.670 sec/step, loss=0.79675, avg_loss=0.77312]\n","Step 3434    [1.662 sec/step, loss=0.77046, avg_loss=0.77302]\n","Step 3435    [1.650 sec/step, loss=0.78655, avg_loss=0.77307]\n","Step 3436    [1.641 sec/step, loss=0.79309, avg_loss=0.77288]\n","Step 3437    [1.629 sec/step, loss=0.77952, avg_loss=0.77250]\n","Step 3438    [1.634 sec/step, loss=0.79095, avg_loss=0.77299]\n","Step 3439    [1.636 sec/step, loss=0.77319, avg_loss=0.77311]\n","Step 3440    [1.699 sec/step, loss=0.71178, avg_loss=0.77236]\n","Generated 32 batches of size 32 in 10.378 sec\n","Step 3441    [1.718 sec/step, loss=0.78628, avg_loss=0.77249]\n","Step 3442    [1.720 sec/step, loss=0.77306, avg_loss=0.77241]\n","Step 3443    [1.715 sec/step, loss=0.75777, avg_loss=0.77211]\n","Step 3444    [1.716 sec/step, loss=0.77310, avg_loss=0.77196]\n","Step 3445    [1.707 sec/step, loss=0.75699, avg_loss=0.77196]\n","Step 3446    [1.699 sec/step, loss=0.74662, avg_loss=0.77223]\n","Step 3447    [1.702 sec/step, loss=0.78556, avg_loss=0.77256]\n","Step 3448    [1.690 sec/step, loss=0.77700, avg_loss=0.77254]\n","Step 3449    [1.698 sec/step, loss=0.76121, avg_loss=0.77261]\n","Step 3450    [1.683 sec/step, loss=0.71919, avg_loss=0.77201]\n","Step 3451    [1.685 sec/step, loss=0.77769, avg_loss=0.77208]\n","Step 3452    [1.679 sec/step, loss=0.76493, avg_loss=0.77192]\n","Step 3453    [1.692 sec/step, loss=0.80069, avg_loss=0.77218]\n","Step 3454    [1.697 sec/step, loss=0.76027, avg_loss=0.77216]\n","Step 3455    [1.699 sec/step, loss=0.76237, avg_loss=0.77224]\n","Step 3456    [1.700 sec/step, loss=0.76402, avg_loss=0.77228]\n","Step 3457    [1.699 sec/step, loss=0.75874, avg_loss=0.77226]\n","Step 3458    [1.698 sec/step, loss=0.73400, avg_loss=0.77229]\n","Step 3459    [1.702 sec/step, loss=0.79453, avg_loss=0.77233]\n","Step 3460    [1.705 sec/step, loss=0.75412, avg_loss=0.77234]\n","Step 3461    [1.711 sec/step, loss=0.79614, avg_loss=0.77258]\n","Step 3462    [1.714 sec/step, loss=0.77231, avg_loss=0.77267]\n","Step 3463    [1.732 sec/step, loss=0.80475, avg_loss=0.77305]\n","Step 3464    [1.735 sec/step, loss=0.77394, avg_loss=0.77270]\n","Step 3465    [1.698 sec/step, loss=0.77454, avg_loss=0.77381]\n","Step 3466    [1.680 sec/step, loss=0.76238, avg_loss=0.77330]\n","Step 3467    [1.683 sec/step, loss=0.78678, avg_loss=0.77328]\n","Step 3468    [1.682 sec/step, loss=0.75220, avg_loss=0.77322]\n","Step 3469    [1.682 sec/step, loss=0.77190, avg_loss=0.77316]\n","Step 3470    [1.674 sec/step, loss=0.72887, avg_loss=0.77263]\n","Step 3471    [1.675 sec/step, loss=0.76606, avg_loss=0.77288]\n","Step 3472    [1.763 sec/step, loss=0.64404, avg_loss=0.77165]\n","Generated 32 batches of size 32 in 10.532 sec\n","Step 3473    [1.758 sec/step, loss=0.74304, avg_loss=0.77116]\n","Step 3474    [1.759 sec/step, loss=0.75929, avg_loss=0.77091]\n","Step 3475    [1.756 sec/step, loss=0.71916, avg_loss=0.77032]\n","Step 3476    [1.753 sec/step, loss=0.74540, avg_loss=0.77010]\n","Step 3477    [1.754 sec/step, loss=0.77805, avg_loss=0.77061]\n","Step 3478    [1.744 sec/step, loss=0.76921, avg_loss=0.77046]\n","Step 3479    [1.727 sec/step, loss=0.77999, avg_loss=0.77011]\n","Step 3480    [1.713 sec/step, loss=0.73414, avg_loss=0.76954]\n","Step 3481    [1.699 sec/step, loss=0.72434, avg_loss=0.76912]\n","Step 3482    [1.694 sec/step, loss=0.74362, avg_loss=0.76875]\n","Step 3483    [1.692 sec/step, loss=0.74547, avg_loss=0.76821]\n","Step 3484    [1.703 sec/step, loss=0.78073, avg_loss=0.76866]\n","Step 3485    [1.714 sec/step, loss=0.76860, avg_loss=0.76858]\n","Step 3486    [1.716 sec/step, loss=0.75913, avg_loss=0.76861]\n","Step 3487    [1.710 sec/step, loss=0.77243, avg_loss=0.76816]\n","Step 3488    [1.702 sec/step, loss=0.75375, avg_loss=0.76791]\n","Step 3489    [1.685 sec/step, loss=0.73802, avg_loss=0.76755]\n","Step 3490    [1.683 sec/step, loss=0.75796, avg_loss=0.76744]\n","Step 3491    [1.683 sec/step, loss=0.79745, avg_loss=0.76742]\n","Step 3492    [1.683 sec/step, loss=0.72632, avg_loss=0.76682]\n","Step 3493    [1.689 sec/step, loss=0.76796, avg_loss=0.76677]\n","Step 3494    [1.695 sec/step, loss=0.78318, avg_loss=0.76665]\n","Step 3495    [1.688 sec/step, loss=0.70431, avg_loss=0.76592]\n","Step 3496    [1.691 sec/step, loss=0.75927, avg_loss=0.76627]\n","Step 3497    [1.690 sec/step, loss=0.75562, avg_loss=0.76623]\n","Step 3498    [1.655 sec/step, loss=0.77981, avg_loss=0.76756]\n","Step 3499    [1.652 sec/step, loss=0.73683, avg_loss=0.76725]\n","Step 3500    [1.658 sec/step, loss=0.76273, avg_loss=0.76727]\n","Writing summary at step: 3500\n","Saving audio and alignment...\n","Generated 8 batches of size 2 in 0.000 sec\n","  0% 0/1 [00:00<?, ?it/s]Training korean : Use jamo\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12639 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49324 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46988 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49548 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44480 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47484 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49373 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44033 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54616 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49345 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48512 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47480 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12639 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49324 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46988 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49548 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44480 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47484 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49373 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44033 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54616 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49345 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48512 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47480 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/train-step-000003500-align000.png\n","100% 1/1 [00:03<00:00,  3.04s/it]\n","Test finished for step 3500.\n","  0% 0/2 [00:00<?, ?it/s]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000003500-align000.png\n"," 50% 1/2 [00:02<00:02,  2.83s/it]Training korean : Use jamo\n","/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab/tacotron2/utils/plot.py:28: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n","  fig, ax = plt.subplots(figsize=(char_len/5, 5))\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000003500-align001.png\n","100% 2/2 [00:05<00:00,  2.79s/it]\n","Test finished for step 3500.\n","Step 3501    [1.654 sec/step, loss=0.77109, avg_loss=0.76707]\n","Step 3502    [1.659 sec/step, loss=0.74066, avg_loss=0.76674]\n","Step 3503    [1.670 sec/step, loss=0.75954, avg_loss=0.76628]\n","Generated 32 batches of size 32 in 11.109 sec\n","Step 3504    [1.737 sec/step, loss=0.65146, avg_loss=0.76508]\n","Step 3505    [1.728 sec/step, loss=0.73462, avg_loss=0.76441]\n","Step 3506    [1.734 sec/step, loss=0.80816, avg_loss=0.76470]\n","Step 3507    [1.742 sec/step, loss=0.77854, avg_loss=0.76528]\n","Step 3508    [1.725 sec/step, loss=0.75808, avg_loss=0.76449]\n","Step 3509    [1.719 sec/step, loss=0.73861, avg_loss=0.76398]\n","Step 3510    [1.703 sec/step, loss=0.75461, avg_loss=0.76371]\n","Step 3511    [1.688 sec/step, loss=0.75208, avg_loss=0.76320]\n","Step 3512    [1.687 sec/step, loss=0.76370, avg_loss=0.76304]\n","Step 3513    [1.689 sec/step, loss=0.74944, avg_loss=0.76284]\n","Step 3514    [1.687 sec/step, loss=0.71295, avg_loss=0.76213]\n","Step 3515    [1.690 sec/step, loss=0.76539, avg_loss=0.76203]\n","Step 3516    [1.702 sec/step, loss=0.77854, avg_loss=0.76201]\n","Step 3517    [1.704 sec/step, loss=0.72182, avg_loss=0.76158]\n","Step 3518    [1.736 sec/step, loss=0.66701, avg_loss=0.76063]\n","Step 3519    [1.737 sec/step, loss=0.78054, avg_loss=0.76065]\n","Step 3520    [1.726 sec/step, loss=0.76500, avg_loss=0.76054]\n","Step 3521    [1.729 sec/step, loss=0.75867, avg_loss=0.76047]\n","Step 3522    [1.729 sec/step, loss=0.75214, avg_loss=0.76012]\n","Step 3523    [1.728 sec/step, loss=0.75824, avg_loss=0.75987]\n","Step 3524    [1.723 sec/step, loss=0.71536, avg_loss=0.75915]\n","Step 3525    [1.699 sec/step, loss=0.73404, avg_loss=0.75871]\n","Step 3526    [1.709 sec/step, loss=0.77767, avg_loss=0.75916]\n","Step 3527    [1.717 sec/step, loss=0.76094, avg_loss=0.75890]\n","Step 3528    [1.710 sec/step, loss=0.72601, avg_loss=0.75805]\n","Step 3529    [1.725 sec/step, loss=0.75018, avg_loss=0.75808]\n","Step 3530    [1.732 sec/step, loss=0.75543, avg_loss=0.75788]\n","Step 3531    [1.730 sec/step, loss=0.74822, avg_loss=0.75749]\n","Step 3532    [1.733 sec/step, loss=0.78388, avg_loss=0.75763]\n","Step 3533    [1.724 sec/step, loss=0.76848, avg_loss=0.75735]\n","Step 3534    [1.731 sec/step, loss=0.71548, avg_loss=0.75680]\n","Step 3535    [1.762 sec/step, loss=0.79681, avg_loss=0.75690]\n","Step 3536    [1.772 sec/step, loss=0.78755, avg_loss=0.75684]\n","Generated 32 batches of size 32 in 10.622 sec\n","Step 3537    [1.783 sec/step, loss=0.78856, avg_loss=0.75693]\n","Step 3538    [1.782 sec/step, loss=0.80724, avg_loss=0.75710]\n","Step 3539    [1.780 sec/step, loss=0.72157, avg_loss=0.75658]\n","Step 3540    [1.709 sec/step, loss=0.74516, avg_loss=0.75691]\n","Step 3541    [1.692 sec/step, loss=0.76909, avg_loss=0.75674]\n","Step 3542    [1.697 sec/step, loss=0.78418, avg_loss=0.75685]\n","Step 3543    [1.696 sec/step, loss=0.76479, avg_loss=0.75692]\n","Step 3544    [1.693 sec/step, loss=0.76538, avg_loss=0.75685]\n","Step 3545    [1.698 sec/step, loss=0.77263, avg_loss=0.75700]\n","Step 3546    [1.698 sec/step, loss=0.73658, avg_loss=0.75690]\n","Step 3547    [1.697 sec/step, loss=0.78856, avg_loss=0.75693]\n","Step 3548    [1.707 sec/step, loss=0.80126, avg_loss=0.75717]\n","Step 3549    [1.694 sec/step, loss=0.75010, avg_loss=0.75706]\n","Step 3550    [1.701 sec/step, loss=0.77280, avg_loss=0.75760]\n","Step 3551    [1.700 sec/step, loss=0.78649, avg_loss=0.75769]\n","Step 3552    [1.699 sec/step, loss=0.76099, avg_loss=0.75765]\n","Step 3553    [1.687 sec/step, loss=0.75181, avg_loss=0.75716]\n","Step 3554    [1.698 sec/step, loss=0.79115, avg_loss=0.75747]\n","Step 3555    [1.695 sec/step, loss=0.76284, avg_loss=0.75747]\n","Step 3556    [1.698 sec/step, loss=0.77027, avg_loss=0.75754]\n","Step 3557    [1.707 sec/step, loss=0.79845, avg_loss=0.75793]\n","Step 3558    [1.717 sec/step, loss=0.77911, avg_loss=0.75838]\n","Step 3559    [1.712 sec/step, loss=0.75535, avg_loss=0.75799]\n","Step 3560    [1.708 sec/step, loss=0.74932, avg_loss=0.75794]\n","Step 3561    [1.702 sec/step, loss=0.77775, avg_loss=0.75776]\n","Step 3562    [1.708 sec/step, loss=0.77960, avg_loss=0.75783]\n","Step 3563    [1.688 sec/step, loss=0.75860, avg_loss=0.75737]\n","Step 3564    [1.681 sec/step, loss=0.77067, avg_loss=0.75734]\n","Step 3565    [1.691 sec/step, loss=0.78237, avg_loss=0.75742]\n","Step 3566    [1.696 sec/step, loss=0.70790, avg_loss=0.75687]\n","Step 3567    [1.716 sec/step, loss=0.77414, avg_loss=0.75675]\n","Step 3568    [1.723 sec/step, loss=0.72405, avg_loss=0.75646]\n","Step 3569    [1.737 sec/step, loss=0.73575, avg_loss=0.75610]\n","Generated 32 batches of size 32 in 10.624 sec\n","Step 3570    [1.739 sec/step, loss=0.74669, avg_loss=0.75628]\n","Step 3571    [1.739 sec/step, loss=0.73709, avg_loss=0.75599]\n","Step 3572    [1.651 sec/step, loss=0.76306, avg_loss=0.75718]\n","Step 3573    [1.687 sec/step, loss=0.67769, avg_loss=0.75653]\n","Step 3574    [1.686 sec/step, loss=0.77860, avg_loss=0.75672]\n","Step 3575    [1.687 sec/step, loss=0.73421, avg_loss=0.75687]\n","Step 3576    [1.688 sec/step, loss=0.70856, avg_loss=0.75650]\n","Step 3577    [1.703 sec/step, loss=0.75602, avg_loss=0.75628]\n","Step 3578    [1.702 sec/step, loss=0.76234, avg_loss=0.75621]\n","Step 3579    [1.693 sec/step, loss=0.74551, avg_loss=0.75587]\n","Step 3580    [1.690 sec/step, loss=0.74867, avg_loss=0.75601]\n","Step 3581    [1.691 sec/step, loss=0.71868, avg_loss=0.75596]\n","Step 3582    [1.694 sec/step, loss=0.76099, avg_loss=0.75613]\n","Step 3583    [1.694 sec/step, loss=0.73285, avg_loss=0.75601]\n","Step 3584    [1.687 sec/step, loss=0.75001, avg_loss=0.75570]\n","Step 3585    [1.668 sec/step, loss=0.74422, avg_loss=0.75545]\n","Step 3586    [1.669 sec/step, loss=0.74395, avg_loss=0.75530]\n","Step 3587    [1.671 sec/step, loss=0.75109, avg_loss=0.75509]\n","Step 3588    [1.677 sec/step, loss=0.76585, avg_loss=0.75521]\n","Step 3589    [1.678 sec/step, loss=0.75512, avg_loss=0.75538]\n","Step 3590    [1.683 sec/step, loss=0.77009, avg_loss=0.75550]\n","Step 3591    [1.682 sec/step, loss=0.77795, avg_loss=0.75531]\n","Step 3592    [1.683 sec/step, loss=0.73218, avg_loss=0.75537]\n","Step 3593    [1.684 sec/step, loss=0.77840, avg_loss=0.75547]\n","Step 3594    [1.671 sec/step, loss=0.71316, avg_loss=0.75477]\n","Step 3595    [1.689 sec/step, loss=0.75341, avg_loss=0.75526]\n","Step 3596    [1.730 sec/step, loss=0.65738, avg_loss=0.75424]\n","Step 3597    [1.730 sec/step, loss=0.77503, avg_loss=0.75444]\n","Step 3598    [1.733 sec/step, loss=0.73747, avg_loss=0.75401]\n","Step 3599    [1.742 sec/step, loss=0.73365, avg_loss=0.75398]\n","Step 3600    [1.747 sec/step, loss=0.75718, avg_loss=0.75393]\n","Writing summary at step: 3600\n","Step 3601    [1.755 sec/step, loss=0.75631, avg_loss=0.75378]\n","Generated 32 batches of size 32 in 10.998 sec\n","Step 3602    [1.768 sec/step, loss=0.78259, avg_loss=0.75420]\n","Step 3603    [1.757 sec/step, loss=0.77934, avg_loss=0.75440]\n","Step 3604    [1.684 sec/step, loss=0.69752, avg_loss=0.75486]\n","Step 3605    [1.695 sec/step, loss=0.76194, avg_loss=0.75513]\n","Step 3606    [1.698 sec/step, loss=0.76572, avg_loss=0.75470]\n","Step 3607    [1.702 sec/step, loss=0.76974, avg_loss=0.75462]\n","Step 3608    [1.703 sec/step, loss=0.75260, avg_loss=0.75456]\n","Step 3609    [1.706 sec/step, loss=0.77851, avg_loss=0.75496]\n","Step 3610    [1.712 sec/step, loss=0.76782, avg_loss=0.75509]\n","Step 3611    [1.712 sec/step, loss=0.75696, avg_loss=0.75514]\n","Step 3612    [1.715 sec/step, loss=0.77017, avg_loss=0.75521]\n","Step 3613    [1.752 sec/step, loss=0.65818, avg_loss=0.75429]\n","Step 3614    [1.751 sec/step, loss=0.71255, avg_loss=0.75429]\n","Step 3615    [1.755 sec/step, loss=0.77370, avg_loss=0.75437]\n","Step 3616    [1.740 sec/step, loss=0.71379, avg_loss=0.75373]\n","Step 3617    [1.736 sec/step, loss=0.73330, avg_loss=0.75384]\n","Step 3618    [1.705 sec/step, loss=0.75388, avg_loss=0.75471]\n","Step 3619    [1.715 sec/step, loss=0.75766, avg_loss=0.75448]\n","Step 3620    [1.721 sec/step, loss=0.76396, avg_loss=0.75447]\n","Step 3621    [1.719 sec/step, loss=0.77275, avg_loss=0.75461]\n","Step 3622    [1.717 sec/step, loss=0.75757, avg_loss=0.75466]\n","Step 3623    [1.715 sec/step, loss=0.77860, avg_loss=0.75487]\n","Step 3624    [1.719 sec/step, loss=0.78677, avg_loss=0.75558]\n","Step 3625    [1.719 sec/step, loss=0.72100, avg_loss=0.75545]\n","Step 3626    [1.713 sec/step, loss=0.75386, avg_loss=0.75521]\n","Step 3627    [1.703 sec/step, loss=0.74680, avg_loss=0.75507]\n","Step 3628    [1.704 sec/step, loss=0.73662, avg_loss=0.75518]\n","Step 3629    [1.701 sec/step, loss=0.73246, avg_loss=0.75500]\n","Step 3630    [1.733 sec/step, loss=0.79156, avg_loss=0.75536]\n","Generated 32 batches of size 32 in 10.231 sec\n","Step 3631    [1.755 sec/step, loss=0.75260, avg_loss=0.75541]\n","Step 3632    [1.759 sec/step, loss=0.76252, avg_loss=0.75519]\n","Step 3633    [1.755 sec/step, loss=0.76731, avg_loss=0.75518]\n","Step 3634    [1.750 sec/step, loss=0.77481, avg_loss=0.75577]\n","Step 3635    [1.713 sec/step, loss=0.74097, avg_loss=0.75522]\n","Step 3636    [1.701 sec/step, loss=0.75466, avg_loss=0.75489]\n","Step 3637    [1.690 sec/step, loss=0.75108, avg_loss=0.75451]\n","Step 3638    [1.687 sec/step, loss=0.73107, avg_loss=0.75375]\n","Step 3639    [1.688 sec/step, loss=0.73425, avg_loss=0.75388]\n","Step 3640    [1.687 sec/step, loss=0.72672, avg_loss=0.75369]\n","Step 3641    [1.687 sec/step, loss=0.72331, avg_loss=0.75324]\n","Step 3642    [1.683 sec/step, loss=0.75547, avg_loss=0.75295]\n","Step 3643    [1.689 sec/step, loss=0.76959, avg_loss=0.75300]\n","Step 3644    [1.688 sec/step, loss=0.75222, avg_loss=0.75286]\n","Step 3645    [1.691 sec/step, loss=0.78579, avg_loss=0.75300]\n","Step 3646    [1.698 sec/step, loss=0.76695, avg_loss=0.75330]\n","Step 3647    [1.695 sec/step, loss=0.75711, avg_loss=0.75299]\n","Step 3648    [1.721 sec/step, loss=0.64711, avg_loss=0.75144]\n","Step 3649    [1.728 sec/step, loss=0.78939, avg_loss=0.75184]\n","Step 3650    [1.724 sec/step, loss=0.74197, avg_loss=0.75153]\n","Step 3651    [1.721 sec/step, loss=0.71475, avg_loss=0.75081]\n","Step 3652    [1.722 sec/step, loss=0.73408, avg_loss=0.75054]\n","Step 3653    [1.720 sec/step, loss=0.74023, avg_loss=0.75043]\n","Step 3654    [1.702 sec/step, loss=0.75710, avg_loss=0.75009]\n","Step 3655    [1.715 sec/step, loss=0.76403, avg_loss=0.75010]\n","Step 3656    [1.713 sec/step, loss=0.74468, avg_loss=0.74984]\n","Step 3657    [1.707 sec/step, loss=0.75611, avg_loss=0.74942]\n","Step 3658    [1.703 sec/step, loss=0.75307, avg_loss=0.74916]\n","Step 3659    [1.702 sec/step, loss=0.72465, avg_loss=0.74885]\n","Step 3660    [1.710 sec/step, loss=0.75715, avg_loss=0.74893]\n","Step 3661    [1.739 sec/step, loss=0.76581, avg_loss=0.74881]\n","Step 3662    [1.751 sec/step, loss=0.74726, avg_loss=0.74849]\n","Step 3663    [1.755 sec/step, loss=0.71046, avg_loss=0.74801]\n","Step 3664    [1.757 sec/step, loss=0.73525, avg_loss=0.74765]\n","Generated 32 batches of size 32 in 10.725 sec\n","Step 3665    [1.751 sec/step, loss=0.77182, avg_loss=0.74755]\n","Step 3666    [1.749 sec/step, loss=0.75709, avg_loss=0.74804]\n","Step 3667    [1.737 sec/step, loss=0.75560, avg_loss=0.74785]\n","Step 3668    [1.728 sec/step, loss=0.72089, avg_loss=0.74782]\n","Step 3669    [1.711 sec/step, loss=0.75614, avg_loss=0.74802]\n","Step 3670    [1.711 sec/step, loss=0.75146, avg_loss=0.74807]\n","Step 3671    [1.732 sec/step, loss=0.78353, avg_loss=0.74854]\n","Step 3672    [1.735 sec/step, loss=0.75762, avg_loss=0.74848]\n","Step 3673    [1.729 sec/step, loss=0.68810, avg_loss=0.74859]\n","Step 3674    [1.727 sec/step, loss=0.74235, avg_loss=0.74822]\n","Step 3675    [1.738 sec/step, loss=0.75787, avg_loss=0.74846]\n","Step 3676    [1.739 sec/step, loss=0.73665, avg_loss=0.74874]\n","Step 3677    [1.721 sec/step, loss=0.73640, avg_loss=0.74854]\n","Step 3678    [1.720 sec/step, loss=0.73810, avg_loss=0.74830]\n","Step 3679    [1.724 sec/step, loss=0.75746, avg_loss=0.74842]\n","Step 3680    [1.724 sec/step, loss=0.73363, avg_loss=0.74827]\n","Step 3681    [1.722 sec/step, loss=0.69687, avg_loss=0.74805]\n","Step 3682    [1.722 sec/step, loss=0.75460, avg_loss=0.74799]\n","Step 3683    [1.731 sec/step, loss=0.78810, avg_loss=0.74854]\n","Step 3684    [1.730 sec/step, loss=0.74045, avg_loss=0.74845]\n","Step 3685    [1.746 sec/step, loss=0.76871, avg_loss=0.74869]\n","Step 3686    [1.742 sec/step, loss=0.75070, avg_loss=0.74876]\n","Step 3687    [1.736 sec/step, loss=0.71430, avg_loss=0.74839]\n","Step 3688    [1.725 sec/step, loss=0.72930, avg_loss=0.74803]\n","Step 3689    [1.729 sec/step, loss=0.77532, avg_loss=0.74823]\n","Step 3690    [1.722 sec/step, loss=0.73553, avg_loss=0.74788]\n","Step 3691    [1.718 sec/step, loss=0.76222, avg_loss=0.74772]\n","Step 3692    [1.720 sec/step, loss=0.74657, avg_loss=0.74787]\n","Step 3693    [1.730 sec/step, loss=0.77258, avg_loss=0.74781]\n","Step 3694    [1.747 sec/step, loss=0.75105, avg_loss=0.74819]\n","Step 3695    [1.754 sec/step, loss=0.78179, avg_loss=0.74847]\n","Generated 32 batches of size 32 in 11.006 sec\n","Step 3696    [1.731 sec/step, loss=0.76511, avg_loss=0.74955]\n","Step 3697    [1.726 sec/step, loss=0.74041, avg_loss=0.74920]\n","Step 3698    [1.723 sec/step, loss=0.77072, avg_loss=0.74954]\n","Step 3699    [1.715 sec/step, loss=0.71757, avg_loss=0.74938]\n","Step 3700    [1.709 sec/step, loss=0.75292, avg_loss=0.74933]\n","Writing summary at step: 3700\n","Step 3701    [1.693 sec/step, loss=0.73788, avg_loss=0.74915]\n","Step 3702    [1.686 sec/step, loss=0.76432, avg_loss=0.74897]\n","Step 3703    [1.681 sec/step, loss=0.73352, avg_loss=0.74851]\n","Step 3704    [1.704 sec/step, loss=0.79192, avg_loss=0.74945]\n","Step 3705    [1.696 sec/step, loss=0.75014, avg_loss=0.74933]\n","Step 3706    [1.696 sec/step, loss=0.76261, avg_loss=0.74930]\n","Step 3707    [1.693 sec/step, loss=0.75092, avg_loss=0.74911]\n","Step 3708    [1.703 sec/step, loss=0.73352, avg_loss=0.74892]\n","Step 3709    [1.737 sec/step, loss=0.65865, avg_loss=0.74773]\n","Step 3710    [1.731 sec/step, loss=0.74770, avg_loss=0.74752]\n","Step 3711    [1.730 sec/step, loss=0.78219, avg_loss=0.74778]\n","Step 3712    [1.726 sec/step, loss=0.76783, avg_loss=0.74775]\n","Step 3713    [1.686 sec/step, loss=0.72291, avg_loss=0.74840]\n","Step 3714    [1.690 sec/step, loss=0.74998, avg_loss=0.74877]\n","Step 3715    [1.687 sec/step, loss=0.73778, avg_loss=0.74842]\n","Step 3716    [1.697 sec/step, loss=0.75865, avg_loss=0.74886]\n","Step 3717    [1.705 sec/step, loss=0.76008, avg_loss=0.74913]\n","Step 3718    [1.701 sec/step, loss=0.72464, avg_loss=0.74884]\n","Step 3719    [1.692 sec/step, loss=0.75990, avg_loss=0.74886]\n","Step 3720    [1.687 sec/step, loss=0.71630, avg_loss=0.74839]\n","Step 3721    [1.687 sec/step, loss=0.76465, avg_loss=0.74830]\n","Step 3722    [1.686 sec/step, loss=0.73741, avg_loss=0.74810]\n","Step 3723    [1.686 sec/step, loss=0.76969, avg_loss=0.74801]\n","Step 3724    [1.701 sec/step, loss=0.75888, avg_loss=0.74773]\n","Step 3725    [1.715 sec/step, loss=0.74936, avg_loss=0.74802]\n","Step 3726    [1.734 sec/step, loss=0.79162, avg_loss=0.74840]\n","Step 3727    [1.744 sec/step, loss=0.74882, avg_loss=0.74842]\n","Generated 32 batches of size 32 in 10.704 sec\n","Step 3728    [1.746 sec/step, loss=0.73723, avg_loss=0.74842]\n","Step 3729    [1.730 sec/step, loss=0.70521, avg_loss=0.74815]\n","Step 3730    [1.697 sec/step, loss=0.76403, avg_loss=0.74787]\n","Step 3731    [1.674 sec/step, loss=0.69602, avg_loss=0.74731]\n","Step 3732    [1.663 sec/step, loss=0.74478, avg_loss=0.74713]\n","Step 3733    [1.664 sec/step, loss=0.73359, avg_loss=0.74679]\n","Step 3734    [1.665 sec/step, loss=0.78320, avg_loss=0.74688]\n","Step 3735    [1.665 sec/step, loss=0.74283, avg_loss=0.74690]\n","Step 3736    [1.663 sec/step, loss=0.73547, avg_loss=0.74670]\n","Step 3737    [1.665 sec/step, loss=0.71392, avg_loss=0.74633]\n","Step 3738    [1.665 sec/step, loss=0.73586, avg_loss=0.74638]\n","Step 3739    [1.667 sec/step, loss=0.78616, avg_loss=0.74690]\n","Step 3740    [1.677 sec/step, loss=0.76539, avg_loss=0.74729]\n","Step 3741    [1.685 sec/step, loss=0.78610, avg_loss=0.74791]\n","Step 3742    [1.720 sec/step, loss=0.63942, avg_loss=0.74675]\n","Step 3743    [1.717 sec/step, loss=0.75389, avg_loss=0.74660]\n","Step 3744    [1.714 sec/step, loss=0.72815, avg_loss=0.74636]\n","Step 3745    [1.712 sec/step, loss=0.77584, avg_loss=0.74626]\n","Step 3746    [1.708 sec/step, loss=0.72450, avg_loss=0.74583]\n","Step 3747    [1.701 sec/step, loss=0.69791, avg_loss=0.74524]\n","Step 3748    [1.662 sec/step, loss=0.71331, avg_loss=0.74590]\n","Step 3749    [1.652 sec/step, loss=0.74333, avg_loss=0.74544]\n","Step 3750    [1.658 sec/step, loss=0.78617, avg_loss=0.74588]\n","Step 3751    [1.669 sec/step, loss=0.79446, avg_loss=0.74668]\n","Step 3752    [1.670 sec/step, loss=0.77639, avg_loss=0.74710]\n","Step 3753    [1.677 sec/step, loss=0.76567, avg_loss=0.74736]\n","Step 3754    [1.680 sec/step, loss=0.76104, avg_loss=0.74740]\n","Step 3755    [1.666 sec/step, loss=0.73108, avg_loss=0.74707]\n","Step 3756    [1.700 sec/step, loss=0.75776, avg_loss=0.74720]\n","Step 3757    [1.708 sec/step, loss=0.76696, avg_loss=0.74731]\n","Step 3758    [1.714 sec/step, loss=0.73780, avg_loss=0.74715]\n","Generated 32 batches of size 32 in 10.896 sec\n","Step 3759    [1.726 sec/step, loss=0.76873, avg_loss=0.74760]\n","Step 3760    [1.722 sec/step, loss=0.74475, avg_loss=0.74747]\n","Step 3761    [1.704 sec/step, loss=0.77842, avg_loss=0.74760]\n","Step 3762    [1.692 sec/step, loss=0.76642, avg_loss=0.74779]\n","Step 3763    [1.691 sec/step, loss=0.75949, avg_loss=0.74828]\n","Step 3764    [1.694 sec/step, loss=0.75071, avg_loss=0.74843]\n","Step 3765    [1.688 sec/step, loss=0.76721, avg_loss=0.74839]\n","Step 3766    [1.683 sec/step, loss=0.72147, avg_loss=0.74803]\n","Step 3767    [1.675 sec/step, loss=0.77100, avg_loss=0.74819]\n","Step 3768    [1.697 sec/step, loss=0.77490, avg_loss=0.74873]\n","Step 3769    [1.705 sec/step, loss=0.75797, avg_loss=0.74874]\n","Step 3770    [1.703 sec/step, loss=0.72802, avg_loss=0.74851]\n","Step 3771    [1.679 sec/step, loss=0.71620, avg_loss=0.74784]\n","Step 3772    [1.681 sec/step, loss=0.73900, avg_loss=0.74765]\n","Step 3773    [1.651 sec/step, loss=0.78010, avg_loss=0.74857]\n","Step 3774    [1.651 sec/step, loss=0.75275, avg_loss=0.74867]\n","Step 3775    [1.651 sec/step, loss=0.75657, avg_loss=0.74866]\n","Step 3776    [1.649 sec/step, loss=0.73840, avg_loss=0.74868]\n","Step 3777    [1.646 sec/step, loss=0.75408, avg_loss=0.74886]\n","Step 3778    [1.647 sec/step, loss=0.75006, avg_loss=0.74898]\n","Step 3779    [1.645 sec/step, loss=0.73000, avg_loss=0.74870]\n","Step 3780    [1.647 sec/step, loss=0.74526, avg_loss=0.74882]\n","Step 3781    [1.656 sec/step, loss=0.75813, avg_loss=0.74943]\n","Step 3782    [1.658 sec/step, loss=0.75754, avg_loss=0.74946]\n","Step 3783    [1.645 sec/step, loss=0.69965, avg_loss=0.74857]\n","Step 3784    [1.647 sec/step, loss=0.73942, avg_loss=0.74856]\n","Step 3785    [1.632 sec/step, loss=0.72314, avg_loss=0.74811]\n","Step 3786    [1.632 sec/step, loss=0.71272, avg_loss=0.74773]\n","Step 3787    [1.644 sec/step, loss=0.78086, avg_loss=0.74839]\n","Step 3788    [1.661 sec/step, loss=0.75019, avg_loss=0.74860]\n","Step 3789    [1.675 sec/step, loss=0.74705, avg_loss=0.74832]\n","Step 3790    [1.712 sec/step, loss=0.77960, avg_loss=0.74876]\n","Generated 32 batches of size 32 in 10.421 sec\n","Step 3791    [1.709 sec/step, loss=0.70201, avg_loss=0.74816]\n","Step 3792    [1.712 sec/step, loss=0.75571, avg_loss=0.74825]\n","Step 3793    [1.695 sec/step, loss=0.72242, avg_loss=0.74775]\n","Step 3794    [1.681 sec/step, loss=0.73649, avg_loss=0.74760]\n","Step 3795    [1.698 sec/step, loss=0.63637, avg_loss=0.74615]\n","Step 3796    [1.679 sec/step, loss=0.72842, avg_loss=0.74578]\n","Step 3797    [1.679 sec/step, loss=0.69552, avg_loss=0.74533]\n","Step 3798    [1.674 sec/step, loss=0.73769, avg_loss=0.74500]\n","Step 3799    [1.674 sec/step, loss=0.69836, avg_loss=0.74481]\n","Step 3800    [1.672 sec/step, loss=0.74435, avg_loss=0.74472]\n","Writing summary at step: 3800\n","Step 3801    [1.677 sec/step, loss=0.75571, avg_loss=0.74490]\n","Step 3802    [1.688 sec/step, loss=0.79011, avg_loss=0.74516]\n","Step 3803    [1.695 sec/step, loss=0.76240, avg_loss=0.74545]\n","Step 3804    [1.677 sec/step, loss=0.74193, avg_loss=0.74495]\n","Step 3805    [1.682 sec/step, loss=0.78330, avg_loss=0.74528]\n","Step 3806    [1.712 sec/step, loss=0.64859, avg_loss=0.74414]\n","Step 3807    [1.708 sec/step, loss=0.72033, avg_loss=0.74384]\n","Step 3808    [1.696 sec/step, loss=0.70611, avg_loss=0.74356]\n","Step 3809    [1.659 sec/step, loss=0.72014, avg_loss=0.74418]\n","Step 3810    [1.658 sec/step, loss=0.71613, avg_loss=0.74386]\n","Step 3811    [1.654 sec/step, loss=0.75468, avg_loss=0.74359]\n","Step 3812    [1.651 sec/step, loss=0.73380, avg_loss=0.74325]\n","Step 3813    [1.651 sec/step, loss=0.73782, avg_loss=0.74339]\n","Step 3814    [1.660 sec/step, loss=0.75777, avg_loss=0.74347]\n","Step 3815    [1.662 sec/step, loss=0.76520, avg_loss=0.74375]\n","Step 3816    [1.653 sec/step, loss=0.67816, avg_loss=0.74294]\n","Step 3817    [1.651 sec/step, loss=0.74210, avg_loss=0.74276]\n","Step 3818    [1.652 sec/step, loss=0.73692, avg_loss=0.74288]\n","Step 3819    [1.660 sec/step, loss=0.73172, avg_loss=0.74260]\n","Step 3820    [1.669 sec/step, loss=0.71162, avg_loss=0.74256]\n","Step 3821    [1.686 sec/step, loss=0.75273, avg_loss=0.74244]\n","Generated 32 batches of size 32 in 10.561 sec\n","Step 3822    [1.714 sec/step, loss=0.75235, avg_loss=0.74259]\n","Step 3823    [1.719 sec/step, loss=0.76578, avg_loss=0.74255]\n","Step 3824    [1.700 sec/step, loss=0.71597, avg_loss=0.74212]\n","Step 3825    [1.694 sec/step, loss=0.73101, avg_loss=0.74193]\n","Step 3826    [1.672 sec/step, loss=0.74502, avg_loss=0.74147]\n","Step 3827    [1.665 sec/step, loss=0.72761, avg_loss=0.74126]\n","Step 3828    [1.670 sec/step, loss=0.76912, avg_loss=0.74158]\n","Step 3829    [1.672 sec/step, loss=0.69992, avg_loss=0.74152]\n","Step 3830    [1.679 sec/step, loss=0.76400, avg_loss=0.74152]\n","Step 3831    [1.681 sec/step, loss=0.70431, avg_loss=0.74160]\n","Step 3832    [1.684 sec/step, loss=0.74890, avg_loss=0.74165]\n","Step 3833    [1.687 sec/step, loss=0.73035, avg_loss=0.74161]\n","Step 3834    [1.688 sec/step, loss=0.75608, avg_loss=0.74134]\n","Step 3835    [1.694 sec/step, loss=0.76806, avg_loss=0.74159]\n","Step 3836    [1.699 sec/step, loss=0.74977, avg_loss=0.74174]\n","Step 3837    [1.701 sec/step, loss=0.76499, avg_loss=0.74225]\n","Step 3838    [1.701 sec/step, loss=0.71996, avg_loss=0.74209]\n","Step 3839    [1.700 sec/step, loss=0.74585, avg_loss=0.74169]\n","Step 3840    [1.702 sec/step, loss=0.74710, avg_loss=0.74150]\n","Step 3841    [1.697 sec/step, loss=0.73874, avg_loss=0.74103]\n","Step 3842    [1.660 sec/step, loss=0.76280, avg_loss=0.74226]\n","Step 3843    [1.655 sec/step, loss=0.70601, avg_loss=0.74178]\n","Step 3844    [1.662 sec/step, loss=0.77511, avg_loss=0.74225]\n","Step 3845    [1.655 sec/step, loss=0.68639, avg_loss=0.74136]\n","Step 3846    [1.666 sec/step, loss=0.76646, avg_loss=0.74178]\n","Step 3847    [1.667 sec/step, loss=0.72675, avg_loss=0.74207]\n","Step 3848    [1.671 sec/step, loss=0.74349, avg_loss=0.74237]\n","Step 3849    [1.673 sec/step, loss=0.74007, avg_loss=0.74234]\n","Step 3850    [1.667 sec/step, loss=0.74011, avg_loss=0.74188]\n","Step 3851    [1.667 sec/step, loss=0.71704, avg_loss=0.74110]\n","Step 3852    [1.681 sec/step, loss=0.76272, avg_loss=0.74097]\n","Generated 32 batches of size 32 in 10.273 sec\n","Step 3853    [1.720 sec/step, loss=0.76969, avg_loss=0.74101]\n","Step 3854    [1.714 sec/step, loss=0.73424, avg_loss=0.74074]\n","Step 3855    [1.719 sec/step, loss=0.73982, avg_loss=0.74083]\n","Step 3856    [1.682 sec/step, loss=0.74005, avg_loss=0.74065]\n","Step 3857    [1.704 sec/step, loss=0.67444, avg_loss=0.73972]\n","Step 3858    [1.701 sec/step, loss=0.76711, avg_loss=0.74002]\n","Step 3859    [1.698 sec/step, loss=0.79414, avg_loss=0.74027]\n","Step 3860    [1.693 sec/step, loss=0.70287, avg_loss=0.73985]\n","Step 3861    [1.680 sec/step, loss=0.74571, avg_loss=0.73952]\n","Step 3862    [1.680 sec/step, loss=0.77367, avg_loss=0.73960]\n","Step 3863    [1.680 sec/step, loss=0.73695, avg_loss=0.73937]\n","Step 3864    [1.673 sec/step, loss=0.72293, avg_loss=0.73909]\n","Step 3865    [1.674 sec/step, loss=0.76703, avg_loss=0.73909]\n","Step 3866    [1.695 sec/step, loss=0.76988, avg_loss=0.73958]\n","Step 3867    [1.694 sec/step, loss=0.78152, avg_loss=0.73968]\n","Step 3868    [1.673 sec/step, loss=0.72599, avg_loss=0.73919]\n","Step 3869    [1.667 sec/step, loss=0.72954, avg_loss=0.73891]\n","Step 3870    [1.676 sec/step, loss=0.76132, avg_loss=0.73924]\n","Step 3871    [1.682 sec/step, loss=0.73054, avg_loss=0.73938]\n","Step 3872    [1.680 sec/step, loss=0.71662, avg_loss=0.73916]\n","Step 3873    [1.682 sec/step, loss=0.75809, avg_loss=0.73894]\n","Step 3874    [1.682 sec/step, loss=0.74897, avg_loss=0.73890]\n","Step 3875    [1.674 sec/step, loss=0.73985, avg_loss=0.73874]\n","Step 3876    [1.686 sec/step, loss=0.77691, avg_loss=0.73912]\n","Step 3877    [1.685 sec/step, loss=0.73949, avg_loss=0.73897]\n","Step 3878    [1.688 sec/step, loss=0.74527, avg_loss=0.73893]\n","Step 3879    [1.702 sec/step, loss=0.75224, avg_loss=0.73915]\n","Step 3880    [1.700 sec/step, loss=0.72016, avg_loss=0.73890]\n","Step 3881    [1.701 sec/step, loss=0.75021, avg_loss=0.73882]\n","Step 3882    [1.695 sec/step, loss=0.74561, avg_loss=0.73870]\n","Step 3883    [1.710 sec/step, loss=0.75243, avg_loss=0.73923]\n","Generated 32 batches of size 32 in 10.515 sec\n","Step 3884    [1.788 sec/step, loss=0.65392, avg_loss=0.73837]\n","Step 3885    [1.790 sec/step, loss=0.74993, avg_loss=0.73864]\n","Step 3886    [1.791 sec/step, loss=0.71470, avg_loss=0.73866]\n","Step 3887    [1.784 sec/step, loss=0.73394, avg_loss=0.73819]\n","Step 3888    [1.769 sec/step, loss=0.73137, avg_loss=0.73800]\n","Step 3889    [1.748 sec/step, loss=0.71023, avg_loss=0.73763]\n","Step 3890    [1.720 sec/step, loss=0.75100, avg_loss=0.73735]\n","Step 3891    [1.725 sec/step, loss=0.75711, avg_loss=0.73790]\n","Step 3892    [1.726 sec/step, loss=0.74526, avg_loss=0.73779]\n","Step 3893    [1.730 sec/step, loss=0.74424, avg_loss=0.73801]\n","Step 3894    [1.734 sec/step, loss=0.75083, avg_loss=0.73816]\n","Step 3895    [1.701 sec/step, loss=0.73325, avg_loss=0.73913]\n","Step 3896    [1.704 sec/step, loss=0.72100, avg_loss=0.73905]\n","Step 3897    [1.711 sec/step, loss=0.78041, avg_loss=0.73990]\n","Step 3898    [1.710 sec/step, loss=0.72653, avg_loss=0.73979]\n","Step 3899    [1.709 sec/step, loss=0.69832, avg_loss=0.73979]\n","Step 3900    [1.708 sec/step, loss=0.73550, avg_loss=0.73970]\n","Writing summary at step: 3900\n","Step 3901    [1.705 sec/step, loss=0.71661, avg_loss=0.73931]\n","Step 3902    [1.685 sec/step, loss=0.68907, avg_loss=0.73830]\n","Step 3903    [1.684 sec/step, loss=0.77750, avg_loss=0.73845]\n","Step 3904    [1.688 sec/step, loss=0.73943, avg_loss=0.73842]\n","Step 3905    [1.684 sec/step, loss=0.74315, avg_loss=0.73802]\n","Step 3906    [1.644 sec/step, loss=0.68150, avg_loss=0.73835]\n","Step 3907    [1.651 sec/step, loss=0.73700, avg_loss=0.73852]\n","Step 3908    [1.653 sec/step, loss=0.74484, avg_loss=0.73891]\n","Step 3909    [1.656 sec/step, loss=0.73755, avg_loss=0.73908]\n","Step 3910    [1.654 sec/step, loss=0.72098, avg_loss=0.73913]\n","Step 3911    [1.651 sec/step, loss=0.70339, avg_loss=0.73862]\n","Step 3912    [1.686 sec/step, loss=0.69980, avg_loss=0.73828]\n","Step 3913    [1.687 sec/step, loss=0.72431, avg_loss=0.73814]\n","Step 3914    [1.688 sec/step, loss=0.71874, avg_loss=0.73775]\n","Step 3915    [1.687 sec/step, loss=0.71401, avg_loss=0.73724]\n","Step 3916    [1.732 sec/step, loss=0.75762, avg_loss=0.73803]\n","Generated 32 batches of size 32 in 10.517 sec\n","Step 3917    [1.737 sec/step, loss=0.73552, avg_loss=0.73797]\n","Step 3918    [1.738 sec/step, loss=0.73434, avg_loss=0.73794]\n","Step 3919    [1.740 sec/step, loss=0.74633, avg_loss=0.73809]\n","Step 3920    [1.735 sec/step, loss=0.72029, avg_loss=0.73817]\n","Step 3921    [1.719 sec/step, loss=0.75361, avg_loss=0.73818]\n","Step 3922    [1.702 sec/step, loss=0.75738, avg_loss=0.73823]\n","Step 3923    [1.694 sec/step, loss=0.68609, avg_loss=0.73744]\n","Step 3924    [1.694 sec/step, loss=0.73315, avg_loss=0.73761]\n","Step 3925    [1.691 sec/step, loss=0.73826, avg_loss=0.73768]\n","Step 3926    [1.700 sec/step, loss=0.74826, avg_loss=0.73771]\n","Step 3927    [1.697 sec/step, loss=0.73053, avg_loss=0.73774]\n","Step 3928    [1.695 sec/step, loss=0.75810, avg_loss=0.73763]\n","Step 3929    [1.705 sec/step, loss=0.76288, avg_loss=0.73826]\n","Step 3930    [1.694 sec/step, loss=0.73662, avg_loss=0.73799]\n","Step 3931    [1.696 sec/step, loss=0.70868, avg_loss=0.73803]\n","Step 3932    [1.699 sec/step, loss=0.73328, avg_loss=0.73788]\n","Step 3933    [1.702 sec/step, loss=0.73945, avg_loss=0.73797]\n","Step 3934    [1.701 sec/step, loss=0.73841, avg_loss=0.73779]\n","Step 3935    [1.691 sec/step, loss=0.69453, avg_loss=0.73705]\n","Step 3936    [1.684 sec/step, loss=0.72860, avg_loss=0.73684]\n","Step 3937    [1.695 sec/step, loss=0.76447, avg_loss=0.73684]\n","Step 3938    [1.737 sec/step, loss=0.66006, avg_loss=0.73624]\n","Step 3939    [1.742 sec/step, loss=0.75375, avg_loss=0.73632]\n","Step 3940    [1.732 sec/step, loss=0.74573, avg_loss=0.73630]\n","Step 3941    [1.734 sec/step, loss=0.73549, avg_loss=0.73627]\n","Step 3942    [1.750 sec/step, loss=0.76027, avg_loss=0.73625]\n","Step 3943    [1.756 sec/step, loss=0.74747, avg_loss=0.73666]\n","Step 3944    [1.753 sec/step, loss=0.75493, avg_loss=0.73646]\n","Step 3945    [1.752 sec/step, loss=0.69367, avg_loss=0.73653]\n","Step 3946    [1.752 sec/step, loss=0.75315, avg_loss=0.73640]\n","Step 3947    [1.757 sec/step, loss=0.72425, avg_loss=0.73637]\n","Step 3948    [1.777 sec/step, loss=0.71551, avg_loss=0.73609]\n","Step 3949    [1.779 sec/step, loss=0.72184, avg_loss=0.73591]\n","Generated 32 batches of size 32 in 10.924 sec\n","Step 3950    [1.801 sec/step, loss=0.77803, avg_loss=0.73629]\n","Step 3951    [1.797 sec/step, loss=0.74978, avg_loss=0.73662]\n","Step 3952    [1.778 sec/step, loss=0.71576, avg_loss=0.73615]\n","Step 3953    [1.738 sec/step, loss=0.75144, avg_loss=0.73597]\n","Step 3954    [1.742 sec/step, loss=0.73294, avg_loss=0.73595]\n","Step 3955    [1.738 sec/step, loss=0.68934, avg_loss=0.73545]\n","Step 3956    [1.740 sec/step, loss=0.73123, avg_loss=0.73536]\n","Step 3957    [1.713 sec/step, loss=0.74610, avg_loss=0.73608]\n","Step 3958    [1.715 sec/step, loss=0.76094, avg_loss=0.73601]\n","Step 3959    [1.708 sec/step, loss=0.71147, avg_loss=0.73519]\n","Step 3960    [1.711 sec/step, loss=0.68652, avg_loss=0.73502]\n","Step 3961    [1.716 sec/step, loss=0.75883, avg_loss=0.73516]\n","Step 3962    [1.710 sec/step, loss=0.72571, avg_loss=0.73468]\n","Step 3963    [1.708 sec/step, loss=0.70500, avg_loss=0.73436]\n","Step 3964    [1.715 sec/step, loss=0.74408, avg_loss=0.73457]\n","Step 3965    [1.747 sec/step, loss=0.60418, avg_loss=0.73294]\n","Step 3966    [1.735 sec/step, loss=0.75416, avg_loss=0.73278]\n","Step 3967    [1.730 sec/step, loss=0.71336, avg_loss=0.73210]\n","Step 3968    [1.735 sec/step, loss=0.72214, avg_loss=0.73206]\n","Step 3969    [1.735 sec/step, loss=0.70764, avg_loss=0.73184]\n","Step 3970    [1.730 sec/step, loss=0.71485, avg_loss=0.73138]\n","Step 3971    [1.731 sec/step, loss=0.75332, avg_loss=0.73161]\n","Step 3972    [1.733 sec/step, loss=0.72987, avg_loss=0.73174]\n","Step 3973    [1.726 sec/step, loss=0.73529, avg_loss=0.73151]\n","Step 3974    [1.742 sec/step, loss=0.75977, avg_loss=0.73162]\n","Step 3975    [1.739 sec/step, loss=0.71555, avg_loss=0.73138]\n","Step 3976    [1.739 sec/step, loss=0.74578, avg_loss=0.73106]\n","Step 3977    [1.747 sec/step, loss=0.74017, avg_loss=0.73107]\n","Step 3978    [1.746 sec/step, loss=0.69982, avg_loss=0.73062]\n","Step 3979    [1.745 sec/step, loss=0.75733, avg_loss=0.73067]\n","Step 3980    [1.756 sec/step, loss=0.72712, avg_loss=0.73074]\n","Step 3981    [1.774 sec/step, loss=0.77356, avg_loss=0.73097]\n","Generated 32 batches of size 32 in 11.237 sec\n","Step 3982    [1.779 sec/step, loss=0.73823, avg_loss=0.73090]\n","Step 3983    [1.767 sec/step, loss=0.69779, avg_loss=0.73035]\n","Step 3984    [1.685 sec/step, loss=0.67779, avg_loss=0.73059]\n","Step 3985    [1.682 sec/step, loss=0.71258, avg_loss=0.73022]\n","Step 3986    [1.693 sec/step, loss=0.73857, avg_loss=0.73045]\n","Step 3987    [1.712 sec/step, loss=0.75482, avg_loss=0.73066]\n","Step 3988    [1.711 sec/step, loss=0.72485, avg_loss=0.73060]\n","Step 3989    [1.714 sec/step, loss=0.73700, avg_loss=0.73087]\n","Step 3990    [1.708 sec/step, loss=0.71273, avg_loss=0.73048]\n","Step 3991    [1.706 sec/step, loss=0.72695, avg_loss=0.73018]\n","Step 3992    [1.701 sec/step, loss=0.72323, avg_loss=0.72996]\n","Step 3993    [1.697 sec/step, loss=0.72046, avg_loss=0.72972]\n","Step 3994    [1.689 sec/step, loss=0.70487, avg_loss=0.72926]\n","Step 3995    [1.689 sec/step, loss=0.74301, avg_loss=0.72936]\n","Step 3996    [1.686 sec/step, loss=0.70378, avg_loss=0.72919]\n","Step 3997    [1.683 sec/step, loss=0.72203, avg_loss=0.72861]\n","Step 3998    [1.685 sec/step, loss=0.72288, avg_loss=0.72857]\n","Step 3999    [1.690 sec/step, loss=0.74610, avg_loss=0.72905]\n","Step 4000    [1.686 sec/step, loss=0.69769, avg_loss=0.72867]\n","Writing summary at step: 4000\n","Saving checkpoint to: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/model.ckpt-4000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Training korean : Use jamo\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44144 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48264 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47582 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50520 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45348 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44144 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48264 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47582 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50520 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45348 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/train-step-000004000-align000.png\n","100% 1/1 [00:02<00:00,  2.89s/it]\n","Test finished for step 4000.\n","  0% 0/2 [00:00<?, ?it/s]Training korean : Use jamo\n","/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab/tacotron2/utils/plot.py:28: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n","  fig, ax = plt.subplots(figsize=(char_len/5, 5))\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12615 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12631 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12596 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12641 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12601 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12628 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12627 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12621 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12623 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12643 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12614 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12613 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12610 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12636 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12599 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12616 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12593 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12622 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12635 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12609 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12624 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12629 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50724 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45720 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50640 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50612 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54532 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46972 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51060 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51080 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51004 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49888 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48516 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46308 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51008 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51228 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44032 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54620 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50836 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47532 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54632 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54644 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49436 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46300 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49492 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48372 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49464 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12615 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12631 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12596 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12641 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12601 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12628 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12627 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12621 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12623 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12643 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12614 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12613 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12610 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12636 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12599 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12616 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12593 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12622 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12635 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12609 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12624 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12629 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50724 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45720 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50640 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50612 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54532 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46972 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51060 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51080 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51004 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49888 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48516 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46308 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51008 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51228 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44032 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54620 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50836 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47532 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54632 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54644 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49436 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46300 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49492 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48372 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49464 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000004000-align000.png\n"," 50% 1/2 [00:07<00:07,  7.96s/it]Training korean : Use jamo\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12632 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12626 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12625 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12630 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12611 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44163 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48400 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50584 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45716 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49549 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45796 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51061 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50632 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44172 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47000 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50556 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44228 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46976 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48757 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51648 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12632 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12626 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12625 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12630 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12611 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44163 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48400 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50584 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45716 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49549 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45796 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51061 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50632 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44172 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47000 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50556 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44228 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46976 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48757 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51648 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000004000-align001.png\n","100% 2/2 [00:14<00:00,  7.38s/it]\n","Test finished for step 4000.\n","Step 4001    [1.695 sec/step, loss=0.73259, avg_loss=0.72883]\n","Step 4002    [1.732 sec/step, loss=0.63029, avg_loss=0.72824]\n","Step 4003    [1.725 sec/step, loss=0.69515, avg_loss=0.72742]\n","Step 4004    [1.724 sec/step, loss=0.75197, avg_loss=0.72754]\n","Step 4005    [1.720 sec/step, loss=0.68507, avg_loss=0.72696]\n","Step 4006    [1.729 sec/step, loss=0.76927, avg_loss=0.72784]\n","Step 4007    [1.726 sec/step, loss=0.74249, avg_loss=0.72789]\n","Step 4008    [1.743 sec/step, loss=0.74403, avg_loss=0.72789]\n","Step 4009    [1.752 sec/step, loss=0.72693, avg_loss=0.72778]\n","Step 4010    [1.787 sec/step, loss=0.74512, avg_loss=0.72802]\n","Generated 32 batches of size 32 in 10.577 sec\n","Step 4011    [1.803 sec/step, loss=0.73961, avg_loss=0.72838]\n","Step 4012    [1.772 sec/step, loss=0.71438, avg_loss=0.72853]\n","Step 4013    [1.772 sec/step, loss=0.69631, avg_loss=0.72825]\n","Step 4014    [1.765 sec/step, loss=0.74740, avg_loss=0.72854]\n","Step 4015    [1.759 sec/step, loss=0.70124, avg_loss=0.72841]\n","Step 4016    [1.722 sec/step, loss=0.73618, avg_loss=0.72819]\n","Step 4017    [1.723 sec/step, loss=0.74473, avg_loss=0.72829]\n","Step 4018    [1.721 sec/step, loss=0.69917, avg_loss=0.72793]\n","Step 4019    [1.709 sec/step, loss=0.71559, avg_loss=0.72763]\n","Step 4020    [1.707 sec/step, loss=0.73834, avg_loss=0.72781]\n","Step 4021    [1.708 sec/step, loss=0.73983, avg_loss=0.72767]\n","Step 4022    [1.696 sec/step, loss=0.68627, avg_loss=0.72696]\n","Step 4023    [1.702 sec/step, loss=0.77528, avg_loss=0.72785]\n","Step 4024    [1.704 sec/step, loss=0.71889, avg_loss=0.72771]\n","Step 4025    [1.708 sec/step, loss=0.75141, avg_loss=0.72784]\n","Step 4026    [1.708 sec/step, loss=0.75290, avg_loss=0.72789]\n","Step 4027    [1.710 sec/step, loss=0.71520, avg_loss=0.72773]\n","Step 4028    [1.748 sec/step, loss=0.62901, avg_loss=0.72644]\n","Step 4029    [1.740 sec/step, loss=0.71372, avg_loss=0.72595]\n","Step 4030    [1.740 sec/step, loss=0.71938, avg_loss=0.72578]\n","Step 4031    [1.746 sec/step, loss=0.72613, avg_loss=0.72595]\n","Step 4032    [1.745 sec/step, loss=0.74690, avg_loss=0.72609]\n","Step 4033    [1.741 sec/step, loss=0.72553, avg_loss=0.72595]\n","Step 4034    [1.739 sec/step, loss=0.72449, avg_loss=0.72581]\n","Step 4035    [1.744 sec/step, loss=0.72309, avg_loss=0.72610]\n","Step 4036    [1.744 sec/step, loss=0.71239, avg_loss=0.72593]\n","Step 4037    [1.731 sec/step, loss=0.73512, avg_loss=0.72564]\n","Step 4038    [1.704 sec/step, loss=0.71536, avg_loss=0.72619]\n","Step 4039    [1.695 sec/step, loss=0.75403, avg_loss=0.72620]\n","Step 4040    [1.720 sec/step, loss=0.74897, avg_loss=0.72623]\n","Step 4041    [1.741 sec/step, loss=0.77341, avg_loss=0.72661]\n","Step 4042    [1.726 sec/step, loss=0.65897, avg_loss=0.72559]\n","Generated 32 batches of size 32 in 10.655 sec\n","Step 4043    [1.735 sec/step, loss=0.74889, avg_loss=0.72561]\n","Step 4044    [1.751 sec/step, loss=0.76320, avg_loss=0.72569]\n","Step 4045    [1.755 sec/step, loss=0.72844, avg_loss=0.72604]\n","Step 4046    [1.748 sec/step, loss=0.71905, avg_loss=0.72570]\n","Step 4047    [1.744 sec/step, loss=0.70519, avg_loss=0.72551]\n","Step 4048    [1.721 sec/step, loss=0.71237, avg_loss=0.72548]\n","Step 4049    [1.718 sec/step, loss=0.70216, avg_loss=0.72528]\n","Step 4050    [1.732 sec/step, loss=0.66851, avg_loss=0.72418]\n","Step 4051    [1.734 sec/step, loss=0.74612, avg_loss=0.72415]\n","Step 4052    [1.739 sec/step, loss=0.72463, avg_loss=0.72424]\n","Step 4053    [1.740 sec/step, loss=0.74473, avg_loss=0.72417]\n","Step 4054    [1.737 sec/step, loss=0.70655, avg_loss=0.72391]\n","Step 4055    [1.748 sec/step, loss=0.76035, avg_loss=0.72462]\n","Step 4056    [1.744 sec/step, loss=0.69830, avg_loss=0.72429]\n","Step 4057    [1.735 sec/step, loss=0.68733, avg_loss=0.72370]\n","Step 4058    [1.728 sec/step, loss=0.73097, avg_loss=0.72340]\n","Step 4059    [1.730 sec/step, loss=0.74913, avg_loss=0.72378]\n","Step 4060    [1.734 sec/step, loss=0.70223, avg_loss=0.72393]\n","Step 4061    [1.732 sec/step, loss=0.74278, avg_loss=0.72377]\n","Step 4062    [1.738 sec/step, loss=0.73527, avg_loss=0.72387]\n","Step 4063    [1.741 sec/step, loss=0.71783, avg_loss=0.72400]\n","Step 4064    [1.736 sec/step, loss=0.69454, avg_loss=0.72350]\n","Step 4065    [1.699 sec/step, loss=0.70021, avg_loss=0.72446]\n","Step 4066    [1.700 sec/step, loss=0.74284, avg_loss=0.72435]\n","Step 4067    [1.696 sec/step, loss=0.71576, avg_loss=0.72437]\n","Step 4068    [1.710 sec/step, loss=0.78992, avg_loss=0.72505]\n","Step 4069    [1.706 sec/step, loss=0.71425, avg_loss=0.72512]\n","Step 4070    [1.706 sec/step, loss=0.74098, avg_loss=0.72538]\n","Step 4071    [1.704 sec/step, loss=0.73324, avg_loss=0.72518]\n","Step 4072    [1.722 sec/step, loss=0.73897, avg_loss=0.72527]\n","Step 4073    [1.748 sec/step, loss=0.75525, avg_loss=0.72547]\n","Step 4074    [1.740 sec/step, loss=0.72994, avg_loss=0.72517]\n","Generated 32 batches of size 32 in 10.803 sec\n","Step 4075    [1.757 sec/step, loss=0.71929, avg_loss=0.72521]\n","Step 4076    [1.749 sec/step, loss=0.71064, avg_loss=0.72485]\n","Step 4077    [1.742 sec/step, loss=0.69868, avg_loss=0.72444]\n","Step 4078    [1.749 sec/step, loss=0.75691, avg_loss=0.72501]\n","Step 4079    [1.734 sec/step, loss=0.71029, avg_loss=0.72454]\n","Step 4080    [1.724 sec/step, loss=0.72742, avg_loss=0.72454]\n","Step 4081    [1.708 sec/step, loss=0.74465, avg_loss=0.72425]\n","Step 4082    [1.701 sec/step, loss=0.70390, avg_loss=0.72391]\n","Step 4083    [1.704 sec/step, loss=0.73426, avg_loss=0.72428]\n","Step 4084    [1.713 sec/step, loss=0.73819, avg_loss=0.72488]\n","Step 4085    [1.711 sec/step, loss=0.69941, avg_loss=0.72475]\n","Step 4086    [1.737 sec/step, loss=0.64765, avg_loss=0.72384]\n","Step 4087    [1.725 sec/step, loss=0.75723, avg_loss=0.72386]\n","Step 4088    [1.722 sec/step, loss=0.67715, avg_loss=0.72339]\n","Step 4089    [1.725 sec/step, loss=0.74916, avg_loss=0.72351]\n","Step 4090    [1.724 sec/step, loss=0.70465, avg_loss=0.72343]\n","Step 4091    [1.729 sec/step, loss=0.74136, avg_loss=0.72357]\n","Step 4092    [1.731 sec/step, loss=0.71833, avg_loss=0.72352]\n","Step 4093    [1.735 sec/step, loss=0.74468, avg_loss=0.72376]\n","Step 4094    [1.739 sec/step, loss=0.71174, avg_loss=0.72383]\n","Step 4095    [1.752 sec/step, loss=0.73641, avg_loss=0.72377]\n","Step 4096    [1.757 sec/step, loss=0.74866, avg_loss=0.72421]\n","Step 4097    [1.763 sec/step, loss=0.73531, avg_loss=0.72435]\n","Step 4098    [1.771 sec/step, loss=0.75231, avg_loss=0.72464]\n","Step 4099    [1.770 sec/step, loss=0.73225, avg_loss=0.72450]\n","Step 4100    [1.769 sec/step, loss=0.70616, avg_loss=0.72459]\n","Writing summary at step: 4100\n","Step 4101    [1.774 sec/step, loss=0.73217, avg_loss=0.72458]\n","Step 4102    [1.736 sec/step, loss=0.69338, avg_loss=0.72521]\n","Step 4103    [1.739 sec/step, loss=0.70168, avg_loss=0.72528]\n","Step 4104    [1.745 sec/step, loss=0.73533, avg_loss=0.72511]\n","Step 4105    [1.752 sec/step, loss=0.66497, avg_loss=0.72491]\n","Step 4106    [1.753 sec/step, loss=0.71659, avg_loss=0.72439]\n","Step 4107    [1.765 sec/step, loss=0.74894, avg_loss=0.72445]\n","Generated 32 batches of size 32 in 10.831 sec\n","Step 4108    [1.758 sec/step, loss=0.74589, avg_loss=0.72447]\n","Step 4109    [1.743 sec/step, loss=0.71866, avg_loss=0.72439]\n","Step 4110    [1.710 sec/step, loss=0.72386, avg_loss=0.72417]\n","Step 4111    [1.698 sec/step, loss=0.73534, avg_loss=0.72413]\n","Step 4112    [1.713 sec/step, loss=0.75629, avg_loss=0.72455]\n","Step 4113    [1.712 sec/step, loss=0.68762, avg_loss=0.72446]\n","Step 4114    [1.718 sec/step, loss=0.76498, avg_loss=0.72464]\n","Step 4115    [1.723 sec/step, loss=0.73782, avg_loss=0.72500]\n","Step 4116    [1.724 sec/step, loss=0.74808, avg_loss=0.72512]\n","Step 4117    [1.721 sec/step, loss=0.75249, avg_loss=0.72520]\n","Step 4118    [1.733 sec/step, loss=0.73037, avg_loss=0.72551]\n","Step 4119    [1.733 sec/step, loss=0.72507, avg_loss=0.72561]\n","Step 4120    [1.733 sec/step, loss=0.72891, avg_loss=0.72551]\n","Step 4121    [1.727 sec/step, loss=0.68633, avg_loss=0.72498]\n","Step 4122    [1.769 sec/step, loss=0.62559, avg_loss=0.72437]\n","Step 4123    [1.764 sec/step, loss=0.71410, avg_loss=0.72376]\n","Step 4124    [1.767 sec/step, loss=0.73416, avg_loss=0.72391]\n","Step 4125    [1.773 sec/step, loss=0.75226, avg_loss=0.72392]\n","Step 4126    [1.764 sec/step, loss=0.72055, avg_loss=0.72360]\n","Step 4127    [1.762 sec/step, loss=0.70178, avg_loss=0.72346]\n","Step 4128    [1.726 sec/step, loss=0.74286, avg_loss=0.72460]\n","Step 4129    [1.725 sec/step, loss=0.71187, avg_loss=0.72458]\n","Step 4130    [1.724 sec/step, loss=0.71805, avg_loss=0.72457]\n","Step 4131    [1.719 sec/step, loss=0.72709, avg_loss=0.72458]\n","Step 4132    [1.718 sec/step, loss=0.74302, avg_loss=0.72454]\n","Step 4133    [1.714 sec/step, loss=0.71012, avg_loss=0.72439]\n","Step 4134    [1.719 sec/step, loss=0.75659, avg_loss=0.72471]\n","Step 4135    [1.738 sec/step, loss=0.75829, avg_loss=0.72506]\n","Step 4136    [1.754 sec/step, loss=0.73519, avg_loss=0.72529]\n","Step 4137    [1.768 sec/step, loss=0.73835, avg_loss=0.72532]\n","Generated 32 batches of size 32 in 10.858 sec\n","Step 4138    [1.778 sec/step, loss=0.78913, avg_loss=0.72606]\n","Step 4139    [1.778 sec/step, loss=0.72609, avg_loss=0.72578]\n","Step 4140    [1.749 sec/step, loss=0.70201, avg_loss=0.72531]\n","Step 4141    [1.725 sec/step, loss=0.74342, avg_loss=0.72501]\n","Step 4142    [1.725 sec/step, loss=0.73579, avg_loss=0.72578]\n","Step 4143    [1.715 sec/step, loss=0.73550, avg_loss=0.72564]\n","Step 4144    [1.698 sec/step, loss=0.72748, avg_loss=0.72529]\n","Step 4145    [1.697 sec/step, loss=0.71424, avg_loss=0.72514]\n","Step 4146    [1.705 sec/step, loss=0.75486, avg_loss=0.72550]\n","Step 4147    [1.703 sec/step, loss=0.70372, avg_loss=0.72549]\n","Step 4148    [1.709 sec/step, loss=0.73439, avg_loss=0.72571]\n","Step 4149    [1.726 sec/step, loss=0.77364, avg_loss=0.72642]\n","Step 4150    [1.691 sec/step, loss=0.70584, avg_loss=0.72680]\n","Step 4151    [1.685 sec/step, loss=0.71508, avg_loss=0.72649]\n","Step 4152    [1.683 sec/step, loss=0.72765, avg_loss=0.72652]\n","Step 4153    [1.675 sec/step, loss=0.66783, avg_loss=0.72575]\n","Step 4154    [1.715 sec/step, loss=0.65143, avg_loss=0.72520]\n","Step 4155    [1.704 sec/step, loss=0.70075, avg_loss=0.72460]\n","Step 4156    [1.710 sec/step, loss=0.72665, avg_loss=0.72488]\n","Step 4157    [1.722 sec/step, loss=0.75253, avg_loss=0.72554]\n","Step 4158    [1.727 sec/step, loss=0.71690, avg_loss=0.72539]\n","Step 4159    [1.722 sec/step, loss=0.73346, avg_loss=0.72524]\n","Step 4160    [1.726 sec/step, loss=0.75436, avg_loss=0.72576]\n","Step 4161    [1.731 sec/step, loss=0.73552, avg_loss=0.72569]\n","Step 4162    [1.723 sec/step, loss=0.72534, avg_loss=0.72559]\n","Step 4163    [1.727 sec/step, loss=0.72690, avg_loss=0.72568]\n","Step 4164    [1.726 sec/step, loss=0.68967, avg_loss=0.72563]\n","Step 4165    [1.728 sec/step, loss=0.72704, avg_loss=0.72590]\n","Step 4166    [1.737 sec/step, loss=0.72804, avg_loss=0.72575]\n","Step 4167    [1.758 sec/step, loss=0.74432, avg_loss=0.72604]\n","Step 4168    [1.752 sec/step, loss=0.72519, avg_loss=0.72539]\n","Step 4169    [1.760 sec/step, loss=0.69700, avg_loss=0.72522]\n","Step 4170    [1.761 sec/step, loss=0.69591, avg_loss=0.72476]\n","Generated 32 batches of size 32 in 10.758 sec\n","Step 4171    [1.771 sec/step, loss=0.74403, avg_loss=0.72487]\n","Step 4172    [1.755 sec/step, loss=0.72848, avg_loss=0.72477]\n","Step 4173    [1.731 sec/step, loss=0.73466, avg_loss=0.72456]\n","Step 4174    [1.721 sec/step, loss=0.70370, avg_loss=0.72430]\n","Step 4175    [1.710 sec/step, loss=0.74199, avg_loss=0.72453]\n","Step 4176    [1.710 sec/step, loss=0.73446, avg_loss=0.72476]\n","Step 4177    [1.714 sec/step, loss=0.72677, avg_loss=0.72505]\n","Step 4178    [1.705 sec/step, loss=0.74368, avg_loss=0.72491]\n","Step 4179    [1.703 sec/step, loss=0.68177, avg_loss=0.72463]\n","Step 4180    [1.711 sec/step, loss=0.74265, avg_loss=0.72478]\n","Step 4181    [1.712 sec/step, loss=0.76889, avg_loss=0.72502]\n","Step 4182    [1.711 sec/step, loss=0.71688, avg_loss=0.72515]\n","Step 4183    [1.710 sec/step, loss=0.70716, avg_loss=0.72488]\n","Step 4184    [1.701 sec/step, loss=0.68839, avg_loss=0.72438]\n","Step 4185    [1.705 sec/step, loss=0.71909, avg_loss=0.72458]\n","Step 4186    [1.673 sec/step, loss=0.74676, avg_loss=0.72557]\n","Step 4187    [1.683 sec/step, loss=0.73280, avg_loss=0.72533]\n","Step 4188    [1.683 sec/step, loss=0.70657, avg_loss=0.72562]\n","Step 4189    [1.679 sec/step, loss=0.67598, avg_loss=0.72489]\n","Step 4190    [1.685 sec/step, loss=0.75124, avg_loss=0.72536]\n","Step 4191    [1.674 sec/step, loss=0.67226, avg_loss=0.72466]\n","Step 4192    [1.670 sec/step, loss=0.69732, avg_loss=0.72445]\n","Step 4193    [1.674 sec/step, loss=0.74559, avg_loss=0.72446]\n","Step 4194    [1.672 sec/step, loss=0.70566, avg_loss=0.72440]\n","Step 4195    [1.653 sec/step, loss=0.72190, avg_loss=0.72426]\n","Step 4196    [1.681 sec/step, loss=0.68115, avg_loss=0.72358]\n","Step 4197    [1.679 sec/step, loss=0.75163, avg_loss=0.72375]\n","Step 4198    [1.676 sec/step, loss=0.73305, avg_loss=0.72355]\n","Step 4199    [1.692 sec/step, loss=0.74835, avg_loss=0.72371]\n","Step 4200    [1.704 sec/step, loss=0.72101, avg_loss=0.72386]\n","Writing summary at step: 4200\n","Generated 32 batches of size 32 in 11.223 sec\n","Step 4201    [1.700 sec/step, loss=0.73411, avg_loss=0.72388]\n","Step 4202    [1.704 sec/step, loss=0.72264, avg_loss=0.72417]\n","Step 4203    [1.702 sec/step, loss=0.69262, avg_loss=0.72408]\n","Step 4204    [1.694 sec/step, loss=0.76750, avg_loss=0.72441]\n","Step 4205    [1.689 sec/step, loss=0.72109, avg_loss=0.72497]\n","Step 4206    [1.679 sec/step, loss=0.73691, avg_loss=0.72517]\n","Step 4207    [1.663 sec/step, loss=0.71654, avg_loss=0.72485]\n","Step 4208    [1.656 sec/step, loss=0.70540, avg_loss=0.72444]\n","Step 4209    [1.661 sec/step, loss=0.70804, avg_loss=0.72433]\n","Step 4210    [1.670 sec/step, loss=0.74779, avg_loss=0.72457]\n","Step 4211    [1.668 sec/step, loss=0.71352, avg_loss=0.72436]\n","Step 4212    [1.656 sec/step, loss=0.72925, avg_loss=0.72409]\n","Step 4213    [1.662 sec/step, loss=0.74075, avg_loss=0.72462]\n","Step 4214    [1.650 sec/step, loss=0.71381, avg_loss=0.72411]\n","Step 4215    [1.650 sec/step, loss=0.72041, avg_loss=0.72393]\n","Step 4216    [1.645 sec/step, loss=0.69470, avg_loss=0.72340]\n","Step 4217    [1.636 sec/step, loss=0.72464, avg_loss=0.72312]\n","Step 4218    [1.647 sec/step, loss=0.75266, avg_loss=0.72334]\n","Step 4219    [1.649 sec/step, loss=0.71859, avg_loss=0.72328]\n","Step 4220    [1.648 sec/step, loss=0.69725, avg_loss=0.72296]\n","Step 4221    [1.652 sec/step, loss=0.71232, avg_loss=0.72322]\n","Step 4222    [1.609 sec/step, loss=0.69405, avg_loss=0.72390]\n","Step 4223    [1.640 sec/step, loss=0.64256, avg_loss=0.72319]\n","Step 4224    [1.645 sec/step, loss=0.73421, avg_loss=0.72319]\n","Step 4225    [1.638 sec/step, loss=0.73584, avg_loss=0.72303]\n","Step 4226    [1.640 sec/step, loss=0.71005, avg_loss=0.72292]\n","Step 4227    [1.642 sec/step, loss=0.72189, avg_loss=0.72312]\n","Step 4228    [1.636 sec/step, loss=0.70108, avg_loss=0.72270]\n","Step 4229    [1.632 sec/step, loss=0.70826, avg_loss=0.72267]\n","Step 4230    [1.659 sec/step, loss=0.72856, avg_loss=0.72277]\n","Step 4231    [1.667 sec/step, loss=0.70896, avg_loss=0.72259]\n","Step 4232    [1.688 sec/step, loss=0.72697, avg_loss=0.72243]\n","Generated 32 batches of size 32 in 10.860 sec\n","Step 4233    [1.704 sec/step, loss=0.73130, avg_loss=0.72264]\n","Step 4234    [1.715 sec/step, loss=0.73487, avg_loss=0.72243]\n","Step 4235    [1.691 sec/step, loss=0.65915, avg_loss=0.72143]\n","Step 4236    [1.684 sec/step, loss=0.76451, avg_loss=0.72173]\n","Step 4237    [1.670 sec/step, loss=0.68445, avg_loss=0.72119]\n","Step 4238    [1.648 sec/step, loss=0.71850, avg_loss=0.72048]\n","Step 4239    [1.647 sec/step, loss=0.67974, avg_loss=0.72002]\n","Step 4240    [1.669 sec/step, loss=0.75543, avg_loss=0.72055]\n","Step 4241    [1.677 sec/step, loss=0.75107, avg_loss=0.72063]\n","Step 4242    [1.676 sec/step, loss=0.69716, avg_loss=0.72024]\n","Step 4243    [1.676 sec/step, loss=0.71722, avg_loss=0.72006]\n","Step 4244    [1.671 sec/step, loss=0.70073, avg_loss=0.71979]\n","Step 4245    [1.673 sec/step, loss=0.70683, avg_loss=0.71972]\n","Step 4246    [1.666 sec/step, loss=0.70913, avg_loss=0.71926]\n","Step 4247    [1.671 sec/step, loss=0.70283, avg_loss=0.71925]\n","Step 4248    [1.675 sec/step, loss=0.72440, avg_loss=0.71915]\n","Step 4249    [1.658 sec/step, loss=0.70573, avg_loss=0.71847]\n","Step 4250    [1.664 sec/step, loss=0.73397, avg_loss=0.71876]\n","Step 4251    [1.663 sec/step, loss=0.70016, avg_loss=0.71861]\n","Step 4252    [1.667 sec/step, loss=0.74354, avg_loss=0.71876]\n","Step 4253    [1.683 sec/step, loss=0.74146, avg_loss=0.71950]\n","Step 4254    [1.646 sec/step, loss=0.70637, avg_loss=0.72005]\n","Step 4255    [1.686 sec/step, loss=0.64006, avg_loss=0.71944]\n","Step 4256    [1.688 sec/step, loss=0.74109, avg_loss=0.71959]\n","Step 4257    [1.684 sec/step, loss=0.73011, avg_loss=0.71936]\n","Step 4258    [1.677 sec/step, loss=0.72860, avg_loss=0.71948]\n","Step 4259    [1.677 sec/step, loss=0.68646, avg_loss=0.71901]\n","Step 4260    [1.670 sec/step, loss=0.71340, avg_loss=0.71860]\n","Step 4261    [1.661 sec/step, loss=0.68573, avg_loss=0.71810]\n","Step 4262    [1.662 sec/step, loss=0.67545, avg_loss=0.71760]\n","Step 4263    [1.681 sec/step, loss=0.75448, avg_loss=0.71788]\n","Step 4264    [1.688 sec/step, loss=0.69136, avg_loss=0.71790]\n","Step 4265    [1.697 sec/step, loss=0.69848, avg_loss=0.71761]\n","Generated 32 batches of size 32 in 10.718 sec\n","Step 4266    [1.695 sec/step, loss=0.74391, avg_loss=0.71777]\n","Step 4267    [1.671 sec/step, loss=0.67854, avg_loss=0.71711]\n","Step 4268    [1.661 sec/step, loss=0.70712, avg_loss=0.71693]\n","Step 4269    [1.660 sec/step, loss=0.74415, avg_loss=0.71740]\n","Step 4270    [1.659 sec/step, loss=0.73066, avg_loss=0.71775]\n","Step 4271    [1.646 sec/step, loss=0.72490, avg_loss=0.71756]\n","Step 4272    [1.646 sec/step, loss=0.73211, avg_loss=0.71760]\n","Step 4273    [1.651 sec/step, loss=0.72525, avg_loss=0.71750]\n","Step 4274    [1.653 sec/step, loss=0.72912, avg_loss=0.71776]\n","Step 4275    [1.653 sec/step, loss=0.74391, avg_loss=0.71777]\n","Step 4276    [1.653 sec/step, loss=0.70733, avg_loss=0.71750]\n","Step 4277    [1.674 sec/step, loss=0.73173, avg_loss=0.71755]\n","Step 4278    [1.679 sec/step, loss=0.75606, avg_loss=0.71768]\n","Step 4279    [1.687 sec/step, loss=0.73041, avg_loss=0.71816]\n","Step 4280    [1.677 sec/step, loss=0.71256, avg_loss=0.71786]\n","Step 4281    [1.671 sec/step, loss=0.69994, avg_loss=0.71717]\n","Step 4282    [1.706 sec/step, loss=0.67538, avg_loss=0.71676]\n","Step 4283    [1.704 sec/step, loss=0.68582, avg_loss=0.71654]\n","Step 4284    [1.705 sec/step, loss=0.67843, avg_loss=0.71644]\n","Step 4285    [1.713 sec/step, loss=0.74191, avg_loss=0.71667]\n","Step 4286    [1.715 sec/step, loss=0.73195, avg_loss=0.71652]\n","Step 4287    [1.699 sec/step, loss=0.71514, avg_loss=0.71635]\n","Step 4288    [1.705 sec/step, loss=0.71715, avg_loss=0.71645]\n","Step 4289    [1.703 sec/step, loss=0.69754, avg_loss=0.71667]\n","Step 4290    [1.696 sec/step, loss=0.65268, avg_loss=0.71568]\n","Step 4291    [1.696 sec/step, loss=0.69209, avg_loss=0.71588]\n","Step 4292    [1.699 sec/step, loss=0.71613, avg_loss=0.71607]\n","Step 4293    [1.703 sec/step, loss=0.71731, avg_loss=0.71579]\n","Step 4294    [1.708 sec/step, loss=0.67628, avg_loss=0.71549]\n","Step 4295    [1.718 sec/step, loss=0.68589, avg_loss=0.71513]\n","Step 4296    [1.704 sec/step, loss=0.71698, avg_loss=0.71549]\n","Step 4297    [1.712 sec/step, loss=0.71916, avg_loss=0.71517]\n","Generated 32 batches of size 32 in 10.844 sec\n","Step 4298    [1.712 sec/step, loss=0.68928, avg_loss=0.71473]\n","Step 4299    [1.703 sec/step, loss=0.75491, avg_loss=0.71480]\n","Step 4300    [1.692 sec/step, loss=0.70266, avg_loss=0.71461]\n","Writing summary at step: 4300\n","Step 4301    [1.686 sec/step, loss=0.70865, avg_loss=0.71436]\n","Step 4302    [1.683 sec/step, loss=0.69934, avg_loss=0.71412]\n","Step 4303    [1.687 sec/step, loss=0.70723, avg_loss=0.71427]\n","Step 4304    [1.688 sec/step, loss=0.72677, avg_loss=0.71386]\n","Step 4305    [1.702 sec/step, loss=0.72351, avg_loss=0.71389]\n","Step 4306    [1.708 sec/step, loss=0.72202, avg_loss=0.71374]\n","Step 4307    [1.709 sec/step, loss=0.72177, avg_loss=0.71379]\n","Step 4308    [1.708 sec/step, loss=0.72199, avg_loss=0.71396]\n","Step 4309    [1.705 sec/step, loss=0.65999, avg_loss=0.71348]\n","Step 4310    [1.716 sec/step, loss=0.75021, avg_loss=0.71350]\n","Step 4311    [1.717 sec/step, loss=0.71502, avg_loss=0.71352]\n","Step 4312    [1.713 sec/step, loss=0.69860, avg_loss=0.71321]\n","Step 4313    [1.705 sec/step, loss=0.65007, avg_loss=0.71230]\n","Step 4314    [1.704 sec/step, loss=0.67226, avg_loss=0.71189]\n","Step 4315    [1.701 sec/step, loss=0.69121, avg_loss=0.71159]\n","Step 4316    [1.711 sec/step, loss=0.73823, avg_loss=0.71203]\n","Step 4317    [1.710 sec/step, loss=0.67720, avg_loss=0.71156]\n","Step 4318    [1.688 sec/step, loss=0.70276, avg_loss=0.71106]\n","Step 4319    [1.687 sec/step, loss=0.69613, avg_loss=0.71083]\n","Step 4320    [1.687 sec/step, loss=0.69285, avg_loss=0.71079]\n","Step 4321    [1.687 sec/step, loss=0.70811, avg_loss=0.71075]\n","Step 4322    [1.691 sec/step, loss=0.72060, avg_loss=0.71101]\n","Step 4323    [1.667 sec/step, loss=0.74454, avg_loss=0.71203]\n","Step 4324    [1.657 sec/step, loss=0.68992, avg_loss=0.71159]\n","Step 4325    [1.672 sec/step, loss=0.70183, avg_loss=0.71125]\n","Step 4326    [1.694 sec/step, loss=0.73619, avg_loss=0.71151]\n","Step 4327    [1.698 sec/step, loss=0.70688, avg_loss=0.71136]\n","Step 4328    [1.706 sec/step, loss=0.69712, avg_loss=0.71132]\n","Generated 32 batches of size 32 in 10.904 sec\n","Step 4329    [1.746 sec/step, loss=0.67395, avg_loss=0.71098]\n","Step 4330    [1.728 sec/step, loss=0.73789, avg_loss=0.71107]\n","Step 4331    [1.719 sec/step, loss=0.70436, avg_loss=0.71102]\n","Step 4332    [1.699 sec/step, loss=0.73409, avg_loss=0.71109]\n","Step 4333    [1.694 sec/step, loss=0.74377, avg_loss=0.71122]\n","Step 4334    [1.678 sec/step, loss=0.66160, avg_loss=0.71049]\n","Step 4335    [1.692 sec/step, loss=0.76032, avg_loss=0.71150]\n","Step 4336    [1.685 sec/step, loss=0.71435, avg_loss=0.71100]\n","Step 4337    [1.695 sec/step, loss=0.71576, avg_loss=0.71131]\n","Step 4338    [1.703 sec/step, loss=0.72485, avg_loss=0.71137]\n","Step 4339    [1.702 sec/step, loss=0.65964, avg_loss=0.71117]\n","Step 4340    [1.685 sec/step, loss=0.68588, avg_loss=0.71048]\n","Step 4341    [1.683 sec/step, loss=0.71531, avg_loss=0.71012]\n","Step 4342    [1.683 sec/step, loss=0.71276, avg_loss=0.71028]\n","Step 4343    [1.684 sec/step, loss=0.73594, avg_loss=0.71046]\n","Step 4344    [1.690 sec/step, loss=0.70302, avg_loss=0.71049]\n","Step 4345    [1.689 sec/step, loss=0.70764, avg_loss=0.71049]\n","Step 4346    [1.688 sec/step, loss=0.72995, avg_loss=0.71070]\n","Step 4347    [1.684 sec/step, loss=0.67817, avg_loss=0.71045]\n","Step 4348    [1.686 sec/step, loss=0.74305, avg_loss=0.71064]\n","Step 4349    [1.688 sec/step, loss=0.69686, avg_loss=0.71055]\n","Step 4350    [1.688 sec/step, loss=0.70932, avg_loss=0.71031]\n","Step 4351    [1.691 sec/step, loss=0.70846, avg_loss=0.71039]\n","Step 4352    [1.684 sec/step, loss=0.71059, avg_loss=0.71006]\n","Step 4353    [1.677 sec/step, loss=0.71458, avg_loss=0.70979]\n","Step 4354    [1.678 sec/step, loss=0.74177, avg_loss=0.71014]\n","Step 4355    [1.678 sec/step, loss=0.61797, avg_loss=0.70992]\n","Step 4356    [1.677 sec/step, loss=0.72546, avg_loss=0.70977]\n","Step 4357    [1.677 sec/step, loss=0.67375, avg_loss=0.70920]\n","Step 4358    [1.684 sec/step, loss=0.69094, avg_loss=0.70883]\n","Step 4359    [1.693 sec/step, loss=0.68710, avg_loss=0.70883]\n","Step 4360    [1.699 sec/step, loss=0.71358, avg_loss=0.70884]\n","Step 4361    [1.718 sec/step, loss=0.71121, avg_loss=0.70909]\n","Generated 32 batches of size 32 in 10.722 sec\n","Step 4362    [1.724 sec/step, loss=0.70366, avg_loss=0.70937]\n","Step 4363    [1.701 sec/step, loss=0.69650, avg_loss=0.70879]\n","Step 4364    [1.694 sec/step, loss=0.66443, avg_loss=0.70852]\n","Step 4365    [1.703 sec/step, loss=0.73850, avg_loss=0.70892]\n","Step 4366    [1.689 sec/step, loss=0.70311, avg_loss=0.70852]\n","Step 4367    [1.690 sec/step, loss=0.66945, avg_loss=0.70842]\n","Step 4368    [1.688 sec/step, loss=0.68763, avg_loss=0.70823]\n","Step 4369    [1.687 sec/step, loss=0.70967, avg_loss=0.70788]\n","Step 4370    [1.684 sec/step, loss=0.69979, avg_loss=0.70758]\n","Step 4371    [1.684 sec/step, loss=0.70004, avg_loss=0.70733]\n","Step 4372    [1.682 sec/step, loss=0.72109, avg_loss=0.70722]\n","Step 4373    [1.683 sec/step, loss=0.74279, avg_loss=0.70739]\n","Step 4374    [1.680 sec/step, loss=0.68308, avg_loss=0.70693]\n","Step 4375    [1.682 sec/step, loss=0.69831, avg_loss=0.70648]\n","Step 4376    [1.681 sec/step, loss=0.71446, avg_loss=0.70655]\n","Step 4377    [1.658 sec/step, loss=0.70946, avg_loss=0.70633]\n","Step 4378    [1.648 sec/step, loss=0.70031, avg_loss=0.70577]\n","Step 4379    [1.649 sec/step, loss=0.72363, avg_loss=0.70570]\n","Step 4380    [1.664 sec/step, loss=0.73493, avg_loss=0.70592]\n","Step 4381    [1.665 sec/step, loss=0.73133, avg_loss=0.70624]\n","Step 4382    [1.633 sec/step, loss=0.71643, avg_loss=0.70665]\n","Step 4383    [1.631 sec/step, loss=0.70037, avg_loss=0.70679]\n","Step 4384    [1.640 sec/step, loss=0.72723, avg_loss=0.70728]\n","Step 4385    [1.631 sec/step, loss=0.70271, avg_loss=0.70689]\n","Step 4386    [1.623 sec/step, loss=0.68538, avg_loss=0.70642]\n","Step 4387    [1.619 sec/step, loss=0.68327, avg_loss=0.70611]\n","Step 4388    [1.653 sec/step, loss=0.62560, avg_loss=0.70519]\n","Step 4389    [1.701 sec/step, loss=0.74259, avg_loss=0.70564]\n","Step 4390    [1.708 sec/step, loss=0.65529, avg_loss=0.70567]\n","Step 4391    [1.719 sec/step, loss=0.72229, avg_loss=0.70597]\n","Generated 32 batches of size 32 in 11.159 sec\n","Step 4392    [1.734 sec/step, loss=0.74385, avg_loss=0.70625]\n","Step 4393    [1.720 sec/step, loss=0.71918, avg_loss=0.70626]\n","Step 4394    [1.717 sec/step, loss=0.72766, avg_loss=0.70678]\n","Step 4395    [1.707 sec/step, loss=0.69345, avg_loss=0.70685]\n","Step 4396    [1.696 sec/step, loss=0.74434, avg_loss=0.70713]\n","Step 4397    [1.691 sec/step, loss=0.75344, avg_loss=0.70747]\n","Step 4398    [1.685 sec/step, loss=0.70272, avg_loss=0.70760]\n","Step 4399    [1.678 sec/step, loss=0.70237, avg_loss=0.70708]\n","Step 4400    [1.680 sec/step, loss=0.71753, avg_loss=0.70723]\n","Writing summary at step: 4400\n","Step 4401    [1.676 sec/step, loss=0.69337, avg_loss=0.70707]\n","Step 4402    [1.675 sec/step, loss=0.68313, avg_loss=0.70691]\n","Step 4403    [1.677 sec/step, loss=0.71664, avg_loss=0.70701]\n","Step 4404    [1.684 sec/step, loss=0.74325, avg_loss=0.70717]\n","Step 4405    [1.679 sec/step, loss=0.72465, avg_loss=0.70718]\n","Step 4406    [1.676 sec/step, loss=0.70093, avg_loss=0.70697]\n","Step 4407    [1.677 sec/step, loss=0.71214, avg_loss=0.70688]\n","Step 4408    [1.674 sec/step, loss=0.70472, avg_loss=0.70670]\n","Step 4409    [1.679 sec/step, loss=0.73166, avg_loss=0.70742]\n","Step 4410    [1.659 sec/step, loss=0.66103, avg_loss=0.70653]\n","Step 4411    [1.656 sec/step, loss=0.70235, avg_loss=0.70640]\n","Step 4412    [1.654 sec/step, loss=0.68473, avg_loss=0.70626]\n","Step 4413    [1.664 sec/step, loss=0.75332, avg_loss=0.70729]\n","Step 4414    [1.672 sec/step, loss=0.72446, avg_loss=0.70782]\n","Step 4415    [1.713 sec/step, loss=0.62534, avg_loss=0.70716]\n","Step 4416    [1.704 sec/step, loss=0.71183, avg_loss=0.70689]\n","Step 4417    [1.703 sec/step, loss=0.68327, avg_loss=0.70695]\n","Step 4418    [1.704 sec/step, loss=0.67604, avg_loss=0.70669]\n","Step 4419    [1.700 sec/step, loss=0.69505, avg_loss=0.70668]\n","Step 4420    [1.714 sec/step, loss=0.73346, avg_loss=0.70708]\n","Step 4421    [1.715 sec/step, loss=0.70411, avg_loss=0.70704]\n","Step 4422    [1.726 sec/step, loss=0.72289, avg_loss=0.70707]\n","Step 4423    [1.726 sec/step, loss=0.69642, avg_loss=0.70658]\n","Step 4424    [1.741 sec/step, loss=0.73207, avg_loss=0.70701]\n","Generated 32 batches of size 32 in 11.099 sec\n","Step 4425    [1.744 sec/step, loss=0.76875, avg_loss=0.70768]\n","Step 4426    [1.726 sec/step, loss=0.71491, avg_loss=0.70746]\n","Step 4427    [1.725 sec/step, loss=0.72496, avg_loss=0.70764]\n","Step 4428    [1.728 sec/step, loss=0.75809, avg_loss=0.70825]\n","Step 4429    [1.694 sec/step, loss=0.72940, avg_loss=0.70881]\n","Step 4430    [1.689 sec/step, loss=0.70041, avg_loss=0.70843]\n","Step 4431    [1.695 sec/step, loss=0.73644, avg_loss=0.70875]\n","Step 4432    [1.699 sec/step, loss=0.70883, avg_loss=0.70850]\n","Step 4433    [1.689 sec/step, loss=0.68486, avg_loss=0.70791]\n","Step 4434    [1.692 sec/step, loss=0.68637, avg_loss=0.70816]\n","Step 4435    [1.680 sec/step, loss=0.67568, avg_loss=0.70731]\n","Step 4436    [1.685 sec/step, loss=0.72115, avg_loss=0.70738]\n","Step 4437    [1.679 sec/step, loss=0.72913, avg_loss=0.70751]\n","Step 4438    [1.668 sec/step, loss=0.66997, avg_loss=0.70697]\n","Step 4439    [1.670 sec/step, loss=0.70312, avg_loss=0.70740]\n","Step 4440    [1.668 sec/step, loss=0.70595, avg_loss=0.70760]\n","Step 4441    [1.669 sec/step, loss=0.74106, avg_loss=0.70786]\n","Step 4442    [1.668 sec/step, loss=0.71156, avg_loss=0.70785]\n","Step 4443    [1.661 sec/step, loss=0.66029, avg_loss=0.70709]\n","Step 4444    [1.662 sec/step, loss=0.72798, avg_loss=0.70734]\n","Step 4445    [1.662 sec/step, loss=0.68641, avg_loss=0.70713]\n","Step 4446    [1.676 sec/step, loss=0.71532, avg_loss=0.70698]\n","Step 4447    [1.676 sec/step, loss=0.70020, avg_loss=0.70720]\n","Step 4448    [1.665 sec/step, loss=0.69414, avg_loss=0.70671]\n","Step 4449    [1.672 sec/step, loss=0.74284, avg_loss=0.70717]\n","Step 4450    [1.669 sec/step, loss=0.71589, avg_loss=0.70724]\n","Step 4451    [1.669 sec/step, loss=0.74019, avg_loss=0.70756]\n","Step 4452    [1.695 sec/step, loss=0.71545, avg_loss=0.70760]\n","Step 4453    [1.692 sec/step, loss=0.69470, avg_loss=0.70741]\n","Step 4454    [1.707 sec/step, loss=0.71310, avg_loss=0.70712]\n","Step 4455    [1.677 sec/step, loss=0.72179, avg_loss=0.70816]\n","Generated 32 batches of size 32 in 11.008 sec\n","Step 4456    [1.683 sec/step, loss=0.75406, avg_loss=0.70844]\n","Step 4457    [1.693 sec/step, loss=0.72180, avg_loss=0.70892]\n","Step 4458    [1.691 sec/step, loss=0.70430, avg_loss=0.70906]\n","Step 4459    [1.681 sec/step, loss=0.68540, avg_loss=0.70904]\n","Step 4460    [1.715 sec/step, loss=0.62865, avg_loss=0.70819]\n","Step 4461    [1.701 sec/step, loss=0.70392, avg_loss=0.70812]\n","Step 4462    [1.699 sec/step, loss=0.72654, avg_loss=0.70835]\n","Step 4463    [1.697 sec/step, loss=0.70282, avg_loss=0.70841]\n","Step 4464    [1.719 sec/step, loss=0.74995, avg_loss=0.70927]\n","Step 4465    [1.704 sec/step, loss=0.70626, avg_loss=0.70894]\n","Step 4466    [1.707 sec/step, loss=0.72229, avg_loss=0.70913]\n","Step 4467    [1.710 sec/step, loss=0.69192, avg_loss=0.70936]\n","Step 4468    [1.710 sec/step, loss=0.69775, avg_loss=0.70946]\n","Step 4469    [1.709 sec/step, loss=0.70997, avg_loss=0.70946]\n","Step 4470    [1.718 sec/step, loss=0.73835, avg_loss=0.70985]\n","Step 4471    [1.719 sec/step, loss=0.70921, avg_loss=0.70994]\n","Step 4472    [1.729 sec/step, loss=0.71001, avg_loss=0.70983]\n","Step 4473    [1.721 sec/step, loss=0.68452, avg_loss=0.70925]\n","Step 4474    [1.724 sec/step, loss=0.70294, avg_loss=0.70945]\n","Step 4475    [1.717 sec/step, loss=0.69757, avg_loss=0.70944]\n","Step 4476    [1.721 sec/step, loss=0.73527, avg_loss=0.70965]\n","Step 4477    [1.724 sec/step, loss=0.69624, avg_loss=0.70951]\n","Step 4478    [1.724 sec/step, loss=0.67545, avg_loss=0.70927]\n","Step 4479    [1.716 sec/step, loss=0.68814, avg_loss=0.70891]\n","Step 4480    [1.711 sec/step, loss=0.73577, avg_loss=0.70892]\n","Step 4481    [1.705 sec/step, loss=0.67774, avg_loss=0.70838]\n","Step 4482    [1.700 sec/step, loss=0.68498, avg_loss=0.70807]\n","Step 4483    [1.701 sec/step, loss=0.68206, avg_loss=0.70789]\n","Step 4484    [1.711 sec/step, loss=0.71978, avg_loss=0.70781]\n","Step 4485    [1.733 sec/step, loss=0.72821, avg_loss=0.70807]\n","Step 4486    [1.736 sec/step, loss=0.67397, avg_loss=0.70795]\n","Generated 32 batches of size 32 in 11.327 sec\n","Step 4487    [1.786 sec/step, loss=0.66642, avg_loss=0.70778]\n","Step 4488    [1.753 sec/step, loss=0.74588, avg_loss=0.70899]\n","Step 4489    [1.707 sec/step, loss=0.70378, avg_loss=0.70860]\n","Step 4490    [1.704 sec/step, loss=0.69871, avg_loss=0.70903]\n","Step 4491    [1.696 sec/step, loss=0.71618, avg_loss=0.70897]\n","Step 4492    [1.688 sec/step, loss=0.74508, avg_loss=0.70898]\n","Step 4493    [1.690 sec/step, loss=0.69983, avg_loss=0.70879]\n","Step 4494    [1.686 sec/step, loss=0.70101, avg_loss=0.70852]\n","Step 4495    [1.684 sec/step, loss=0.68693, avg_loss=0.70846]\n","Step 4496    [1.684 sec/step, loss=0.72680, avg_loss=0.70828]\n","Step 4497    [1.678 sec/step, loss=0.69956, avg_loss=0.70774]\n","Step 4498    [1.687 sec/step, loss=0.71125, avg_loss=0.70783]\n","Step 4499    [1.686 sec/step, loss=0.69265, avg_loss=0.70773]\n","Step 4500    [1.683 sec/step, loss=0.67023, avg_loss=0.70726]\n","Writing summary at step: 4500\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Training korean : Use jamo\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12620 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49884 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44036 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49440 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44257 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51012 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51328 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48512 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53441 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47160 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45908 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45768 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12620 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49884 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44036 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49440 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44257 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51012 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51328 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48512 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53441 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47160 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45908 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45768 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/train-step-000004500-align000.png\n","100% 1/1 [00:02<00:00,  2.24s/it]\n","Test finished for step 4500.\n","  0% 0/2 [00:00<?, ?it/s]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000004500-align000.png\n"," 50% 1/2 [00:02<00:02,  2.53s/it]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000004500-align001.png\n","100% 2/2 [00:04<00:00,  2.50s/it]\n","Test finished for step 4500.\n","Step 4501    [1.685 sec/step, loss=0.70641, avg_loss=0.70739]\n","Step 4502    [1.689 sec/step, loss=0.72538, avg_loss=0.70781]\n","Step 4503    [1.686 sec/step, loss=0.69196, avg_loss=0.70757]\n","Step 4504    [1.674 sec/step, loss=0.70642, avg_loss=0.70720]\n","Step 4505    [1.670 sec/step, loss=0.71575, avg_loss=0.70711]\n","Step 4506    [1.680 sec/step, loss=0.73305, avg_loss=0.70743]\n","Step 4507    [1.674 sec/step, loss=0.66971, avg_loss=0.70701]\n","Step 4508    [1.673 sec/step, loss=0.69420, avg_loss=0.70690]\n","Step 4509    [1.672 sec/step, loss=0.72944, avg_loss=0.70688]\n","Step 4510    [1.681 sec/step, loss=0.72159, avg_loss=0.70748]\n","Step 4511    [1.690 sec/step, loss=0.73605, avg_loss=0.70782]\n","Step 4512    [1.701 sec/step, loss=0.72049, avg_loss=0.70818]\n","Step 4513    [1.692 sec/step, loss=0.66799, avg_loss=0.70732]\n","Step 4514    [1.721 sec/step, loss=0.74499, avg_loss=0.70753]\n","Generated 32 batches of size 32 in 10.315 sec\n","Step 4515    [1.742 sec/step, loss=0.65154, avg_loss=0.70779]\n","Step 4516    [1.741 sec/step, loss=0.70816, avg_loss=0.70776]\n","Step 4517    [1.744 sec/step, loss=0.69600, avg_loss=0.70788]\n","Step 4518    [1.761 sec/step, loss=0.74571, avg_loss=0.70858]\n","Step 4519    [1.767 sec/step, loss=0.72613, avg_loss=0.70889]\n","Step 4520    [1.751 sec/step, loss=0.66876, avg_loss=0.70824]\n","Step 4521    [1.749 sec/step, loss=0.71240, avg_loss=0.70833]\n","Step 4522    [1.740 sec/step, loss=0.70984, avg_loss=0.70820]\n","Step 4523    [1.732 sec/step, loss=0.69384, avg_loss=0.70817]\n","Step 4524    [1.722 sec/step, loss=0.68609, avg_loss=0.70771]\n","Step 4525    [1.704 sec/step, loss=0.72260, avg_loss=0.70725]\n","Step 4526    [1.703 sec/step, loss=0.71161, avg_loss=0.70722]\n","Step 4527    [1.705 sec/step, loss=0.70253, avg_loss=0.70699]\n","Step 4528    [1.699 sec/step, loss=0.72982, avg_loss=0.70671]\n","Step 4529    [1.694 sec/step, loss=0.67831, avg_loss=0.70620]\n","Step 4530    [1.691 sec/step, loss=0.67109, avg_loss=0.70590]\n","Step 4531    [1.684 sec/step, loss=0.69737, avg_loss=0.70551]\n","Step 4532    [1.676 sec/step, loss=0.64343, avg_loss=0.70486]\n","Step 4533    [1.680 sec/step, loss=0.69912, avg_loss=0.70500]\n","Step 4534    [1.689 sec/step, loss=0.71327, avg_loss=0.70527]\n","Step 4535    [1.731 sec/step, loss=0.58893, avg_loss=0.70440]\n","Step 4536    [1.732 sec/step, loss=0.74161, avg_loss=0.70461]\n","Step 4537    [1.738 sec/step, loss=0.70450, avg_loss=0.70436]\n","Step 4538    [1.743 sec/step, loss=0.71797, avg_loss=0.70484]\n","Step 4539    [1.755 sec/step, loss=0.71508, avg_loss=0.70496]\n","Step 4540    [1.752 sec/step, loss=0.67084, avg_loss=0.70461]\n","Step 4541    [1.747 sec/step, loss=0.68521, avg_loss=0.70405]\n","Step 4542    [1.751 sec/step, loss=0.71531, avg_loss=0.70409]\n","Step 4543    [1.753 sec/step, loss=0.67315, avg_loss=0.70422]\n","Step 4544    [1.765 sec/step, loss=0.72588, avg_loss=0.70420]\n","Step 4545    [1.771 sec/step, loss=0.72017, avg_loss=0.70453]\n","Step 4546    [1.758 sec/step, loss=0.67077, avg_loss=0.70409]\n","Step 4547    [1.778 sec/step, loss=0.72173, avg_loss=0.70430]\n","Step 4548    [1.789 sec/step, loss=0.70960, avg_loss=0.70446]\n","Step 4549    [1.784 sec/step, loss=0.67673, avg_loss=0.70380]\n","Step 4550    [1.787 sec/step, loss=0.67808, avg_loss=0.70342]\n","Generated 32 batches of size 32 in 10.368 sec\n","Step 4551    [1.786 sec/step, loss=0.71697, avg_loss=0.70319]\n","Step 4552    [1.762 sec/step, loss=0.69744, avg_loss=0.70301]\n","Step 4553    [1.759 sec/step, loss=0.69523, avg_loss=0.70301]\n","Step 4554    [1.739 sec/step, loss=0.67813, avg_loss=0.70266]\n","Step 4555    [1.731 sec/step, loss=0.70154, avg_loss=0.70246]\n","Step 4556    [1.725 sec/step, loss=0.72231, avg_loss=0.70214]\n","Step 4557    [1.714 sec/step, loss=0.70837, avg_loss=0.70201]\n","Step 4558    [1.719 sec/step, loss=0.76449, avg_loss=0.70261]\n","Step 4559    [1.722 sec/step, loss=0.68505, avg_loss=0.70261]\n","Step 4560    [1.681 sec/step, loss=0.68432, avg_loss=0.70316]\n","Step 4561    [1.683 sec/step, loss=0.71980, avg_loss=0.70332]\n","Step 4562    [1.677 sec/step, loss=0.70112, avg_loss=0.70307]\n","Step 4563    [1.677 sec/step, loss=0.68525, avg_loss=0.70289]\n","Step 4564    [1.659 sec/step, loss=0.72910, avg_loss=0.70268]\n","Step 4565    [1.657 sec/step, loss=0.71249, avg_loss=0.70275]\n","Step 4566    [1.654 sec/step, loss=0.70729, avg_loss=0.70260]\n","Step 4567    [1.657 sec/step, loss=0.69828, avg_loss=0.70266]\n","Step 4568    [1.659 sec/step, loss=0.68165, avg_loss=0.70250]\n","Step 4569    [1.672 sec/step, loss=0.74012, avg_loss=0.70280]\n","Step 4570    [1.660 sec/step, loss=0.65813, avg_loss=0.70200]\n","Step 4571    [1.659 sec/step, loss=0.68884, avg_loss=0.70179]\n","Step 4572    [1.647 sec/step, loss=0.69793, avg_loss=0.70167]\n","Step 4573    [1.647 sec/step, loss=0.68236, avg_loss=0.70165]\n","Step 4574    [1.663 sec/step, loss=0.72168, avg_loss=0.70184]\n","Step 4575    [1.667 sec/step, loss=0.71246, avg_loss=0.70199]\n","Step 4576    [1.670 sec/step, loss=0.73365, avg_loss=0.70197]\n","Step 4577    [1.667 sec/step, loss=0.70665, avg_loss=0.70208]\n","Step 4578    [1.674 sec/step, loss=0.68887, avg_loss=0.70221]\n","Step 4579    [1.699 sec/step, loss=0.72900, avg_loss=0.70262]\n","Step 4580    [1.696 sec/step, loss=0.67352, avg_loss=0.70200]\n","Step 4581    [1.722 sec/step, loss=0.73793, avg_loss=0.70260]\n","Generated 32 batches of size 32 in 10.634 sec\n","Step 4582    [1.729 sec/step, loss=0.70394, avg_loss=0.70279]\n","Step 4583    [1.732 sec/step, loss=0.68505, avg_loss=0.70282]\n","Step 4584    [1.721 sec/step, loss=0.73510, avg_loss=0.70297]\n","Step 4585    [1.702 sec/step, loss=0.69786, avg_loss=0.70267]\n","Step 4586    [1.738 sec/step, loss=0.66802, avg_loss=0.70261]\n","Step 4587    [1.691 sec/step, loss=0.68996, avg_loss=0.70284]\n","Step 4588    [1.685 sec/step, loss=0.65608, avg_loss=0.70195]\n","Step 4589    [1.684 sec/step, loss=0.69891, avg_loss=0.70190]\n","Step 4590    [1.687 sec/step, loss=0.68564, avg_loss=0.70177]\n","Step 4591    [1.692 sec/step, loss=0.71437, avg_loss=0.70175]\n","Step 4592    [1.686 sec/step, loss=0.70032, avg_loss=0.70130]\n","Step 4593    [1.691 sec/step, loss=0.72267, avg_loss=0.70153]\n","Step 4594    [1.700 sec/step, loss=0.72456, avg_loss=0.70176]\n","Step 4595    [1.706 sec/step, loss=0.71030, avg_loss=0.70200]\n","Step 4596    [1.704 sec/step, loss=0.68827, avg_loss=0.70161]\n","Step 4597    [1.718 sec/step, loss=0.72950, avg_loss=0.70191]\n","Step 4598    [1.708 sec/step, loss=0.67925, avg_loss=0.70159]\n","Step 4599    [1.744 sec/step, loss=0.63118, avg_loss=0.70098]\n","Step 4600    [1.746 sec/step, loss=0.68528, avg_loss=0.70113]\n","Writing summary at step: 4600\n","Step 4601    [1.746 sec/step, loss=0.70757, avg_loss=0.70114]\n","Step 4602    [1.742 sec/step, loss=0.69267, avg_loss=0.70081]\n","Step 4603    [1.743 sec/step, loss=0.69202, avg_loss=0.70081]\n","Step 4604    [1.740 sec/step, loss=0.66677, avg_loss=0.70042]\n","Step 4605    [1.737 sec/step, loss=0.67182, avg_loss=0.69998]\n","Step 4606    [1.728 sec/step, loss=0.69549, avg_loss=0.69960]\n","Step 4607    [1.730 sec/step, loss=0.67334, avg_loss=0.69964]\n","Step 4608    [1.729 sec/step, loss=0.69487, avg_loss=0.69964]\n","Step 4609    [1.747 sec/step, loss=0.70122, avg_loss=0.69936]\n","Step 4610    [1.767 sec/step, loss=0.71438, avg_loss=0.69929]\n","Step 4611    [1.777 sec/step, loss=0.70526, avg_loss=0.69898]\n","Generated 32 batches of size 32 in 10.563 sec\n","Step 4612    [1.778 sec/step, loss=0.73243, avg_loss=0.69910]\n","Step 4613    [1.796 sec/step, loss=0.71486, avg_loss=0.69957]\n","Step 4614    [1.765 sec/step, loss=0.69936, avg_loss=0.69911]\n","Step 4615    [1.701 sec/step, loss=0.67675, avg_loss=0.69937]\n","Step 4616    [1.698 sec/step, loss=0.63425, avg_loss=0.69863]\n","Step 4617    [1.707 sec/step, loss=0.72736, avg_loss=0.69894]\n","Step 4618    [1.693 sec/step, loss=0.68325, avg_loss=0.69832]\n","Step 4619    [1.690 sec/step, loss=0.70330, avg_loss=0.69809]\n","Step 4620    [1.695 sec/step, loss=0.69750, avg_loss=0.69838]\n","Step 4621    [1.690 sec/step, loss=0.64013, avg_loss=0.69765]\n","Step 4622    [1.692 sec/step, loss=0.70336, avg_loss=0.69759]\n","Step 4623    [1.692 sec/step, loss=0.67386, avg_loss=0.69739]\n","Step 4624    [1.686 sec/step, loss=0.65809, avg_loss=0.69711]\n","Step 4625    [1.681 sec/step, loss=0.68105, avg_loss=0.69669]\n","Step 4626    [1.674 sec/step, loss=0.66379, avg_loss=0.69621]\n","Step 4627    [1.668 sec/step, loss=0.65330, avg_loss=0.69572]\n","Step 4628    [1.674 sec/step, loss=0.71177, avg_loss=0.69554]\n","Step 4629    [1.675 sec/step, loss=0.67569, avg_loss=0.69552]\n","Step 4630    [1.678 sec/step, loss=0.70200, avg_loss=0.69582]\n","Step 4631    [1.683 sec/step, loss=0.71958, avg_loss=0.69605]\n","Step 4632    [1.690 sec/step, loss=0.70593, avg_loss=0.69667]\n","Step 4633    [1.697 sec/step, loss=0.73456, avg_loss=0.69703]\n","Step 4634    [1.686 sec/step, loss=0.66953, avg_loss=0.69659]\n","Step 4635    [1.644 sec/step, loss=0.68796, avg_loss=0.69758]\n","Step 4636    [1.656 sec/step, loss=0.71104, avg_loss=0.69727]\n","Step 4637    [1.649 sec/step, loss=0.71271, avg_loss=0.69736]\n","Step 4638    [1.646 sec/step, loss=0.70542, avg_loss=0.69723]\n","Step 4639    [1.634 sec/step, loss=0.70174, avg_loss=0.69710]\n","Step 4640    [1.677 sec/step, loss=0.63047, avg_loss=0.69669]\n","Step 4641    [1.704 sec/step, loss=0.72856, avg_loss=0.69713]\n","Step 4642    [1.732 sec/step, loss=0.72131, avg_loss=0.69719]\n","Generated 32 batches of size 32 in 10.444 sec\n","Step 4643    [1.745 sec/step, loss=0.72793, avg_loss=0.69773]\n","Step 4644    [1.730 sec/step, loss=0.68173, avg_loss=0.69729]\n","Step 4645    [1.723 sec/step, loss=0.68477, avg_loss=0.69694]\n","Step 4646    [1.716 sec/step, loss=0.67661, avg_loss=0.69700]\n","Step 4647    [1.699 sec/step, loss=0.69193, avg_loss=0.69670]\n","Step 4648    [1.692 sec/step, loss=0.69769, avg_loss=0.69658]\n","Step 4649    [1.693 sec/step, loss=0.70375, avg_loss=0.69685]\n","Step 4650    [1.694 sec/step, loss=0.70482, avg_loss=0.69712]\n","Step 4651    [1.695 sec/step, loss=0.71672, avg_loss=0.69712]\n","Step 4652    [1.695 sec/step, loss=0.68021, avg_loss=0.69694]\n","Step 4653    [1.699 sec/step, loss=0.70604, avg_loss=0.69705]\n","Step 4654    [1.705 sec/step, loss=0.71549, avg_loss=0.69742]\n","Step 4655    [1.709 sec/step, loss=0.71458, avg_loss=0.69756]\n","Step 4656    [1.703 sec/step, loss=0.66516, avg_loss=0.69698]\n","Step 4657    [1.698 sec/step, loss=0.68876, avg_loss=0.69679]\n","Step 4658    [1.691 sec/step, loss=0.68433, avg_loss=0.69599]\n","Step 4659    [1.692 sec/step, loss=0.71452, avg_loss=0.69628]\n","Step 4660    [1.693 sec/step, loss=0.67608, avg_loss=0.69620]\n","Step 4661    [1.695 sec/step, loss=0.71129, avg_loss=0.69611]\n","Step 4662    [1.708 sec/step, loss=0.72488, avg_loss=0.69635]\n","Step 4663    [1.737 sec/step, loss=0.72055, avg_loss=0.69670]\n","Step 4664    [1.731 sec/step, loss=0.68340, avg_loss=0.69625]\n","Step 4665    [1.728 sec/step, loss=0.67567, avg_loss=0.69588]\n","Step 4666    [1.732 sec/step, loss=0.69587, avg_loss=0.69576]\n","Step 4667    [1.732 sec/step, loss=0.71702, avg_loss=0.69595]\n","Step 4668    [1.735 sec/step, loss=0.71178, avg_loss=0.69625]\n","Step 4669    [1.719 sec/step, loss=0.65451, avg_loss=0.69540]\n","Step 4670    [1.731 sec/step, loss=0.72665, avg_loss=0.69608]\n","Step 4671    [1.737 sec/step, loss=0.71092, avg_loss=0.69630]\n","Step 4672    [1.750 sec/step, loss=0.74675, avg_loss=0.69679]\n","Step 4673    [1.759 sec/step, loss=0.67297, avg_loss=0.69670]\n","Step 4674    [1.749 sec/step, loss=0.69178, avg_loss=0.69640]\n","Step 4675    [1.766 sec/step, loss=0.74158, avg_loss=0.69669]\n","Generated 32 batches of size 32 in 10.894 sec\n","Step 4676    [1.814 sec/step, loss=0.60779, avg_loss=0.69543]\n","Step 4677    [1.812 sec/step, loss=0.66656, avg_loss=0.69503]\n","Step 4678    [1.805 sec/step, loss=0.70144, avg_loss=0.69516]\n","Step 4679    [1.782 sec/step, loss=0.68667, avg_loss=0.69473]\n","Step 4680    [1.779 sec/step, loss=0.67547, avg_loss=0.69475]\n","Step 4681    [1.752 sec/step, loss=0.65339, avg_loss=0.69391]\n","Step 4682    [1.787 sec/step, loss=0.61388, avg_loss=0.69301]\n","Step 4683    [1.784 sec/step, loss=0.67130, avg_loss=0.69287]\n","Step 4684    [1.776 sec/step, loss=0.67274, avg_loss=0.69224]\n","Step 4685    [1.776 sec/step, loss=0.69790, avg_loss=0.69225]\n","Step 4686    [1.736 sec/step, loss=0.67518, avg_loss=0.69232]\n","Step 4687    [1.734 sec/step, loss=0.69513, avg_loss=0.69237]\n","Step 4688    [1.734 sec/step, loss=0.65070, avg_loss=0.69231]\n","Step 4689    [1.735 sec/step, loss=0.65789, avg_loss=0.69190]\n","Step 4690    [1.736 sec/step, loss=0.69971, avg_loss=0.69204]\n","Step 4691    [1.730 sec/step, loss=0.69164, avg_loss=0.69182]\n","Step 4692    [1.735 sec/step, loss=0.71703, avg_loss=0.69198]\n","Step 4693    [1.728 sec/step, loss=0.69476, avg_loss=0.69171]\n","Step 4694    [1.726 sec/step, loss=0.70370, avg_loss=0.69150]\n","Step 4695    [1.729 sec/step, loss=0.72341, avg_loss=0.69163]\n","Step 4696    [1.730 sec/step, loss=0.72249, avg_loss=0.69197]\n","Step 4697    [1.712 sec/step, loss=0.67749, avg_loss=0.69145]\n","Step 4698    [1.719 sec/step, loss=0.68758, avg_loss=0.69153]\n","Step 4699    [1.687 sec/step, loss=0.70162, avg_loss=0.69224]\n","Step 4700    [1.695 sec/step, loss=0.70975, avg_loss=0.69248]\n","Writing summary at step: 4700\n","Step 4701    [1.692 sec/step, loss=0.67270, avg_loss=0.69213]\n","Step 4702    [1.701 sec/step, loss=0.73319, avg_loss=0.69254]\n","Step 4703    [1.699 sec/step, loss=0.68358, avg_loss=0.69245]\n","Step 4704    [1.719 sec/step, loss=0.69316, avg_loss=0.69272]\n","Step 4705    [1.730 sec/step, loss=0.69308, avg_loss=0.69293]\n","Step 4706    [1.752 sec/step, loss=0.71198, avg_loss=0.69310]\n","Generated 32 batches of size 32 in 10.575 sec\n","Step 4707    [1.766 sec/step, loss=0.69726, avg_loss=0.69334]\n","Step 4708    [1.767 sec/step, loss=0.67650, avg_loss=0.69315]\n","Step 4709    [1.745 sec/step, loss=0.66079, avg_loss=0.69275]\n","Step 4710    [1.732 sec/step, loss=0.68512, avg_loss=0.69245]\n","Step 4711    [1.731 sec/step, loss=0.73874, avg_loss=0.69279]\n","Step 4712    [1.719 sec/step, loss=0.64503, avg_loss=0.69192]\n","Step 4713    [1.705 sec/step, loss=0.67540, avg_loss=0.69152]\n","Step 4714    [1.710 sec/step, loss=0.72791, avg_loss=0.69181]\n","Step 4715    [1.713 sec/step, loss=0.67800, avg_loss=0.69182]\n","Step 4716    [1.723 sec/step, loss=0.69886, avg_loss=0.69246]\n","Step 4717    [1.712 sec/step, loss=0.67112, avg_loss=0.69190]\n","Step 4718    [1.712 sec/step, loss=0.68468, avg_loss=0.69192]\n","Step 4719    [1.724 sec/step, loss=0.70572, avg_loss=0.69194]\n","Step 4720    [1.727 sec/step, loss=0.69964, avg_loss=0.69196]\n","Step 4721    [1.729 sec/step, loss=0.65860, avg_loss=0.69215]\n","Step 4722    [1.732 sec/step, loss=0.72198, avg_loss=0.69233]\n","Step 4723    [1.737 sec/step, loss=0.70588, avg_loss=0.69265]\n","Step 4724    [1.742 sec/step, loss=0.68939, avg_loss=0.69297]\n","Step 4725    [1.741 sec/step, loss=0.67231, avg_loss=0.69288]\n","Step 4726    [1.746 sec/step, loss=0.71212, avg_loss=0.69336]\n","Step 4727    [1.745 sec/step, loss=0.64554, avg_loss=0.69328]\n","Step 4728    [1.736 sec/step, loss=0.67351, avg_loss=0.69290]\n","Step 4729    [1.740 sec/step, loss=0.69813, avg_loss=0.69313]\n","Step 4730    [1.774 sec/step, loss=0.57787, avg_loss=0.69189]\n","Step 4731    [1.782 sec/step, loss=0.71760, avg_loss=0.69187]\n","Step 4732    [1.777 sec/step, loss=0.67699, avg_loss=0.69158]\n","Step 4733    [1.770 sec/step, loss=0.65764, avg_loss=0.69081]\n","Step 4734    [1.771 sec/step, loss=0.64872, avg_loss=0.69060]\n","Step 4735    [1.772 sec/step, loss=0.68057, avg_loss=0.69053]\n","Step 4736    [1.763 sec/step, loss=0.67231, avg_loss=0.69014]\n","Step 4737    [1.764 sec/step, loss=0.65811, avg_loss=0.68959]\n","Step 4738    [1.775 sec/step, loss=0.68231, avg_loss=0.68936]\n","Step 4739    [1.801 sec/step, loss=0.72156, avg_loss=0.68956]\n","Generated 32 batches of size 32 in 10.900 sec\n","Step 4740    [1.773 sec/step, loss=0.71298, avg_loss=0.69038]\n","Step 4741    [1.743 sec/step, loss=0.69412, avg_loss=0.69004]\n","Step 4742    [1.708 sec/step, loss=0.63362, avg_loss=0.68916]\n","Step 4743    [1.697 sec/step, loss=0.69433, avg_loss=0.68883]\n","Step 4744    [1.701 sec/step, loss=0.69605, avg_loss=0.68897]\n","Step 4745    [1.696 sec/step, loss=0.65884, avg_loss=0.68871]\n","Step 4746    [1.707 sec/step, loss=0.71267, avg_loss=0.68907]\n","Step 4747    [1.702 sec/step, loss=0.64019, avg_loss=0.68855]\n","Step 4748    [1.713 sec/step, loss=0.70573, avg_loss=0.68863]\n","Step 4749    [1.707 sec/step, loss=0.69401, avg_loss=0.68854]\n","Step 4750    [1.702 sec/step, loss=0.70050, avg_loss=0.68849]\n","Step 4751    [1.699 sec/step, loss=0.67187, avg_loss=0.68805]\n","Step 4752    [1.719 sec/step, loss=0.73884, avg_loss=0.68863]\n","Step 4753    [1.723 sec/step, loss=0.70039, avg_loss=0.68857]\n","Step 4754    [1.724 sec/step, loss=0.71458, avg_loss=0.68857]\n","Step 4755    [1.722 sec/step, loss=0.67589, avg_loss=0.68818]\n","Step 4756    [1.721 sec/step, loss=0.65696, avg_loss=0.68810]\n","Step 4757    [1.729 sec/step, loss=0.68381, avg_loss=0.68805]\n","Step 4758    [1.727 sec/step, loss=0.68372, avg_loss=0.68804]\n","Step 4759    [1.735 sec/step, loss=0.73650, avg_loss=0.68826]\n","Step 4760    [1.734 sec/step, loss=0.68745, avg_loss=0.68837]\n","Step 4761    [1.729 sec/step, loss=0.67959, avg_loss=0.68806]\n","Step 4762    [1.720 sec/step, loss=0.72091, avg_loss=0.68802]\n","Step 4763    [1.699 sec/step, loss=0.69041, avg_loss=0.68772]\n","Step 4764    [1.702 sec/step, loss=0.68087, avg_loss=0.68769]\n","Step 4765    [1.707 sec/step, loss=0.71204, avg_loss=0.68805]\n","Step 4766    [1.709 sec/step, loss=0.70908, avg_loss=0.68819]\n","Step 4767    [1.702 sec/step, loss=0.67365, avg_loss=0.68775]\n","Step 4768    [1.709 sec/step, loss=0.66137, avg_loss=0.68725]\n","Generated 32 batches of size 32 in 10.299 sec\n","Step 4769    [1.784 sec/step, loss=0.61185, avg_loss=0.68682]\n","Step 4770    [1.777 sec/step, loss=0.70185, avg_loss=0.68657]\n","Step 4771    [1.770 sec/step, loss=0.66649, avg_loss=0.68613]\n","Step 4772    [1.757 sec/step, loss=0.69744, avg_loss=0.68564]\n","Step 4773    [1.758 sec/step, loss=0.70235, avg_loss=0.68593]\n","Step 4774    [1.746 sec/step, loss=0.68252, avg_loss=0.68584]\n","Step 4775    [1.731 sec/step, loss=0.70901, avg_loss=0.68551]\n","Step 4776    [1.674 sec/step, loss=0.65300, avg_loss=0.68596]\n","Step 4777    [1.683 sec/step, loss=0.71946, avg_loss=0.68649]\n","Step 4778    [1.688 sec/step, loss=0.70139, avg_loss=0.68649]\n","Step 4779    [1.687 sec/step, loss=0.68205, avg_loss=0.68645]\n","Step 4780    [1.691 sec/step, loss=0.72182, avg_loss=0.68691]\n","Step 4781    [1.695 sec/step, loss=0.68584, avg_loss=0.68723]\n","Step 4782    [1.669 sec/step, loss=0.71221, avg_loss=0.68822]\n","Step 4783    [1.675 sec/step, loss=0.70095, avg_loss=0.68851]\n","Step 4784    [1.683 sec/step, loss=0.72139, avg_loss=0.68900]\n","Step 4785    [1.701 sec/step, loss=0.72231, avg_loss=0.68925]\n","Step 4786    [1.704 sec/step, loss=0.68186, avg_loss=0.68931]\n","Step 4787    [1.710 sec/step, loss=0.69411, avg_loss=0.68930]\n","Step 4788    [1.712 sec/step, loss=0.67944, avg_loss=0.68959]\n","Step 4789    [1.710 sec/step, loss=0.66089, avg_loss=0.68962]\n","Step 4790    [1.709 sec/step, loss=0.68784, avg_loss=0.68950]\n","Step 4791    [1.706 sec/step, loss=0.66043, avg_loss=0.68919]\n","Step 4792    [1.702 sec/step, loss=0.70276, avg_loss=0.68905]\n","Step 4793    [1.703 sec/step, loss=0.68815, avg_loss=0.68898]\n","Step 4794    [1.699 sec/step, loss=0.68717, avg_loss=0.68881]\n","Step 4795    [1.701 sec/step, loss=0.71041, avg_loss=0.68868]\n","Step 4796    [1.691 sec/step, loss=0.64718, avg_loss=0.68793]\n","Step 4797    [1.694 sec/step, loss=0.72106, avg_loss=0.68837]\n","Step 4798    [1.692 sec/step, loss=0.68986, avg_loss=0.68839]\n","Step 4799    [1.693 sec/step, loss=0.71515, avg_loss=0.68853]\n","Step 4800    [1.689 sec/step, loss=0.65886, avg_loss=0.68802]\n","Writing summary at step: 4800\n","Generated 32 batches of size 32 in 10.431 sec\n","Step 4801    [1.755 sec/step, loss=0.65868, avg_loss=0.68788]\n","Step 4802    [1.743 sec/step, loss=0.66519, avg_loss=0.68720]\n","Step 4803    [1.742 sec/step, loss=0.68202, avg_loss=0.68718]\n","Step 4804    [1.730 sec/step, loss=0.71501, avg_loss=0.68740]\n","Step 4805    [1.717 sec/step, loss=0.65761, avg_loss=0.68704]\n","Step 4806    [1.698 sec/step, loss=0.69806, avg_loss=0.68691]\n","Step 4807    [1.685 sec/step, loss=0.67215, avg_loss=0.68665]\n","Step 4808    [1.684 sec/step, loss=0.67803, avg_loss=0.68667]\n","Step 4809    [1.685 sec/step, loss=0.66039, avg_loss=0.68667]\n","Step 4810    [1.673 sec/step, loss=0.69641, avg_loss=0.68678]\n","Step 4811    [1.655 sec/step, loss=0.65828, avg_loss=0.68597]\n","Step 4812    [1.659 sec/step, loss=0.66547, avg_loss=0.68618]\n","Step 4813    [1.663 sec/step, loss=0.66944, avg_loss=0.68612]\n","Step 4814    [1.654 sec/step, loss=0.70124, avg_loss=0.68585]\n","Step 4815    [1.696 sec/step, loss=0.62184, avg_loss=0.68529]\n","Step 4816    [1.690 sec/step, loss=0.68614, avg_loss=0.68516]\n","Step 4817    [1.702 sec/step, loss=0.71820, avg_loss=0.68563]\n","Step 4818    [1.698 sec/step, loss=0.66144, avg_loss=0.68540]\n","Step 4819    [1.681 sec/step, loss=0.62822, avg_loss=0.68463]\n","Step 4820    [1.676 sec/step, loss=0.68817, avg_loss=0.68451]\n","Step 4821    [1.680 sec/step, loss=0.70542, avg_loss=0.68498]\n","Step 4822    [1.671 sec/step, loss=0.66281, avg_loss=0.68439]\n","Step 4823    [1.668 sec/step, loss=0.67543, avg_loss=0.68408]\n","Step 4824    [1.670 sec/step, loss=0.68670, avg_loss=0.68406]\n","Step 4825    [1.685 sec/step, loss=0.69608, avg_loss=0.68429]\n","Step 4826    [1.692 sec/step, loss=0.72619, avg_loss=0.68444]\n","Step 4827    [1.698 sec/step, loss=0.70222, avg_loss=0.68500]\n","Step 4828    [1.699 sec/step, loss=0.69213, avg_loss=0.68519]\n","Step 4829    [1.694 sec/step, loss=0.65416, avg_loss=0.68475]\n","Step 4830    [1.663 sec/step, loss=0.68712, avg_loss=0.68584]\n","Step 4831    [1.662 sec/step, loss=0.68271, avg_loss=0.68549]\n","Step 4832    [1.667 sec/step, loss=0.68967, avg_loss=0.68562]\n","Step 4833    [1.685 sec/step, loss=0.70693, avg_loss=0.68611]\n","Generated 32 batches of size 32 in 10.318 sec\n","Step 4834    [1.709 sec/step, loss=0.71110, avg_loss=0.68674]\n","Step 4835    [1.709 sec/step, loss=0.68843, avg_loss=0.68681]\n","Step 4836    [1.696 sec/step, loss=0.65387, avg_loss=0.68663]\n","Step 4837    [1.694 sec/step, loss=0.67536, avg_loss=0.68680]\n","Step 4838    [1.688 sec/step, loss=0.70696, avg_loss=0.68705]\n","Step 4839    [1.682 sec/step, loss=0.73283, avg_loss=0.68716]\n","Step 4840    [1.670 sec/step, loss=0.69238, avg_loss=0.68696]\n","Step 4841    [1.673 sec/step, loss=0.69288, avg_loss=0.68694]\n","Step 4842    [1.691 sec/step, loss=0.71160, avg_loss=0.68772]\n","Step 4843    [1.692 sec/step, loss=0.67799, avg_loss=0.68756]\n","Step 4844    [1.692 sec/step, loss=0.68445, avg_loss=0.68744]\n","Step 4845    [1.695 sec/step, loss=0.65681, avg_loss=0.68742]\n","Step 4846    [1.691 sec/step, loss=0.69889, avg_loss=0.68729]\n","Step 4847    [1.694 sec/step, loss=0.64461, avg_loss=0.68733]\n","Step 4848    [1.718 sec/step, loss=0.57675, avg_loss=0.68604]\n","Step 4849    [1.722 sec/step, loss=0.71195, avg_loss=0.68622]\n","Step 4850    [1.724 sec/step, loss=0.67414, avg_loss=0.68596]\n","Step 4851    [1.730 sec/step, loss=0.69859, avg_loss=0.68622]\n","Step 4852    [1.719 sec/step, loss=0.70740, avg_loss=0.68591]\n","Step 4853    [1.708 sec/step, loss=0.67018, avg_loss=0.68561]\n","Step 4854    [1.707 sec/step, loss=0.69535, avg_loss=0.68541]\n","Step 4855    [1.703 sec/step, loss=0.64424, avg_loss=0.68510]\n","Step 4856    [1.706 sec/step, loss=0.67995, avg_loss=0.68533]\n","Step 4857    [1.705 sec/step, loss=0.70864, avg_loss=0.68558]\n","Step 4858    [1.706 sec/step, loss=0.67067, avg_loss=0.68545]\n","Step 4859    [1.696 sec/step, loss=0.65077, avg_loss=0.68459]\n","Step 4860    [1.694 sec/step, loss=0.63716, avg_loss=0.68409]\n","Step 4861    [1.703 sec/step, loss=0.72058, avg_loss=0.68450]\n","Step 4862    [1.700 sec/step, loss=0.68226, avg_loss=0.68411]\n","Step 4863    [1.706 sec/step, loss=0.66716, avg_loss=0.68388]\n","Step 4864    [1.713 sec/step, loss=0.67100, avg_loss=0.68378]\n","Step 4865    [1.726 sec/step, loss=0.71033, avg_loss=0.68376]\n","Step 4866    [1.726 sec/step, loss=0.66206, avg_loss=0.68329]\n","Step 4867    [1.734 sec/step, loss=0.64179, avg_loss=0.68297]\n","Generated 32 batches of size 32 in 10.937 sec\n","Step 4868    [1.735 sec/step, loss=0.72391, avg_loss=0.68360]\n","Step 4869    [1.659 sec/step, loss=0.65601, avg_loss=0.68404]\n","Step 4870    [1.663 sec/step, loss=0.69302, avg_loss=0.68395]\n","Step 4871    [1.682 sec/step, loss=0.68996, avg_loss=0.68418]\n","Step 4872    [1.682 sec/step, loss=0.68135, avg_loss=0.68402]\n","Step 4873    [1.695 sec/step, loss=0.75476, avg_loss=0.68455]\n","Step 4874    [1.703 sec/step, loss=0.69224, avg_loss=0.68465]\n","Step 4875    [1.696 sec/step, loss=0.67627, avg_loss=0.68432]\n","Step 4876    [1.708 sec/step, loss=0.71226, avg_loss=0.68491]\n","Step 4877    [1.705 sec/step, loss=0.69201, avg_loss=0.68464]\n","Step 4878    [1.708 sec/step, loss=0.71439, avg_loss=0.68477]\n","Step 4879    [1.744 sec/step, loss=0.65923, avg_loss=0.68454]\n","Step 4880    [1.737 sec/step, loss=0.67627, avg_loss=0.68408]\n","Step 4881    [1.742 sec/step, loss=0.70343, avg_loss=0.68426]\n","Step 4882    [1.729 sec/step, loss=0.68579, avg_loss=0.68399]\n","Step 4883    [1.728 sec/step, loss=0.66906, avg_loss=0.68368]\n","Step 4884    [1.721 sec/step, loss=0.66350, avg_loss=0.68310]\n","Step 4885    [1.715 sec/step, loss=0.71329, avg_loss=0.68301]\n","Step 4886    [1.714 sec/step, loss=0.68823, avg_loss=0.68307]\n","Step 4887    [1.712 sec/step, loss=0.69213, avg_loss=0.68305]\n","Step 4888    [1.712 sec/step, loss=0.67571, avg_loss=0.68301]\n","Step 4889    [1.711 sec/step, loss=0.64378, avg_loss=0.68284]\n","Step 4890    [1.706 sec/step, loss=0.65330, avg_loss=0.68250]\n","Step 4891    [1.705 sec/step, loss=0.65544, avg_loss=0.68245]\n","Step 4892    [1.710 sec/step, loss=0.70511, avg_loss=0.68247]\n","Step 4893    [1.711 sec/step, loss=0.70538, avg_loss=0.68264]\n","Step 4894    [1.709 sec/step, loss=0.70044, avg_loss=0.68277]\n","Step 4895    [1.706 sec/step, loss=0.64992, avg_loss=0.68217]\n","Step 4896    [1.720 sec/step, loss=0.70236, avg_loss=0.68272]\n","Step 4897    [1.724 sec/step, loss=0.67806, avg_loss=0.68229]\n","Step 4898    [1.737 sec/step, loss=0.69966, avg_loss=0.68239]\n","Generated 32 batches of size 32 in 10.576 sec\n","Step 4899    [1.744 sec/step, loss=0.67164, avg_loss=0.68195]\n","Step 4900    [1.745 sec/step, loss=0.69132, avg_loss=0.68228]\n","Writing summary at step: 4900\n","Step 4901    [1.680 sec/step, loss=0.69371, avg_loss=0.68263]\n","Step 4902    [1.692 sec/step, loss=0.70436, avg_loss=0.68302]\n","Step 4903    [1.694 sec/step, loss=0.68211, avg_loss=0.68302]\n","Step 4904    [1.687 sec/step, loss=0.64214, avg_loss=0.68229]\n","Step 4905    [1.686 sec/step, loss=0.65884, avg_loss=0.68231]\n","Step 4906    [1.682 sec/step, loss=0.65751, avg_loss=0.68190]\n","Step 4907    [1.683 sec/step, loss=0.67883, avg_loss=0.68197]\n","Step 4908    [1.689 sec/step, loss=0.69393, avg_loss=0.68213]\n","Step 4909    [1.731 sec/step, loss=0.62531, avg_loss=0.68178]\n","Step 4910    [1.727 sec/step, loss=0.63778, avg_loss=0.68119]\n","Step 4911    [1.736 sec/step, loss=0.72135, avg_loss=0.68182]\n","Step 4912    [1.734 sec/step, loss=0.67432, avg_loss=0.68191]\n","Step 4913    [1.740 sec/step, loss=0.71213, avg_loss=0.68233]\n","Step 4914    [1.739 sec/step, loss=0.67185, avg_loss=0.68204]\n","Step 4915    [1.697 sec/step, loss=0.66740, avg_loss=0.68250]\n","Step 4916    [1.701 sec/step, loss=0.69493, avg_loss=0.68258]\n","Step 4917    [1.692 sec/step, loss=0.66902, avg_loss=0.68209]\n","Step 4918    [1.700 sec/step, loss=0.68825, avg_loss=0.68236]\n","Step 4919    [1.715 sec/step, loss=0.70485, avg_loss=0.68313]\n","Step 4920    [1.717 sec/step, loss=0.68791, avg_loss=0.68312]\n","Step 4921    [1.714 sec/step, loss=0.67018, avg_loss=0.68277]\n","Step 4922    [1.728 sec/step, loss=0.73009, avg_loss=0.68344]\n","Step 4923    [1.747 sec/step, loss=0.71538, avg_loss=0.68384]\n","Step 4924    [1.742 sec/step, loss=0.65838, avg_loss=0.68356]\n","Step 4925    [1.726 sec/step, loss=0.66974, avg_loss=0.68330]\n","Step 4926    [1.728 sec/step, loss=0.69246, avg_loss=0.68296]\n","Step 4927    [1.742 sec/step, loss=0.69234, avg_loss=0.68286]\n","Step 4928    [1.747 sec/step, loss=0.64923, avg_loss=0.68243]\n","Step 4929    [1.765 sec/step, loss=0.69347, avg_loss=0.68283]\n","Generated 32 batches of size 32 in 10.926 sec\n","Step 4930    [1.770 sec/step, loss=0.67559, avg_loss=0.68271]\n","Step 4931    [1.757 sec/step, loss=0.66180, avg_loss=0.68250]\n","Step 4932    [1.757 sec/step, loss=0.70378, avg_loss=0.68264]\n","Step 4933    [1.738 sec/step, loss=0.68247, avg_loss=0.68240]\n","Step 4934    [1.714 sec/step, loss=0.66969, avg_loss=0.68198]\n","Step 4935    [1.714 sec/step, loss=0.66998, avg_loss=0.68180]\n","Step 4936    [1.717 sec/step, loss=0.65871, avg_loss=0.68185]\n","Step 4937    [1.713 sec/step, loss=0.63545, avg_loss=0.68145]\n","Step 4938    [1.714 sec/step, loss=0.70023, avg_loss=0.68138]\n","Step 4939    [1.694 sec/step, loss=0.66640, avg_loss=0.68072]\n","Step 4940    [1.698 sec/step, loss=0.69441, avg_loss=0.68074]\n","Step 4941    [1.731 sec/step, loss=0.60053, avg_loss=0.67981]\n","Step 4942    [1.719 sec/step, loss=0.71307, avg_loss=0.67983]\n","Step 4943    [1.721 sec/step, loss=0.71253, avg_loss=0.68017]\n","Step 4944    [1.719 sec/step, loss=0.68338, avg_loss=0.68016]\n","Step 4945    [1.737 sec/step, loss=0.68702, avg_loss=0.68047]\n","Step 4946    [1.735 sec/step, loss=0.67678, avg_loss=0.68024]\n","Step 4947    [1.735 sec/step, loss=0.67033, avg_loss=0.68050]\n","Step 4948    [1.693 sec/step, loss=0.65981, avg_loss=0.68133]\n","Step 4949    [1.694 sec/step, loss=0.67833, avg_loss=0.68100]\n","Step 4950    [1.698 sec/step, loss=0.71061, avg_loss=0.68136]\n","Step 4951    [1.688 sec/step, loss=0.64051, avg_loss=0.68078]\n","Step 4952    [1.689 sec/step, loss=0.70861, avg_loss=0.68079]\n","Step 4953    [1.701 sec/step, loss=0.70318, avg_loss=0.68112]\n","Step 4954    [1.699 sec/step, loss=0.68315, avg_loss=0.68100]\n","Step 4955    [1.701 sec/step, loss=0.68352, avg_loss=0.68139]\n","Step 4956    [1.703 sec/step, loss=0.67416, avg_loss=0.68133]\n","Step 4957    [1.699 sec/step, loss=0.66122, avg_loss=0.68086]\n","Step 4958    [1.706 sec/step, loss=0.67906, avg_loss=0.68094]\n","Step 4959    [1.740 sec/step, loss=0.72205, avg_loss=0.68166]\n","Step 4960    [1.754 sec/step, loss=0.68805, avg_loss=0.68217]\n","Generated 32 batches of size 32 in 10.490 sec\n","Step 4961    [1.757 sec/step, loss=0.70729, avg_loss=0.68203]\n","Step 4962    [1.754 sec/step, loss=0.64543, avg_loss=0.68166]\n","Step 4963    [1.740 sec/step, loss=0.65837, avg_loss=0.68158]\n","Step 4964    [1.730 sec/step, loss=0.65089, avg_loss=0.68138]\n","Step 4965    [1.719 sec/step, loss=0.70525, avg_loss=0.68133]\n","Step 4966    [1.717 sec/step, loss=0.69092, avg_loss=0.68161]\n","Step 4967    [1.719 sec/step, loss=0.71039, avg_loss=0.68230]\n","Step 4968    [1.712 sec/step, loss=0.70155, avg_loss=0.68208]\n","Step 4969    [1.713 sec/step, loss=0.65272, avg_loss=0.68204]\n","Step 4970    [1.709 sec/step, loss=0.69863, avg_loss=0.68210]\n","Step 4971    [1.691 sec/step, loss=0.65579, avg_loss=0.68176]\n","Step 4972    [1.696 sec/step, loss=0.66385, avg_loss=0.68158]\n","Step 4973    [1.683 sec/step, loss=0.70402, avg_loss=0.68108]\n","Step 4974    [1.688 sec/step, loss=0.70758, avg_loss=0.68123]\n","Step 4975    [1.688 sec/step, loss=0.65591, avg_loss=0.68103]\n","Step 4976    [1.679 sec/step, loss=0.66016, avg_loss=0.68050]\n","Step 4977    [1.675 sec/step, loss=0.65951, avg_loss=0.68018]\n","Step 4978    [1.675 sec/step, loss=0.70175, avg_loss=0.68005]\n","Step 4979    [1.663 sec/step, loss=0.70807, avg_loss=0.68054]\n","Step 4980    [1.683 sec/step, loss=0.72527, avg_loss=0.68103]\n","Step 4981    [1.674 sec/step, loss=0.62248, avg_loss=0.68022]\n","Step 4982    [1.674 sec/step, loss=0.66507, avg_loss=0.68001]\n","Step 4983    [1.707 sec/step, loss=0.59227, avg_loss=0.67925]\n","Step 4984    [1.706 sec/step, loss=0.65919, avg_loss=0.67920]\n","Step 4985    [1.694 sec/step, loss=0.68007, avg_loss=0.67887]\n","Step 4986    [1.699 sec/step, loss=0.69664, avg_loss=0.67896]\n","Step 4987    [1.691 sec/step, loss=0.65246, avg_loss=0.67856]\n","Step 4988    [1.691 sec/step, loss=0.69156, avg_loss=0.67872]\n","Step 4989    [1.695 sec/step, loss=0.65921, avg_loss=0.67887]\n","Step 4990    [1.712 sec/step, loss=0.67897, avg_loss=0.67913]\n","Step 4991    [1.723 sec/step, loss=0.65405, avg_loss=0.67911]\n","Step 4992    [1.734 sec/step, loss=0.70975, avg_loss=0.67916]\n","Step 4993    [1.743 sec/step, loss=0.68275, avg_loss=0.67893]\n","Generated 32 batches of size 32 in 10.812 sec\n","Step 4994    [1.748 sec/step, loss=0.67344, avg_loss=0.67866]\n","Step 4995    [1.745 sec/step, loss=0.68024, avg_loss=0.67897]\n","Step 4996    [1.735 sec/step, loss=0.67432, avg_loss=0.67869]\n","Step 4997    [1.726 sec/step, loss=0.66029, avg_loss=0.67851]\n","Step 4998    [1.710 sec/step, loss=0.65048, avg_loss=0.67802]\n","Step 4999    [1.703 sec/step, loss=0.69285, avg_loss=0.67823]\n","Step 5000    [1.717 sec/step, loss=0.73104, avg_loss=0.67863]\n","Writing summary at step: 5000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Training korean : Use jamo\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12600 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12619 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50620 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44404 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46523 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51200 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47111 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51089 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45936 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45576 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53356 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 53076 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12600 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12619 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50620 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44404 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46523 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51200 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47111 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51089 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45936 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45576 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53356 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 53076 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/train-step-000005000-align000.png\n","100% 1/1 [00:04<00:00,  4.61s/it]\n","Test finished for step 5000.\n","  0% 0/2 [00:00<?, ?it/s]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000005000-align000.png\n"," 50% 1/2 [00:04<00:04,  4.10s/it]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000005000-align001.png\n","100% 2/2 [00:08<00:00,  4.06s/it]\n","Test finished for step 5000.\n","Step 5001    [1.715 sec/step, loss=0.63597, avg_loss=0.67805]\n","Step 5002    [1.706 sec/step, loss=0.66395, avg_loss=0.67765]\n","Step 5003    [1.706 sec/step, loss=0.67627, avg_loss=0.67759]\n","Step 5004    [1.707 sec/step, loss=0.62326, avg_loss=0.67740]\n","Step 5005    [1.709 sec/step, loss=0.65799, avg_loss=0.67739]\n","Step 5006    [1.704 sec/step, loss=0.65157, avg_loss=0.67733]\n","Step 5007    [1.708 sec/step, loss=0.68850, avg_loss=0.67743]\n","Step 5008    [1.708 sec/step, loss=0.69126, avg_loss=0.67740]\n","Step 5009    [1.668 sec/step, loss=0.67596, avg_loss=0.67791]\n","Step 5010    [1.676 sec/step, loss=0.70326, avg_loss=0.67856]\n","Step 5011    [1.666 sec/step, loss=0.67959, avg_loss=0.67814]\n","Step 5012    [1.670 sec/step, loss=0.66415, avg_loss=0.67804]\n","Step 5013    [1.673 sec/step, loss=0.69848, avg_loss=0.67791]\n","Step 5014    [1.672 sec/step, loss=0.66163, avg_loss=0.67780]\n","Step 5015    [1.669 sec/step, loss=0.64900, avg_loss=0.67762]\n","Step 5016    [1.665 sec/step, loss=0.66825, avg_loss=0.67735]\n","Step 5017    [1.665 sec/step, loss=0.67145, avg_loss=0.67738]\n","Step 5018    [1.664 sec/step, loss=0.70754, avg_loss=0.67757]\n","Step 5019    [1.666 sec/step, loss=0.69522, avg_loss=0.67747]\n","Step 5020    [1.686 sec/step, loss=0.69955, avg_loss=0.67759]\n","Step 5021    [1.704 sec/step, loss=0.66690, avg_loss=0.67756]\n","Step 5022    [1.712 sec/step, loss=0.71039, avg_loss=0.67736]\n","Generated 32 batches of size 32 in 10.145 sec\n","Step 5023    [1.705 sec/step, loss=0.69102, avg_loss=0.67712]\n","Step 5024    [1.708 sec/step, loss=0.67541, avg_loss=0.67729]\n","Step 5025    [1.713 sec/step, loss=0.69329, avg_loss=0.67752]\n","Step 5026    [1.701 sec/step, loss=0.66743, avg_loss=0.67727]\n","Step 5027    [1.687 sec/step, loss=0.68155, avg_loss=0.67716]\n","Step 5028    [1.719 sec/step, loss=0.62348, avg_loss=0.67691]\n","Step 5029    [1.708 sec/step, loss=0.68390, avg_loss=0.67681]\n","Step 5030    [1.695 sec/step, loss=0.66053, avg_loss=0.67666]\n","Step 5031    [1.715 sec/step, loss=0.71746, avg_loss=0.67722]\n","Step 5032    [1.713 sec/step, loss=0.70357, avg_loss=0.67721]\n","Step 5033    [1.721 sec/step, loss=0.71317, avg_loss=0.67752]\n","Step 5034    [1.721 sec/step, loss=0.66770, avg_loss=0.67750]\n","Step 5035    [1.726 sec/step, loss=0.69517, avg_loss=0.67775]\n","Step 5036    [1.729 sec/step, loss=0.69154, avg_loss=0.67808]\n","Step 5037    [1.735 sec/step, loss=0.67904, avg_loss=0.67852]\n","Step 5038    [1.732 sec/step, loss=0.68497, avg_loss=0.67837]\n","Step 5039    [1.735 sec/step, loss=0.69182, avg_loss=0.67862]\n","Step 5040    [1.739 sec/step, loss=0.69592, avg_loss=0.67863]\n","Step 5041    [1.702 sec/step, loss=0.65647, avg_loss=0.67919]\n","Step 5042    [1.702 sec/step, loss=0.66779, avg_loss=0.67874]\n","Step 5043    [1.703 sec/step, loss=0.70327, avg_loss=0.67865]\n","Step 5044    [1.703 sec/step, loss=0.66159, avg_loss=0.67843]\n","Step 5045    [1.694 sec/step, loss=0.71316, avg_loss=0.67869]\n","Step 5046    [1.692 sec/step, loss=0.66196, avg_loss=0.67854]\n","Step 5047    [1.693 sec/step, loss=0.68305, avg_loss=0.67867]\n","Step 5048    [1.707 sec/step, loss=0.71030, avg_loss=0.67918]\n","Step 5049    [1.732 sec/step, loss=0.64641, avg_loss=0.67886]\n","Step 5050    [1.726 sec/step, loss=0.65633, avg_loss=0.67831]\n","Step 5051    [1.726 sec/step, loss=0.64964, avg_loss=0.67841]\n","Step 5052    [1.729 sec/step, loss=0.66849, avg_loss=0.67800]\n","Step 5053    [1.737 sec/step, loss=0.68577, avg_loss=0.67783]\n","Step 5054    [1.755 sec/step, loss=0.72091, avg_loss=0.67821]\n","Step 5055    [1.758 sec/step, loss=0.63979, avg_loss=0.67777]\n","Generated 32 batches of size 32 in 10.555 sec\n","Step 5056    [1.756 sec/step, loss=0.65633, avg_loss=0.67759]\n","Step 5057    [1.752 sec/step, loss=0.65769, avg_loss=0.67756]\n","Step 5058    [1.743 sec/step, loss=0.67102, avg_loss=0.67748]\n","Step 5059    [1.709 sec/step, loss=0.66974, avg_loss=0.67695]\n","Step 5060    [1.698 sec/step, loss=0.66631, avg_loss=0.67674]\n","Step 5061    [1.687 sec/step, loss=0.66781, avg_loss=0.67634]\n","Step 5062    [1.689 sec/step, loss=0.68841, avg_loss=0.67677]\n","Step 5063    [1.697 sec/step, loss=0.67457, avg_loss=0.67693]\n","Step 5064    [1.704 sec/step, loss=0.70861, avg_loss=0.67751]\n","Step 5065    [1.695 sec/step, loss=0.65057, avg_loss=0.67696]\n","Step 5066    [1.732 sec/step, loss=0.60044, avg_loss=0.67606]\n","Step 5067    [1.723 sec/step, loss=0.65433, avg_loss=0.67550]\n","Step 5068    [1.723 sec/step, loss=0.70374, avg_loss=0.67552]\n","Step 5069    [1.727 sec/step, loss=0.70389, avg_loss=0.67603]\n","Step 5070    [1.730 sec/step, loss=0.70620, avg_loss=0.67611]\n","Step 5071    [1.729 sec/step, loss=0.66935, avg_loss=0.67624]\n","Step 5072    [1.732 sec/step, loss=0.70034, avg_loss=0.67661]\n","Step 5073    [1.727 sec/step, loss=0.67595, avg_loss=0.67633]\n","Step 5074    [1.725 sec/step, loss=0.73630, avg_loss=0.67661]\n","Step 5075    [1.733 sec/step, loss=0.69434, avg_loss=0.67700]\n","Step 5076    [1.733 sec/step, loss=0.67567, avg_loss=0.67715]\n","Step 5077    [1.732 sec/step, loss=0.68186, avg_loss=0.67738]\n","Step 5078    [1.723 sec/step, loss=0.64472, avg_loss=0.67681]\n","Step 5079    [1.698 sec/step, loss=0.68009, avg_loss=0.67653]\n","Step 5080    [1.694 sec/step, loss=0.70330, avg_loss=0.67631]\n","Step 5081    [1.702 sec/step, loss=0.69679, avg_loss=0.67705]\n","Step 5082    [1.701 sec/step, loss=0.66076, avg_loss=0.67701]\n","Step 5083    [1.664 sec/step, loss=0.63254, avg_loss=0.67741]\n","Step 5084    [1.682 sec/step, loss=0.68072, avg_loss=0.67763]\n","Step 5085    [1.683 sec/step, loss=0.68399, avg_loss=0.67766]\n","Step 5086    [1.680 sec/step, loss=0.64794, avg_loss=0.67718]\n","Step 5087    [1.695 sec/step, loss=0.67495, avg_loss=0.67740]\n","Step 5088    [1.705 sec/step, loss=0.69077, avg_loss=0.67739]\n","Generated 32 batches of size 32 in 10.721 sec\n","Step 5089    [1.724 sec/step, loss=0.73424, avg_loss=0.67814]\n","Step 5090    [1.718 sec/step, loss=0.70593, avg_loss=0.67841]\n","Step 5091    [1.710 sec/step, loss=0.67018, avg_loss=0.67858]\n","Step 5092    [1.701 sec/step, loss=0.71433, avg_loss=0.67862]\n","Step 5093    [1.691 sec/step, loss=0.67999, avg_loss=0.67859]\n","Step 5094    [1.689 sec/step, loss=0.66875, avg_loss=0.67855]\n","Step 5095    [1.688 sec/step, loss=0.68196, avg_loss=0.67856]\n","Step 5096    [1.688 sec/step, loss=0.65203, avg_loss=0.67834]\n","Step 5097    [1.699 sec/step, loss=0.70320, avg_loss=0.67877]\n","Step 5098    [1.714 sec/step, loss=0.71685, avg_loss=0.67943]\n","Step 5099    [1.719 sec/step, loss=0.70278, avg_loss=0.67953]\n","Step 5100    [1.705 sec/step, loss=0.68916, avg_loss=0.67911]\n","Writing summary at step: 5100\n","Step 5101    [1.706 sec/step, loss=0.67915, avg_loss=0.67955]\n","Step 5102    [1.705 sec/step, loss=0.65891, avg_loss=0.67950]\n","Step 5103    [1.745 sec/step, loss=0.60519, avg_loss=0.67879]\n","Step 5104    [1.754 sec/step, loss=0.69541, avg_loss=0.67951]\n","Step 5105    [1.751 sec/step, loss=0.66402, avg_loss=0.67957]\n","Step 5106    [1.751 sec/step, loss=0.65379, avg_loss=0.67959]\n","Step 5107    [1.748 sec/step, loss=0.67356, avg_loss=0.67944]\n","Step 5108    [1.745 sec/step, loss=0.69877, avg_loss=0.67951]\n","Step 5109    [1.741 sec/step, loss=0.66760, avg_loss=0.67943]\n","Step 5110    [1.732 sec/step, loss=0.63620, avg_loss=0.67876]\n","Step 5111    [1.734 sec/step, loss=0.68549, avg_loss=0.67882]\n","Step 5112    [1.730 sec/step, loss=0.66233, avg_loss=0.67880]\n","Step 5113    [1.720 sec/step, loss=0.69476, avg_loss=0.67876]\n","Step 5114    [1.724 sec/step, loss=0.65876, avg_loss=0.67874]\n","Step 5115    [1.733 sec/step, loss=0.63966, avg_loss=0.67864]\n","Step 5116    [1.739 sec/step, loss=0.67018, avg_loss=0.67866]\n","Step 5117    [1.755 sec/step, loss=0.69450, avg_loss=0.67889]\n","Generated 32 batches of size 32 in 10.594 sec\n","Step 5118    [1.788 sec/step, loss=0.71029, avg_loss=0.67892]\n","Step 5119    [1.778 sec/step, loss=0.70000, avg_loss=0.67897]\n","Step 5120    [1.756 sec/step, loss=0.67294, avg_loss=0.67870]\n","Step 5121    [1.743 sec/step, loss=0.69559, avg_loss=0.67899]\n","Step 5122    [1.727 sec/step, loss=0.69824, avg_loss=0.67887]\n","Step 5123    [1.719 sec/step, loss=0.70920, avg_loss=0.67905]\n","Step 5124    [1.716 sec/step, loss=0.67214, avg_loss=0.67902]\n","Step 5125    [1.718 sec/step, loss=0.67182, avg_loss=0.67880]\n","Step 5126    [1.725 sec/step, loss=0.68432, avg_loss=0.67897]\n","Step 5127    [1.720 sec/step, loss=0.63180, avg_loss=0.67847]\n","Step 5128    [1.683 sec/step, loss=0.65693, avg_loss=0.67881]\n","Step 5129    [1.676 sec/step, loss=0.63262, avg_loss=0.67829]\n","Step 5130    [1.681 sec/step, loss=0.66268, avg_loss=0.67832]\n","Step 5131    [1.663 sec/step, loss=0.64825, avg_loss=0.67762]\n","Step 5132    [1.659 sec/step, loss=0.65634, avg_loss=0.67715]\n","Step 5133    [1.653 sec/step, loss=0.68093, avg_loss=0.67683]\n","Step 5134    [1.656 sec/step, loss=0.67853, avg_loss=0.67694]\n","Step 5135    [1.655 sec/step, loss=0.69430, avg_loss=0.67693]\n","Step 5136    [1.655 sec/step, loss=0.68408, avg_loss=0.67685]\n","Step 5137    [1.653 sec/step, loss=0.66621, avg_loss=0.67673]\n","Step 5138    [1.651 sec/step, loss=0.66247, avg_loss=0.67650]\n","Step 5139    [1.652 sec/step, loss=0.68699, avg_loss=0.67645]\n","Step 5140    [1.683 sec/step, loss=0.60630, avg_loss=0.67556]\n","Step 5141    [1.699 sec/step, loss=0.70006, avg_loss=0.67599]\n","Step 5142    [1.695 sec/step, loss=0.64149, avg_loss=0.67573]\n","Step 5143    [1.696 sec/step, loss=0.69268, avg_loss=0.67562]\n","Step 5144    [1.694 sec/step, loss=0.65801, avg_loss=0.67559]\n","Step 5145    [1.683 sec/step, loss=0.65327, avg_loss=0.67499]\n","Step 5146    [1.693 sec/step, loss=0.71104, avg_loss=0.67548]\n","Step 5147    [1.695 sec/step, loss=0.64952, avg_loss=0.67514]\n","Step 5148    [1.708 sec/step, loss=0.71681, avg_loss=0.67521]\n","Step 5149    [1.695 sec/step, loss=0.70671, avg_loss=0.67581]\n","Generated 32 batches of size 32 in 10.612 sec\n","Step 5150    [1.719 sec/step, loss=0.69569, avg_loss=0.67621]\n","Step 5151    [1.722 sec/step, loss=0.66478, avg_loss=0.67636]\n","Step 5152    [1.710 sec/step, loss=0.68979, avg_loss=0.67657]\n","Step 5153    [1.711 sec/step, loss=0.73018, avg_loss=0.67701]\n","Step 5154    [1.686 sec/step, loss=0.63420, avg_loss=0.67615]\n","Step 5155    [1.684 sec/step, loss=0.68029, avg_loss=0.67655]\n","Step 5156    [1.691 sec/step, loss=0.71487, avg_loss=0.67714]\n","Step 5157    [1.708 sec/step, loss=0.71132, avg_loss=0.67767]\n","Step 5158    [1.708 sec/step, loss=0.64378, avg_loss=0.67740]\n","Step 5159    [1.709 sec/step, loss=0.66208, avg_loss=0.67732]\n","Step 5160    [1.714 sec/step, loss=0.69389, avg_loss=0.67760]\n","Step 5161    [1.716 sec/step, loss=0.69845, avg_loss=0.67791]\n","Step 5162    [1.718 sec/step, loss=0.68141, avg_loss=0.67784]\n","Step 5163    [1.714 sec/step, loss=0.66760, avg_loss=0.67777]\n","Step 5164    [1.717 sec/step, loss=0.70272, avg_loss=0.67771]\n","Step 5165    [1.720 sec/step, loss=0.65615, avg_loss=0.67776]\n","Step 5166    [1.697 sec/step, loss=0.68203, avg_loss=0.67858]\n","Step 5167    [1.696 sec/step, loss=0.66222, avg_loss=0.67866]\n","Step 5168    [1.694 sec/step, loss=0.66006, avg_loss=0.67822]\n","Step 5169    [1.690 sec/step, loss=0.66960, avg_loss=0.67788]\n","Step 5170    [1.688 sec/step, loss=0.64577, avg_loss=0.67728]\n","Step 5171    [1.697 sec/step, loss=0.68038, avg_loss=0.67739]\n","Step 5172    [1.690 sec/step, loss=0.63703, avg_loss=0.67675]\n","Step 5173    [1.699 sec/step, loss=0.71613, avg_loss=0.67715]\n","Step 5174    [1.686 sec/step, loss=0.62430, avg_loss=0.67603]\n","Step 5175    [1.678 sec/step, loss=0.64665, avg_loss=0.67556]\n","Step 5176    [1.685 sec/step, loss=0.69848, avg_loss=0.67579]\n","Step 5177    [1.686 sec/step, loss=0.68496, avg_loss=0.67582]\n","Step 5178    [1.728 sec/step, loss=0.63939, avg_loss=0.67576]\n","Step 5179    [1.743 sec/step, loss=0.68858, avg_loss=0.67585]\n","Step 5180    [1.742 sec/step, loss=0.68894, avg_loss=0.67570]\n","Step 5181    [1.740 sec/step, loss=0.64073, avg_loss=0.67514]\n","Step 5182    [1.743 sec/step, loss=0.64863, avg_loss=0.67502]\n","Step 5183    [1.749 sec/step, loss=0.64630, avg_loss=0.67516]\n","Generated 32 batches of size 32 in 11.025 sec\n","Step 5184    [1.742 sec/step, loss=0.70120, avg_loss=0.67536]\n","Step 5185    [1.747 sec/step, loss=0.70964, avg_loss=0.67562]\n","Step 5186    [1.745 sec/step, loss=0.69236, avg_loss=0.67607]\n","Step 5187    [1.732 sec/step, loss=0.67807, avg_loss=0.67610]\n","Step 5188    [1.725 sec/step, loss=0.67076, avg_loss=0.67590]\n","Step 5189    [1.707 sec/step, loss=0.69162, avg_loss=0.67547]\n","Step 5190    [1.704 sec/step, loss=0.67746, avg_loss=0.67519]\n","Step 5191    [1.715 sec/step, loss=0.70821, avg_loss=0.67557]\n","Step 5192    [1.728 sec/step, loss=0.71364, avg_loss=0.67556]\n","Step 5193    [1.726 sec/step, loss=0.67072, avg_loss=0.67547]\n","Step 5194    [1.729 sec/step, loss=0.69221, avg_loss=0.67570]\n","Step 5195    [1.739 sec/step, loss=0.67784, avg_loss=0.67566]\n","Step 5196    [1.747 sec/step, loss=0.69639, avg_loss=0.67610]\n","Step 5197    [1.740 sec/step, loss=0.68427, avg_loss=0.67591]\n","Step 5198    [1.724 sec/step, loss=0.65509, avg_loss=0.67530]\n","Step 5199    [1.710 sec/step, loss=0.64567, avg_loss=0.67473]\n","Step 5200    [1.712 sec/step, loss=0.68402, avg_loss=0.67467]\n","Writing summary at step: 5200\n","Step 5201    [1.710 sec/step, loss=0.67400, avg_loss=0.67462]\n","Step 5202    [1.711 sec/step, loss=0.66911, avg_loss=0.67472]\n","Step 5203    [1.674 sec/step, loss=0.68048, avg_loss=0.67548]\n","Step 5204    [1.669 sec/step, loss=0.65309, avg_loss=0.67505]\n","Step 5205    [1.672 sec/step, loss=0.65485, avg_loss=0.67496]\n","Step 5206    [1.679 sec/step, loss=0.68403, avg_loss=0.67526]\n","Step 5207    [1.678 sec/step, loss=0.66313, avg_loss=0.67516]\n","Step 5208    [1.712 sec/step, loss=0.58314, avg_loss=0.67400]\n","Step 5209    [1.715 sec/step, loss=0.65860, avg_loss=0.67391]\n","Step 5210    [1.725 sec/step, loss=0.64770, avg_loss=0.67403]\n","Step 5211    [1.739 sec/step, loss=0.68637, avg_loss=0.67404]\n","Step 5212    [1.747 sec/step, loss=0.66077, avg_loss=0.67402]\n","Step 5213    [1.746 sec/step, loss=0.64634, avg_loss=0.67354]\n","Step 5214    [1.747 sec/step, loss=0.62128, avg_loss=0.67316]\n","Generated 32 batches of size 32 in 10.886 sec\n","Step 5215    [1.746 sec/step, loss=0.66250, avg_loss=0.67339]\n","Step 5216    [1.749 sec/step, loss=0.69715, avg_loss=0.67366]\n","Step 5217    [1.730 sec/step, loss=0.63545, avg_loss=0.67307]\n","Step 5218    [1.700 sec/step, loss=0.68307, avg_loss=0.67280]\n","Step 5219    [1.700 sec/step, loss=0.65970, avg_loss=0.67240]\n","Step 5220    [1.704 sec/step, loss=0.67155, avg_loss=0.67238]\n","Step 5221    [1.701 sec/step, loss=0.66127, avg_loss=0.67204]\n","Step 5222    [1.699 sec/step, loss=0.64367, avg_loss=0.67149]\n","Step 5223    [1.697 sec/step, loss=0.69360, avg_loss=0.67134]\n","Step 5224    [1.703 sec/step, loss=0.69101, avg_loss=0.67153]\n","Step 5225    [1.699 sec/step, loss=0.65285, avg_loss=0.67134]\n","Step 5226    [1.731 sec/step, loss=0.59217, avg_loss=0.67041]\n","Step 5227    [1.732 sec/step, loss=0.66904, avg_loss=0.67079]\n","Step 5228    [1.734 sec/step, loss=0.68395, avg_loss=0.67106]\n","Step 5229    [1.735 sec/step, loss=0.65499, avg_loss=0.67128]\n","Step 5230    [1.731 sec/step, loss=0.64909, avg_loss=0.67114]\n","Step 5231    [1.733 sec/step, loss=0.69313, avg_loss=0.67159]\n","Step 5232    [1.753 sec/step, loss=0.71369, avg_loss=0.67217]\n","Step 5233    [1.752 sec/step, loss=0.68177, avg_loss=0.67218]\n","Step 5234    [1.747 sec/step, loss=0.63794, avg_loss=0.67177]\n","Step 5235    [1.742 sec/step, loss=0.64815, avg_loss=0.67131]\n","Step 5236    [1.738 sec/step, loss=0.66938, avg_loss=0.67116]\n","Step 5237    [1.747 sec/step, loss=0.70385, avg_loss=0.67154]\n","Step 5238    [1.750 sec/step, loss=0.67521, avg_loss=0.67166]\n","Step 5239    [1.747 sec/step, loss=0.65909, avg_loss=0.67139]\n","Step 5240    [1.717 sec/step, loss=0.68847, avg_loss=0.67221]\n","Step 5241    [1.700 sec/step, loss=0.64586, avg_loss=0.67167]\n","Step 5242    [1.708 sec/step, loss=0.63978, avg_loss=0.67165]\n","Step 5243    [1.701 sec/step, loss=0.62065, avg_loss=0.67093]\n","Step 5244    [1.704 sec/step, loss=0.63826, avg_loss=0.67073]\n","Step 5245    [1.716 sec/step, loss=0.66750, avg_loss=0.67087]\n","Step 5246    [1.734 sec/step, loss=0.70955, avg_loss=0.67086]\n","Generated 32 batches of size 32 in 11.000 sec\n","Step 5247    [1.743 sec/step, loss=0.69610, avg_loss=0.67132]\n","Step 5248    [1.721 sec/step, loss=0.65358, avg_loss=0.67069]\n","Step 5249    [1.716 sec/step, loss=0.66990, avg_loss=0.67032]\n","Step 5250    [1.698 sec/step, loss=0.68017, avg_loss=0.67017]\n","Step 5251    [1.706 sec/step, loss=0.70757, avg_loss=0.67060]\n","Step 5252    [1.745 sec/step, loss=0.62906, avg_loss=0.66999]\n","Step 5253    [1.735 sec/step, loss=0.68661, avg_loss=0.66955]\n","Step 5254    [1.748 sec/step, loss=0.70507, avg_loss=0.67026]\n","Step 5255    [1.750 sec/step, loss=0.66330, avg_loss=0.67009]\n","Step 5256    [1.753 sec/step, loss=0.73240, avg_loss=0.67027]\n","Step 5257    [1.742 sec/step, loss=0.67115, avg_loss=0.66987]\n","Step 5258    [1.748 sec/step, loss=0.67013, avg_loss=0.67013]\n","Step 5259    [1.747 sec/step, loss=0.63544, avg_loss=0.66986]\n","Step 5260    [1.744 sec/step, loss=0.67487, avg_loss=0.66967]\n","Step 5261    [1.738 sec/step, loss=0.64668, avg_loss=0.66915]\n","Step 5262    [1.737 sec/step, loss=0.66736, avg_loss=0.66901]\n","Step 5263    [1.736 sec/step, loss=0.62807, avg_loss=0.66862]\n","Step 5264    [1.734 sec/step, loss=0.68086, avg_loss=0.66840]\n","Step 5265    [1.734 sec/step, loss=0.66295, avg_loss=0.66847]\n","Step 5266    [1.717 sec/step, loss=0.65865, avg_loss=0.66823]\n","Step 5267    [1.724 sec/step, loss=0.71361, avg_loss=0.66875]\n","Step 5268    [1.732 sec/step, loss=0.69365, avg_loss=0.66908]\n","Step 5269    [1.733 sec/step, loss=0.64514, avg_loss=0.66884]\n","Step 5270    [1.735 sec/step, loss=0.66709, avg_loss=0.66905]\n","Step 5271    [1.743 sec/step, loss=0.69515, avg_loss=0.66920]\n","Step 5272    [1.741 sec/step, loss=0.64733, avg_loss=0.66930]\n","Step 5273    [1.730 sec/step, loss=0.63705, avg_loss=0.66851]\n","Step 5274    [1.742 sec/step, loss=0.66857, avg_loss=0.66896]\n","Step 5275    [1.755 sec/step, loss=0.66753, avg_loss=0.66916]\n","Step 5276    [1.753 sec/step, loss=0.63357, avg_loss=0.66852]\n","Step 5277    [1.765 sec/step, loss=0.65208, avg_loss=0.66819]\n","Step 5278    [1.731 sec/step, loss=0.64472, avg_loss=0.66824]\n","Generated 32 batches of size 32 in 10.630 sec\n","Step 5279    [1.725 sec/step, loss=0.68414, avg_loss=0.66820]\n","Step 5280    [1.711 sec/step, loss=0.66494, avg_loss=0.66796]\n","Step 5281    [1.707 sec/step, loss=0.61900, avg_loss=0.66774]\n","Step 5282    [1.708 sec/step, loss=0.68134, avg_loss=0.66807]\n","Step 5283    [1.705 sec/step, loss=0.66687, avg_loss=0.66827]\n","Step 5284    [1.693 sec/step, loss=0.64170, avg_loss=0.66768]\n","Step 5285    [1.679 sec/step, loss=0.60461, avg_loss=0.66663]\n","Step 5286    [1.718 sec/step, loss=0.59636, avg_loss=0.66567]\n","Step 5287    [1.719 sec/step, loss=0.65506, avg_loss=0.66544]\n","Step 5288    [1.721 sec/step, loss=0.67422, avg_loss=0.66547]\n","Step 5289    [1.724 sec/step, loss=0.68180, avg_loss=0.66537]\n","Step 5290    [1.720 sec/step, loss=0.66129, avg_loss=0.66521]\n","Step 5291    [1.708 sec/step, loss=0.64102, avg_loss=0.66454]\n","Step 5292    [1.689 sec/step, loss=0.67957, avg_loss=0.66420]\n","Step 5293    [1.688 sec/step, loss=0.65499, avg_loss=0.66404]\n","Step 5294    [1.703 sec/step, loss=0.71069, avg_loss=0.66423]\n","Step 5295    [1.696 sec/step, loss=0.68691, avg_loss=0.66432]\n","Step 5296    [1.687 sec/step, loss=0.66114, avg_loss=0.66396]\n","Step 5297    [1.685 sec/step, loss=0.66404, avg_loss=0.66376]\n","Step 5298    [1.702 sec/step, loss=0.68819, avg_loss=0.66409]\n","Step 5299    [1.705 sec/step, loss=0.64390, avg_loss=0.66407]\n","Step 5300    [1.699 sec/step, loss=0.65505, avg_loss=0.66378]\n","Writing summary at step: 5300\n","Step 5301    [1.710 sec/step, loss=0.71041, avg_loss=0.66415]\n","Step 5302    [1.709 sec/step, loss=0.63620, avg_loss=0.66382]\n","Step 5303    [1.709 sec/step, loss=0.66453, avg_loss=0.66366]\n","Step 5304    [1.707 sec/step, loss=0.67032, avg_loss=0.66383]\n","Step 5305    [1.725 sec/step, loss=0.67213, avg_loss=0.66401]\n","Step 5306    [1.734 sec/step, loss=0.69656, avg_loss=0.66413]\n","Step 5307    [1.756 sec/step, loss=0.69729, avg_loss=0.66447]\n","Step 5308    [1.719 sec/step, loss=0.63592, avg_loss=0.66500]\n","Generated 32 batches of size 32 in 10.994 sec\n","Step 5309    [1.730 sec/step, loss=0.70156, avg_loss=0.66543]\n","Step 5310    [1.724 sec/step, loss=0.65111, avg_loss=0.66546]\n","Step 5311    [1.712 sec/step, loss=0.66727, avg_loss=0.66527]\n","Step 5312    [1.714 sec/step, loss=0.68881, avg_loss=0.66555]\n","Step 5313    [1.708 sec/step, loss=0.64488, avg_loss=0.66554]\n","Step 5314    [1.706 sec/step, loss=0.64761, avg_loss=0.66580]\n","Step 5315    [1.701 sec/step, loss=0.66051, avg_loss=0.66578]\n","Step 5316    [1.696 sec/step, loss=0.66248, avg_loss=0.66544]\n","Step 5317    [1.699 sec/step, loss=0.65350, avg_loss=0.66562]\n","Step 5318    [1.698 sec/step, loss=0.68161, avg_loss=0.66560]\n","Step 5319    [1.700 sec/step, loss=0.66837, avg_loss=0.66569]\n","Step 5320    [1.707 sec/step, loss=0.69348, avg_loss=0.66591]\n","Step 5321    [1.729 sec/step, loss=0.68862, avg_loss=0.66618]\n","Step 5322    [1.730 sec/step, loss=0.64893, avg_loss=0.66623]\n","Step 5323    [1.724 sec/step, loss=0.66207, avg_loss=0.66592]\n","Step 5324    [1.729 sec/step, loss=0.68668, avg_loss=0.66587]\n","Step 5325    [1.736 sec/step, loss=0.67023, avg_loss=0.66605]\n","Step 5326    [1.698 sec/step, loss=0.63950, avg_loss=0.66652]\n","Step 5327    [1.695 sec/step, loss=0.61868, avg_loss=0.66602]\n","Step 5328    [1.692 sec/step, loss=0.66837, avg_loss=0.66586]\n","Step 5329    [1.694 sec/step, loss=0.64240, avg_loss=0.66574]\n","Step 5330    [1.697 sec/step, loss=0.65562, avg_loss=0.66580]\n","Step 5331    [1.698 sec/step, loss=0.65777, avg_loss=0.66545]\n","Step 5332    [1.683 sec/step, loss=0.68578, avg_loss=0.66517]\n","Step 5333    [1.717 sec/step, loss=0.64106, avg_loss=0.66476]\n","Step 5334    [1.722 sec/step, loss=0.65733, avg_loss=0.66496]\n","Step 5335    [1.722 sec/step, loss=0.63769, avg_loss=0.66485]\n","Step 5336    [1.729 sec/step, loss=0.69351, avg_loss=0.66509]\n","Step 5337    [1.722 sec/step, loss=0.61204, avg_loss=0.66417]\n","Step 5338    [1.723 sec/step, loss=0.63679, avg_loss=0.66379]\n","Step 5339    [1.744 sec/step, loss=0.67538, avg_loss=0.66395]\n","Step 5340    [1.745 sec/step, loss=0.63272, avg_loss=0.66340]\n","Step 5341    [1.750 sec/step, loss=0.65094, avg_loss=0.66345]\n","Generated 32 batches of size 32 in 11.353 sec\n","Step 5342    [1.763 sec/step, loss=0.68963, avg_loss=0.66395]\n","Step 5343    [1.760 sec/step, loss=0.64488, avg_loss=0.66419]\n","Step 5344    [1.756 sec/step, loss=0.62281, avg_loss=0.66403]\n","Step 5345    [1.746 sec/step, loss=0.67872, avg_loss=0.66415]\n","Step 5346    [1.729 sec/step, loss=0.69276, avg_loss=0.66398]\n","Step 5347    [1.723 sec/step, loss=0.67344, avg_loss=0.66375]\n","Step 5348    [1.719 sec/step, loss=0.64491, avg_loss=0.66366]\n","Step 5349    [1.712 sec/step, loss=0.68719, avg_loss=0.66384]\n","Step 5350    [1.708 sec/step, loss=0.66117, avg_loss=0.66365]\n","Step 5351    [1.702 sec/step, loss=0.65281, avg_loss=0.66310]\n","Step 5352    [1.661 sec/step, loss=0.63517, avg_loss=0.66316]\n","Step 5353    [1.653 sec/step, loss=0.66801, avg_loss=0.66297]\n","Step 5354    [1.643 sec/step, loss=0.64254, avg_loss=0.66235]\n","Step 5355    [1.641 sec/step, loss=0.65957, avg_loss=0.66231]\n","Step 5356    [1.628 sec/step, loss=0.63665, avg_loss=0.66135]\n","Step 5357    [1.623 sec/step, loss=0.61530, avg_loss=0.66080]\n","Step 5358    [1.625 sec/step, loss=0.67807, avg_loss=0.66088]\n","Step 5359    [1.643 sec/step, loss=0.69888, avg_loss=0.66151]\n","Step 5360    [1.678 sec/step, loss=0.60377, avg_loss=0.66080]\n","Step 5361    [1.694 sec/step, loss=0.70345, avg_loss=0.66137]\n","Step 5362    [1.694 sec/step, loss=0.66788, avg_loss=0.66137]\n","Step 5363    [1.698 sec/step, loss=0.70044, avg_loss=0.66210]\n","Step 5364    [1.691 sec/step, loss=0.65341, avg_loss=0.66182]\n","Step 5365    [1.695 sec/step, loss=0.68363, avg_loss=0.66203]\n","Step 5366    [1.702 sec/step, loss=0.68379, avg_loss=0.66228]\n","Step 5367    [1.701 sec/step, loss=0.70136, avg_loss=0.66216]\n","Step 5368    [1.692 sec/step, loss=0.65789, avg_loss=0.66180]\n","Step 5369    [1.698 sec/step, loss=0.64100, avg_loss=0.66176]\n","Step 5370    [1.699 sec/step, loss=0.65255, avg_loss=0.66161]\n","Step 5371    [1.683 sec/step, loss=0.60552, avg_loss=0.66072]\n","Step 5372    [1.703 sec/step, loss=0.65994, avg_loss=0.66084]\n","Generated 32 batches of size 32 in 10.497 sec\n","Step 5373    [1.723 sec/step, loss=0.69833, avg_loss=0.66145]\n","Step 5374    [1.716 sec/step, loss=0.65373, avg_loss=0.66131]\n","Step 5375    [1.715 sec/step, loss=0.68913, avg_loss=0.66152]\n","Step 5376    [1.708 sec/step, loss=0.64308, avg_loss=0.66162]\n","Step 5377    [1.698 sec/step, loss=0.69200, avg_loss=0.66202]\n","Step 5378    [1.691 sec/step, loss=0.63156, avg_loss=0.66188]\n","Step 5379    [1.684 sec/step, loss=0.65414, avg_loss=0.66158]\n","Step 5380    [1.682 sec/step, loss=0.64608, avg_loss=0.66140]\n","Step 5381    [1.686 sec/step, loss=0.66248, avg_loss=0.66183]\n","Step 5382    [1.683 sec/step, loss=0.66969, avg_loss=0.66171]\n","Step 5383    [1.688 sec/step, loss=0.66812, avg_loss=0.66173]\n","Step 5384    [1.691 sec/step, loss=0.63241, avg_loss=0.66163]\n","Step 5385    [1.706 sec/step, loss=0.68843, avg_loss=0.66247]\n","Step 5386    [1.668 sec/step, loss=0.64101, avg_loss=0.66292]\n","Step 5387    [1.666 sec/step, loss=0.63841, avg_loss=0.66275]\n","Step 5388    [1.662 sec/step, loss=0.65975, avg_loss=0.66261]\n","Step 5389    [1.665 sec/step, loss=0.69954, avg_loss=0.66278]\n","Step 5390    [1.674 sec/step, loss=0.67119, avg_loss=0.66288]\n","Step 5391    [1.711 sec/step, loss=0.61449, avg_loss=0.66262]\n","Step 5392    [1.709 sec/step, loss=0.66293, avg_loss=0.66245]\n","Step 5393    [1.712 sec/step, loss=0.68903, avg_loss=0.66279]\n","Step 5394    [1.697 sec/step, loss=0.67198, avg_loss=0.66241]\n","Step 5395    [1.698 sec/step, loss=0.69079, avg_loss=0.66244]\n","Step 5396    [1.699 sec/step, loss=0.63987, avg_loss=0.66223]\n","Step 5397    [1.709 sec/step, loss=0.69266, avg_loss=0.66252]\n","Step 5398    [1.692 sec/step, loss=0.60826, avg_loss=0.66172]\n","Step 5399    [1.699 sec/step, loss=0.67292, avg_loss=0.66201]\n","Step 5400    [1.697 sec/step, loss=0.63089, avg_loss=0.66177]\n","Writing summary at step: 5400\n","Step 5401    [1.694 sec/step, loss=0.65936, avg_loss=0.66126]\n","Step 5402    [1.736 sec/step, loss=0.69097, avg_loss=0.66180]\n","Generated 32 batches of size 32 in 10.652 sec\n","Step 5403    [1.736 sec/step, loss=0.62852, avg_loss=0.66144]\n","Step 5404    [1.733 sec/step, loss=0.63561, avg_loss=0.66110]\n","Step 5405    [1.719 sec/step, loss=0.66253, avg_loss=0.66100]\n","Step 5406    [1.706 sec/step, loss=0.64385, avg_loss=0.66047]\n","Step 5407    [1.687 sec/step, loss=0.65998, avg_loss=0.66010]\n","Step 5408    [1.688 sec/step, loss=0.66281, avg_loss=0.66037]\n","Step 5409    [1.676 sec/step, loss=0.65336, avg_loss=0.65989]\n","Step 5410    [1.690 sec/step, loss=0.68552, avg_loss=0.66023]\n","Step 5411    [1.694 sec/step, loss=0.68496, avg_loss=0.66041]\n","Step 5412    [1.684 sec/step, loss=0.63351, avg_loss=0.65986]\n","Step 5413    [1.689 sec/step, loss=0.65812, avg_loss=0.65999]\n","Step 5414    [1.693 sec/step, loss=0.66991, avg_loss=0.66021]\n","Step 5415    [1.696 sec/step, loss=0.67419, avg_loss=0.66035]\n","Step 5416    [1.710 sec/step, loss=0.70568, avg_loss=0.66078]\n","Step 5417    [1.712 sec/step, loss=0.64480, avg_loss=0.66069]\n","Step 5418    [1.705 sec/step, loss=0.64169, avg_loss=0.66029]\n","Step 5419    [1.698 sec/step, loss=0.62449, avg_loss=0.65985]\n","Step 5420    [1.691 sec/step, loss=0.66027, avg_loss=0.65952]\n","Step 5421    [1.671 sec/step, loss=0.66810, avg_loss=0.65932]\n","Step 5422    [1.674 sec/step, loss=0.66105, avg_loss=0.65944]\n","Step 5423    [1.681 sec/step, loss=0.67388, avg_loss=0.65956]\n","Step 5424    [1.672 sec/step, loss=0.64577, avg_loss=0.65915]\n","Step 5425    [1.661 sec/step, loss=0.62169, avg_loss=0.65866]\n","Step 5426    [1.696 sec/step, loss=0.59265, avg_loss=0.65819]\n","Step 5427    [1.698 sec/step, loss=0.65219, avg_loss=0.65853]\n","Step 5428    [1.705 sec/step, loss=0.67025, avg_loss=0.65855]\n","Step 5429    [1.713 sec/step, loss=0.69852, avg_loss=0.65911]\n","Step 5430    [1.719 sec/step, loss=0.69243, avg_loss=0.65948]\n","Step 5431    [1.714 sec/step, loss=0.65604, avg_loss=0.65946]\n","Step 5432    [1.718 sec/step, loss=0.64091, avg_loss=0.65901]\n","Step 5433    [1.695 sec/step, loss=0.65432, avg_loss=0.65914]\n","Step 5434    [1.706 sec/step, loss=0.66573, avg_loss=0.65923]\n","Step 5435    [1.710 sec/step, loss=0.61564, avg_loss=0.65901]\n","Step 5436    [1.714 sec/step, loss=0.67066, avg_loss=0.65878]\n","Generated 32 batches of size 32 in 10.830 sec\n","Step 5437    [1.724 sec/step, loss=0.68664, avg_loss=0.65952]\n","Step 5438    [1.719 sec/step, loss=0.61670, avg_loss=0.65932]\n","Step 5439    [1.695 sec/step, loss=0.62791, avg_loss=0.65885]\n","Step 5440    [1.685 sec/step, loss=0.65067, avg_loss=0.65903]\n","Step 5441    [1.681 sec/step, loss=0.65762, avg_loss=0.65910]\n","Step 5442    [1.666 sec/step, loss=0.68865, avg_loss=0.65909]\n","Step 5443    [1.669 sec/step, loss=0.67030, avg_loss=0.65934]\n","Step 5444    [1.677 sec/step, loss=0.65572, avg_loss=0.65967]\n","Step 5445    [1.677 sec/step, loss=0.65516, avg_loss=0.65943]\n","Step 5446    [1.666 sec/step, loss=0.63015, avg_loss=0.65881]\n","Step 5447    [1.661 sec/step, loss=0.62070, avg_loss=0.65828]\n","Step 5448    [1.676 sec/step, loss=0.70007, avg_loss=0.65883]\n","Step 5449    [1.669 sec/step, loss=0.63682, avg_loss=0.65833]\n","Step 5450    [1.667 sec/step, loss=0.62559, avg_loss=0.65797]\n","Step 5451    [1.662 sec/step, loss=0.60057, avg_loss=0.65745]\n","Step 5452    [1.660 sec/step, loss=0.64336, avg_loss=0.65753]\n","Step 5453    [1.661 sec/step, loss=0.67583, avg_loss=0.65761]\n","Step 5454    [1.661 sec/step, loss=0.64480, avg_loss=0.65763]\n","Step 5455    [1.659 sec/step, loss=0.66468, avg_loss=0.65768]\n","Step 5456    [1.660 sec/step, loss=0.64571, avg_loss=0.65777]\n","Step 5457    [1.665 sec/step, loss=0.64331, avg_loss=0.65805]\n","Step 5458    [1.661 sec/step, loss=0.67495, avg_loss=0.65802]\n","Step 5459    [1.653 sec/step, loss=0.69188, avg_loss=0.65795]\n","Step 5460    [1.616 sec/step, loss=0.63120, avg_loss=0.65823]\n","Step 5461    [1.601 sec/step, loss=0.64921, avg_loss=0.65768]\n","Step 5462    [1.633 sec/step, loss=0.62997, avg_loss=0.65731]\n","Step 5463    [1.636 sec/step, loss=0.69068, avg_loss=0.65721]\n","Step 5464    [1.654 sec/step, loss=0.69365, avg_loss=0.65761]\n","Step 5465    [1.670 sec/step, loss=0.67246, avg_loss=0.65750]\n","Step 5466    [1.679 sec/step, loss=0.69448, avg_loss=0.65761]\n","Generated 32 batches of size 32 in 10.905 sec\n","Step 5467    [1.702 sec/step, loss=0.71535, avg_loss=0.65775]\n","Step 5468    [1.713 sec/step, loss=0.69723, avg_loss=0.65814]\n","Step 5469    [1.709 sec/step, loss=0.68941, avg_loss=0.65862]\n","Step 5470    [1.710 sec/step, loss=0.66355, avg_loss=0.65873]\n","Step 5471    [1.709 sec/step, loss=0.65095, avg_loss=0.65919]\n","Step 5472    [1.693 sec/step, loss=0.66452, avg_loss=0.65923]\n","Step 5473    [1.680 sec/step, loss=0.66803, avg_loss=0.65893]\n","Step 5474    [1.680 sec/step, loss=0.64774, avg_loss=0.65887]\n","Step 5475    [1.671 sec/step, loss=0.67532, avg_loss=0.65873]\n","Step 5476    [1.671 sec/step, loss=0.64845, avg_loss=0.65879]\n","Step 5477    [1.676 sec/step, loss=0.68319, avg_loss=0.65870]\n","Step 5478    [1.696 sec/step, loss=0.67374, avg_loss=0.65912]\n","Step 5479    [1.697 sec/step, loss=0.64626, avg_loss=0.65904]\n","Step 5480    [1.699 sec/step, loss=0.64709, avg_loss=0.65905]\n","Step 5481    [1.701 sec/step, loss=0.66915, avg_loss=0.65912]\n","Step 5482    [1.706 sec/step, loss=0.67964, avg_loss=0.65922]\n","Step 5483    [1.706 sec/step, loss=0.64867, avg_loss=0.65902]\n","Step 5484    [1.707 sec/step, loss=0.64914, avg_loss=0.65919]\n","Step 5485    [1.710 sec/step, loss=0.67078, avg_loss=0.65901]\n","Step 5486    [1.709 sec/step, loss=0.63779, avg_loss=0.65898]\n","Step 5487    [1.716 sec/step, loss=0.67310, avg_loss=0.65933]\n","Step 5488    [1.714 sec/step, loss=0.64363, avg_loss=0.65917]\n","Step 5489    [1.706 sec/step, loss=0.65901, avg_loss=0.65876]\n","Step 5490    [1.739 sec/step, loss=0.59947, avg_loss=0.65804]\n","Step 5491    [1.716 sec/step, loss=0.68474, avg_loss=0.65875]\n","Step 5492    [1.721 sec/step, loss=0.68990, avg_loss=0.65902]\n","Step 5493    [1.720 sec/step, loss=0.65940, avg_loss=0.65872]\n","Step 5494    [1.715 sec/step, loss=0.61992, avg_loss=0.65820]\n","Step 5495    [1.709 sec/step, loss=0.65706, avg_loss=0.65786]\n","Step 5496    [1.718 sec/step, loss=0.62857, avg_loss=0.65775]\n","Step 5497    [1.714 sec/step, loss=0.61032, avg_loss=0.65693]\n","Step 5498    [1.721 sec/step, loss=0.63655, avg_loss=0.65721]\n","Step 5499    [1.727 sec/step, loss=0.64784, avg_loss=0.65696]\n","Step 5500    [1.740 sec/step, loss=0.64616, avg_loss=0.65711]\n","Writing summary at step: 5500\n","Generated 32 batches of size 32 in 10.719 sec\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Training korean : Use jamo\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12618 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12642 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12637 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12598 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12634 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12594 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52285 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51088 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47196 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51032 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49373 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44033 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 55016 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50476 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47566 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 46104 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44620 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12618 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12642 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12637 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12598 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12634 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12594 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52285 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51088 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47196 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51032 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49373 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44033 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 55016 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50476 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47566 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 46104 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44620 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/train-step-000005500-align000.png\n","100% 1/1 [00:03<00:00,  3.40s/it]\n","Test finished for step 5500.\n","  0% 0/2 [00:00<?, ?it/s]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000005500-align000.png\n"," 50% 1/2 [00:04<00:04,  4.60s/it]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000005500-align001.png\n","100% 2/2 [00:09<00:00,  4.55s/it]\n","Test finished for step 5500.\n","Step 5501    [1.737 sec/step, loss=0.67317, avg_loss=0.65725]\n","Step 5502    [1.699 sec/step, loss=0.68737, avg_loss=0.65721]\n","Step 5503    [1.695 sec/step, loss=0.64860, avg_loss=0.65741]\n","Step 5504    [1.701 sec/step, loss=0.64575, avg_loss=0.65751]\n","Step 5505    [1.702 sec/step, loss=0.67259, avg_loss=0.65762]\n","Step 5506    [1.707 sec/step, loss=0.67420, avg_loss=0.65792]\n","Step 5507    [1.706 sec/step, loss=0.65754, avg_loss=0.65789]\n","Step 5508    [1.704 sec/step, loss=0.63475, avg_loss=0.65761]\n","Step 5509    [1.704 sec/step, loss=0.63569, avg_loss=0.65744]\n","Step 5510    [1.688 sec/step, loss=0.61610, avg_loss=0.65674]\n","Step 5511    [1.679 sec/step, loss=0.62845, avg_loss=0.65618]\n","Step 5512    [1.686 sec/step, loss=0.69011, avg_loss=0.65674]\n","Step 5513    [1.696 sec/step, loss=0.67193, avg_loss=0.65688]\n","Step 5514    [1.690 sec/step, loss=0.64606, avg_loss=0.65664]\n","Step 5515    [1.687 sec/step, loss=0.65440, avg_loss=0.65645]\n","Step 5516    [1.666 sec/step, loss=0.60335, avg_loss=0.65542]\n","Step 5517    [1.666 sec/step, loss=0.65816, avg_loss=0.65556]\n","Step 5518    [1.667 sec/step, loss=0.64149, avg_loss=0.65555]\n","Step 5519    [1.674 sec/step, loss=0.67567, avg_loss=0.65607]\n","Step 5520    [1.667 sec/step, loss=0.62139, avg_loss=0.65568]\n","Step 5521    [1.679 sec/step, loss=0.67856, avg_loss=0.65578]\n","Step 5522    [1.676 sec/step, loss=0.62492, avg_loss=0.65542]\n","Step 5523    [1.672 sec/step, loss=0.68237, avg_loss=0.65551]\n","Step 5524    [1.679 sec/step, loss=0.69123, avg_loss=0.65596]\n","Step 5525    [1.689 sec/step, loss=0.66963, avg_loss=0.65644]\n","Step 5526    [1.667 sec/step, loss=0.65868, avg_loss=0.65710]\n","Generated 32 batches of size 32 in 10.445 sec\n","Step 5527    [1.741 sec/step, loss=0.59608, avg_loss=0.65654]\n","Step 5528    [1.738 sec/step, loss=0.67415, avg_loss=0.65658]\n","Step 5529    [1.735 sec/step, loss=0.68074, avg_loss=0.65640]\n","Step 5530    [1.734 sec/step, loss=0.66872, avg_loss=0.65616]\n","Step 5531    [1.745 sec/step, loss=0.69287, avg_loss=0.65653]\n","Step 5532    [1.733 sec/step, loss=0.63069, avg_loss=0.65643]\n","Step 5533    [1.720 sec/step, loss=0.63888, avg_loss=0.65627]\n","Step 5534    [1.710 sec/step, loss=0.66259, avg_loss=0.65624]\n","Step 5535    [1.711 sec/step, loss=0.67436, avg_loss=0.65683]\n","Step 5536    [1.700 sec/step, loss=0.62799, avg_loss=0.65640]\n","Step 5537    [1.687 sec/step, loss=0.63685, avg_loss=0.65591]\n","Step 5538    [1.687 sec/step, loss=0.65350, avg_loss=0.65627]\n","Step 5539    [1.695 sec/step, loss=0.67362, avg_loss=0.65673]\n","Step 5540    [1.695 sec/step, loss=0.62979, avg_loss=0.65652]\n","Step 5541    [1.693 sec/step, loss=0.63315, avg_loss=0.65628]\n","Step 5542    [1.687 sec/step, loss=0.63183, avg_loss=0.65571]\n","Step 5543    [1.688 sec/step, loss=0.67112, avg_loss=0.65572]\n","Step 5544    [1.681 sec/step, loss=0.64743, avg_loss=0.65563]\n","Step 5545    [1.676 sec/step, loss=0.61791, avg_loss=0.65526]\n","Step 5546    [1.693 sec/step, loss=0.70070, avg_loss=0.65597]\n","Step 5547    [1.729 sec/step, loss=0.61910, avg_loss=0.65595]\n","Step 5548    [1.717 sec/step, loss=0.65375, avg_loss=0.65549]\n","Step 5549    [1.726 sec/step, loss=0.70044, avg_loss=0.65612]\n","Step 5550    [1.723 sec/step, loss=0.60001, avg_loss=0.65587]\n","Step 5551    [1.732 sec/step, loss=0.67333, avg_loss=0.65660]\n","Step 5552    [1.737 sec/step, loss=0.64228, avg_loss=0.65658]\n","Step 5553    [1.733 sec/step, loss=0.62038, avg_loss=0.65603]\n","Step 5554    [1.736 sec/step, loss=0.64523, avg_loss=0.65603]\n","Step 5555    [1.736 sec/step, loss=0.65942, avg_loss=0.65598]\n","Step 5556    [1.744 sec/step, loss=0.68349, avg_loss=0.65636]\n","Step 5557    [1.745 sec/step, loss=0.67157, avg_loss=0.65664]\n","Step 5558    [1.755 sec/step, loss=0.66004, avg_loss=0.65649]\n","Step 5559    [1.756 sec/step, loss=0.64058, avg_loss=0.65598]\n","Step 5560    [1.783 sec/step, loss=0.67847, avg_loss=0.65645]\n","Generated 32 batches of size 32 in 10.562 sec\n","Step 5561    [1.800 sec/step, loss=0.67166, avg_loss=0.65668]\n","Step 5562    [1.777 sec/step, loss=0.68951, avg_loss=0.65727]\n","Step 5563    [1.771 sec/step, loss=0.64263, avg_loss=0.65679]\n","Step 5564    [1.754 sec/step, loss=0.63560, avg_loss=0.65621]\n","Step 5565    [1.745 sec/step, loss=0.71183, avg_loss=0.65661]\n","Step 5566    [1.731 sec/step, loss=0.65692, avg_loss=0.65623]\n","Step 5567    [1.704 sec/step, loss=0.61804, avg_loss=0.65526]\n","Step 5568    [1.697 sec/step, loss=0.65279, avg_loss=0.65481]\n","Step 5569    [1.694 sec/step, loss=0.64439, avg_loss=0.65436]\n","Step 5570    [1.700 sec/step, loss=0.69252, avg_loss=0.65465]\n","Step 5571    [1.738 sec/step, loss=0.58656, avg_loss=0.65401]\n","Step 5572    [1.733 sec/step, loss=0.62897, avg_loss=0.65365]\n","Step 5573    [1.734 sec/step, loss=0.67129, avg_loss=0.65369]\n","Step 5574    [1.739 sec/step, loss=0.67180, avg_loss=0.65393]\n","Step 5575    [1.758 sec/step, loss=0.67106, avg_loss=0.65388]\n","Step 5576    [1.760 sec/step, loss=0.65598, avg_loss=0.65396]\n","Step 5577    [1.754 sec/step, loss=0.65282, avg_loss=0.65365]\n","Step 5578    [1.741 sec/step, loss=0.65306, avg_loss=0.65345]\n","Step 5579    [1.736 sec/step, loss=0.62597, avg_loss=0.65325]\n","Step 5580    [1.733 sec/step, loss=0.63046, avg_loss=0.65308]\n","Step 5581    [1.728 sec/step, loss=0.60419, avg_loss=0.65243]\n","Step 5582    [1.720 sec/step, loss=0.63436, avg_loss=0.65198]\n","Step 5583    [1.717 sec/step, loss=0.66951, avg_loss=0.65218]\n","Step 5584    [1.720 sec/step, loss=0.67011, avg_loss=0.65239]\n","Step 5585    [1.706 sec/step, loss=0.66157, avg_loss=0.65230]\n","Step 5586    [1.713 sec/step, loss=0.66387, avg_loss=0.65256]\n","Step 5587    [1.711 sec/step, loss=0.64298, avg_loss=0.65226]\n","Step 5588    [1.710 sec/step, loss=0.63869, avg_loss=0.65221]\n","Step 5589    [1.714 sec/step, loss=0.68705, avg_loss=0.65249]\n","Step 5590    [1.676 sec/step, loss=0.63060, avg_loss=0.65280]\n","Step 5591    [1.674 sec/step, loss=0.66569, avg_loss=0.65261]\n","Step 5592    [1.682 sec/step, loss=0.64054, avg_loss=0.65212]\n","Step 5593    [1.688 sec/step, loss=0.64286, avg_loss=0.65195]\n","Generated 32 batches of size 32 in 11.005 sec\n","Step 5594    [1.717 sec/step, loss=0.65701, avg_loss=0.65233]\n","Step 5595    [1.726 sec/step, loss=0.69001, avg_loss=0.65266]\n","Step 5596    [1.720 sec/step, loss=0.66861, avg_loss=0.65306]\n","Step 5597    [1.713 sec/step, loss=0.64315, avg_loss=0.65338]\n","Step 5598    [1.711 sec/step, loss=0.68546, avg_loss=0.65387]\n","Step 5599    [1.706 sec/step, loss=0.67569, avg_loss=0.65415]\n","Step 5600    [1.699 sec/step, loss=0.66101, avg_loss=0.65430]\n","Writing summary at step: 5600\n","Step 5601    [1.695 sec/step, loss=0.64659, avg_loss=0.65403]\n","Step 5602    [1.691 sec/step, loss=0.63881, avg_loss=0.65355]\n","Step 5603    [1.692 sec/step, loss=0.65765, avg_loss=0.65364]\n","Step 5604    [1.727 sec/step, loss=0.58644, avg_loss=0.65305]\n","Step 5605    [1.720 sec/step, loss=0.63396, avg_loss=0.65266]\n","Step 5606    [1.720 sec/step, loss=0.67745, avg_loss=0.65269]\n","Step 5607    [1.726 sec/step, loss=0.69396, avg_loss=0.65306]\n","Step 5608    [1.726 sec/step, loss=0.65214, avg_loss=0.65323]\n","Step 5609    [1.729 sec/step, loss=0.67545, avg_loss=0.65363]\n","Step 5610    [1.733 sec/step, loss=0.66756, avg_loss=0.65414]\n","Step 5611    [1.738 sec/step, loss=0.66938, avg_loss=0.65455]\n","Step 5612    [1.734 sec/step, loss=0.64936, avg_loss=0.65414]\n","Step 5613    [1.723 sec/step, loss=0.66241, avg_loss=0.65405]\n","Step 5614    [1.720 sec/step, loss=0.62467, avg_loss=0.65384]\n","Step 5615    [1.723 sec/step, loss=0.64790, avg_loss=0.65377]\n","Step 5616    [1.723 sec/step, loss=0.63611, avg_loss=0.65410]\n","Step 5617    [1.720 sec/step, loss=0.62879, avg_loss=0.65380]\n","Step 5618    [1.717 sec/step, loss=0.59661, avg_loss=0.65336]\n","Step 5619    [1.725 sec/step, loss=0.68206, avg_loss=0.65342]\n","Step 5620    [1.728 sec/step, loss=0.64832, avg_loss=0.65369]\n","Step 5621    [1.729 sec/step, loss=0.66483, avg_loss=0.65355]\n","Step 5622    [1.748 sec/step, loss=0.66765, avg_loss=0.65398]\n","Step 5623    [1.770 sec/step, loss=0.70330, avg_loss=0.65419]\n","Generated 32 batches of size 32 in 11.017 sec\n","Step 5624    [1.770 sec/step, loss=0.66898, avg_loss=0.65397]\n","Step 5625    [1.772 sec/step, loss=0.67343, avg_loss=0.65400]\n","Step 5626    [1.758 sec/step, loss=0.62461, avg_loss=0.65366]\n","Step 5627    [1.685 sec/step, loss=0.65765, avg_loss=0.65428]\n","Step 5628    [1.686 sec/step, loss=0.67580, avg_loss=0.65429]\n","Step 5629    [1.700 sec/step, loss=0.69762, avg_loss=0.65446]\n","Step 5630    [1.692 sec/step, loss=0.63582, avg_loss=0.65413]\n","Step 5631    [1.687 sec/step, loss=0.66782, avg_loss=0.65388]\n","Step 5632    [1.694 sec/step, loss=0.65497, avg_loss=0.65413]\n","Step 5633    [1.704 sec/step, loss=0.69370, avg_loss=0.65468]\n","Step 5634    [1.702 sec/step, loss=0.64689, avg_loss=0.65452]\n","Step 5635    [1.699 sec/step, loss=0.62740, avg_loss=0.65405]\n","Step 5636    [1.704 sec/step, loss=0.65065, avg_loss=0.65428]\n","Step 5637    [1.740 sec/step, loss=0.58379, avg_loss=0.65374]\n","Step 5638    [1.744 sec/step, loss=0.64702, avg_loss=0.65368]\n","Step 5639    [1.740 sec/step, loss=0.64314, avg_loss=0.65337]\n","Step 5640    [1.748 sec/step, loss=0.68663, avg_loss=0.65394]\n","Step 5641    [1.753 sec/step, loss=0.64867, avg_loss=0.65410]\n","Step 5642    [1.757 sec/step, loss=0.65019, avg_loss=0.65428]\n","Step 5643    [1.755 sec/step, loss=0.62143, avg_loss=0.65379]\n","Step 5644    [1.753 sec/step, loss=0.63945, avg_loss=0.65371]\n","Step 5645    [1.754 sec/step, loss=0.62710, avg_loss=0.65380]\n","Step 5646    [1.743 sec/step, loss=0.66079, avg_loss=0.65340]\n","Step 5647    [1.705 sec/step, loss=0.62145, avg_loss=0.65342]\n","Step 5648    [1.708 sec/step, loss=0.68157, avg_loss=0.65370]\n","Step 5649    [1.710 sec/step, loss=0.66938, avg_loss=0.65339]\n","Step 5650    [1.711 sec/step, loss=0.63741, avg_loss=0.65376]\n","Step 5651    [1.710 sec/step, loss=0.66046, avg_loss=0.65363]\n","Step 5652    [1.726 sec/step, loss=0.67648, avg_loss=0.65398]\n","Step 5653    [1.754 sec/step, loss=0.67103, avg_loss=0.65448]\n","Step 5654    [1.767 sec/step, loss=0.66771, avg_loss=0.65471]\n","Step 5655    [1.770 sec/step, loss=0.59956, avg_loss=0.65411]\n","Step 5656    [1.771 sec/step, loss=0.62517, avg_loss=0.65353]\n","Generated 32 batches of size 32 in 10.708 sec\n","Step 5657    [1.781 sec/step, loss=0.67489, avg_loss=0.65356]\n","Step 5658    [1.770 sec/step, loss=0.63551, avg_loss=0.65331]\n","Step 5659    [1.758 sec/step, loss=0.63519, avg_loss=0.65326]\n","Step 5660    [1.738 sec/step, loss=0.66421, avg_loss=0.65312]\n","Step 5661    [1.721 sec/step, loss=0.64881, avg_loss=0.65289]\n","Step 5662    [1.713 sec/step, loss=0.66306, avg_loss=0.65262]\n","Step 5663    [1.716 sec/step, loss=0.65324, avg_loss=0.65273]\n","Step 5664    [1.712 sec/step, loss=0.61403, avg_loss=0.65251]\n","Step 5665    [1.701 sec/step, loss=0.64613, avg_loss=0.65186]\n","Step 5666    [1.717 sec/step, loss=0.71632, avg_loss=0.65245]\n","Step 5667    [1.724 sec/step, loss=0.66782, avg_loss=0.65295]\n","Step 5668    [1.720 sec/step, loss=0.64460, avg_loss=0.65287]\n","Step 5669    [1.730 sec/step, loss=0.68788, avg_loss=0.65330]\n","Step 5670    [1.733 sec/step, loss=0.67510, avg_loss=0.65313]\n","Step 5671    [1.704 sec/step, loss=0.67174, avg_loss=0.65398]\n","Step 5672    [1.706 sec/step, loss=0.64337, avg_loss=0.65412]\n","Step 5673    [1.702 sec/step, loss=0.66548, avg_loss=0.65407]\n","Step 5674    [1.696 sec/step, loss=0.64757, avg_loss=0.65382]\n","Step 5675    [1.676 sec/step, loss=0.62080, avg_loss=0.65332]\n","Step 5676    [1.675 sec/step, loss=0.63959, avg_loss=0.65316]\n","Step 5677    [1.675 sec/step, loss=0.65952, avg_loss=0.65322]\n","Step 5678    [1.666 sec/step, loss=0.59766, avg_loss=0.65267]\n","Step 5679    [1.671 sec/step, loss=0.66572, avg_loss=0.65307]\n","Step 5680    [1.682 sec/step, loss=0.68249, avg_loss=0.65359]\n","Step 5681    [1.725 sec/step, loss=0.59662, avg_loss=0.65351]\n","Step 5682    [1.730 sec/step, loss=0.67066, avg_loss=0.65388]\n","Step 5683    [1.727 sec/step, loss=0.64526, avg_loss=0.65363]\n","Step 5684    [1.726 sec/step, loss=0.66830, avg_loss=0.65362]\n","Step 5685    [1.747 sec/step, loss=0.67000, avg_loss=0.65370]\n","Step 5686    [1.756 sec/step, loss=0.66727, avg_loss=0.65373]\n","Step 5687    [1.764 sec/step, loss=0.64545, avg_loss=0.65376]\n","Step 5688    [1.772 sec/step, loss=0.64576, avg_loss=0.65383]\n","Generated 32 batches of size 32 in 10.618 sec\n","Step 5689    [1.771 sec/step, loss=0.65218, avg_loss=0.65348]\n","Step 5690    [1.764 sec/step, loss=0.64164, avg_loss=0.65359]\n","Step 5691    [1.752 sec/step, loss=0.61553, avg_loss=0.65309]\n","Step 5692    [1.741 sec/step, loss=0.65245, avg_loss=0.65321]\n","Step 5693    [1.732 sec/step, loss=0.61662, avg_loss=0.65295]\n","Step 5694    [1.710 sec/step, loss=0.66070, avg_loss=0.65298]\n","Step 5695    [1.700 sec/step, loss=0.62311, avg_loss=0.65231]\n","Step 5696    [1.696 sec/step, loss=0.64925, avg_loss=0.65212]\n","Step 5697    [1.704 sec/step, loss=0.68388, avg_loss=0.65253]\n","Step 5698    [1.734 sec/step, loss=0.64069, avg_loss=0.65208]\n","Step 5699    [1.725 sec/step, loss=0.63900, avg_loss=0.65171]\n","Step 5700    [1.721 sec/step, loss=0.64469, avg_loss=0.65155]\n","Writing summary at step: 5700\n","Step 5701    [1.723 sec/step, loss=0.66592, avg_loss=0.65174]\n","Step 5702    [1.722 sec/step, loss=0.60911, avg_loss=0.65145]\n","Step 5703    [1.722 sec/step, loss=0.63738, avg_loss=0.65124]\n","Step 5704    [1.703 sec/step, loss=0.70163, avg_loss=0.65240]\n","Step 5705    [1.708 sec/step, loss=0.66743, avg_loss=0.65273]\n","Step 5706    [1.701 sec/step, loss=0.62560, avg_loss=0.65221]\n","Step 5707    [1.692 sec/step, loss=0.61951, avg_loss=0.65147]\n","Step 5708    [1.689 sec/step, loss=0.64120, avg_loss=0.65136]\n","Step 5709    [1.691 sec/step, loss=0.65805, avg_loss=0.65118]\n","Step 5710    [1.691 sec/step, loss=0.65353, avg_loss=0.65104]\n","Step 5711    [1.688 sec/step, loss=0.64929, avg_loss=0.65084]\n","Step 5712    [1.699 sec/step, loss=0.70035, avg_loss=0.65135]\n","Step 5713    [1.695 sec/step, loss=0.62274, avg_loss=0.65096]\n","Step 5714    [1.698 sec/step, loss=0.65952, avg_loss=0.65130]\n","Step 5715    [1.695 sec/step, loss=0.63126, avg_loss=0.65114]\n","Step 5716    [1.699 sec/step, loss=0.61725, avg_loss=0.65095]\n","Step 5717    [1.716 sec/step, loss=0.67301, avg_loss=0.65139]\n","Step 5718    [1.736 sec/step, loss=0.67048, avg_loss=0.65213]\n","Step 5719    [1.744 sec/step, loss=0.68917, avg_loss=0.65220]\n","Generated 32 batches of size 32 in 10.823 sec\n","Step 5720    [1.747 sec/step, loss=0.62580, avg_loss=0.65198]\n","Step 5721    [1.736 sec/step, loss=0.68615, avg_loss=0.65219]\n","Step 5722    [1.725 sec/step, loss=0.67653, avg_loss=0.65228]\n","Step 5723    [1.701 sec/step, loss=0.63975, avg_loss=0.65164]\n","Step 5724    [1.705 sec/step, loss=0.66219, avg_loss=0.65157]\n","Step 5725    [1.715 sec/step, loss=0.68050, avg_loss=0.65165]\n","Step 5726    [1.717 sec/step, loss=0.65624, avg_loss=0.65196]\n","Step 5727    [1.716 sec/step, loss=0.62928, avg_loss=0.65168]\n","Step 5728    [1.709 sec/step, loss=0.60048, avg_loss=0.65092]\n","Step 5729    [1.687 sec/step, loss=0.63156, avg_loss=0.65026]\n","Step 5730    [1.695 sec/step, loss=0.65421, avg_loss=0.65045]\n","Step 5731    [1.700 sec/step, loss=0.66472, avg_loss=0.65042]\n","Step 5732    [1.702 sec/step, loss=0.64827, avg_loss=0.65035]\n","Step 5733    [1.699 sec/step, loss=0.66204, avg_loss=0.65003]\n","Step 5734    [1.698 sec/step, loss=0.64390, avg_loss=0.65000]\n","Step 5735    [1.705 sec/step, loss=0.66318, avg_loss=0.65036]\n","Step 5736    [1.703 sec/step, loss=0.62779, avg_loss=0.65013]\n","Step 5737    [1.671 sec/step, loss=0.65770, avg_loss=0.65087]\n","Step 5738    [1.669 sec/step, loss=0.64521, avg_loss=0.65085]\n","Step 5739    [1.666 sec/step, loss=0.63395, avg_loss=0.65076]\n","Step 5740    [1.661 sec/step, loss=0.68208, avg_loss=0.65072]\n","Step 5741    [1.657 sec/step, loss=0.62678, avg_loss=0.65050]\n","Step 5742    [1.654 sec/step, loss=0.61405, avg_loss=0.65014]\n","Step 5743    [1.693 sec/step, loss=0.56844, avg_loss=0.64961]\n","Step 5744    [1.693 sec/step, loss=0.61849, avg_loss=0.64940]\n","Step 5745    [1.695 sec/step, loss=0.62369, avg_loss=0.64936]\n","Step 5746    [1.697 sec/step, loss=0.66770, avg_loss=0.64943]\n","Step 5747    [1.712 sec/step, loss=0.67802, avg_loss=0.65000]\n","Step 5748    [1.723 sec/step, loss=0.64501, avg_loss=0.64963]\n","Step 5749    [1.723 sec/step, loss=0.64191, avg_loss=0.64936]\n","Step 5750    [1.737 sec/step, loss=0.64320, avg_loss=0.64942]\n","Step 5751    [1.745 sec/step, loss=0.64118, avg_loss=0.64922]\n","Generated 32 batches of size 32 in 10.897 sec\n","Step 5752    [1.742 sec/step, loss=0.68488, avg_loss=0.64931]\n","Step 5753    [1.718 sec/step, loss=0.64669, avg_loss=0.64906]\n","Step 5754    [1.709 sec/step, loss=0.66438, avg_loss=0.64903]\n","Step 5755    [1.702 sec/step, loss=0.59890, avg_loss=0.64902]\n","Step 5756    [1.694 sec/step, loss=0.62347, avg_loss=0.64901]\n","Step 5757    [1.679 sec/step, loss=0.62403, avg_loss=0.64850]\n","Step 5758    [1.676 sec/step, loss=0.59779, avg_loss=0.64812]\n","Step 5759    [1.675 sec/step, loss=0.63211, avg_loss=0.64809]\n","Step 5760    [1.670 sec/step, loss=0.63192, avg_loss=0.64777]\n","Step 5761    [1.667 sec/step, loss=0.60993, avg_loss=0.64738]\n","Step 5762    [1.659 sec/step, loss=0.59943, avg_loss=0.64674]\n","Step 5763    [1.668 sec/step, loss=0.67879, avg_loss=0.64700]\n","Step 5764    [1.671 sec/step, loss=0.63239, avg_loss=0.64718]\n","Step 5765    [1.684 sec/step, loss=0.66676, avg_loss=0.64739]\n","Step 5766    [1.668 sec/step, loss=0.64526, avg_loss=0.64668]\n","Step 5767    [1.663 sec/step, loss=0.65318, avg_loss=0.64653]\n","Step 5768    [1.666 sec/step, loss=0.66282, avg_loss=0.64671]\n","Step 5769    [1.660 sec/step, loss=0.66553, avg_loss=0.64649]\n","Step 5770    [1.650 sec/step, loss=0.65645, avg_loss=0.64630]\n","Step 5771    [1.679 sec/step, loss=0.57563, avg_loss=0.64534]\n","Step 5772    [1.680 sec/step, loss=0.64129, avg_loss=0.64532]\n","Step 5773    [1.682 sec/step, loss=0.66389, avg_loss=0.64530]\n","Step 5774    [1.700 sec/step, loss=0.66282, avg_loss=0.64546]\n","Step 5775    [1.700 sec/step, loss=0.63538, avg_loss=0.64560]\n","Step 5776    [1.700 sec/step, loss=0.63584, avg_loss=0.64556]\n","Step 5777    [1.696 sec/step, loss=0.61820, avg_loss=0.64515]\n","Step 5778    [1.701 sec/step, loss=0.64448, avg_loss=0.64562]\n","Step 5779    [1.702 sec/step, loss=0.66370, avg_loss=0.64560]\n","Step 5780    [1.710 sec/step, loss=0.64642, avg_loss=0.64524]\n","Step 5781    [1.688 sec/step, loss=0.67735, avg_loss=0.64605]\n","Step 5782    [1.707 sec/step, loss=0.65763, avg_loss=0.64592]\n","Generated 32 batches of size 32 in 10.718 sec\n","Step 5783    [1.714 sec/step, loss=0.61966, avg_loss=0.64566]\n","Step 5784    [1.714 sec/step, loss=0.65650, avg_loss=0.64554]\n","Step 5785    [1.700 sec/step, loss=0.67366, avg_loss=0.64558]\n","Step 5786    [1.689 sec/step, loss=0.65570, avg_loss=0.64546]\n","Step 5787    [1.685 sec/step, loss=0.68601, avg_loss=0.64587]\n","Step 5788    [1.678 sec/step, loss=0.62331, avg_loss=0.64564]\n","Step 5789    [1.679 sec/step, loss=0.67261, avg_loss=0.64585]\n","Step 5790    [1.690 sec/step, loss=0.67951, avg_loss=0.64623]\n","Step 5791    [1.691 sec/step, loss=0.62488, avg_loss=0.64632]\n","Step 5792    [1.686 sec/step, loss=0.62452, avg_loss=0.64604]\n","Step 5793    [1.694 sec/step, loss=0.67022, avg_loss=0.64658]\n","Step 5794    [1.687 sec/step, loss=0.63276, avg_loss=0.64630]\n","Step 5795    [1.695 sec/step, loss=0.64602, avg_loss=0.64653]\n","Step 5796    [1.701 sec/step, loss=0.65525, avg_loss=0.64659]\n","Step 5797    [1.698 sec/step, loss=0.64967, avg_loss=0.64624]\n","Step 5798    [1.666 sec/step, loss=0.64015, avg_loss=0.64624]\n","Step 5799    [1.675 sec/step, loss=0.67757, avg_loss=0.64662]\n","Step 5800    [1.674 sec/step, loss=0.63460, avg_loss=0.64652]\n","Writing summary at step: 5800\n","Step 5801    [1.673 sec/step, loss=0.65122, avg_loss=0.64638]\n","Step 5802    [1.675 sec/step, loss=0.62180, avg_loss=0.64650]\n","Step 5803    [1.671 sec/step, loss=0.62510, avg_loss=0.64638]\n","Step 5804    [1.653 sec/step, loss=0.64942, avg_loss=0.64586]\n","Step 5805    [1.654 sec/step, loss=0.65824, avg_loss=0.64577]\n","Step 5806    [1.653 sec/step, loss=0.59709, avg_loss=0.64548]\n","Step 5807    [1.657 sec/step, loss=0.64972, avg_loss=0.64578]\n","Step 5808    [1.662 sec/step, loss=0.66231, avg_loss=0.64600]\n","Step 5809    [1.696 sec/step, loss=0.62366, avg_loss=0.64565]\n","Step 5810    [1.706 sec/step, loss=0.68655, avg_loss=0.64598]\n","Step 5811    [1.729 sec/step, loss=0.69287, avg_loss=0.64642]\n","Step 5812    [1.722 sec/step, loss=0.61063, avg_loss=0.64552]\n","Step 5813    [1.732 sec/step, loss=0.62814, avg_loss=0.64557]\n","Step 5814    [1.736 sec/step, loss=0.62662, avg_loss=0.64525]\n","Generated 32 batches of size 32 in 11.150 sec\n","Step 5815    [1.766 sec/step, loss=0.69462, avg_loss=0.64588]\n","Step 5816    [1.767 sec/step, loss=0.66790, avg_loss=0.64639]\n","Step 5817    [1.752 sec/step, loss=0.62887, avg_loss=0.64594]\n","Step 5818    [1.735 sec/step, loss=0.64992, avg_loss=0.64574]\n","Step 5819    [1.717 sec/step, loss=0.66615, avg_loss=0.64551]\n","Step 5820    [1.712 sec/step, loss=0.62438, avg_loss=0.64549]\n","Step 5821    [1.717 sec/step, loss=0.66713, avg_loss=0.64530]\n","Step 5822    [1.709 sec/step, loss=0.63143, avg_loss=0.64485]\n","Step 5823    [1.708 sec/step, loss=0.62920, avg_loss=0.64475]\n","Step 5824    [1.697 sec/step, loss=0.63415, avg_loss=0.64447]\n","Step 5825    [1.676 sec/step, loss=0.62289, avg_loss=0.64389]\n","Step 5826    [1.711 sec/step, loss=0.59194, avg_loss=0.64325]\n","Step 5827    [1.710 sec/step, loss=0.62525, avg_loss=0.64321]\n","Step 5828    [1.722 sec/step, loss=0.66000, avg_loss=0.64380]\n","Step 5829    [1.724 sec/step, loss=0.63080, avg_loss=0.64379]\n","Step 5830    [1.724 sec/step, loss=0.65892, avg_loss=0.64384]\n","Step 5831    [1.716 sec/step, loss=0.64730, avg_loss=0.64367]\n","Step 5832    [1.716 sec/step, loss=0.67040, avg_loss=0.64389]\n","Step 5833    [1.715 sec/step, loss=0.65621, avg_loss=0.64383]\n","Step 5834    [1.712 sec/step, loss=0.60802, avg_loss=0.64347]\n","Step 5835    [1.711 sec/step, loss=0.63729, avg_loss=0.64321]\n","Step 5836    [1.711 sec/step, loss=0.64012, avg_loss=0.64334]\n","Step 5837    [1.715 sec/step, loss=0.67695, avg_loss=0.64353]\n","Step 5838    [1.712 sec/step, loss=0.62836, avg_loss=0.64336]\n","Step 5839    [1.720 sec/step, loss=0.66169, avg_loss=0.64364]\n","Step 5840    [1.712 sec/step, loss=0.59815, avg_loss=0.64280]\n","Step 5841    [1.716 sec/step, loss=0.64628, avg_loss=0.64299]\n","Step 5842    [1.716 sec/step, loss=0.62370, avg_loss=0.64309]\n","Step 5843    [1.695 sec/step, loss=0.65293, avg_loss=0.64393]\n","Step 5844    [1.708 sec/step, loss=0.63025, avg_loss=0.64405]\n","Step 5845    [1.733 sec/step, loss=0.69114, avg_loss=0.64473]\n","Generated 32 batches of size 32 in 10.824 sec\n","Step 5846    [1.737 sec/step, loss=0.66318, avg_loss=0.64468]\n","Step 5847    [1.728 sec/step, loss=0.66274, avg_loss=0.64453]\n","Step 5848    [1.713 sec/step, loss=0.62288, avg_loss=0.64431]\n","Step 5849    [1.722 sec/step, loss=0.67286, avg_loss=0.64462]\n","Step 5850    [1.714 sec/step, loss=0.64568, avg_loss=0.64464]\n","Step 5851    [1.701 sec/step, loss=0.61074, avg_loss=0.64434]\n","Step 5852    [1.688 sec/step, loss=0.66203, avg_loss=0.64411]\n","Step 5853    [1.686 sec/step, loss=0.62942, avg_loss=0.64394]\n","Step 5854    [1.679 sec/step, loss=0.61714, avg_loss=0.64346]\n","Step 5855    [1.685 sec/step, loss=0.64504, avg_loss=0.64393]\n","Step 5856    [1.684 sec/step, loss=0.62944, avg_loss=0.64399]\n","Step 5857    [1.684 sec/step, loss=0.63480, avg_loss=0.64409]\n","Step 5858    [1.683 sec/step, loss=0.60024, avg_loss=0.64412]\n","Step 5859    [1.686 sec/step, loss=0.63470, avg_loss=0.64414]\n","Step 5860    [1.702 sec/step, loss=0.67644, avg_loss=0.64459]\n","Step 5861    [1.714 sec/step, loss=0.67239, avg_loss=0.64521]\n","Step 5862    [1.722 sec/step, loss=0.65140, avg_loss=0.64573]\n","Step 5863    [1.714 sec/step, loss=0.64990, avg_loss=0.64544]\n","Step 5864    [1.720 sec/step, loss=0.67541, avg_loss=0.64587]\n","Step 5865    [1.712 sec/step, loss=0.65875, avg_loss=0.64579]\n","Step 5866    [1.713 sec/step, loss=0.64989, avg_loss=0.64584]\n","Step 5867    [1.723 sec/step, loss=0.67179, avg_loss=0.64603]\n","Step 5868    [1.718 sec/step, loss=0.63001, avg_loss=0.64570]\n","Step 5869    [1.722 sec/step, loss=0.66499, avg_loss=0.64569]\n","Step 5870    [1.725 sec/step, loss=0.65599, avg_loss=0.64569]\n","Step 5871    [1.686 sec/step, loss=0.64093, avg_loss=0.64634]\n","Step 5872    [1.682 sec/step, loss=0.59097, avg_loss=0.64584]\n","Step 5873    [1.683 sec/step, loss=0.66063, avg_loss=0.64581]\n","Step 5874    [1.662 sec/step, loss=0.60836, avg_loss=0.64526]\n","Step 5875    [1.678 sec/step, loss=0.64918, avg_loss=0.64540]\n","Step 5876    [1.700 sec/step, loss=0.68350, avg_loss=0.64588]\n","Step 5877    [1.706 sec/step, loss=0.63497, avg_loss=0.64604]\n","Step 5878    [1.716 sec/step, loss=0.63002, avg_loss=0.64590]\n","Generated 32 batches of size 32 in 10.559 sec\n","Step 5879    [1.715 sec/step, loss=0.60918, avg_loss=0.64535]\n","Step 5880    [1.702 sec/step, loss=0.63589, avg_loss=0.64525]\n","Step 5881    [1.684 sec/step, loss=0.64384, avg_loss=0.64491]\n","Step 5882    [1.693 sec/step, loss=0.58284, avg_loss=0.64417]\n","Step 5883    [1.688 sec/step, loss=0.61630, avg_loss=0.64413]\n","Step 5884    [1.683 sec/step, loss=0.62244, avg_loss=0.64379]\n","Step 5885    [1.673 sec/step, loss=0.58751, avg_loss=0.64293]\n","Step 5886    [1.675 sec/step, loss=0.67711, avg_loss=0.64314]\n","Step 5887    [1.669 sec/step, loss=0.63184, avg_loss=0.64260]\n","Step 5888    [1.667 sec/step, loss=0.61968, avg_loss=0.64257]\n","Step 5889    [1.668 sec/step, loss=0.67894, avg_loss=0.64263]\n","Step 5890    [1.665 sec/step, loss=0.63541, avg_loss=0.64219]\n","Step 5891    [1.668 sec/step, loss=0.66622, avg_loss=0.64260]\n","Step 5892    [1.676 sec/step, loss=0.66842, avg_loss=0.64304]\n","Step 5893    [1.667 sec/step, loss=0.61333, avg_loss=0.64247]\n","Step 5894    [1.666 sec/step, loss=0.63891, avg_loss=0.64253]\n","Step 5895    [1.671 sec/step, loss=0.68740, avg_loss=0.64295]\n","Step 5896    [1.665 sec/step, loss=0.64838, avg_loss=0.64288]\n","Step 5897    [1.661 sec/step, loss=0.64011, avg_loss=0.64278]\n","Step 5898    [1.660 sec/step, loss=0.63481, avg_loss=0.64273]\n","Step 5899    [1.654 sec/step, loss=0.64345, avg_loss=0.64239]\n","Step 5900    [1.655 sec/step, loss=0.61688, avg_loss=0.64221]\n","Writing summary at step: 5900\n","Step 5901    [1.652 sec/step, loss=0.63664, avg_loss=0.64206]\n","Step 5902    [1.656 sec/step, loss=0.66052, avg_loss=0.64245]\n","Step 5903    [1.660 sec/step, loss=0.66158, avg_loss=0.64282]\n","Step 5904    [1.668 sec/step, loss=0.68899, avg_loss=0.64321]\n","Step 5905    [1.662 sec/step, loss=0.59776, avg_loss=0.64261]\n","Step 5906    [1.673 sec/step, loss=0.65302, avg_loss=0.64317]\n","Step 5907    [1.695 sec/step, loss=0.68526, avg_loss=0.64352]\n","Generated 32 batches of size 32 in 11.216 sec\n","Step 5908    [1.760 sec/step, loss=0.63992, avg_loss=0.64330]\n","Step 5909    [1.724 sec/step, loss=0.66730, avg_loss=0.64373]\n","Step 5910    [1.735 sec/step, loss=0.69568, avg_loss=0.64383]\n","Step 5911    [1.713 sec/step, loss=0.65117, avg_loss=0.64341]\n","Step 5912    [1.714 sec/step, loss=0.65852, avg_loss=0.64389]\n","Step 5913    [1.710 sec/step, loss=0.66086, avg_loss=0.64422]\n","Step 5914    [1.704 sec/step, loss=0.64257, avg_loss=0.64437]\n","Step 5915    [1.677 sec/step, loss=0.66452, avg_loss=0.64407]\n","Step 5916    [1.671 sec/step, loss=0.62318, avg_loss=0.64363]\n","Step 5917    [1.678 sec/step, loss=0.67332, avg_loss=0.64407]\n","Step 5918    [1.675 sec/step, loss=0.61035, avg_loss=0.64368]\n","Step 5919    [1.673 sec/step, loss=0.63804, avg_loss=0.64339]\n","Step 5920    [1.673 sec/step, loss=0.64812, avg_loss=0.64363]\n","Step 5921    [1.661 sec/step, loss=0.61069, avg_loss=0.64307]\n","Step 5922    [1.657 sec/step, loss=0.62175, avg_loss=0.64297]\n","Step 5923    [1.661 sec/step, loss=0.65888, avg_loss=0.64327]\n","Step 5924    [1.665 sec/step, loss=0.66770, avg_loss=0.64360]\n","Step 5925    [1.675 sec/step, loss=0.66052, avg_loss=0.64398]\n","Step 5926    [1.640 sec/step, loss=0.62925, avg_loss=0.64435]\n","Step 5927    [1.661 sec/step, loss=0.66089, avg_loss=0.64471]\n","Step 5928    [1.660 sec/step, loss=0.67725, avg_loss=0.64488]\n","Step 5929    [1.657 sec/step, loss=0.61374, avg_loss=0.64471]\n","Step 5930    [1.652 sec/step, loss=0.63528, avg_loss=0.64447]\n","Step 5931    [1.663 sec/step, loss=0.68328, avg_loss=0.64483]\n","Step 5932    [1.657 sec/step, loss=0.61955, avg_loss=0.64433]\n","Step 5933    [1.685 sec/step, loss=0.61882, avg_loss=0.64395]\n","Step 5934    [1.688 sec/step, loss=0.63518, avg_loss=0.64422]\n","Step 5935    [1.686 sec/step, loss=0.64168, avg_loss=0.64427]\n","Step 5936    [1.683 sec/step, loss=0.61945, avg_loss=0.64406]\n","Step 5937    [1.674 sec/step, loss=0.61514, avg_loss=0.64344]\n","Step 5938    [1.684 sec/step, loss=0.66208, avg_loss=0.64378]\n","Step 5939    [1.707 sec/step, loss=0.67859, avg_loss=0.64395]\n","Step 5940    [1.723 sec/step, loss=0.64661, avg_loss=0.64443]\n","Generated 32 batches of size 32 in 10.563 sec\n","Step 5941    [1.734 sec/step, loss=0.67312, avg_loss=0.64470]\n","Step 5942    [1.737 sec/step, loss=0.66469, avg_loss=0.64511]\n","Step 5943    [1.721 sec/step, loss=0.64267, avg_loss=0.64501]\n","Step 5944    [1.714 sec/step, loss=0.66235, avg_loss=0.64533]\n","Step 5945    [1.691 sec/step, loss=0.63683, avg_loss=0.64479]\n","Step 5946    [1.678 sec/step, loss=0.62897, avg_loss=0.64444]\n","Step 5947    [1.672 sec/step, loss=0.62384, avg_loss=0.64406]\n","Step 5948    [1.681 sec/step, loss=0.65026, avg_loss=0.64433]\n","Step 5949    [1.665 sec/step, loss=0.66755, avg_loss=0.64428]\n","Step 5950    [1.662 sec/step, loss=0.63207, avg_loss=0.64414]\n","Step 5951    [1.665 sec/step, loss=0.62280, avg_loss=0.64426]\n","Step 5952    [1.662 sec/step, loss=0.64443, avg_loss=0.64408]\n","Step 5953    [1.662 sec/step, loss=0.61085, avg_loss=0.64390]\n","Step 5954    [1.666 sec/step, loss=0.62601, avg_loss=0.64399]\n","Step 5955    [1.703 sec/step, loss=0.53334, avg_loss=0.64287]\n","Step 5956    [1.702 sec/step, loss=0.60693, avg_loss=0.64265]\n","Step 5957    [1.707 sec/step, loss=0.63959, avg_loss=0.64269]\n","Step 5958    [1.714 sec/step, loss=0.66746, avg_loss=0.64337]\n","Step 5959    [1.719 sec/step, loss=0.68269, avg_loss=0.64385]\n","Step 5960    [1.704 sec/step, loss=0.65648, avg_loss=0.64365]\n","Step 5961    [1.695 sec/step, loss=0.63736, avg_loss=0.64330]\n","Step 5962    [1.699 sec/step, loss=0.65032, avg_loss=0.64328]\n","Step 5963    [1.706 sec/step, loss=0.68207, avg_loss=0.64361]\n","Step 5964    [1.699 sec/step, loss=0.62395, avg_loss=0.64309]\n","Step 5965    [1.692 sec/step, loss=0.61055, avg_loss=0.64261]\n","Step 5966    [1.699 sec/step, loss=0.68352, avg_loss=0.64295]\n","Step 5967    [1.703 sec/step, loss=0.68397, avg_loss=0.64307]\n","Step 5968    [1.701 sec/step, loss=0.61349, avg_loss=0.64290]\n","Step 5969    [1.693 sec/step, loss=0.62512, avg_loss=0.64250]\n","Step 5970    [1.706 sec/step, loss=0.66816, avg_loss=0.64263]\n","Step 5971    [1.721 sec/step, loss=0.66083, avg_loss=0.64282]\n","Step 5972    [1.739 sec/step, loss=0.67442, avg_loss=0.64366]\n","Step 5973    [1.734 sec/step, loss=0.62059, avg_loss=0.64326]\n","Generated 32 batches of size 32 in 10.655 sec\n","Step 5974    [1.738 sec/step, loss=0.59773, avg_loss=0.64315]\n","Step 5975    [1.724 sec/step, loss=0.64886, avg_loss=0.64315]\n","Step 5976    [1.702 sec/step, loss=0.62267, avg_loss=0.64254]\n","Step 5977    [1.702 sec/step, loss=0.65339, avg_loss=0.64272]\n","Step 5978    [1.693 sec/step, loss=0.66653, avg_loss=0.64309]\n","Step 5979    [1.703 sec/step, loss=0.67886, avg_loss=0.64379]\n","Step 5980    [1.709 sec/step, loss=0.67291, avg_loss=0.64416]\n","Step 5981    [1.707 sec/step, loss=0.65309, avg_loss=0.64425]\n","Step 5982    [1.681 sec/step, loss=0.69472, avg_loss=0.64537]\n","Step 5983    [1.685 sec/step, loss=0.64663, avg_loss=0.64567]\n","Step 5984    [1.724 sec/step, loss=0.61988, avg_loss=0.64565]\n","Step 5985    [1.732 sec/step, loss=0.65644, avg_loss=0.64634]\n","Step 5986    [1.728 sec/step, loss=0.65055, avg_loss=0.64607]\n","Step 5987    [1.727 sec/step, loss=0.63993, avg_loss=0.64615]\n","Step 5988    [1.731 sec/step, loss=0.65174, avg_loss=0.64647]\n","Step 5989    [1.723 sec/step, loss=0.63426, avg_loss=0.64602]\n","Step 5990    [1.723 sec/step, loss=0.66034, avg_loss=0.64627]\n","Step 5991    [1.721 sec/step, loss=0.62270, avg_loss=0.64584]\n","Step 5992    [1.716 sec/step, loss=0.63727, avg_loss=0.64553]\n","Step 5993    [1.722 sec/step, loss=0.67405, avg_loss=0.64613]\n","Step 5994    [1.720 sec/step, loss=0.59519, avg_loss=0.64570]\n","Step 5995    [1.709 sec/step, loss=0.63940, avg_loss=0.64522]\n","Step 5996    [1.706 sec/step, loss=0.59742, avg_loss=0.64471]\n","Step 5997    [1.710 sec/step, loss=0.65065, avg_loss=0.64481]\n","Step 5998    [1.726 sec/step, loss=0.68653, avg_loss=0.64533]\n","Step 5999    [1.724 sec/step, loss=0.65836, avg_loss=0.64548]\n","Step 6000    [1.725 sec/step, loss=0.63434, avg_loss=0.64565]\n","Writing summary at step: 6000\n","Saving checkpoint to: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/model.ckpt-6000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Training korean : Use jamo\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 12612 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49916 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44050 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51665 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51600 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44600 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49688 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 12612 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49916 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44050 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51665 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51600 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44600 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49688 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/train-step-000006000-align000.png\n","100% 1/1 [00:04<00:00,  4.64s/it]\n","Test finished for step 6000.\n","  0% 0/2 [00:00<?, ?it/s]Generated 32 batches of size 32 in 11.085 sec\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000006000-align000.png\n"," 50% 1/2 [00:09<00:09,  9.50s/it]Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/test-step-000006000-align001.png\n","100% 2/2 [00:16<00:00,  8.17s/it]\n","Test finished for step 6000.\n","Step 6001    [1.729 sec/step, loss=0.66640, avg_loss=0.64595]\n","Step 6002    [1.723 sec/step, loss=0.61708, avg_loss=0.64552]\n","Step 6003    [1.728 sec/step, loss=0.68490, avg_loss=0.64575]\n","Step 6004    [1.725 sec/step, loss=0.66559, avg_loss=0.64552]\n","Step 6005    [1.725 sec/step, loss=0.62676, avg_loss=0.64581]\n","Step 6006    [1.722 sec/step, loss=0.65856, avg_loss=0.64586]\n","Step 6007    [1.696 sec/step, loss=0.62340, avg_loss=0.64524]\n","Step 6008    [1.625 sec/step, loss=0.62331, avg_loss=0.64508]\n","Step 6009    [1.630 sec/step, loss=0.65977, avg_loss=0.64500]\n","Step 6010    [1.614 sec/step, loss=0.66102, avg_loss=0.64465]\n","Step 6011    [1.610 sec/step, loss=0.61254, avg_loss=0.64427]\n","Step 6012    [1.608 sec/step, loss=0.63584, avg_loss=0.64404]\n","Step 6013    [1.602 sec/step, loss=0.62634, avg_loss=0.64370]\n","Step 6014    [1.609 sec/step, loss=0.65487, avg_loss=0.64382]\n","Step 6015    [1.606 sec/step, loss=0.62047, avg_loss=0.64338]\n","Step 6016    [1.607 sec/step, loss=0.62355, avg_loss=0.64338]\n","Step 6017    [1.603 sec/step, loss=0.66666, avg_loss=0.64332]\n","Step 6018    [1.609 sec/step, loss=0.63016, avg_loss=0.64351]\n","Step 6019    [1.608 sec/step, loss=0.64101, avg_loss=0.64354]\n","Step 6020    [1.630 sec/step, loss=0.69353, avg_loss=0.64400]\n","Step 6021    [1.670 sec/step, loss=0.60337, avg_loss=0.64392]\n","Step 6022    [1.671 sec/step, loss=0.62208, avg_loss=0.64393]\n","Step 6023    [1.669 sec/step, loss=0.64127, avg_loss=0.64375]\n","Step 6024    [1.663 sec/step, loss=0.64463, avg_loss=0.64352]\n","Step 6025    [1.665 sec/step, loss=0.66944, avg_loss=0.64361]\n","Step 6026    [1.668 sec/step, loss=0.66382, avg_loss=0.64396]\n","Step 6027    [1.647 sec/step, loss=0.61389, avg_loss=0.64349]\n","Step 6028    [1.636 sec/step, loss=0.60208, avg_loss=0.64273]\n","Step 6029    [1.652 sec/step, loss=0.68962, avg_loss=0.64349]\n","Step 6030    [1.652 sec/step, loss=0.63472, avg_loss=0.64349]\n","Step 6031    [1.647 sec/step, loss=0.66494, avg_loss=0.64330]\n","Step 6032    [1.675 sec/step, loss=0.68886, avg_loss=0.64400]\n","Step 6033    [1.652 sec/step, loss=0.63340, avg_loss=0.64414]\n","Step 6034    [1.664 sec/step, loss=0.64583, avg_loss=0.64425]\n","Generated 32 batches of size 32 in 10.560 sec\n","Step 6035    [1.672 sec/step, loss=0.65680, avg_loss=0.64440]\n","Step 6036    [1.678 sec/step, loss=0.66527, avg_loss=0.64486]\n","Step 6037    [1.679 sec/step, loss=0.63084, avg_loss=0.64502]\n","Step 6038    [1.666 sec/step, loss=0.63140, avg_loss=0.64471]\n","Step 6039    [1.636 sec/step, loss=0.61040, avg_loss=0.64403]\n","Step 6040    [1.629 sec/step, loss=0.67578, avg_loss=0.64432]\n","Step 6041    [1.616 sec/step, loss=0.61842, avg_loss=0.64377]\n","Step 6042    [1.612 sec/step, loss=0.61887, avg_loss=0.64331]\n","Step 6043    [1.611 sec/step, loss=0.61201, avg_loss=0.64301]\n","Step 6044    [1.616 sec/step, loss=0.67065, avg_loss=0.64309]\n","Step 6045    [1.632 sec/step, loss=0.65781, avg_loss=0.64330]\n","Step 6046    [1.634 sec/step, loss=0.61427, avg_loss=0.64315]\n","Step 6047    [1.641 sec/step, loss=0.64997, avg_loss=0.64341]\n","Step 6048    [1.635 sec/step, loss=0.63123, avg_loss=0.64322]\n","Step 6049    [1.636 sec/step, loss=0.66107, avg_loss=0.64316]\n","Step 6050    [1.640 sec/step, loss=0.63928, avg_loss=0.64323]\n","Step 6051    [1.640 sec/step, loss=0.62477, avg_loss=0.64325]\n","Step 6052    [1.677 sec/step, loss=0.58011, avg_loss=0.64261]\n","Step 6053    [1.675 sec/step, loss=0.61911, avg_loss=0.64269]\n","Step 6054    [1.671 sec/step, loss=0.61700, avg_loss=0.64260]\n","Step 6055    [1.635 sec/step, loss=0.66189, avg_loss=0.64389]\n","Step 6056    [1.638 sec/step, loss=0.63688, avg_loss=0.64419]\n","Step 6057    [1.641 sec/step, loss=0.66536, avg_loss=0.64444]\n","Step 6058    [1.644 sec/step, loss=0.65389, avg_loss=0.64431]\n","Step 6059    [1.638 sec/step, loss=0.61256, avg_loss=0.64361]\n","Step 6060    [1.638 sec/step, loss=0.64492, avg_loss=0.64349]\n","Step 6061    [1.642 sec/step, loss=0.63355, avg_loss=0.64345]\n","Step 6062    [1.631 sec/step, loss=0.58098, avg_loss=0.64276]\n","Step 6063    [1.626 sec/step, loss=0.65057, avg_loss=0.64244]\n","Step 6064    [1.658 sec/step, loss=0.62986, avg_loss=0.64250]\n","Step 6065    [1.684 sec/step, loss=0.65486, avg_loss=0.64295]\n","Step 6066    [1.689 sec/step, loss=0.62749, avg_loss=0.64239]\n","Generated 32 batches of size 32 in 10.742 sec\n","Step 6067    [1.674 sec/step, loss=0.61878, avg_loss=0.64173]\n","Step 6068    [1.679 sec/step, loss=0.61887, avg_loss=0.64179]\n","Step 6069    [1.686 sec/step, loss=0.65509, avg_loss=0.64209]\n","Step 6070    [1.667 sec/step, loss=0.61506, avg_loss=0.64156]\n","Step 6071    [1.655 sec/step, loss=0.65156, avg_loss=0.64146]\n","Step 6072    [1.640 sec/step, loss=0.60012, avg_loss=0.64072]\n","Step 6073    [1.635 sec/step, loss=0.59661, avg_loss=0.64048]\n","Step 6074    [1.633 sec/step, loss=0.62784, avg_loss=0.64078]\n","Step 6075    [1.630 sec/step, loss=0.61975, avg_loss=0.64049]\n","Step 6076    [1.627 sec/step, loss=0.60166, avg_loss=0.64028]\n","Step 6077    [1.622 sec/step, loss=0.64353, avg_loss=0.64018]\n","Step 6078    [1.624 sec/step, loss=0.64766, avg_loss=0.63999]\n","Step 6079    [1.619 sec/step, loss=0.66403, avg_loss=0.63984]\n","Step 6080    [1.627 sec/step, loss=0.69135, avg_loss=0.64003]\n","Step 6081    [1.630 sec/step, loss=0.65027, avg_loss=0.64000]\n","Step 6082    [1.623 sec/step, loss=0.62734, avg_loss=0.63933]\n","Step 6083    [1.620 sec/step, loss=0.63369, avg_loss=0.63920]\n","Step 6084    [1.589 sec/step, loss=0.65777, avg_loss=0.63958]\n","Step 6085    [1.591 sec/step, loss=0.64862, avg_loss=0.63950]\n","Step 6086    [1.586 sec/step, loss=0.61242, avg_loss=0.63912]\n","Step 6087    [1.585 sec/step, loss=0.60800, avg_loss=0.63880]\n","Step 6088    [1.587 sec/step, loss=0.63530, avg_loss=0.63863]\n","Step 6089    [1.603 sec/step, loss=0.69334, avg_loss=0.63922]\n","Step 6090    [1.599 sec/step, loss=0.64028, avg_loss=0.63902]\n","Step 6091    [1.602 sec/step, loss=0.65386, avg_loss=0.63934]\n","Step 6092    [1.637 sec/step, loss=0.59723, avg_loss=0.63894]\n","Step 6093    [1.639 sec/step, loss=0.65735, avg_loss=0.63877]\n","Step 6094    [1.650 sec/step, loss=0.64313, avg_loss=0.63925]\n","Step 6095    [1.653 sec/step, loss=0.64345, avg_loss=0.63929]\n","Step 6096    [1.659 sec/step, loss=0.58702, avg_loss=0.63918]\n","Step 6097    [1.688 sec/step, loss=0.68513, avg_loss=0.63953]\n","Step 6098    [1.683 sec/step, loss=0.65084, avg_loss=0.63917]\n","Step 6099    [1.691 sec/step, loss=0.63345, avg_loss=0.63892]\n","Generated 32 batches of size 32 in 10.909 sec\n","Step 6100    [1.701 sec/step, loss=0.67430, avg_loss=0.63932]\n","Writing summary at step: 6100\n","Step 6101    [1.697 sec/step, loss=0.63444, avg_loss=0.63900]\n","Step 6102    [1.708 sec/step, loss=0.65915, avg_loss=0.63942]\n","Step 6103    [1.701 sec/step, loss=0.63922, avg_loss=0.63897]\n","Step 6104    [1.701 sec/step, loss=0.63975, avg_loss=0.63871]\n","Step 6105    [1.708 sec/step, loss=0.65791, avg_loss=0.63902]\n","Step 6106    [1.703 sec/step, loss=0.64013, avg_loss=0.63884]\n","Step 6107    [1.709 sec/step, loss=0.64844, avg_loss=0.63909]\n","Step 6108    [1.717 sec/step, loss=0.65884, avg_loss=0.63944]\n","Step 6109    [1.710 sec/step, loss=0.64491, avg_loss=0.63929]\n","Step 6110    [1.699 sec/step, loss=0.58684, avg_loss=0.63855]\n","Step 6111    [1.698 sec/step, loss=0.61571, avg_loss=0.63858]\n","Step 6112    [1.695 sec/step, loss=0.63014, avg_loss=0.63853]\n","Step 6113    [1.696 sec/step, loss=0.60951, avg_loss=0.63836]\n","Step 6114    [1.695 sec/step, loss=0.64869, avg_loss=0.63830]\n","Step 6115    [1.702 sec/step, loss=0.67206, avg_loss=0.63881]\n","Step 6116    [1.706 sec/step, loss=0.64224, avg_loss=0.63900]\n","Step 6117    [1.709 sec/step, loss=0.65585, avg_loss=0.63889]\n","Step 6118    [1.707 sec/step, loss=0.61455, avg_loss=0.63873]\n","Step 6119    [1.715 sec/step, loss=0.68088, avg_loss=0.63913]\n","Step 6120    [1.697 sec/step, loss=0.64135, avg_loss=0.63861]\n","Step 6121    [1.658 sec/step, loss=0.62751, avg_loss=0.63885]\n","Step 6122    [1.658 sec/step, loss=0.61699, avg_loss=0.63880]\n","Step 6123    [1.658 sec/step, loss=0.63176, avg_loss=0.63871]\n","Step 6124    [1.656 sec/step, loss=0.62272, avg_loss=0.63849]\n","Step 6125    [1.682 sec/step, loss=0.58042, avg_loss=0.63760]\n","Step 6126    [1.686 sec/step, loss=0.67730, avg_loss=0.63773]\n","Step 6127    [1.723 sec/step, loss=0.69821, avg_loss=0.63858]\n","Step 6128    [1.739 sec/step, loss=0.64333, avg_loss=0.63899]\n","Step 6129    [1.737 sec/step, loss=0.63345, avg_loss=0.63843]\n","Generated 32 batches of size 32 in 10.835 sec\n","Step 6130    [1.745 sec/step, loss=0.66960, avg_loss=0.63877]\n","Step 6131    [1.736 sec/step, loss=0.63429, avg_loss=0.63847]\n","Step 6132    [1.707 sec/step, loss=0.61154, avg_loss=0.63770]\n","Step 6133    [1.709 sec/step, loss=0.64050, avg_loss=0.63777]\n","Step 6134    [1.695 sec/step, loss=0.60390, avg_loss=0.63735]\n","Step 6135    [1.685 sec/step, loss=0.62374, avg_loss=0.63702]\n","Step 6136    [1.678 sec/step, loss=0.62064, avg_loss=0.63657]\n","Step 6137    [1.682 sec/step, loss=0.62983, avg_loss=0.63656]\n","Step 6138    [1.684 sec/step, loss=0.60147, avg_loss=0.63626]\n","Step 6139    [1.688 sec/step, loss=0.62978, avg_loss=0.63645]\n","Step 6140    [1.689 sec/step, loss=0.64666, avg_loss=0.63616]\n","Step 6141    [1.692 sec/step, loss=0.66341, avg_loss=0.63661]\n","Step 6142    [1.694 sec/step, loss=0.62592, avg_loss=0.63668]\n","Step 6143    [1.692 sec/step, loss=0.59514, avg_loss=0.63651]\n","Step 6144    [1.689 sec/step, loss=0.64926, avg_loss=0.63630]\n","Step 6145    [1.670 sec/step, loss=0.61125, avg_loss=0.63584]\n","Step 6146    [1.672 sec/step, loss=0.64330, avg_loss=0.63613]\n","Step 6147    [1.668 sec/step, loss=0.62908, avg_loss=0.63592]\n","Step 6148    [1.677 sec/step, loss=0.67549, avg_loss=0.63636]\n","Step 6149    [1.691 sec/step, loss=0.67531, avg_loss=0.63650]\n","Step 6150    [1.689 sec/step, loss=0.62886, avg_loss=0.63640]\n","Step 6151    [1.686 sec/step, loss=0.59712, avg_loss=0.63612]\n","Step 6152    [1.649 sec/step, loss=0.63891, avg_loss=0.63671]\n","Step 6153    [1.650 sec/step, loss=0.60972, avg_loss=0.63662]\n","Step 6154    [1.657 sec/step, loss=0.66384, avg_loss=0.63708]\n","Step 6155    [1.655 sec/step, loss=0.63004, avg_loss=0.63677]\n","Step 6156    [1.652 sec/step, loss=0.61204, avg_loss=0.63652]\n","Step 6157    [1.654 sec/step, loss=0.65158, avg_loss=0.63638]\n","Step 6158    [1.661 sec/step, loss=0.64836, avg_loss=0.63632]\n","Step 6159    [1.672 sec/step, loss=0.61499, avg_loss=0.63635]\n","Step 6160    [1.677 sec/step, loss=0.60019, avg_loss=0.63590]\n","Step 6161    [1.685 sec/step, loss=0.64948, avg_loss=0.63606]\n","Step 6162    [1.694 sec/step, loss=0.61794, avg_loss=0.63643]\n","Step 6163    [1.702 sec/step, loss=0.64221, avg_loss=0.63635]\n","Generated 32 batches of size 32 in 11.258 sec\n","Step 6164    [1.684 sec/step, loss=0.66427, avg_loss=0.63669]\n","Step 6165    [1.662 sec/step, loss=0.62527, avg_loss=0.63639]\n","Step 6166    [1.686 sec/step, loss=0.57149, avg_loss=0.63583]\n","Step 6167    [1.694 sec/step, loss=0.66124, avg_loss=0.63626]\n","Step 6168    [1.691 sec/step, loss=0.63918, avg_loss=0.63646]\n","Step 6169    [1.695 sec/step, loss=0.64901, avg_loss=0.63640]\n","Step 6170    [1.696 sec/step, loss=0.62631, avg_loss=0.63651]\n","Step 6171    [1.698 sec/step, loss=0.64286, avg_loss=0.63643]\n","Step 6172    [1.703 sec/step, loss=0.62345, avg_loss=0.63666]\n","Step 6173    [1.710 sec/step, loss=0.65815, avg_loss=0.63728]\n","Step 6174    [1.708 sec/step, loss=0.60248, avg_loss=0.63702]\n","Step 6175    [1.720 sec/step, loss=0.68097, avg_loss=0.63763]\n","Step 6176    [1.725 sec/step, loss=0.65323, avg_loss=0.63815]\n","Step 6177    [1.726 sec/step, loss=0.62447, avg_loss=0.63796]\n","Step 6178    [1.740 sec/step, loss=0.69718, avg_loss=0.63845]\n","Step 6179    [1.730 sec/step, loss=0.58916, avg_loss=0.63771]\n","Step 6180    [1.721 sec/step, loss=0.66651, avg_loss=0.63746]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mAEjvczYwNSA","executionInfo":{"elapsed":296537,"status":"ok","timestamp":1618635308580,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"},"user_tz":-540},"outputId":"bfe296e7-67e5-4f12-b638-c38d9805f227"},"source":["#### Use this code if you want to resume. (training with pretrained models)\n","!python train_tacotron2.py --data_paths ./data/iu --batch_size 32 --load_path ./logdir-tacotron2/pretrained_checkpoint"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From train_tacotron2.py:27: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","WARNING:tensorflow:From train_tacotron2.py:27: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n","\n","UPDATE attention_kernel: (31,) -> [31]\n","UPDATE model_type: multi-speaker -> single-speaker\n","UPDATE postnet_kernel_size: (5,) -> [5]\n","['../../../data/Voice_IU/preprocess_result']\n","==================================================\n","==================================================\n"," [*] Checkpoint path: ./logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/model.ckpt\n"," [*] Loading training data from: ['../../../data/Voice_IU/preprocess_result']\n"," [*] Using model: ./logdir-tacotron2/preprocess_result_2021-04-05_09-28-33\n","Hyperparameters:\n","  adam_beta1: 0.9\n","  adam_beta2: 0.999\n","  allow_clipping_in_normalization: True\n","  attention_dim: 128\n","  attention_filters: 32\n","  attention_kernel: [31]\n","  attention_size: 128\n","  attention_type: bah_mon_norm\n","  attention_win_size: 7\n","  cleaners: korean_cleaners\n","  clip_mels_length: True\n","  cumulative_weights: True\n","  dec_prenet_sizes: [256, 256]\n","  decoder_layers: 2\n","  decoder_lstm_units: 1024\n","  dilation_channels: 256\n","  dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n","  dropout_prob: 0.5\n","  embedding_size: 512\n","  enc_conv_channels: 512\n","  enc_conv_kernel_size: 5\n","  enc_conv_num_layers: 3\n","  encoder_lstm_units: 256\n","  fft_size: 2048\n","  filter_width: 3\n","  gc_channels: 32\n","  griffin_lim_iters: 60\n","  hop_size: 300\n","  inference_prenet_dropout: True\n","  initial_data_greedy: True\n","  initial_phase_step: 8000\n","  input_type: raw\n","  l2_regularization_strength: 0\n","  legacy: True\n","  main_data: ['']\n","  main_data_greedy_factor: 0\n","  mask_encoder: True\n","  max_abs_value: 4.0\n","  max_checkpoints: 3\n","  max_mel_frames: 1000\n","  max_n_frame: 1000\n","  min_level_db: -100\n","  min_n_frame: 150\n","  min_tokens: 30\n","  model_type: single-speaker\n","  momentum: 0.9\n","  name: Tacotron-2\n","  num_mels: 80\n","  num_steps: 1000000\n","  optimizer: adam\n","  out_channels: 30\n","  post_bank_channel_size: 128\n","  post_bank_size: 8\n","  post_highway_depth: 4\n","  post_maxpool_width: 2\n","  post_proj_sizes: [256, 80]\n","  post_proj_width: 3\n","  post_rnn_size: 128\n","  postnet_channels: 512\n","  postnet_kernel_size: [5]\n","  postnet_num_layers: 5\n","  power: 1.5\n","  preemphasis: 0.97\n","  preemphasize: True\n","  prenet_layers: [256, 256]\n","  prioritize_loss: False\n","  quantization_channels: 256\n","  reduction_factor: 2\n","  ref_level_db: 20\n","  rescaling: True\n","  rescaling_max: 0.999\n","  residual_channels: 128\n","  residual_legacy: True\n","  sample_rate: 24000\n","  sample_size: 9000\n","  scalar_input: True\n","  signal_normalization: True\n","  silence_threshold: 0\n","  skip_channels: 128\n","  skip_inadequate: False\n","  skip_path_filter: False\n","  smoothing: False\n","  speaker_embedding_size: 16\n","  store_metadata: False\n","  symmetric_mels: True\n","  synthesis_constraint: False\n","  synthesis_constraint_type: window\n","  tacotron_decay_learning_rate: True\n","  tacotron_decay_rate: 0.5\n","  tacotron_decay_steps: 18000\n","  tacotron_final_learning_rate: 0.0001\n","  tacotron_initial_learning_rate: 0.001\n","  tacotron_reg_weight: 1e-06\n","  tacotron_start_decay: 40000\n","  tacotron_zoneout_rate: 0.1\n","  trim_fft_size: 512\n","  trim_hop_size: 128\n","  trim_silence: True\n","  trim_top_db: 23\n","  upsample_factor: [12, 25]\n","  upsample_type: SubPixel\n","  use_biases: True\n","  use_lws: False\n","  wavenet_batch_size: 2\n","  wavenet_clip_gradients: True\n","  wavenet_decay_rate: 0.5\n","  wavenet_decay_steps: 300000\n","  wavenet_dropout: 0.05\n","  wavenet_learning_rate: 0.001\n","  win_size: 1200\n","filter_by_min_max_frame_batch: 100% 2897/2897 [02:56<00:00, 16.46it/s]\n"," [../../../data/Voice_IU/preprocess_result] Loaded metadata for 2088 examples (2.07 hours)\n"," [../../../data/Voice_IU/preprocess_result] Max length: 996\n"," [../../../data/Voice_IU/preprocess_result] Min length: 150\n","========================================\n","Data Amount:\n","{'../../../data/Voice_IU/preprocess_result': 1.0}\n","========================================\n","filter_by_min_max_frame_batch: 100% 2897/2897 [00:13<00:00, 219.45it/s]\n"," [../../../data/Voice_IU/preprocess_result] Loaded metadata for 2088 examples (2.07 hours)\n"," [../../../data/Voice_IU/preprocess_result] Max length: 996\n"," [../../../data/Voice_IU/preprocess_result] Min length: 150\n","========================================\n","Data Amount:\n","{'../../../data/Voice_IU/preprocess_result': 1.0}\n","========================================\n","========================================\n"," model_type: single-speaker\n","========================================\n","Initialized Tacotron model. Dimensions: \n","    embedding:                512\n","    encoder conv out:               512\n","    encoder out:              512\n","    attention out:            1024\n","    decoder prenet lstm concat out :        1536\n","    decoder cell out:         162\n","    decoder out (2 frames):  162\n","    decoder mel out:    80\n","    mel out:    80\n","    postnet out:              256\n","    linear out:               1025\n","  Tacotron Parameters       29.142 Million.\n","========================================\n"," model_type: single-speaker\n","========================================\n","Initialized Tacotron model. Dimensions: \n","    embedding:                512\n","    encoder conv out:               512\n","    encoder out:              512\n","    attention out:            1024\n","    decoder prenet lstm concat out :        1536\n","    decoder cell out:         162\n","    decoder out (2 frames):  162\n","    decoder mel out:    80\n","    mel out:    80\n","    postnet out:              256\n","    linear out:               1025\n","  Tacotron Parameters       29.142 Million.\n","2021-04-17 04:53:42.285650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-04-17 04:53:42.343963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-04-17 04:53:42.344738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2021-04-17 04:53:42.356625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-04-17 04:53:42.583201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-04-17 04:53:42.701375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-04-17 04:53:42.715413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-04-17 04:53:43.010372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-04-17 04:53:43.082733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-04-17 04:53:43.586632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-04-17 04:53:43.586835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-04-17 04:53:43.587568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-04-17 04:53:43.588101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-04-17 04:53:43.689509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2021-04-17 04:53:43.689935: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5627d5502e00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-04-17 04:53:43.689969: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-04-17 04:53:43.842159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-04-17 04:53:43.842933: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5627d5502540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-04-17 04:53:43.842966: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2021-04-17 04:53:43.843311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-04-17 04:53:43.843934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2021-04-17 04:53:43.844050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-04-17 04:53:43.844089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-04-17 04:53:43.844119: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-04-17 04:53:43.844142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-04-17 04:53:43.844162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-04-17 04:53:43.844186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-04-17 04:53:43.844211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-04-17 04:53:43.844314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-04-17 04:53:43.844912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-04-17 04:53:43.845452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-04-17 04:53:43.848407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-04-17 04:53:43.850699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-04-17 04:53:43.850736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-04-17 04:53:43.850752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-04-17 04:53:43.853701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-04-17 04:53:43.856366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-04-17 04:53:43.859103: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-04-17 04:53:43.859256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"," [*] Found lastest checkpoint: ./logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/model.ckpt-46000\n","Resuming from checkpoint: ./logdir-tacotron2/preprocess_result_2021-04-05_09-28-33/model.ckpt-46000 at commit: None\n","Generated 8 batches of size 2 in 0.000 sec\n","2021-04-17 04:54:07.417359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","Generated 32 batches of size 32 in 11.998 sec\n","2021-04-17 04:54:11.571875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","Step 46001   [21.473 sec/step, loss=0.74174, avg_loss=0.74174]\n","Step 46002   [11.762 sec/step, loss=0.63311, avg_loss=0.68743]\n","Step 46003   [8.282 sec/step, loss=0.75576, avg_loss=0.71021]\n","Step 46004   [6.801 sec/step, loss=1.02171, avg_loss=0.78808]\n","Step 46005   [5.700 sec/step, loss=0.91274, avg_loss=0.81301]\n","Step 46006   [5.078 sec/step, loss=0.81011, avg_loss=0.81253]\n","Step 46007   [4.588 sec/step, loss=0.78735, avg_loss=0.80893]\n","Step 46008   [4.156 sec/step, loss=0.91704, avg_loss=0.82245]\n","Step 46009   [3.886 sec/step, loss=0.79572, avg_loss=0.81948]\n","Step 46010   [3.621 sec/step, loss=0.94519, avg_loss=0.83205]\n","Step 46011   [3.419 sec/step, loss=0.75923, avg_loss=0.82543]\n","Step 46012   [3.303 sec/step, loss=0.88204, avg_loss=0.83014]\n","Step 46013   [3.211 sec/step, loss=1.03224, avg_loss=0.84569]\n","Step 46014   [3.172 sec/step, loss=0.75850, avg_loss=0.83946]\n","Step 46015   [3.077 sec/step, loss=0.96075, avg_loss=0.84755]\n","Step 46016   [2.989 sec/step, loss=0.82502, avg_loss=0.84614]\n","Step 46017   [2.957 sec/step, loss=0.98532, avg_loss=0.85433]\n","Step 46018   [3.106 sec/step, loss=0.70691, avg_loss=0.84614]\n","Step 46019   [3.067 sec/step, loss=0.89766, avg_loss=0.84885]\n","2021-04-17 04:54:59.137035: W tensorflow/core/kernels/queue_base.cc:277] _0_datafeeder/input_queue_1: Skipping cancelled enqueue attempt with queue not closed\n","2021-04-17 04:54:59.137147: W tensorflow/core/kernels/queue_base.cc:277] _1_datafeeder/input_queue: Skipping cancelled enqueue attempt with queue not closed\n","Traceback (most recent call last):\n","  File \"train_tacotron2.py\", line 287, in <module>\n","    main()\n","  File \"train_tacotron2.py\", line 283, in main\n","    train(config.model_dir, config)\n","  File \"train_tacotron2.py\", line 190, in train\n","    step, loss, opt = sess.run([global_step, model.loss_without_coeff, model.optimize])\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n","\t [[{{node datafeeder/input_queue_enqueue}}]]\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/datafeeder_tacotron2.py\", line 189, in run\n","    self._enqueue_next_group()\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/datafeeder_tacotron2.py\", line 225, in _enqueue_next_group\n","    self._session.run(self._enqueue_op, feed_dict=feed_dict)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n","\t [[node datafeeder/input_queue_enqueue (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\n","\n","Original stack trace for 'datafeeder/input_queue_enqueue':\n","  File \"train_tacotron2.py\", line 287, in <module>\n","    main()\n","  File \"train_tacotron2.py\", line 283, in main\n","    train(config.model_dir, config)\n","  File \"train_tacotron2.py\", line 121, in train\n","    train_feeder = DataFeederTacotron2(coord, data_dirs, hparams, config, 32,data_type='train', batch_size=config.batch_size)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/datafeeder_tacotron2.py\", line 144, in __init__\n","    self._enqueue_op = queue.enqueue(self._placeholders)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/data_flow_ops.py\", line 346, in enqueue\n","    self._queue_ref, vals, name=scope)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/gen_data_flow_ops.py\", line 4410, in queue_enqueue_v2\n","    timeout_ms=timeout_ms, name=name)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n","\t [[{{node datafeeder/input_queue_1_enqueue}}]]\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/datafeeder_tacotron2.py\", line 189, in run\n","    self._enqueue_next_group()\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/datafeeder_tacotron2.py\", line 225, in _enqueue_next_group\n","    self._session.run(self._enqueue_op, feed_dict=feed_dict)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n","\t [[node datafeeder/input_queue_1_enqueue (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\n","\n","Original stack trace for 'datafeeder/input_queue_1_enqueue':\n","  File \"train_tacotron2.py\", line 287, in <module>\n","    main()\n","  File \"train_tacotron2.py\", line 283, in main\n","    train(config.model_dir, config)\n","  File \"train_tacotron2.py\", line 122, in train\n","    test_feeder = DataFeederTacotron2(coord, data_dirs, hparams, config, 8, data_type='test', batch_size=config.num_test)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/datafeeder_tacotron2.py\", line 144, in __init__\n","    self._enqueue_op = queue.enqueue(self._placeholders)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/data_flow_ops.py\", line 346, in enqueue\n","    self._queue_ref, vals, name=scope)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/gen_data_flow_ops.py\", line 4410, in queue_enqueue_v2\n","    timeout_ms=timeout_ms, name=name)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jROyIV34v7wY"},"source":["# Tacotron2 for kss dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0r7AHqXra8tR","executionInfo":{"elapsed":3423076,"status":"ok","timestamp":1617804036317,"user":{"displayName":"­이예빈(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"14411664074289532491"},"user_tz":-540},"outputId":"f3f304a4-27b2-4661-f59f-0fb60ad4c80d"},"source":["# preprocessing (Only for the first starting. Data will be saved into the out_dir)\n","!python preprocess.py --num_workers 8 --name kss --in_dir write_your_dataset_path/kss --out_dir ./data/kss"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Hyperparameters:\n","  adam_beta1: 0.9\n","  adam_beta2: 0.999\n","  allow_clipping_in_normalization: True\n","  attention_dim: 128\n","  attention_filters: 32\n","  attention_kernel: (31,)\n","  attention_size: 128\n","  attention_type: bah_mon_norm\n","  attention_win_size: 7\n","  cleaners: korean_cleaners\n","  clip_mels_length: True\n","  cumulative_weights: True\n","  dec_prenet_sizes: [256, 256]\n","  decoder_layers: 2\n","  decoder_lstm_units: 1024\n","  dilation_channels: 256\n","  dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n","  dropout_prob: 0.5\n","  embedding_size: 512\n","  enc_conv_channels: 512\n","  enc_conv_kernel_size: 5\n","  enc_conv_num_layers: 3\n","  encoder_lstm_units: 256\n","  fft_size: 2048\n","  filter_width: 3\n","  gc_channels: 32\n","  griffin_lim_iters: 60\n","  hop_size: 300\n","  inference_prenet_dropout: True\n","  initial_data_greedy: True\n","  initial_phase_step: 8000\n","  input_type: raw\n","  l2_regularization_strength: 0\n","  legacy: True\n","  main_data: ['']\n","  main_data_greedy_factor: 0\n","  mask_encoder: True\n","  max_abs_value: 4.0\n","  max_checkpoints: 3\n","  max_mel_frames: 1000\n","  max_n_frame: 1000\n","  min_level_db: -100\n","  min_n_frame: 150\n","  min_tokens: 30\n","  model_type: multi-speaker\n","  momentum: 0.9\n","  name: Tacotron-2\n","  num_mels: 80\n","  num_steps: 1000000\n","  optimizer: adam\n","  out_channels: 30\n","  post_bank_channel_size: 128\n","  post_bank_size: 8\n","  post_highway_depth: 4\n","  post_maxpool_width: 2\n","  post_proj_sizes: [256, 80]\n","  post_proj_width: 3\n","  post_rnn_size: 128\n","  postnet_channels: 512\n","  postnet_kernel_size: (5,)\n","  postnet_num_layers: 5\n","  power: 1.5\n","  preemphasis: 0.97\n","  preemphasize: True\n","  prenet_layers: [256, 256]\n","  prioritize_loss: False\n","  quantization_channels: 256\n","  reduction_factor: 2\n","  ref_level_db: 20\n","  rescaling: True\n","  rescaling_max: 0.999\n","  residual_channels: 128\n","  residual_legacy: True\n","  sample_rate: 24000\n","  sample_size: 9000\n","  scalar_input: True\n","  signal_normalization: True\n","  silence_threshold: 0\n","  skip_channels: 128\n","  skip_inadequate: False\n","  skip_path_filter: False\n","  smoothing: False\n","  speaker_embedding_size: 16\n","  store_metadata: False\n","  symmetric_mels: True\n","  synthesis_constraint: False\n","  synthesis_constraint_type: window\n","  tacotron_decay_learning_rate: True\n","  tacotron_decay_rate: 0.5\n","  tacotron_decay_steps: 18000\n","  tacotron_final_learning_rate: 0.0001\n","  tacotron_initial_learning_rate: 0.001\n","  tacotron_reg_weight: 1e-06\n","  tacotron_start_decay: 40000\n","  tacotron_zoneout_rate: 0.1\n","  trim_fft_size: 512\n","  trim_hop_size: 128\n","  trim_silence: True\n","  trim_top_db: 23\n","  upsample_factor: [12, 25]\n","  upsample_type: SubPixel\n","  use_biases: True\n","  use_lws: False\n","  wavenet_batch_size: 2\n","  wavenet_clip_gradients: True\n","  wavenet_decay_rate: 0.5\n","  wavenet_decay_steps: 300000\n","  wavenet_dropout: 0.05\n","  wavenet_learning_rate: 0.001\n","  win_size: 1200\n","Sampling frequency: 24000\n","  0% 0/12854 [00:00<?, ?it/s]concurrent.futures.process._RemoteTraceback: \n","\"\"\"\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/concurrent/futures/process.py\", line 239, in _process_worker\n","    r = call_item.fn(*call_item.args, **call_item.kwargs)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/kss.py\", line 167, in _process_utterance\n","    'tokens': text_to_sequence(text),   # eos(~)에 해당하는 \"1\"이 끝에 붙는다.\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/__init__.py\", line 42, in text_to_sequence\n","    return _text_to_sequence(text, cleaner_names, as_token)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/__init__.py\", line 63, in _text_to_sequence\n","    sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/__init__.py\", line 110, in _clean_text\n","    text = cleaner(text) # '존경하는' --> ['ᄌ', 'ᅩ', 'ᆫ', 'ᄀ', 'ᅧ', 'ᆼ', 'ᄒ', 'ᅡ', 'ᄂ', 'ᅳ', 'ᆫ', '~']\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/cleaners.py\", line 29, in korean_cleaners\n","    text = ko_tokenize(text) # '존경하는' --> ['ᄌ', 'ᅩ', 'ᆫ', 'ᄀ', 'ᅧ', 'ᆼ', 'ᄒ', 'ᅡ', 'ᄂ', 'ᅳ', 'ᆫ', '~']\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/korean.py\", line 142, in tokenize\n","    text = normalize(text)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/korean.py\", line 163, in normalize\n","    text = normalize_quote(text)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/korean.py\", line 204, in normalize_quote\n","    return re.sub(quote_checker, fn, text)\n","  File \"/usr/lib/python3.7/re.py\", line 194, in sub\n","    return _compile(pattern, flags).sub(repl, string, count)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/korean.py\", line 201, in fn\n","    sentences = sent_tokenize(unquoted_text)\n","  File \"/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\", line 94, in sent_tokenize\n","    tokenizer = load('tokenizers/punkt/{0}.pickle'.format(language))\n","  File \"/usr/local/lib/python3.7/dist-packages/nltk/data.py\", line 834, in load\n","    opened_resource = _open(resource_url)\n","  File \"/usr/local/lib/python3.7/dist-packages/nltk/data.py\", line 952, in _open\n","    return find(path_, path + ['']).open()\n","  File \"/usr/local/lib/python3.7/dist-packages/nltk/data.py\", line 673, in find\n","    raise LookupError(resource_not_found)\n","LookupError: \n","**********************************************************************\n","  Resource \u001b[93mpunkt\u001b[0m not found.\n","  Please use the NLTK Downloader to obtain the resource:\n","\n","  \u001b[31m>>> import nltk\n","  >>> nltk.download('punkt')\n","  \u001b[0m\n","  Searched in:\n","    - '/root/nltk_data'\n","    - '/usr/share/nltk_data'\n","    - '/usr/local/share/nltk_data'\n","    - '/usr/lib/nltk_data'\n","    - '/usr/local/lib/nltk_data'\n","    - '/usr/nltk_data'\n","    - '/usr/lib/nltk_data'\n","    - ''\n","**********************************************************************\n","\n","\"\"\"\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"preprocess.py\", line 61, in <module>\n","    preprocess(mod, in_dir, out_dir, num_workers)\n","  File \"preprocess.py\", line 21, in preprocess\n","    metadata = mod.build_from_path(hparams, in_dir, out_dir,num_workers=num_workers, tqdm=tqdm)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/kss.py\", line 44, in build_from_path\n","    return [future.result() for future in tqdm(futures) if future.result() is not None]\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/kss.py\", line 44, in <listcomp>\n","    return [future.result() for future in tqdm(futures) if future.result() is not None]\n","  File \"/usr/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\n","    return self.__get_result()\n","  File \"/usr/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\n","    raise self._exception\n","  File \"/usr/lib/python3.7/concurrent/futures/process.py\", line 239, in _process_worker\n","    r = call_item.fn(*call_item.args, **call_item.kwargs)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/datasets/kss.py\", line 167, in _process_utterance\n","    'tokens': text_to_sequence(text),   # eos(~)에 해당하는 \"1\"이 끝에 붙는다.\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/__init__.py\", line 42, in text_to_sequence\n","    return _text_to_sequence(text, cleaner_names, as_token)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/__init__.py\", line 63, in _text_to_sequence\n","    sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/__init__.py\", line 110, in _clean_text\n","    text = cleaner(text) # '존경하는' --> ['ᄌ', 'ᅩ', 'ᆫ', 'ᄀ', 'ᅧ', 'ᆼ', 'ᄒ', 'ᅡ', 'ᄂ', 'ᅳ', 'ᆫ', '~']\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/cleaners.py\", line 29, in korean_cleaners\n","    text = ko_tokenize(text) # '존경하는' --> ['ᄌ', 'ᅩ', 'ᆫ', 'ᄀ', 'ᅧ', 'ᆼ', 'ᄒ', 'ᅡ', 'ᄂ', 'ᅳ', 'ᆫ', '~']\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/korean.py\", line 142, in tokenize\n","    text = normalize(text)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/korean.py\", line 163, in normalize\n","    text = normalize_quote(text)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/korean.py\", line 204, in normalize_quote\n","    return re.sub(quote_checker, fn, text)\n","  File \"/usr/lib/python3.7/re.py\", line 194, in sub\n","    return _compile(pattern, flags).sub(repl, string, count)\n","  File \"/content/drive/.shortcut-targets-by-id/1mQ5CexiSXSxIuga_EdNGPwg5UvVjXutb/2021-1 융합캡스톤디자인/workspace/Tacotron-in-colab_yb/tacotron2/text/korean.py\", line 201, in fn\n","    sentences = sent_tokenize(unquoted_text)\n","  File \"/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\", line 94, in sent_tokenize\n","    tokenizer = load('tokenizers/punkt/{0}.pickle'.format(language))\n","  File \"/usr/local/lib/python3.7/dist-packages/nltk/data.py\", line 834, in load\n","    opened_resource = _open(resource_url)\n","  File \"/usr/local/lib/python3.7/dist-packages/nltk/data.py\", line 952, in _open\n","    return find(path_, path + ['']).open()\n","  File \"/usr/local/lib/python3.7/dist-packages/nltk/data.py\", line 673, in find\n","    raise LookupError(resource_not_found)\n","LookupError: \n","**********************************************************************\n","  Resource \u001b[93mpunkt\u001b[0m not found.\n","  Please use the NLTK Downloader to obtain the resource:\n","\n","  \u001b[31m>>> import nltk\n","  >>> nltk.download('punkt')\n","  \u001b[0m\n","  Searched in:\n","    - '/root/nltk_data'\n","    - '/usr/share/nltk_data'\n","    - '/usr/local/share/nltk_data'\n","    - '/usr/lib/nltk_data'\n","    - '/usr/local/lib/nltk_data'\n","    - '/usr/nltk_data'\n","    - '/usr/lib/nltk_data'\n","    - ''\n","**********************************************************************\n","\n","  0% 0/12854 [55:03<?, ?it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upMn8q8kwKNC","outputId":"a530b825-6a73-4169-d711-53e94a21b27b"},"source":["# train tacotron2 without loading models (checkpoint). use kss & iu dataset\n","!python train_tacotron2.py --data_paths ./data/kss,./data/iu --batch_size 32"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","Step 2849    [1.446 sec/step, loss=0.92209, avg_loss=0.89426]\n","Step 2850    [1.448 sec/step, loss=0.89447, avg_loss=0.89357]\n","Step 2851    [1.440 sec/step, loss=0.90978, avg_loss=0.89379]\n","Step 2852    [1.440 sec/step, loss=0.95183, avg_loss=0.89399]\n","Step 2853    [1.376 sec/step, loss=0.89265, avg_loss=0.89376]\n","Step 2854    [1.370 sec/step, loss=0.92236, avg_loss=0.89414]\n","Step 2855    [1.370 sec/step, loss=0.91539, avg_loss=0.89429]\n","Step 2856    [1.370 sec/step, loss=0.91299, avg_loss=0.89417]\n","Step 2857    [1.372 sec/step, loss=0.89192, avg_loss=0.89389]\n","Step 2858    [1.372 sec/step, loss=0.90695, avg_loss=0.89369]\n","Step 2859    [1.373 sec/step, loss=0.90350, avg_loss=0.89362]\n","Step 2860    [1.379 sec/step, loss=0.90268, avg_loss=0.89389]\n","Step 2861    [1.408 sec/step, loss=0.65297, avg_loss=0.89140]\n","Step 2862    [1.405 sec/step, loss=0.93475, avg_loss=0.89189]\n","Step 2863    [1.405 sec/step, loss=0.91281, avg_loss=0.89222]\n","Step 2864    [1.405 sec/step, loss=0.92588, avg_loss=0.89255]\n","Step 2865    [1.404 sec/step, loss=0.90918, avg_loss=0.89283]\n","Step 2866    [1.402 sec/step, loss=0.90276, avg_loss=0.89291]\n","Step 2867    [1.407 sec/step, loss=0.89506, avg_loss=0.89305]\n","Step 2868    [1.405 sec/step, loss=0.84956, avg_loss=0.89339]\n","Step 2869    [1.410 sec/step, loss=0.89563, avg_loss=0.89358]\n","Step 2870    [1.409 sec/step, loss=0.90400, avg_loss=0.89352]\n","Step 2871    [1.413 sec/step, loss=0.92906, avg_loss=0.89382]\n","Step 2872    [1.396 sec/step, loss=0.90292, avg_loss=0.89569]\n","Step 2873    [1.404 sec/step, loss=0.91212, avg_loss=0.89567]\n","Step 2874    [1.407 sec/step, loss=0.89418, avg_loss=0.89549]\n","Step 2875    [1.416 sec/step, loss=0.89624, avg_loss=0.89551]\n","Step 2876    [1.415 sec/step, loss=0.87444, avg_loss=0.89558]\n","Step 2877    [1.417 sec/step, loss=0.88985, avg_loss=0.89556]\n","Step 2878    [1.407 sec/step, loss=0.89846, avg_loss=0.89594]\n","Step 2879    [1.404 sec/step, loss=0.89626, avg_loss=0.89601]\n","Generated 32 batches of size 32 in 17.721 sec\n","Step 2880    [1.445 sec/step, loss=0.87301, avg_loss=0.89606]\n","Step 2881    [1.441 sec/step, loss=0.88026, avg_loss=0.89563]\n","Step 2882    [1.457 sec/step, loss=0.65120, avg_loss=0.89327]\n","Step 2883    [1.457 sec/step, loss=0.88869, avg_loss=0.89324]\n","Step 2884    [1.453 sec/step, loss=0.89580, avg_loss=0.89298]\n","Step 2885    [1.393 sec/step, loss=0.90495, avg_loss=0.89309]\n","Step 2886    [1.391 sec/step, loss=0.89858, avg_loss=0.89348]\n","Step 2887    [1.385 sec/step, loss=0.89201, avg_loss=0.89292]\n","Step 2888    [1.384 sec/step, loss=0.87832, avg_loss=0.89240]\n","Step 2889    [1.385 sec/step, loss=0.87089, avg_loss=0.89227]\n","Step 2890    [1.383 sec/step, loss=0.90130, avg_loss=0.89226]\n","Step 2891    [1.380 sec/step, loss=0.90054, avg_loss=0.89217]\n","Step 2892    [1.383 sec/step, loss=0.88044, avg_loss=0.89182]\n","Step 2893    [1.390 sec/step, loss=0.84878, avg_loss=0.89114]\n","Step 2894    [1.390 sec/step, loss=0.89570, avg_loss=0.89096]\n","Step 2895    [1.396 sec/step, loss=0.86431, avg_loss=0.89075]\n","Step 2896    [1.394 sec/step, loss=0.89322, avg_loss=0.89049]\n","Step 2897    [1.401 sec/step, loss=0.87790, avg_loss=0.89032]\n","Step 2898    [1.405 sec/step, loss=0.87489, avg_loss=0.89013]\n","Step 2899    [1.406 sec/step, loss=0.88209, avg_loss=0.88991]\n","Step 2900    [1.404 sec/step, loss=0.92261, avg_loss=0.88986]\n","Writing summary at step: 2900\n","Step 2901    [1.404 sec/step, loss=0.92820, avg_loss=0.88994]\n","Step 2902    [1.410 sec/step, loss=0.89223, avg_loss=0.88972]\n","Step 2903    [1.410 sec/step, loss=0.87676, avg_loss=0.88954]\n","Step 2904    [1.416 sec/step, loss=0.89967, avg_loss=0.88922]\n","Step 2905    [1.415 sec/step, loss=0.89442, avg_loss=0.88911]\n","Step 2906    [1.419 sec/step, loss=0.92298, avg_loss=0.88942]\n","Step 2907    [1.414 sec/step, loss=0.88355, avg_loss=0.88921]\n","Step 2908    [1.418 sec/step, loss=0.88817, avg_loss=0.88915]\n","Step 2909    [1.419 sec/step, loss=0.87660, avg_loss=0.88879]\n","Step 2910    [1.432 sec/step, loss=0.86409, avg_loss=0.88841]\n","Generated 32 batches of size 32 in 19.110 sec\n","Step 2911    [1.496 sec/step, loss=0.92296, avg_loss=0.88844]\n","Step 2912    [1.478 sec/step, loss=0.87200, avg_loss=0.88895]\n","Step 2913    [1.467 sec/step, loss=0.92566, avg_loss=0.88912]\n","Step 2914    [1.460 sec/step, loss=0.89010, avg_loss=0.88917]\n","Step 2915    [1.427 sec/step, loss=0.89908, avg_loss=0.89138]\n","Step 2916    [1.395 sec/step, loss=0.91549, avg_loss=0.89108]\n","Step 2917    [1.392 sec/step, loss=0.89534, avg_loss=0.89123]\n","Step 2918    [1.386 sec/step, loss=0.87192, avg_loss=0.89105]\n","Step 2919    [1.385 sec/step, loss=0.91176, avg_loss=0.89144]\n","Step 2920    [1.378 sec/step, loss=0.89293, avg_loss=0.89141]\n","Step 2921    [1.381 sec/step, loss=0.92128, avg_loss=0.89156]\n","Step 2922    [1.388 sec/step, loss=0.85844, avg_loss=0.89101]\n","Step 2923    [1.389 sec/step, loss=0.88592, avg_loss=0.89083]\n","Step 2924    [1.393 sec/step, loss=0.88344, avg_loss=0.89058]\n","Step 2925    [1.389 sec/step, loss=0.86324, avg_loss=0.89027]\n","Step 2926    [1.395 sec/step, loss=0.88470, avg_loss=0.89006]\n","Step 2927    [1.395 sec/step, loss=0.88832, avg_loss=0.89022]\n","Step 2928    [1.402 sec/step, loss=0.84099, avg_loss=0.88913]\n","Step 2929    [1.401 sec/step, loss=0.90844, avg_loss=0.88916]\n","Step 2930    [1.394 sec/step, loss=0.90261, avg_loss=0.88939]\n","Step 2931    [1.399 sec/step, loss=0.84244, avg_loss=0.88885]\n","Step 2932    [1.416 sec/step, loss=0.82677, avg_loss=0.88790]\n","Step 2933    [1.418 sec/step, loss=0.92649, avg_loss=0.88807]\n","Step 2934    [1.429 sec/step, loss=0.90054, avg_loss=0.88808]\n","Step 2935    [1.473 sec/step, loss=0.67177, avg_loss=0.88572]\n","Step 2936    [1.474 sec/step, loss=0.92534, avg_loss=0.88603]\n","Step 2937    [1.477 sec/step, loss=0.89964, avg_loss=0.88620]\n","Step 2938    [1.483 sec/step, loss=0.87756, avg_loss=0.88595]\n","Step 2939    [1.479 sec/step, loss=0.90357, avg_loss=0.88608]\n","Step 2940    [1.477 sec/step, loss=0.88758, avg_loss=0.88594]\n","Step 2941    [1.478 sec/step, loss=0.87598, avg_loss=0.88536]\n","Step 2942    [1.475 sec/step, loss=0.87653, avg_loss=0.88519]\n","Generated 32 batches of size 32 in 19.261 sec\n","Step 2943    [1.503 sec/step, loss=0.86510, avg_loss=0.88470]\n","Step 2944    [1.459 sec/step, loss=0.87826, avg_loss=0.88723]\n","Step 2945    [1.437 sec/step, loss=0.89456, avg_loss=0.88774]\n","Step 2946    [1.442 sec/step, loss=0.81766, avg_loss=0.88676]\n","Step 2947    [1.440 sec/step, loss=0.89828, avg_loss=0.88635]\n","Step 2948    [1.414 sec/step, loss=0.90758, avg_loss=0.88615]\n","Step 2949    [1.415 sec/step, loss=0.90665, avg_loss=0.88600]\n","Step 2950    [1.408 sec/step, loss=0.90284, avg_loss=0.88608]\n","Step 2951    [1.409 sec/step, loss=0.89421, avg_loss=0.88593]\n","Step 2952    [1.411 sec/step, loss=0.85869, avg_loss=0.88499]\n","Step 2953    [1.416 sec/step, loss=0.90630, avg_loss=0.88513]\n","Step 2954    [1.423 sec/step, loss=0.84090, avg_loss=0.88432]\n","Step 2955    [1.423 sec/step, loss=0.88855, avg_loss=0.88405]\n","Step 2956    [1.423 sec/step, loss=0.90701, avg_loss=0.88399]\n","Step 2957    [1.424 sec/step, loss=0.89814, avg_loss=0.88405]\n","Step 2958    [1.422 sec/step, loss=0.87449, avg_loss=0.88373]\n","Step 2959    [1.420 sec/step, loss=0.91025, avg_loss=0.88379]\n","Step 2960    [1.420 sec/step, loss=0.88805, avg_loss=0.88365]\n","Step 2961    [1.391 sec/step, loss=0.90230, avg_loss=0.88614]\n","Step 2962    [1.388 sec/step, loss=0.89468, avg_loss=0.88574]\n","Step 2963    [1.390 sec/step, loss=0.89313, avg_loss=0.88554]\n","Step 2964    [1.393 sec/step, loss=0.87759, avg_loss=0.88506]\n","Step 2965    [1.397 sec/step, loss=0.87692, avg_loss=0.88474]\n","Step 2966    [1.444 sec/step, loss=0.58961, avg_loss=0.88161]\n","Step 2967    [1.440 sec/step, loss=0.90904, avg_loss=0.88175]\n","Step 2968    [1.433 sec/step, loss=0.94634, avg_loss=0.88271]\n","Step 2969    [1.435 sec/step, loss=0.90254, avg_loss=0.88278]\n","Step 2970    [1.440 sec/step, loss=0.93453, avg_loss=0.88309]\n","Step 2971    [1.441 sec/step, loss=0.87452, avg_loss=0.88254]\n","Step 2972    [1.436 sec/step, loss=0.91234, avg_loss=0.88264]\n","Step 2973    [1.429 sec/step, loss=0.92230, avg_loss=0.88274]\n","Step 2974    [1.429 sec/step, loss=0.92105, avg_loss=0.88301]\n","Generated 32 batches of size 32 in 19.619 sec\n","Step 2975    [1.466 sec/step, loss=0.88857, avg_loss=0.88293]\n","Step 2976    [1.458 sec/step, loss=0.90375, avg_loss=0.88322]\n","Step 2977    [1.459 sec/step, loss=0.85555, avg_loss=0.88288]\n","Step 2978    [1.451 sec/step, loss=0.88194, avg_loss=0.88271]\n","Step 2979    [1.450 sec/step, loss=0.89877, avg_loss=0.88274]\n","Step 2980    [1.396 sec/step, loss=0.90848, avg_loss=0.88309]\n","Step 2981    [1.400 sec/step, loss=0.87924, avg_loss=0.88308]\n","Step 2982    [1.379 sec/step, loss=0.89703, avg_loss=0.88554]\n","Step 2983    [1.374 sec/step, loss=0.90545, avg_loss=0.88571]\n","Step 2984    [1.374 sec/step, loss=0.90974, avg_loss=0.88585]\n","Step 2985    [1.406 sec/step, loss=0.56530, avg_loss=0.88245]\n","Step 2986    [1.414 sec/step, loss=0.88422, avg_loss=0.88231]\n","Step 2987    [1.415 sec/step, loss=0.90397, avg_loss=0.88243]\n","Step 2988    [1.418 sec/step, loss=0.89770, avg_loss=0.88262]\n","Step 2989    [1.412 sec/step, loss=0.89914, avg_loss=0.88291]\n","Step 2990    [1.417 sec/step, loss=0.88015, avg_loss=0.88269]\n","Step 2991    [1.422 sec/step, loss=0.87261, avg_loss=0.88241]\n","Step 2992    [1.430 sec/step, loss=0.86125, avg_loss=0.88222]\n","Step 2993    [1.419 sec/step, loss=0.90711, avg_loss=0.88281]\n","Step 2994    [1.416 sec/step, loss=0.91337, avg_loss=0.88298]\n","Step 2995    [1.410 sec/step, loss=0.90521, avg_loss=0.88339]\n","Step 2996    [1.408 sec/step, loss=0.91288, avg_loss=0.88359]\n","Step 2997    [1.406 sec/step, loss=0.90319, avg_loss=0.88384]\n","Step 2998    [1.407 sec/step, loss=0.90416, avg_loss=0.88413]\n","Step 2999    [1.408 sec/step, loss=0.92644, avg_loss=0.88458]\n","Step 3000    [1.412 sec/step, loss=0.87004, avg_loss=0.88405]\n","Writing summary at step: 3000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (78300,)\n","Check wav file:  (108300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000003000-align000.png\n","100% 1/1 [00:04<00:00,  4.90s/it]\n","Test finished for step 3000.\n","  0% 0/4 [00:00<?, ?it/s]Generated 32 batches of size 32 in 20.811 sec\n","Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000003000-align000.png\n"," 25% 1/4 [00:11<00:34, 11.53s/it]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000003000-align001.png\n"," 50% 2/4 [00:21<00:22, 11.12s/it]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000003000-align002.png\n"," 75% 3/4 [00:32<00:10, 10.92s/it]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000003000-align003.png\n","100% 4/4 [00:42<00:00, 10.60s/it]\n","Test finished for step 3000.\n","Step 3001    [1.414 sec/step, loss=0.90442, avg_loss=0.88381]\n","Step 3002    [1.418 sec/step, loss=0.91575, avg_loss=0.88405]\n","Step 3003    [1.422 sec/step, loss=0.89458, avg_loss=0.88423]\n","Step 3004    [1.418 sec/step, loss=0.93329, avg_loss=0.88456]\n","Step 3005    [1.418 sec/step, loss=0.90617, avg_loss=0.88468]\n","Step 3006    [1.415 sec/step, loss=0.89823, avg_loss=0.88443]\n","Step 3007    [1.414 sec/step, loss=0.92199, avg_loss=0.88482]\n","Step 3008    [1.408 sec/step, loss=0.91863, avg_loss=0.88512]\n","Step 3009    [1.402 sec/step, loss=0.87862, avg_loss=0.88514]\n","Step 3010    [1.387 sec/step, loss=0.89391, avg_loss=0.88544]\n","Step 3011    [1.320 sec/step, loss=0.91087, avg_loss=0.88532]\n","Step 3012    [1.323 sec/step, loss=0.88819, avg_loss=0.88548]\n","Step 3013    [1.327 sec/step, loss=0.88120, avg_loss=0.88504]\n","Step 3014    [1.334 sec/step, loss=0.85724, avg_loss=0.88471]\n","Step 3015    [1.330 sec/step, loss=0.91027, avg_loss=0.88482]\n","Step 3016    [1.329 sec/step, loss=0.91057, avg_loss=0.88477]\n","Step 3017    [1.338 sec/step, loss=0.85139, avg_loss=0.88433]\n","Step 3018    [1.343 sec/step, loss=0.89336, avg_loss=0.88455]\n","Step 3019    [1.349 sec/step, loss=0.91414, avg_loss=0.88457]\n","Step 3020    [1.347 sec/step, loss=0.88421, avg_loss=0.88448]\n","Step 3021    [1.351 sec/step, loss=0.87721, avg_loss=0.88404]\n","Step 3022    [1.345 sec/step, loss=0.89324, avg_loss=0.88439]\n","Step 3023    [1.349 sec/step, loss=0.89501, avg_loss=0.88448]\n","Step 3024    [1.346 sec/step, loss=0.86904, avg_loss=0.88434]\n","Step 3025    [1.346 sec/step, loss=0.88752, avg_loss=0.88458]\n","Step 3026    [1.338 sec/step, loss=0.89680, avg_loss=0.88470]\n","Step 3027    [1.336 sec/step, loss=0.90722, avg_loss=0.88489]\n","Step 3028    [1.331 sec/step, loss=0.88396, avg_loss=0.88532]\n","Step 3029    [1.341 sec/step, loss=0.87271, avg_loss=0.88496]\n","Step 3030    [1.384 sec/step, loss=0.66941, avg_loss=0.88263]\n","Step 3031    [1.382 sec/step, loss=0.89226, avg_loss=0.88313]\n","Step 3032    [1.369 sec/step, loss=0.91519, avg_loss=0.88401]\n","Step 3033    [1.384 sec/step, loss=0.91409, avg_loss=0.88389]\n","Step 3034    [1.382 sec/step, loss=0.89338, avg_loss=0.88382]\n","Step 3035    [1.335 sec/step, loss=0.88140, avg_loss=0.88591]\n","Step 3036    [1.339 sec/step, loss=0.90393, avg_loss=0.88570]\n","Generated 32 batches of size 32 in 19.462 sec\n","Step 3037    [1.367 sec/step, loss=0.87185, avg_loss=0.88542]\n","Step 3038    [1.361 sec/step, loss=0.86225, avg_loss=0.88527]\n","Step 3039    [1.357 sec/step, loss=0.91566, avg_loss=0.88539]\n","Step 3040    [1.355 sec/step, loss=0.89296, avg_loss=0.88544]\n","Step 3041    [1.352 sec/step, loss=0.89170, avg_loss=0.88560]\n","Step 3042    [1.358 sec/step, loss=0.87817, avg_loss=0.88562]\n","Step 3043    [1.321 sec/step, loss=0.89363, avg_loss=0.88590]\n","Step 3044    [1.323 sec/step, loss=0.87234, avg_loss=0.88584]\n","Step 3045    [1.325 sec/step, loss=0.88626, avg_loss=0.88576]\n","Step 3046    [1.317 sec/step, loss=0.88184, avg_loss=0.88640]\n","Step 3047    [1.320 sec/step, loss=0.88597, avg_loss=0.88628]\n","Step 3048    [1.323 sec/step, loss=0.91209, avg_loss=0.88632]\n","Step 3049    [1.324 sec/step, loss=0.90842, avg_loss=0.88634]\n","Step 3050    [1.331 sec/step, loss=0.88392, avg_loss=0.88615]\n","Step 3051    [1.332 sec/step, loss=0.85598, avg_loss=0.88577]\n","Step 3052    [1.357 sec/step, loss=0.62320, avg_loss=0.88341]\n","Step 3053    [1.356 sec/step, loss=0.85810, avg_loss=0.88293]\n","Step 3054    [1.347 sec/step, loss=0.90107, avg_loss=0.88353]\n","Step 3055    [1.347 sec/step, loss=0.91275, avg_loss=0.88378]\n","Step 3056    [1.350 sec/step, loss=0.89855, avg_loss=0.88369]\n","Step 3057    [1.359 sec/step, loss=0.81945, avg_loss=0.88290]\n","Step 3058    [1.356 sec/step, loss=0.90239, avg_loss=0.88318]\n","Step 3059    [1.361 sec/step, loss=0.84973, avg_loss=0.88258]\n","Step 3060    [1.359 sec/step, loss=0.91447, avg_loss=0.88284]\n","Step 3061    [1.365 sec/step, loss=0.89908, avg_loss=0.88281]\n","Step 3062    [1.375 sec/step, loss=0.88604, avg_loss=0.88272]\n","Step 3063    [1.375 sec/step, loss=0.91757, avg_loss=0.88297]\n","Step 3064    [1.379 sec/step, loss=0.86771, avg_loss=0.88287]\n","Step 3065    [1.380 sec/step, loss=0.91443, avg_loss=0.88325]\n","Step 3066    [1.342 sec/step, loss=0.88189, avg_loss=0.88617]\n","Step 3067    [1.342 sec/step, loss=0.89543, avg_loss=0.88603]\n","Step 3068    [1.341 sec/step, loss=0.91216, avg_loss=0.88569]\n","Generated 32 batches of size 32 in 17.865 sec\n","Step 3069    [1.394 sec/step, loss=0.89205, avg_loss=0.88559]\n","Step 3070    [1.390 sec/step, loss=0.88804, avg_loss=0.88512]\n","Step 3071    [1.382 sec/step, loss=0.89789, avg_loss=0.88535]\n","Step 3072    [1.384 sec/step, loss=0.88878, avg_loss=0.88512]\n","Step 3073    [1.402 sec/step, loss=0.66675, avg_loss=0.88256]\n","Step 3074    [1.400 sec/step, loss=0.91517, avg_loss=0.88250]\n","Step 3075    [1.357 sec/step, loss=0.87171, avg_loss=0.88234]\n","Step 3076    [1.357 sec/step, loss=0.85518, avg_loss=0.88185]\n","Step 3077    [1.351 sec/step, loss=0.88467, avg_loss=0.88214]\n","Step 3078    [1.354 sec/step, loss=0.85928, avg_loss=0.88191]\n","Step 3079    [1.365 sec/step, loss=0.85599, avg_loss=0.88149]\n","Step 3080    [1.364 sec/step, loss=0.88163, avg_loss=0.88122]\n","Step 3081    [1.364 sec/step, loss=0.88660, avg_loss=0.88129]\n","Step 3082    [1.370 sec/step, loss=0.81762, avg_loss=0.88050]\n","Step 3083    [1.374 sec/step, loss=0.89747, avg_loss=0.88042]\n","Step 3084    [1.375 sec/step, loss=0.87599, avg_loss=0.88008]\n","Step 3085    [1.344 sec/step, loss=0.86528, avg_loss=0.88308]\n","Step 3086    [1.335 sec/step, loss=0.88093, avg_loss=0.88305]\n","Step 3087    [1.337 sec/step, loss=0.85824, avg_loss=0.88259]\n","Step 3088    [1.334 sec/step, loss=0.89996, avg_loss=0.88261]\n","Step 3089    [1.342 sec/step, loss=0.86501, avg_loss=0.88227]\n","Step 3090    [1.344 sec/step, loss=0.88482, avg_loss=0.88232]\n","Step 3091    [1.342 sec/step, loss=0.93779, avg_loss=0.88297]\n","Step 3092    [1.335 sec/step, loss=0.89105, avg_loss=0.88327]\n","Step 3093    [1.339 sec/step, loss=0.93674, avg_loss=0.88356]\n","Step 3094    [1.345 sec/step, loss=0.89927, avg_loss=0.88342]\n","Step 3095    [1.350 sec/step, loss=0.91620, avg_loss=0.88353]\n","Step 3096    [1.361 sec/step, loss=0.90240, avg_loss=0.88343]\n","Step 3097    [1.366 sec/step, loss=0.85622, avg_loss=0.88296]\n","Step 3098    [1.367 sec/step, loss=0.88572, avg_loss=0.88277]\n","Step 3099    [1.367 sec/step, loss=0.89727, avg_loss=0.88248]\n","Step 3100    [1.365 sec/step, loss=0.88767, avg_loss=0.88266]\n","Writing summary at step: 3100\n","Generated 32 batches of size 32 in 19.331 sec\n","Step 3101    [1.364 sec/step, loss=0.87585, avg_loss=0.88237]\n","Step 3102    [1.359 sec/step, loss=0.90078, avg_loss=0.88222]\n","Step 3103    [1.352 sec/step, loss=0.90035, avg_loss=0.88228]\n","Step 3104    [1.348 sec/step, loss=0.89596, avg_loss=0.88191]\n","Step 3105    [1.350 sec/step, loss=0.88101, avg_loss=0.88166]\n","Step 3106    [1.349 sec/step, loss=0.87929, avg_loss=0.88147]\n","Step 3107    [1.350 sec/step, loss=0.87863, avg_loss=0.88103]\n","Step 3108    [1.354 sec/step, loss=0.91090, avg_loss=0.88096]\n","Step 3109    [1.355 sec/step, loss=0.89631, avg_loss=0.88113]\n","Step 3110    [1.358 sec/step, loss=0.83727, avg_loss=0.88057]\n","Step 3111    [1.360 sec/step, loss=0.87258, avg_loss=0.88018]\n","Step 3112    [1.354 sec/step, loss=0.88970, avg_loss=0.88020]\n","Step 3113    [1.352 sec/step, loss=0.88625, avg_loss=0.88025]\n","Step 3114    [1.345 sec/step, loss=0.88792, avg_loss=0.88056]\n","Step 3115    [1.345 sec/step, loss=0.88487, avg_loss=0.88030]\n","Step 3116    [1.357 sec/step, loss=0.81333, avg_loss=0.87933]\n","Step 3117    [1.346 sec/step, loss=0.89395, avg_loss=0.87975]\n","Step 3118    [1.341 sec/step, loss=0.87591, avg_loss=0.87958]\n","Step 3119    [1.336 sec/step, loss=0.86405, avg_loss=0.87908]\n","Step 3120    [1.337 sec/step, loss=0.90920, avg_loss=0.87933]\n","Step 3121    [1.332 sec/step, loss=0.89947, avg_loss=0.87955]\n","Step 3122    [1.339 sec/step, loss=0.84291, avg_loss=0.87905]\n","Step 3123    [1.336 sec/step, loss=0.88597, avg_loss=0.87896]\n","Step 3124    [1.339 sec/step, loss=0.91222, avg_loss=0.87939]\n","Step 3125    [1.349 sec/step, loss=0.88745, avg_loss=0.87939]\n","Step 3126    [1.391 sec/step, loss=0.67103, avg_loss=0.87713]\n","Step 3127    [1.394 sec/step, loss=0.87509, avg_loss=0.87681]\n","Step 3128    [1.393 sec/step, loss=0.87272, avg_loss=0.87670]\n","Step 3129    [1.392 sec/step, loss=0.88202, avg_loss=0.87679]\n","Step 3130    [1.359 sec/step, loss=0.87452, avg_loss=0.87884]\n","Step 3131    [1.360 sec/step, loss=0.87669, avg_loss=0.87869]\n","Generated 32 batches of size 32 in 19.513 sec\n","Step 3132    [1.397 sec/step, loss=0.87847, avg_loss=0.87832]\n","Step 3133    [1.386 sec/step, loss=0.87110, avg_loss=0.87789]\n","Step 3134    [1.380 sec/step, loss=0.88986, avg_loss=0.87785]\n","Step 3135    [1.380 sec/step, loss=0.92022, avg_loss=0.87824]\n","Step 3136    [1.373 sec/step, loss=0.89162, avg_loss=0.87812]\n","Step 3137    [1.338 sec/step, loss=0.85454, avg_loss=0.87795]\n","Step 3138    [1.344 sec/step, loss=0.82149, avg_loss=0.87754]\n","Step 3139    [1.349 sec/step, loss=0.88668, avg_loss=0.87725]\n","Step 3140    [1.348 sec/step, loss=0.88152, avg_loss=0.87713]\n","Step 3141    [1.369 sec/step, loss=0.73107, avg_loss=0.87553]\n","Step 3142    [1.359 sec/step, loss=0.87435, avg_loss=0.87549]\n","Step 3143    [1.355 sec/step, loss=0.87731, avg_loss=0.87533]\n","Step 3144    [1.360 sec/step, loss=0.86092, avg_loss=0.87521]\n","Step 3145    [1.361 sec/step, loss=0.89408, avg_loss=0.87529]\n","Step 3146    [1.359 sec/step, loss=0.89139, avg_loss=0.87539]\n","Step 3147    [1.353 sec/step, loss=0.87237, avg_loss=0.87525]\n","Step 3148    [1.349 sec/step, loss=0.89058, avg_loss=0.87503]\n","Step 3149    [1.348 sec/step, loss=0.91333, avg_loss=0.87508]\n","Step 3150    [1.343 sec/step, loss=0.89161, avg_loss=0.87516]\n","Step 3151    [1.342 sec/step, loss=0.89668, avg_loss=0.87557]\n","Step 3152    [1.316 sec/step, loss=0.86476, avg_loss=0.87798]\n","Step 3153    [1.316 sec/step, loss=0.86331, avg_loss=0.87804]\n","Step 3154    [1.317 sec/step, loss=0.89056, avg_loss=0.87793]\n","Step 3155    [1.337 sec/step, loss=0.78587, avg_loss=0.87666]\n","Step 3156    [1.341 sec/step, loss=0.88607, avg_loss=0.87654]\n","Step 3157    [1.334 sec/step, loss=0.88865, avg_loss=0.87723]\n","Step 3158    [1.339 sec/step, loss=0.88755, avg_loss=0.87708]\n","Step 3159    [1.343 sec/step, loss=0.88865, avg_loss=0.87747]\n","Step 3160    [1.343 sec/step, loss=0.88125, avg_loss=0.87714]\n","Step 3161    [1.338 sec/step, loss=0.87186, avg_loss=0.87687]\n","Step 3162    [1.344 sec/step, loss=0.85192, avg_loss=0.87652]\n","Step 3163    [1.350 sec/step, loss=0.87134, avg_loss=0.87606]\n","Generated 32 batches of size 32 in 19.707 sec\n","Step 3164    [1.395 sec/step, loss=0.87326, avg_loss=0.87612]\n","Step 3165    [1.391 sec/step, loss=0.86944, avg_loss=0.87567]\n","Step 3166    [1.382 sec/step, loss=0.87076, avg_loss=0.87556]\n","Step 3167    [1.379 sec/step, loss=0.88431, avg_loss=0.87544]\n","Step 3168    [1.382 sec/step, loss=0.85719, avg_loss=0.87489]\n","Step 3169    [1.333 sec/step, loss=0.81642, avg_loss=0.87414]\n","Step 3170    [1.341 sec/step, loss=0.96822, avg_loss=0.87494]\n","Step 3171    [1.342 sec/step, loss=0.92033, avg_loss=0.87516]\n","Step 3172    [1.366 sec/step, loss=0.65922, avg_loss=0.87287]\n","Step 3173    [1.342 sec/step, loss=0.89492, avg_loss=0.87515]\n","Step 3174    [1.346 sec/step, loss=0.88039, avg_loss=0.87480]\n","Step 3175    [1.347 sec/step, loss=0.86506, avg_loss=0.87474]\n","Step 3176    [1.348 sec/step, loss=0.87478, avg_loss=0.87493]\n","Step 3177    [1.348 sec/step, loss=0.87926, avg_loss=0.87488]\n","Step 3178    [1.346 sec/step, loss=0.88793, avg_loss=0.87517]\n","Step 3179    [1.340 sec/step, loss=0.91808, avg_loss=0.87579]\n","Step 3180    [1.340 sec/step, loss=0.84788, avg_loss=0.87545]\n","Step 3181    [1.335 sec/step, loss=0.86497, avg_loss=0.87523]\n","Step 3182    [1.330 sec/step, loss=0.90216, avg_loss=0.87608]\n","Step 3183    [1.328 sec/step, loss=0.87785, avg_loss=0.87588]\n","Step 3184    [1.323 sec/step, loss=0.87825, avg_loss=0.87590]\n","Step 3185    [1.323 sec/step, loss=0.88876, avg_loss=0.87614]\n","Step 3186    [1.327 sec/step, loss=0.86872, avg_loss=0.87602]\n","Step 3187    [1.326 sec/step, loss=0.88071, avg_loss=0.87624]\n","Step 3188    [1.335 sec/step, loss=0.89736, avg_loss=0.87622]\n","Step 3189    [1.332 sec/step, loss=0.90432, avg_loss=0.87661]\n","Step 3190    [1.335 sec/step, loss=0.90044, avg_loss=0.87676]\n","Step 3191    [1.337 sec/step, loss=0.91696, avg_loss=0.87656]\n","Step 3192    [1.342 sec/step, loss=0.86366, avg_loss=0.87628]\n","Step 3193    [1.352 sec/step, loss=0.90086, avg_loss=0.87592]\n","Step 3194    [1.352 sec/step, loss=0.89057, avg_loss=0.87584]\n","Step 3195    [1.355 sec/step, loss=0.88860, avg_loss=0.87556]\n","Generated 32 batches of size 32 in 19.809 sec\n","Step 3196    [1.409 sec/step, loss=0.89989, avg_loss=0.87554]\n","Step 3197    [1.401 sec/step, loss=0.86546, avg_loss=0.87563]\n","Step 3198    [1.397 sec/step, loss=0.87831, avg_loss=0.87555]\n","Step 3199    [1.396 sec/step, loss=0.86037, avg_loss=0.87519]\n","Step 3200    [1.394 sec/step, loss=0.89028, avg_loss=0.87521]\n","Writing summary at step: 3200\n","Step 3201    [1.393 sec/step, loss=0.89831, avg_loss=0.87544]\n","Step 3202    [1.391 sec/step, loss=0.91907, avg_loss=0.87562]\n","Step 3203    [1.390 sec/step, loss=0.89216, avg_loss=0.87554]\n","Step 3204    [1.392 sec/step, loss=0.89420, avg_loss=0.87552]\n","Step 3205    [1.390 sec/step, loss=0.86298, avg_loss=0.87534]\n","Step 3206    [1.422 sec/step, loss=0.60844, avg_loss=0.87263]\n","Step 3207    [1.432 sec/step, loss=0.80493, avg_loss=0.87189]\n","Step 3208    [1.430 sec/step, loss=0.89539, avg_loss=0.87174]\n","Step 3209    [1.430 sec/step, loss=0.92357, avg_loss=0.87201]\n","Step 3210    [1.428 sec/step, loss=0.93146, avg_loss=0.87295]\n","Step 3211    [1.430 sec/step, loss=0.86760, avg_loss=0.87290]\n","Step 3212    [1.431 sec/step, loss=0.91371, avg_loss=0.87314]\n","Step 3213    [1.428 sec/step, loss=0.89158, avg_loss=0.87320]\n","Step 3214    [1.436 sec/step, loss=0.85321, avg_loss=0.87285]\n","Step 3215    [1.439 sec/step, loss=0.86507, avg_loss=0.87265]\n","Step 3216    [1.428 sec/step, loss=0.89831, avg_loss=0.87350]\n","Step 3217    [1.428 sec/step, loss=0.89346, avg_loss=0.87350]\n","Step 3218    [1.431 sec/step, loss=0.89536, avg_loss=0.87369]\n","Step 3219    [1.433 sec/step, loss=0.88604, avg_loss=0.87391]\n","Step 3220    [1.445 sec/step, loss=0.86356, avg_loss=0.87345]\n","Step 3221    [1.451 sec/step, loss=0.88646, avg_loss=0.87332]\n","Step 3222    [1.461 sec/step, loss=0.85257, avg_loss=0.87342]\n","Step 3223    [1.473 sec/step, loss=0.84299, avg_loss=0.87299]\n","Step 3224    [1.476 sec/step, loss=0.87898, avg_loss=0.87266]\n","Step 3225    [1.468 sec/step, loss=0.89801, avg_loss=0.87276]\n","Step 3226    [1.436 sec/step, loss=0.87922, avg_loss=0.87485]\n","Generated 32 batches of size 32 in 18.313 sec\n","Step 3227    [1.468 sec/step, loss=0.89630, avg_loss=0.87506]\n","Step 3228    [1.471 sec/step, loss=0.85808, avg_loss=0.87491]\n","Step 3229    [1.465 sec/step, loss=0.86542, avg_loss=0.87475]\n","Step 3230    [1.459 sec/step, loss=0.86514, avg_loss=0.87465]\n","Step 3231    [1.451 sec/step, loss=0.87465, avg_loss=0.87463]\n","Step 3232    [1.411 sec/step, loss=0.91946, avg_loss=0.87504]\n","Step 3233    [1.406 sec/step, loss=0.89817, avg_loss=0.87531]\n","Step 3234    [1.408 sec/step, loss=0.87323, avg_loss=0.87515]\n","Step 3235    [1.409 sec/step, loss=0.87368, avg_loss=0.87468]\n","Step 3236    [1.413 sec/step, loss=0.90662, avg_loss=0.87483]\n","Step 3237    [1.414 sec/step, loss=0.88534, avg_loss=0.87514]\n","Step 3238    [1.417 sec/step, loss=0.84841, avg_loss=0.87541]\n","Step 3239    [1.419 sec/step, loss=0.88589, avg_loss=0.87540]\n","Step 3240    [1.417 sec/step, loss=0.91462, avg_loss=0.87573]\n","Step 3241    [1.400 sec/step, loss=0.85933, avg_loss=0.87701]\n","Step 3242    [1.427 sec/step, loss=0.65162, avg_loss=0.87479]\n","Step 3243    [1.430 sec/step, loss=0.86532, avg_loss=0.87467]\n","Step 3244    [1.423 sec/step, loss=0.89774, avg_loss=0.87503]\n","Step 3245    [1.423 sec/step, loss=0.87066, avg_loss=0.87480]\n","Step 3246    [1.423 sec/step, loss=0.89803, avg_loss=0.87487]\n","Step 3247    [1.424 sec/step, loss=0.87060, avg_loss=0.87485]\n","Step 3248    [1.424 sec/step, loss=0.88973, avg_loss=0.87484]\n","Step 3249    [1.428 sec/step, loss=0.87015, avg_loss=0.87441]\n","Step 3250    [1.429 sec/step, loss=0.87030, avg_loss=0.87420]\n","Step 3251    [1.442 sec/step, loss=0.83039, avg_loss=0.87353]\n","Step 3252    [1.450 sec/step, loss=0.89486, avg_loss=0.87383]\n","Step 3253    [1.449 sec/step, loss=0.86172, avg_loss=0.87382]\n","Step 3254    [1.450 sec/step, loss=0.87807, avg_loss=0.87369]\n","Step 3255    [1.433 sec/step, loss=0.88032, avg_loss=0.87464]\n","Step 3256    [1.430 sec/step, loss=0.89456, avg_loss=0.87472]\n","Step 3257    [1.435 sec/step, loss=0.87208, avg_loss=0.87456]\n","Step 3258    [1.445 sec/step, loss=0.87865, avg_loss=0.87447]\n","Generated 32 batches of size 32 in 18.253 sec\n","Step 3259    [1.489 sec/step, loss=0.87358, avg_loss=0.87432]\n","Step 3260    [1.486 sec/step, loss=0.87167, avg_loss=0.87422]\n","Step 3261    [1.491 sec/step, loss=0.86357, avg_loss=0.87414]\n","Step 3262    [1.480 sec/step, loss=0.88775, avg_loss=0.87450]\n","Step 3263    [1.470 sec/step, loss=0.87450, avg_loss=0.87453]\n","Step 3264    [1.420 sec/step, loss=0.88943, avg_loss=0.87469]\n","Step 3265    [1.421 sec/step, loss=0.88967, avg_loss=0.87489]\n","Step 3266    [1.424 sec/step, loss=0.91537, avg_loss=0.87534]\n","Step 3267    [1.428 sec/step, loss=0.86565, avg_loss=0.87515]\n","Step 3268    [1.423 sec/step, loss=0.91211, avg_loss=0.87570]\n","Step 3269    [1.411 sec/step, loss=0.86882, avg_loss=0.87623]\n","Step 3270    [1.403 sec/step, loss=0.86182, avg_loss=0.87516]\n","Step 3271    [1.402 sec/step, loss=0.86946, avg_loss=0.87465]\n","Step 3272    [1.378 sec/step, loss=0.88482, avg_loss=0.87691]\n","Step 3273    [1.383 sec/step, loss=0.87250, avg_loss=0.87668]\n","Step 3274    [1.408 sec/step, loss=0.56079, avg_loss=0.87349]\n","Step 3275    [1.407 sec/step, loss=0.87691, avg_loss=0.87361]\n","Step 3276    [1.406 sec/step, loss=0.87237, avg_loss=0.87358]\n","Step 3277    [1.408 sec/step, loss=0.88500, avg_loss=0.87364]\n","Step 3278    [1.408 sec/step, loss=0.86135, avg_loss=0.87337]\n","Step 3279    [1.407 sec/step, loss=0.86984, avg_loss=0.87289]\n","Step 3280    [1.407 sec/step, loss=0.87785, avg_loss=0.87319]\n","Step 3281    [1.405 sec/step, loss=0.86986, avg_loss=0.87324]\n","Step 3282    [1.406 sec/step, loss=0.89470, avg_loss=0.87317]\n","Step 3283    [1.411 sec/step, loss=0.88042, avg_loss=0.87319]\n","Step 3284    [1.415 sec/step, loss=0.89379, avg_loss=0.87335]\n","Step 3285    [1.418 sec/step, loss=0.88199, avg_loss=0.87328]\n","Step 3286    [1.417 sec/step, loss=0.87500, avg_loss=0.87334]\n","Step 3287    [1.428 sec/step, loss=0.86666, avg_loss=0.87320]\n","Step 3288    [1.439 sec/step, loss=0.84765, avg_loss=0.87270]\n","Step 3289    [1.446 sec/step, loss=0.86585, avg_loss=0.87232]\n","Step 3290    [1.444 sec/step, loss=0.85885, avg_loss=0.87190]\n","Generated 32 batches of size 32 in 19.442 sec\n","Step 3291    [1.500 sec/step, loss=0.87956, avg_loss=0.87153]\n","Step 3292    [1.498 sec/step, loss=0.85313, avg_loss=0.87142]\n","Step 3293    [1.485 sec/step, loss=0.86864, avg_loss=0.87110]\n","Step 3294    [1.485 sec/step, loss=0.85587, avg_loss=0.87076]\n","Step 3295    [1.478 sec/step, loss=0.85581, avg_loss=0.87043]\n","Step 3296    [1.414 sec/step, loss=0.90833, avg_loss=0.87051]\n","Step 3297    [1.417 sec/step, loss=0.90320, avg_loss=0.87089]\n","Step 3298    [1.414 sec/step, loss=0.86478, avg_loss=0.87075]\n","Step 3299    [1.412 sec/step, loss=0.93017, avg_loss=0.87145]\n","Step 3300    [1.413 sec/step, loss=0.88584, avg_loss=0.87141]\n","Writing summary at step: 3300\n","Step 3301    [1.415 sec/step, loss=0.88250, avg_loss=0.87125]\n","Step 3302    [1.418 sec/step, loss=0.86758, avg_loss=0.87073]\n","Step 3303    [1.422 sec/step, loss=0.86495, avg_loss=0.87046]\n","Step 3304    [1.422 sec/step, loss=0.86649, avg_loss=0.87019]\n","Step 3305    [1.430 sec/step, loss=0.80591, avg_loss=0.86961]\n","Step 3306    [1.398 sec/step, loss=0.85027, avg_loss=0.87203]\n","Step 3307    [1.389 sec/step, loss=0.86174, avg_loss=0.87260]\n","Step 3308    [1.385 sec/step, loss=0.89885, avg_loss=0.87264]\n","Step 3309    [1.390 sec/step, loss=0.87386, avg_loss=0.87214]\n","Step 3310    [1.388 sec/step, loss=0.87684, avg_loss=0.87159]\n","Step 3311    [1.387 sec/step, loss=0.87967, avg_loss=0.87171]\n","Step 3312    [1.387 sec/step, loss=0.90789, avg_loss=0.87166]\n","Step 3313    [1.393 sec/step, loss=0.87865, avg_loss=0.87153]\n","Step 3314    [1.392 sec/step, loss=0.87016, avg_loss=0.87170]\n","Step 3315    [1.397 sec/step, loss=0.85840, avg_loss=0.87163]\n","Step 3316    [1.400 sec/step, loss=0.87404, avg_loss=0.87139]\n","Step 3317    [1.405 sec/step, loss=0.85196, avg_loss=0.87097]\n","Step 3318    [1.406 sec/step, loss=0.88496, avg_loss=0.87087]\n","Step 3319    [1.405 sec/step, loss=0.87791, avg_loss=0.87079]\n","Step 3320    [1.438 sec/step, loss=0.62902, avg_loss=0.86844]\n","Step 3321    [1.433 sec/step, loss=0.89839, avg_loss=0.86856]\n","Generated 32 batches of size 32 in 19.657 sec\n","Step 3322    [1.463 sec/step, loss=0.87978, avg_loss=0.86883]\n","Step 3323    [1.448 sec/step, loss=0.86680, avg_loss=0.86907]\n","Step 3324    [1.451 sec/step, loss=0.83199, avg_loss=0.86860]\n","Step 3325    [1.455 sec/step, loss=0.83969, avg_loss=0.86802]\n","Step 3326    [1.445 sec/step, loss=0.87544, avg_loss=0.86798]\n","Step 3327    [1.410 sec/step, loss=0.86063, avg_loss=0.86762]\n","Step 3328    [1.406 sec/step, loss=0.90259, avg_loss=0.86807]\n","Step 3329    [1.404 sec/step, loss=0.85935, avg_loss=0.86801]\n","Step 3330    [1.403 sec/step, loss=0.86182, avg_loss=0.86797]\n","Step 3331    [1.403 sec/step, loss=0.88576, avg_loss=0.86808]\n","Step 3332    [1.403 sec/step, loss=0.89633, avg_loss=0.86785]\n","Step 3333    [1.405 sec/step, loss=0.86637, avg_loss=0.86754]\n","Step 3334    [1.405 sec/step, loss=0.87521, avg_loss=0.86755]\n","Step 3335    [1.403 sec/step, loss=0.87168, avg_loss=0.86753]\n","Step 3336    [1.401 sec/step, loss=0.83488, avg_loss=0.86682]\n","Step 3337    [1.405 sec/step, loss=0.85809, avg_loss=0.86654]\n","Step 3338    [1.397 sec/step, loss=0.87999, avg_loss=0.86686]\n","Step 3339    [1.416 sec/step, loss=0.73928, avg_loss=0.86539]\n","Step 3340    [1.421 sec/step, loss=0.86757, avg_loss=0.86492]\n","Step 3341    [1.417 sec/step, loss=0.88447, avg_loss=0.86518]\n","Step 3342    [1.391 sec/step, loss=0.86207, avg_loss=0.86728]\n","Step 3343    [1.395 sec/step, loss=0.83782, avg_loss=0.86700]\n","Step 3344    [1.397 sec/step, loss=0.85003, avg_loss=0.86653]\n","Step 3345    [1.402 sec/step, loss=0.87313, avg_loss=0.86655]\n","Step 3346    [1.406 sec/step, loss=0.88367, avg_loss=0.86641]\n","Step 3347    [1.409 sec/step, loss=0.85018, avg_loss=0.86620]\n","Step 3348    [1.412 sec/step, loss=0.87782, avg_loss=0.86609]\n","Step 3349    [1.415 sec/step, loss=0.87135, avg_loss=0.86610]\n","Step 3350    [1.427 sec/step, loss=0.88047, avg_loss=0.86620]\n","Step 3351    [1.420 sec/step, loss=0.83676, avg_loss=0.86626]\n","Step 3352    [1.415 sec/step, loss=0.84433, avg_loss=0.86576]\n","Step 3353    [1.417 sec/step, loss=0.86730, avg_loss=0.86581]\n","Generated 32 batches of size 32 in 19.835 sec\n","Step 3354    [1.486 sec/step, loss=0.88552, avg_loss=0.86589]\n","Step 3355    [1.483 sec/step, loss=0.88305, avg_loss=0.86591]\n","Step 3356    [1.480 sec/step, loss=0.85780, avg_loss=0.86555]\n","Step 3357    [1.475 sec/step, loss=0.83784, avg_loss=0.86520]\n","Step 3358    [1.463 sec/step, loss=0.86570, avg_loss=0.86508]\n","Step 3359    [1.409 sec/step, loss=0.85549, avg_loss=0.86489]\n","Step 3360    [1.410 sec/step, loss=0.88207, avg_loss=0.86500]\n","Step 3361    [1.402 sec/step, loss=0.87477, avg_loss=0.86511]\n","Step 3362    [1.406 sec/step, loss=0.83870, avg_loss=0.86462]\n","Step 3363    [1.410 sec/step, loss=0.85567, avg_loss=0.86443]\n","Step 3364    [1.403 sec/step, loss=0.86265, avg_loss=0.86416]\n","Step 3365    [1.404 sec/step, loss=0.87175, avg_loss=0.86398]\n","Step 3366    [1.405 sec/step, loss=0.91373, avg_loss=0.86397]\n","Step 3367    [1.408 sec/step, loss=0.86909, avg_loss=0.86400]\n","Step 3368    [1.407 sec/step, loss=0.90233, avg_loss=0.86390]\n","Step 3369    [1.407 sec/step, loss=0.86747, avg_loss=0.86389]\n","Step 3370    [1.406 sec/step, loss=0.92556, avg_loss=0.86453]\n","Step 3371    [1.410 sec/step, loss=0.87383, avg_loss=0.86457]\n","Step 3372    [1.406 sec/step, loss=0.90414, avg_loss=0.86477]\n","Step 3373    [1.408 sec/step, loss=0.86768, avg_loss=0.86472]\n","Step 3374    [1.379 sec/step, loss=0.88862, avg_loss=0.86800]\n","Step 3375    [1.380 sec/step, loss=0.89495, avg_loss=0.86818]\n","Step 3376    [1.381 sec/step, loss=0.86316, avg_loss=0.86808]\n","Step 3377    [1.399 sec/step, loss=0.88556, avg_loss=0.86809]\n","Step 3378    [1.404 sec/step, loss=0.88027, avg_loss=0.86828]\n","Step 3379    [1.444 sec/step, loss=0.61926, avg_loss=0.86577]\n","Step 3380    [1.467 sec/step, loss=0.80582, avg_loss=0.86505]\n","Step 3381    [1.470 sec/step, loss=0.86479, avg_loss=0.86500]\n","Step 3382    [1.472 sec/step, loss=0.85146, avg_loss=0.86457]\n","Step 3383    [1.473 sec/step, loss=0.86036, avg_loss=0.86437]\n","Step 3384    [1.482 sec/step, loss=0.84678, avg_loss=0.86390]\n","Step 3385    [1.485 sec/step, loss=0.88071, avg_loss=0.86389]\n","Generated 32 batches of size 32 in 19.939 sec\n","Step 3386    [1.489 sec/step, loss=0.87764, avg_loss=0.86391]\n","Step 3387    [1.473 sec/step, loss=0.88316, avg_loss=0.86408]\n","Step 3388    [1.463 sec/step, loss=0.86060, avg_loss=0.86421]\n","Step 3389    [1.457 sec/step, loss=0.86695, avg_loss=0.86422]\n","Step 3390    [1.452 sec/step, loss=0.85185, avg_loss=0.86415]\n","Step 3391    [1.424 sec/step, loss=0.55672, avg_loss=0.86092]\n","Step 3392    [1.422 sec/step, loss=0.87302, avg_loss=0.86112]\n","Step 3393    [1.421 sec/step, loss=0.89409, avg_loss=0.86137]\n","Step 3394    [1.413 sec/step, loss=0.87550, avg_loss=0.86157]\n","Step 3395    [1.419 sec/step, loss=0.89636, avg_loss=0.86197]\n","Step 3396    [1.418 sec/step, loss=0.86798, avg_loss=0.86157]\n","Step 3397    [1.421 sec/step, loss=0.85990, avg_loss=0.86114]\n","Step 3398    [1.423 sec/step, loss=0.86882, avg_loss=0.86118]\n","Step 3399    [1.426 sec/step, loss=0.87377, avg_loss=0.86061]\n","Step 3400    [1.424 sec/step, loss=0.85521, avg_loss=0.86031]\n","Writing summary at step: 3400\n","Step 3401    [1.423 sec/step, loss=0.88895, avg_loss=0.86037]\n","Step 3402    [1.420 sec/step, loss=0.86040, avg_loss=0.86030]\n","Step 3403    [1.419 sec/step, loss=0.86363, avg_loss=0.86029]\n","Step 3404    [1.424 sec/step, loss=0.83820, avg_loss=0.86000]\n","Step 3405    [1.415 sec/step, loss=0.87272, avg_loss=0.86067]\n","Step 3406    [1.419 sec/step, loss=0.88679, avg_loss=0.86104]\n","Step 3407    [1.419 sec/step, loss=0.88293, avg_loss=0.86125]\n","Step 3408    [1.423 sec/step, loss=0.87771, avg_loss=0.86104]\n","Step 3409    [1.424 sec/step, loss=0.86554, avg_loss=0.86096]\n","Step 3410    [1.432 sec/step, loss=0.85635, avg_loss=0.86075]\n","Step 3411    [1.437 sec/step, loss=0.86126, avg_loss=0.86057]\n","Step 3412    [1.438 sec/step, loss=0.86117, avg_loss=0.86010]\n","Step 3413    [1.438 sec/step, loss=0.86540, avg_loss=0.85997]\n","Step 3414    [1.436 sec/step, loss=0.88327, avg_loss=0.86010]\n","Step 3415    [1.437 sec/step, loss=0.86227, avg_loss=0.86014]\n","Step 3416    [1.455 sec/step, loss=0.81371, avg_loss=0.85953]\n","Generated 32 batches of size 32 in 18.465 sec\n","Step 3417    [1.497 sec/step, loss=0.86747, avg_loss=0.85969]\n","Step 3418    [1.495 sec/step, loss=0.88151, avg_loss=0.85965]\n","Step 3419    [1.513 sec/step, loss=0.70670, avg_loss=0.85794]\n","Step 3420    [1.467 sec/step, loss=0.90986, avg_loss=0.86075]\n","Step 3421    [1.472 sec/step, loss=0.88764, avg_loss=0.86064]\n","Step 3422    [1.425 sec/step, loss=0.88225, avg_loss=0.86067]\n","Step 3423    [1.428 sec/step, loss=0.86034, avg_loss=0.86060]\n","Step 3424    [1.422 sec/step, loss=0.85392, avg_loss=0.86082]\n","Step 3425    [1.418 sec/step, loss=0.88201, avg_loss=0.86125]\n","Step 3426    [1.425 sec/step, loss=0.84725, avg_loss=0.86096]\n","Step 3427    [1.421 sec/step, loss=0.87036, avg_loss=0.86106]\n","Step 3428    [1.421 sec/step, loss=0.87820, avg_loss=0.86082]\n","Step 3429    [1.423 sec/step, loss=0.83884, avg_loss=0.86061]\n","Step 3430    [1.422 sec/step, loss=0.85476, avg_loss=0.86054]\n","Step 3431    [1.423 sec/step, loss=0.87371, avg_loss=0.86042]\n","Step 3432    [1.429 sec/step, loss=0.83607, avg_loss=0.85982]\n","Step 3433    [1.427 sec/step, loss=0.87210, avg_loss=0.85988]\n","Step 3434    [1.425 sec/step, loss=0.85690, avg_loss=0.85969]\n","Step 3435    [1.427 sec/step, loss=0.85511, avg_loss=0.85953]\n","Step 3436    [1.424 sec/step, loss=0.87938, avg_loss=0.85997]\n","Step 3437    [1.422 sec/step, loss=0.87533, avg_loss=0.86014]\n","Step 3438    [1.426 sec/step, loss=0.87287, avg_loss=0.86007]\n","Step 3439    [1.405 sec/step, loss=0.85322, avg_loss=0.86121]\n","Step 3440    [1.421 sec/step, loss=0.75645, avg_loss=0.86010]\n","Step 3441    [1.424 sec/step, loss=0.87511, avg_loss=0.86001]\n","Step 3442    [1.436 sec/step, loss=0.84425, avg_loss=0.85983]\n","Step 3443    [1.435 sec/step, loss=0.86222, avg_loss=0.86007]\n","Step 3444    [1.437 sec/step, loss=0.86197, avg_loss=0.86019]\n","Step 3445    [1.432 sec/step, loss=0.88724, avg_loss=0.86033]\n","Step 3446    [1.433 sec/step, loss=0.86141, avg_loss=0.86011]\n","Step 3447    [1.435 sec/step, loss=0.86788, avg_loss=0.86029]\n","Step 3448    [1.436 sec/step, loss=0.87843, avg_loss=0.86029]\n","Generated 32 batches of size 32 in 18.910 sec\n","Step 3449    [1.487 sec/step, loss=0.86965, avg_loss=0.86028]\n","Step 3450    [1.474 sec/step, loss=0.84943, avg_loss=0.85997]\n","Step 3451    [1.468 sec/step, loss=0.83877, avg_loss=0.85999]\n","Step 3452    [1.466 sec/step, loss=0.87947, avg_loss=0.86034]\n","Step 3453    [1.475 sec/step, loss=0.78648, avg_loss=0.85953]\n","Step 3454    [1.403 sec/step, loss=0.89120, avg_loss=0.85959]\n","Step 3455    [1.402 sec/step, loss=0.87359, avg_loss=0.85949]\n","Step 3456    [1.402 sec/step, loss=0.84407, avg_loss=0.85936]\n","Step 3457    [1.397 sec/step, loss=0.84773, avg_loss=0.85945]\n","Step 3458    [1.399 sec/step, loss=0.83995, avg_loss=0.85920]\n","Step 3459    [1.404 sec/step, loss=0.86686, avg_loss=0.85931]\n","Step 3460    [1.408 sec/step, loss=0.86364, avg_loss=0.85913]\n","Step 3461    [1.408 sec/step, loss=0.86681, avg_loss=0.85905]\n","Step 3462    [1.401 sec/step, loss=0.85675, avg_loss=0.85923]\n","Step 3463    [1.406 sec/step, loss=0.85522, avg_loss=0.85922]\n","Step 3464    [1.410 sec/step, loss=0.87890, avg_loss=0.85938]\n","Step 3465    [1.407 sec/step, loss=0.87015, avg_loss=0.85937]\n","Step 3466    [1.402 sec/step, loss=0.88335, avg_loss=0.85907]\n","Step 3467    [1.398 sec/step, loss=0.85326, avg_loss=0.85891]\n","Step 3468    [1.399 sec/step, loss=0.87185, avg_loss=0.85860]\n","Step 3469    [1.404 sec/step, loss=0.87602, avg_loss=0.85869]\n","Step 3470    [1.404 sec/step, loss=0.88454, avg_loss=0.85828]\n","Step 3471    [1.407 sec/step, loss=0.85530, avg_loss=0.85809]\n","Step 3472    [1.414 sec/step, loss=0.87896, avg_loss=0.85784]\n","Step 3473    [1.411 sec/step, loss=0.85221, avg_loss=0.85769]\n","Step 3474    [1.413 sec/step, loss=0.86799, avg_loss=0.85748]\n","Step 3475    [1.423 sec/step, loss=0.87535, avg_loss=0.85728]\n","Step 3476    [1.425 sec/step, loss=0.84137, avg_loss=0.85707]\n","Step 3477    [1.411 sec/step, loss=0.89722, avg_loss=0.85718]\n","Step 3478    [1.409 sec/step, loss=0.88122, avg_loss=0.85719]\n","Step 3479    [1.376 sec/step, loss=0.86549, avg_loss=0.85965]\n","Step 3480    [1.401 sec/step, loss=0.55566, avg_loss=0.85715]\n","Generated 32 batches of size 32 in 19.558 sec\n","Step 3481    [1.427 sec/step, loss=0.88093, avg_loss=0.85731]\n","Step 3482    [1.424 sec/step, loss=0.85963, avg_loss=0.85740]\n","Step 3483    [1.419 sec/step, loss=0.87834, avg_loss=0.85758]\n","Step 3484    [1.410 sec/step, loss=0.85826, avg_loss=0.85769]\n","Step 3485    [1.404 sec/step, loss=0.88109, avg_loss=0.85769]\n","Step 3486    [1.397 sec/step, loss=0.87890, avg_loss=0.85771]\n","Step 3487    [1.400 sec/step, loss=0.86668, avg_loss=0.85754]\n","Step 3488    [1.392 sec/step, loss=0.86420, avg_loss=0.85758]\n","Step 3489    [1.391 sec/step, loss=0.83985, avg_loss=0.85731]\n","Step 3490    [1.387 sec/step, loss=0.86829, avg_loss=0.85747]\n","Step 3491    [1.354 sec/step, loss=0.85523, avg_loss=0.86046]\n","Step 3492    [1.356 sec/step, loss=0.84390, avg_loss=0.86017]\n","Step 3493    [1.361 sec/step, loss=0.86410, avg_loss=0.85987]\n","Step 3494    [1.361 sec/step, loss=0.89829, avg_loss=0.86009]\n","Step 3495    [1.357 sec/step, loss=0.88419, avg_loss=0.85997]\n","Step 3496    [1.357 sec/step, loss=0.86287, avg_loss=0.85992]\n","Step 3497    [1.355 sec/step, loss=0.87950, avg_loss=0.86012]\n","Step 3498    [1.360 sec/step, loss=0.83817, avg_loss=0.85981]\n","Step 3499    [1.358 sec/step, loss=0.86476, avg_loss=0.85972]\n","Step 3500    [1.360 sec/step, loss=0.86749, avg_loss=0.85984]\n","Writing summary at step: 3500\n","Saving audio and alignment...\n","Generated 8 batches of size 4 in 0.000 sec\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (110700,)\n","Check wav file:  (140700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000003500-align000.png\n","100% 1/1 [00:04<00:00,  4.49s/it]\n","Test finished for step 3500.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (62100,)\n","Check wav file:  (92100,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000003500-align000.png\n"," 25% 1/4 [00:02<00:06,  2.29s/it]Check wav file before change:  (62100,)\n","Check wav file:  (92100,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000003500-align001.png\n"," 50% 2/4 [00:04<00:04,  2.34s/it]Check wav file before change:  (62100,)\n","Check wav file:  (92100,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000003500-align002.png\n"," 75% 3/4 [00:07<00:02,  2.33s/it]Check wav file before change:  (62100,)\n","Check wav file:  (92100,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000003500-align003.png\n","100% 4/4 [00:09<00:00,  2.40s/it]\n","Test finished for step 3500.\n","Step 3501    [1.360 sec/step, loss=0.89832, avg_loss=0.85994]\n","Step 3502    [1.382 sec/step, loss=0.76879, avg_loss=0.85902]\n","Step 3503    [1.384 sec/step, loss=0.86510, avg_loss=0.85903]\n","Step 3504    [1.385 sec/step, loss=0.84936, avg_loss=0.85915]\n","Step 3505    [1.391 sec/step, loss=0.87988, avg_loss=0.85922]\n","Step 3506    [1.393 sec/step, loss=0.89085, avg_loss=0.85926]\n","Step 3507    [1.391 sec/step, loss=0.86382, avg_loss=0.85907]\n","Step 3508    [1.389 sec/step, loss=0.89672, avg_loss=0.85926]\n","Step 3509    [1.393 sec/step, loss=0.85177, avg_loss=0.85912]\n","Step 3510    [1.397 sec/step, loss=0.85017, avg_loss=0.85906]\n","Generated 32 batches of size 32 in 19.662 sec\n","Step 3511    [1.442 sec/step, loss=0.89157, avg_loss=0.85936]\n","Step 3512    [1.442 sec/step, loss=0.87517, avg_loss=0.85950]\n","Step 3513    [1.436 sec/step, loss=0.89626, avg_loss=0.85981]\n","Step 3514    [1.432 sec/step, loss=0.85668, avg_loss=0.85954]\n","Step 3515    [1.421 sec/step, loss=0.86282, avg_loss=0.85955]\n","Step 3516    [1.403 sec/step, loss=0.88406, avg_loss=0.86025]\n","Step 3517    [1.357 sec/step, loss=0.86513, avg_loss=0.86023]\n","Step 3518    [1.365 sec/step, loss=0.83831, avg_loss=0.85980]\n","Step 3519    [1.348 sec/step, loss=0.87342, avg_loss=0.86146]\n","Step 3520    [1.359 sec/step, loss=0.81686, avg_loss=0.86053]\n","Step 3521    [1.355 sec/step, loss=0.90028, avg_loss=0.86066]\n","Step 3522    [1.355 sec/step, loss=0.90620, avg_loss=0.86090]\n","Step 3523    [1.352 sec/step, loss=0.86697, avg_loss=0.86097]\n","Step 3524    [1.347 sec/step, loss=0.86861, avg_loss=0.86111]\n","Step 3525    [1.343 sec/step, loss=0.86239, avg_loss=0.86092]\n","Step 3526    [1.339 sec/step, loss=0.85107, avg_loss=0.86096]\n","Step 3527    [1.341 sec/step, loss=0.86463, avg_loss=0.86090]\n","Step 3528    [1.343 sec/step, loss=0.87027, avg_loss=0.86082]\n","Step 3529    [1.345 sec/step, loss=0.86001, avg_loss=0.86103]\n","Step 3530    [1.342 sec/step, loss=0.88495, avg_loss=0.86133]\n","Step 3531    [1.344 sec/step, loss=0.86384, avg_loss=0.86123]\n","Step 3532    [1.344 sec/step, loss=0.88445, avg_loss=0.86172]\n","Step 3533    [1.348 sec/step, loss=0.85764, avg_loss=0.86157]\n","Step 3534    [1.355 sec/step, loss=0.85319, avg_loss=0.86154]\n","Step 3535    [1.366 sec/step, loss=0.82183, avg_loss=0.86120]\n","Step 3536    [1.375 sec/step, loss=0.87463, avg_loss=0.86116]\n","Step 3537    [1.386 sec/step, loss=0.83172, avg_loss=0.86072]\n","Step 3538    [1.424 sec/step, loss=0.60811, avg_loss=0.85807]\n","Step 3539    [1.428 sec/step, loss=0.88361, avg_loss=0.85838]\n","Step 3540    [1.417 sec/step, loss=0.85305, avg_loss=0.85934]\n","Step 3541    [1.418 sec/step, loss=0.85964, avg_loss=0.85919]\n","Step 3542    [1.411 sec/step, loss=0.90348, avg_loss=0.85978]\n","Generated 32 batches of size 32 in 19.721 sec\n","Step 3543    [1.418 sec/step, loss=0.85569, avg_loss=0.85971]\n","Step 3544    [1.415 sec/step, loss=0.87627, avg_loss=0.85986]\n","Step 3545    [1.413 sec/step, loss=0.86691, avg_loss=0.85965]\n","Step 3546    [1.411 sec/step, loss=0.90037, avg_loss=0.86004]\n","Step 3547    [1.404 sec/step, loss=0.90725, avg_loss=0.86044]\n","Step 3548    [1.403 sec/step, loss=0.88335, avg_loss=0.86049]\n","Step 3549    [1.346 sec/step, loss=0.85921, avg_loss=0.86038]\n","Step 3550    [1.346 sec/step, loss=0.86489, avg_loss=0.86054]\n","Step 3551    [1.347 sec/step, loss=0.84663, avg_loss=0.86061]\n","Step 3552    [1.346 sec/step, loss=0.86889, avg_loss=0.86051]\n","Step 3553    [1.336 sec/step, loss=0.89740, avg_loss=0.86162]\n","Step 3554    [1.342 sec/step, loss=0.84054, avg_loss=0.86111]\n","Step 3555    [1.349 sec/step, loss=0.85893, avg_loss=0.86097]\n","Step 3556    [1.358 sec/step, loss=0.85552, avg_loss=0.86108]\n","Step 3557    [1.360 sec/step, loss=0.87515, avg_loss=0.86135]\n","Step 3558    [1.362 sec/step, loss=0.87856, avg_loss=0.86174]\n","Step 3559    [1.361 sec/step, loss=0.88085, avg_loss=0.86188]\n","Step 3560    [1.357 sec/step, loss=0.86083, avg_loss=0.86185]\n","Step 3561    [1.357 sec/step, loss=0.88888, avg_loss=0.86207]\n","Step 3562    [1.366 sec/step, loss=0.87277, avg_loss=0.86223]\n","Step 3563    [1.361 sec/step, loss=0.86183, avg_loss=0.86230]\n","Step 3564    [1.361 sec/step, loss=0.87547, avg_loss=0.86226]\n","Step 3565    [1.359 sec/step, loss=0.91833, avg_loss=0.86275]\n","Step 3566    [1.370 sec/step, loss=0.89003, avg_loss=0.86281]\n","Step 3567    [1.371 sec/step, loss=0.85665, avg_loss=0.86285]\n","Step 3568    [1.377 sec/step, loss=0.85520, avg_loss=0.86268]\n","Step 3569    [1.377 sec/step, loss=0.88083, avg_loss=0.86273]\n","Step 3570    [1.424 sec/step, loss=0.61657, avg_loss=0.86005]\n","Step 3571    [1.428 sec/step, loss=0.84603, avg_loss=0.85996]\n","Step 3572    [1.425 sec/step, loss=0.86693, avg_loss=0.85984]\n","Step 3573    [1.425 sec/step, loss=0.85883, avg_loss=0.85990]\n","Step 3574    [1.428 sec/step, loss=0.88082, avg_loss=0.86003]\n","Generated 32 batches of size 32 in 19.716 sec\n","Step 3575    [1.452 sec/step, loss=0.86102, avg_loss=0.85989]\n","Step 3576    [1.455 sec/step, loss=0.85916, avg_loss=0.86006]\n","Step 3577    [1.452 sec/step, loss=0.85366, avg_loss=0.85963]\n","Step 3578    [1.447 sec/step, loss=0.86799, avg_loss=0.85950]\n","Step 3579    [1.437 sec/step, loss=0.90000, avg_loss=0.85984]\n","Step 3580    [1.391 sec/step, loss=0.83938, avg_loss=0.86268]\n","Step 3581    [1.362 sec/step, loss=0.88228, avg_loss=0.86269]\n","Step 3582    [1.368 sec/step, loss=0.88604, avg_loss=0.86296]\n","Step 3583    [1.367 sec/step, loss=0.87809, avg_loss=0.86295]\n","Step 3584    [1.363 sec/step, loss=0.91472, avg_loss=0.86352]\n","Step 3585    [1.363 sec/step, loss=0.87389, avg_loss=0.86345]\n","Step 3586    [1.364 sec/step, loss=0.85534, avg_loss=0.86321]\n","Step 3587    [1.362 sec/step, loss=0.87867, avg_loss=0.86333]\n","Step 3588    [1.362 sec/step, loss=0.86202, avg_loss=0.86331]\n","Step 3589    [1.370 sec/step, loss=0.80610, avg_loss=0.86297]\n","Step 3590    [1.372 sec/step, loss=0.86263, avg_loss=0.86292]\n","Step 3591    [1.377 sec/step, loss=0.83932, avg_loss=0.86276]\n","Step 3592    [1.370 sec/step, loss=0.85133, avg_loss=0.86283]\n","Step 3593    [1.368 sec/step, loss=0.90362, avg_loss=0.86323]\n","Step 3594    [1.373 sec/step, loss=0.86070, avg_loss=0.86285]\n","Step 3595    [1.379 sec/step, loss=0.86547, avg_loss=0.86266]\n","Step 3596    [1.380 sec/step, loss=0.89026, avg_loss=0.86294]\n","Step 3597    [1.380 sec/step, loss=0.88077, avg_loss=0.86295]\n","Step 3598    [1.386 sec/step, loss=0.87912, avg_loss=0.86336]\n","Step 3599    [1.388 sec/step, loss=0.85748, avg_loss=0.86329]\n","Step 3600    [1.394 sec/step, loss=0.88031, avg_loss=0.86341]\n","Writing summary at step: 3600\n","Step 3601    [1.402 sec/step, loss=0.84134, avg_loss=0.86284]\n","Step 3602    [1.384 sec/step, loss=0.88270, avg_loss=0.86398]\n","Step 3603    [1.387 sec/step, loss=0.86569, avg_loss=0.86399]\n","Step 3604    [1.385 sec/step, loss=0.87866, avg_loss=0.86428]\n","Step 3605    [1.378 sec/step, loss=0.83031, avg_loss=0.86379]\n","Generated 32 batches of size 32 in 17.734 sec\n","Step 3606    [1.389 sec/step, loss=0.85706, avg_loss=0.86345]\n","Step 3607    [1.389 sec/step, loss=0.84982, avg_loss=0.86331]\n","Step 3608    [1.388 sec/step, loss=0.85645, avg_loss=0.86291]\n","Step 3609    [1.381 sec/step, loss=0.86671, avg_loss=0.86306]\n","Step 3610    [1.373 sec/step, loss=0.87500, avg_loss=0.86330]\n","Step 3611    [1.322 sec/step, loss=0.84123, avg_loss=0.86280]\n","Step 3612    [1.321 sec/step, loss=0.85773, avg_loss=0.86263]\n","Step 3613    [1.323 sec/step, loss=0.88601, avg_loss=0.86252]\n","Step 3614    [1.322 sec/step, loss=0.85575, avg_loss=0.86251]\n","Step 3615    [1.325 sec/step, loss=0.89534, avg_loss=0.86284]\n","Step 3616    [1.354 sec/step, loss=0.58162, avg_loss=0.85981]\n","Step 3617    [1.357 sec/step, loss=0.84675, avg_loss=0.85963]\n","Step 3618    [1.356 sec/step, loss=0.84969, avg_loss=0.85974]\n","Step 3619    [1.359 sec/step, loss=0.81411, avg_loss=0.85915]\n","Step 3620    [1.350 sec/step, loss=0.83045, avg_loss=0.85929]\n","Step 3621    [1.358 sec/step, loss=0.76604, avg_loss=0.85795]\n","Step 3622    [1.360 sec/step, loss=0.83351, avg_loss=0.85722]\n","Step 3623    [1.363 sec/step, loss=0.84538, avg_loss=0.85700]\n","Step 3624    [1.364 sec/step, loss=0.85894, avg_loss=0.85691]\n","Step 3625    [1.363 sec/step, loss=0.86508, avg_loss=0.85693]\n","Step 3626    [1.366 sec/step, loss=0.85711, avg_loss=0.85699]\n","Step 3627    [1.366 sec/step, loss=0.85794, avg_loss=0.85693]\n","Step 3628    [1.367 sec/step, loss=0.82046, avg_loss=0.85643]\n","Step 3629    [1.382 sec/step, loss=0.83760, avg_loss=0.85620]\n","Step 3630    [1.384 sec/step, loss=0.85344, avg_loss=0.85589]\n","Step 3631    [1.384 sec/step, loss=0.84350, avg_loss=0.85569]\n","Step 3632    [1.383 sec/step, loss=0.86474, avg_loss=0.85549]\n","Step 3633    [1.380 sec/step, loss=0.86206, avg_loss=0.85553]\n","Step 3634    [1.375 sec/step, loss=0.91284, avg_loss=0.85613]\n","Step 3635    [1.368 sec/step, loss=0.85458, avg_loss=0.85646]\n","Step 3636    [1.366 sec/step, loss=0.86550, avg_loss=0.85636]\n","Step 3637    [1.362 sec/step, loss=0.84852, avg_loss=0.85653]\n","Generated 32 batches of size 32 in 18.959 sec\n","Step 3638    [1.384 sec/step, loss=0.85459, avg_loss=0.85900]\n","Step 3639    [1.380 sec/step, loss=0.83891, avg_loss=0.85855]\n","Step 3640    [1.376 sec/step, loss=0.81834, avg_loss=0.85820]\n","Step 3641    [1.379 sec/step, loss=0.82027, avg_loss=0.85781]\n","Step 3642    [1.378 sec/step, loss=0.82813, avg_loss=0.85706]\n","Step 3643    [1.372 sec/step, loss=0.86842, avg_loss=0.85718]\n","Step 3644    [1.370 sec/step, loss=0.85944, avg_loss=0.85702]\n","Step 3645    [1.400 sec/step, loss=0.58077, avg_loss=0.85415]\n","Step 3646    [1.400 sec/step, loss=0.86376, avg_loss=0.85379]\n","Step 3647    [1.399 sec/step, loss=0.85237, avg_loss=0.85324]\n","Step 3648    [1.397 sec/step, loss=0.90991, avg_loss=0.85350]\n","Step 3649    [1.402 sec/step, loss=0.83895, avg_loss=0.85330]\n","Step 3650    [1.402 sec/step, loss=0.84627, avg_loss=0.85312]\n","Step 3651    [1.397 sec/step, loss=0.86708, avg_loss=0.85332]\n","Step 3652    [1.395 sec/step, loss=0.84027, avg_loss=0.85303]\n","Step 3653    [1.394 sec/step, loss=0.82767, avg_loss=0.85234]\n","Step 3654    [1.392 sec/step, loss=0.84255, avg_loss=0.85236]\n","Step 3655    [1.397 sec/step, loss=0.80892, avg_loss=0.85186]\n","Step 3656    [1.387 sec/step, loss=0.85922, avg_loss=0.85189]\n","Step 3657    [1.387 sec/step, loss=0.85789, avg_loss=0.85172]\n","Step 3658    [1.379 sec/step, loss=0.86990, avg_loss=0.85163]\n","Step 3659    [1.376 sec/step, loss=0.84718, avg_loss=0.85130]\n","Step 3660    [1.377 sec/step, loss=0.87641, avg_loss=0.85145]\n","Step 3661    [1.383 sec/step, loss=0.83673, avg_loss=0.85093]\n","Step 3662    [1.385 sec/step, loss=0.85541, avg_loss=0.85076]\n","Step 3663    [1.390 sec/step, loss=0.82007, avg_loss=0.85034]\n","Step 3664    [1.389 sec/step, loss=0.85874, avg_loss=0.85017]\n","Step 3665    [1.394 sec/step, loss=0.84740, avg_loss=0.84946]\n","Step 3666    [1.391 sec/step, loss=0.86859, avg_loss=0.84925]\n","Step 3667    [1.392 sec/step, loss=0.84632, avg_loss=0.84915]\n","Step 3668    [1.391 sec/step, loss=0.86097, avg_loss=0.84920]\n","Step 3669    [1.391 sec/step, loss=0.86801, avg_loss=0.84908]\n","Generated 32 batches of size 32 in 19.938 sec\n","Step 3670    [1.422 sec/step, loss=0.87266, avg_loss=0.85164]\n","Step 3671    [1.411 sec/step, loss=0.86755, avg_loss=0.85185]\n","Step 3672    [1.409 sec/step, loss=0.87534, avg_loss=0.85194]\n","Step 3673    [1.409 sec/step, loss=0.85243, avg_loss=0.85187]\n","Step 3674    [1.404 sec/step, loss=0.84281, avg_loss=0.85149]\n","Step 3675    [1.368 sec/step, loss=0.85329, avg_loss=0.85142]\n","Step 3676    [1.361 sec/step, loss=0.83623, avg_loss=0.85119]\n","Step 3677    [1.364 sec/step, loss=0.86116, avg_loss=0.85126]\n","Step 3678    [1.372 sec/step, loss=0.82443, avg_loss=0.85083]\n","Step 3679    [1.372 sec/step, loss=0.85817, avg_loss=0.85041]\n","Step 3680    [1.369 sec/step, loss=0.84958, avg_loss=0.85051]\n","Step 3681    [1.369 sec/step, loss=0.83284, avg_loss=0.85001]\n","Step 3682    [1.384 sec/step, loss=0.65670, avg_loss=0.84772]\n","Step 3683    [1.386 sec/step, loss=0.82742, avg_loss=0.84721]\n","Step 3684    [1.398 sec/step, loss=0.78536, avg_loss=0.84592]\n","Step 3685    [1.401 sec/step, loss=0.83720, avg_loss=0.84555]\n","Step 3686    [1.401 sec/step, loss=0.84670, avg_loss=0.84547]\n","Step 3687    [1.401 sec/step, loss=0.82866, avg_loss=0.84497]\n","Step 3688    [1.406 sec/step, loss=0.84658, avg_loss=0.84481]\n","Step 3689    [1.398 sec/step, loss=0.83970, avg_loss=0.84515]\n","Step 3690    [1.400 sec/step, loss=0.84033, avg_loss=0.84493]\n","Step 3691    [1.394 sec/step, loss=0.83634, avg_loss=0.84490]\n","Step 3692    [1.396 sec/step, loss=0.85678, avg_loss=0.84495]\n","Step 3693    [1.407 sec/step, loss=0.89951, avg_loss=0.84491]\n","Step 3694    [1.417 sec/step, loss=0.81891, avg_loss=0.84449]\n","Step 3695    [1.414 sec/step, loss=0.84406, avg_loss=0.84428]\n","Step 3696    [1.419 sec/step, loss=0.86960, avg_loss=0.84407]\n","Step 3697    [1.423 sec/step, loss=0.83690, avg_loss=0.84363]\n","Step 3698    [1.427 sec/step, loss=0.81933, avg_loss=0.84303]\n","Step 3699    [1.429 sec/step, loss=0.84774, avg_loss=0.84294]\n","Step 3700    [1.430 sec/step, loss=0.85127, avg_loss=0.84265]\n","Writing summary at step: 3700\n","Generated 32 batches of size 32 in 19.554 sec\n","Step 3701    [1.472 sec/step, loss=0.88029, avg_loss=0.84304]\n","Step 3702    [1.476 sec/step, loss=0.88295, avg_loss=0.84304]\n","Step 3703    [1.470 sec/step, loss=0.85040, avg_loss=0.84289]\n","Step 3704    [1.470 sec/step, loss=0.82035, avg_loss=0.84230]\n","Step 3705    [1.469 sec/step, loss=0.85781, avg_loss=0.84258]\n","Step 3706    [1.455 sec/step, loss=0.86957, avg_loss=0.84270]\n","Step 3707    [1.455 sec/step, loss=0.86418, avg_loss=0.84285]\n","Step 3708    [1.457 sec/step, loss=0.84215, avg_loss=0.84270]\n","Step 3709    [1.454 sec/step, loss=0.83863, avg_loss=0.84242]\n","Step 3710    [1.453 sec/step, loss=0.85114, avg_loss=0.84218]\n","Step 3711    [1.456 sec/step, loss=0.82404, avg_loss=0.84201]\n","Step 3712    [1.455 sec/step, loss=0.88141, avg_loss=0.84225]\n","Step 3713    [1.456 sec/step, loss=0.85389, avg_loss=0.84193]\n","Step 3714    [1.460 sec/step, loss=0.82223, avg_loss=0.84159]\n","Step 3715    [1.460 sec/step, loss=0.84612, avg_loss=0.84110]\n","Step 3716    [1.431 sec/step, loss=0.85736, avg_loss=0.84386]\n","Step 3717    [1.425 sec/step, loss=0.86539, avg_loss=0.84404]\n","Step 3718    [1.420 sec/step, loss=0.82512, avg_loss=0.84380]\n","Step 3719    [1.414 sec/step, loss=0.84199, avg_loss=0.84408]\n","Step 3720    [1.411 sec/step, loss=0.88750, avg_loss=0.84465]\n","Step 3721    [1.399 sec/step, loss=0.85338, avg_loss=0.84552]\n","Step 3722    [1.398 sec/step, loss=0.84751, avg_loss=0.84566]\n","Step 3723    [1.396 sec/step, loss=0.85508, avg_loss=0.84576]\n","Step 3724    [1.411 sec/step, loss=0.82386, avg_loss=0.84541]\n","Step 3725    [1.414 sec/step, loss=0.87770, avg_loss=0.84553]\n","Step 3726    [1.412 sec/step, loss=0.84032, avg_loss=0.84537]\n","Step 3727    [1.417 sec/step, loss=0.85003, avg_loss=0.84529]\n","Step 3728    [1.433 sec/step, loss=0.78441, avg_loss=0.84493]\n","Step 3729    [1.425 sec/step, loss=0.83654, avg_loss=0.84492]\n","Step 3730    [1.430 sec/step, loss=0.88373, avg_loss=0.84522]\n","Step 3731    [1.469 sec/step, loss=0.64154, avg_loss=0.84320]\n","Step 3732    [1.468 sec/step, loss=0.85094, avg_loss=0.84306]\n","Generated 32 batches of size 32 in 19.818 sec\n","Step 3733    [1.493 sec/step, loss=0.83436, avg_loss=0.84278]\n","Step 3734    [1.501 sec/step, loss=0.78813, avg_loss=0.84154]\n","Step 3735    [1.523 sec/step, loss=0.60948, avg_loss=0.83909]\n","Step 3736    [1.519 sec/step, loss=0.85231, avg_loss=0.83895]\n","Step 3737    [1.510 sec/step, loss=0.86576, avg_loss=0.83913]\n","Step 3738    [1.443 sec/step, loss=0.88027, avg_loss=0.83938]\n","Step 3739    [1.440 sec/step, loss=0.88517, avg_loss=0.83985]\n","Step 3740    [1.434 sec/step, loss=0.84238, avg_loss=0.84009]\n","Step 3741    [1.425 sec/step, loss=0.84581, avg_loss=0.84034]\n","Step 3742    [1.422 sec/step, loss=0.86030, avg_loss=0.84066]\n","Step 3743    [1.421 sec/step, loss=0.86544, avg_loss=0.84063]\n","Step 3744    [1.427 sec/step, loss=0.84326, avg_loss=0.84047]\n","Step 3745    [1.400 sec/step, loss=0.83319, avg_loss=0.84300]\n","Step 3746    [1.398 sec/step, loss=0.85607, avg_loss=0.84292]\n","Step 3747    [1.398 sec/step, loss=0.86785, avg_loss=0.84307]\n","Step 3748    [1.398 sec/step, loss=0.84087, avg_loss=0.84238]\n","Step 3749    [1.392 sec/step, loss=0.85195, avg_loss=0.84251]\n","Step 3750    [1.391 sec/step, loss=0.86058, avg_loss=0.84266]\n","Step 3751    [1.400 sec/step, loss=0.83054, avg_loss=0.84229]\n","Step 3752    [1.403 sec/step, loss=0.86936, avg_loss=0.84258]\n","Step 3753    [1.401 sec/step, loss=0.84569, avg_loss=0.84276]\n","Step 3754    [1.399 sec/step, loss=0.85531, avg_loss=0.84289]\n","Step 3755    [1.392 sec/step, loss=0.85146, avg_loss=0.84332]\n","Step 3756    [1.405 sec/step, loss=0.84973, avg_loss=0.84322]\n","Step 3757    [1.412 sec/step, loss=0.86292, avg_loss=0.84327]\n","Step 3758    [1.424 sec/step, loss=0.84258, avg_loss=0.84300]\n","Step 3759    [1.434 sec/step, loss=0.86232, avg_loss=0.84315]\n","Step 3760    [1.436 sec/step, loss=0.87919, avg_loss=0.84318]\n","Step 3761    [1.444 sec/step, loss=0.85616, avg_loss=0.84337]\n","Step 3762    [1.436 sec/step, loss=0.84690, avg_loss=0.84329]\n","Step 3763    [1.438 sec/step, loss=0.84865, avg_loss=0.84357]\n","Step 3764    [1.439 sec/step, loss=0.86782, avg_loss=0.84366]\n","Generated 32 batches of size 32 in 18.646 sec\n","Step 3765    [1.477 sec/step, loss=0.86544, avg_loss=0.84384]\n","Step 3766    [1.470 sec/step, loss=0.86698, avg_loss=0.84383]\n","Step 3767    [1.464 sec/step, loss=0.86427, avg_loss=0.84401]\n","Step 3768    [1.469 sec/step, loss=0.81906, avg_loss=0.84359]\n","Step 3769    [1.470 sec/step, loss=0.83677, avg_loss=0.84327]\n","Step 3770    [1.391 sec/step, loss=0.85614, avg_loss=0.84311]\n","Step 3771    [1.393 sec/step, loss=0.81572, avg_loss=0.84259]\n","Step 3772    [1.392 sec/step, loss=0.85343, avg_loss=0.84237]\n","Step 3773    [1.393 sec/step, loss=0.83709, avg_loss=0.84222]\n","Step 3774    [1.394 sec/step, loss=0.83255, avg_loss=0.84212]\n","Step 3775    [1.396 sec/step, loss=0.86395, avg_loss=0.84222]\n","Step 3776    [1.397 sec/step, loss=0.86722, avg_loss=0.84253]\n","Step 3777    [1.393 sec/step, loss=0.86837, avg_loss=0.84260]\n","Step 3778    [1.385 sec/step, loss=0.87586, avg_loss=0.84312]\n","Step 3779    [1.389 sec/step, loss=0.83634, avg_loss=0.84290]\n","Step 3780    [1.395 sec/step, loss=0.81997, avg_loss=0.84260]\n","Step 3781    [1.395 sec/step, loss=0.87388, avg_loss=0.84301]\n","Step 3782    [1.372 sec/step, loss=0.85837, avg_loss=0.84503]\n","Step 3783    [1.371 sec/step, loss=0.85328, avg_loss=0.84529]\n","Step 3784    [1.361 sec/step, loss=0.85647, avg_loss=0.84600]\n","Step 3785    [1.360 sec/step, loss=0.86199, avg_loss=0.84625]\n","Step 3786    [1.391 sec/step, loss=0.59321, avg_loss=0.84371]\n","Step 3787    [1.390 sec/step, loss=0.84990, avg_loss=0.84393]\n","Step 3788    [1.394 sec/step, loss=0.88194, avg_loss=0.84428]\n","Step 3789    [1.397 sec/step, loss=0.85027, avg_loss=0.84439]\n","Step 3790    [1.398 sec/step, loss=0.86186, avg_loss=0.84460]\n","Step 3791    [1.409 sec/step, loss=0.83917, avg_loss=0.84463]\n","Step 3792    [1.409 sec/step, loss=0.86875, avg_loss=0.84475]\n","Step 3793    [1.404 sec/step, loss=0.87277, avg_loss=0.84448]\n","Step 3794    [1.398 sec/step, loss=0.83391, avg_loss=0.84463]\n","Step 3795    [1.411 sec/step, loss=0.85058, avg_loss=0.84470]\n","Step 3796    [1.407 sec/step, loss=0.84532, avg_loss=0.84445]\n","Generated 32 batches of size 32 in 18.017 sec\n","Step 3797    [1.444 sec/step, loss=0.85933, avg_loss=0.84468]\n","Step 3798    [1.429 sec/step, loss=0.82110, avg_loss=0.84470]\n","Step 3799    [1.424 sec/step, loss=0.83736, avg_loss=0.84459]\n","Step 3800    [1.419 sec/step, loss=0.87021, avg_loss=0.84478]\n","Writing summary at step: 3800\n","Step 3801    [1.371 sec/step, loss=0.86147, avg_loss=0.84459]\n","Step 3802    [1.367 sec/step, loss=0.88155, avg_loss=0.84458]\n","Step 3803    [1.373 sec/step, loss=0.80938, avg_loss=0.84417]\n","Step 3804    [1.395 sec/step, loss=0.56090, avg_loss=0.84157]\n","Step 3805    [1.395 sec/step, loss=0.84510, avg_loss=0.84145]\n","Step 3806    [1.394 sec/step, loss=0.86290, avg_loss=0.84138]\n","Step 3807    [1.397 sec/step, loss=0.80340, avg_loss=0.84077]\n","Step 3808    [1.394 sec/step, loss=0.85888, avg_loss=0.84094]\n","Step 3809    [1.394 sec/step, loss=0.83234, avg_loss=0.84088]\n","Step 3810    [1.395 sec/step, loss=0.84526, avg_loss=0.84082]\n","Step 3811    [1.389 sec/step, loss=0.85491, avg_loss=0.84113]\n","Step 3812    [1.390 sec/step, loss=0.88836, avg_loss=0.84120]\n","Step 3813    [1.390 sec/step, loss=0.86570, avg_loss=0.84132]\n","Step 3814    [1.397 sec/step, loss=0.82526, avg_loss=0.84135]\n","Step 3815    [1.395 sec/step, loss=0.84437, avg_loss=0.84133]\n","Step 3816    [1.394 sec/step, loss=0.83492, avg_loss=0.84110]\n","Step 3817    [1.400 sec/step, loss=0.82535, avg_loss=0.84070]\n","Step 3818    [1.398 sec/step, loss=0.85014, avg_loss=0.84095]\n","Step 3819    [1.407 sec/step, loss=0.83820, avg_loss=0.84092]\n","Step 3820    [1.411 sec/step, loss=0.85844, avg_loss=0.84062]\n","Step 3821    [1.414 sec/step, loss=0.85893, avg_loss=0.84068]\n","Step 3822    [1.418 sec/step, loss=0.86730, avg_loss=0.84088]\n","Step 3823    [1.421 sec/step, loss=0.85046, avg_loss=0.84083]\n","Step 3824    [1.409 sec/step, loss=0.86003, avg_loss=0.84119]\n","Step 3825    [1.412 sec/step, loss=0.85910, avg_loss=0.84101]\n","Step 3826    [1.424 sec/step, loss=0.82441, avg_loss=0.84085]\n","Step 3827    [1.425 sec/step, loss=0.82935, avg_loss=0.84064]\n","Generated 32 batches of size 32 in 19.748 sec\n","Step 3828    [1.485 sec/step, loss=0.85910, avg_loss=0.84139]\n","Step 3829    [1.479 sec/step, loss=0.81209, avg_loss=0.84114]\n","Step 3830    [1.472 sec/step, loss=0.87517, avg_loss=0.84106]\n","Step 3831    [1.435 sec/step, loss=0.86541, avg_loss=0.84330]\n","Step 3832    [1.433 sec/step, loss=0.85097, avg_loss=0.84330]\n","Step 3833    [1.404 sec/step, loss=0.86375, avg_loss=0.84359]\n","Step 3834    [1.398 sec/step, loss=0.84650, avg_loss=0.84418]\n","Step 3835    [1.371 sec/step, loss=0.84573, avg_loss=0.84654]\n","Step 3836    [1.370 sec/step, loss=0.85764, avg_loss=0.84659]\n","Step 3837    [1.373 sec/step, loss=0.87527, avg_loss=0.84669]\n","Step 3838    [1.376 sec/step, loss=0.86106, avg_loss=0.84649]\n","Step 3839    [1.375 sec/step, loss=0.83534, avg_loss=0.84600]\n","Step 3840    [1.373 sec/step, loss=0.85057, avg_loss=0.84608]\n","Step 3841    [1.386 sec/step, loss=0.78389, avg_loss=0.84546]\n","Step 3842    [1.387 sec/step, loss=0.85266, avg_loss=0.84538]\n","Step 3843    [1.387 sec/step, loss=0.85987, avg_loss=0.84533]\n","Step 3844    [1.381 sec/step, loss=0.86995, avg_loss=0.84559]\n","Step 3845    [1.403 sec/step, loss=0.69216, avg_loss=0.84418]\n","Step 3846    [1.402 sec/step, loss=0.85065, avg_loss=0.84413]\n","Step 3847    [1.402 sec/step, loss=0.88195, avg_loss=0.84427]\n","Step 3848    [1.402 sec/step, loss=0.85452, avg_loss=0.84441]\n","Step 3849    [1.410 sec/step, loss=0.80820, avg_loss=0.84397]\n","Step 3850    [1.417 sec/step, loss=0.85338, avg_loss=0.84390]\n","Step 3851    [1.418 sec/step, loss=0.86839, avg_loss=0.84428]\n","Step 3852    [1.419 sec/step, loss=0.85319, avg_loss=0.84411]\n","Step 3853    [1.425 sec/step, loss=0.85556, avg_loss=0.84421]\n","Step 3854    [1.435 sec/step, loss=0.86017, avg_loss=0.84426]\n","Step 3855    [1.439 sec/step, loss=0.84879, avg_loss=0.84423]\n","Step 3856    [1.432 sec/step, loss=0.85906, avg_loss=0.84433]\n","Step 3857    [1.428 sec/step, loss=0.85963, avg_loss=0.84429]\n","Step 3858    [1.424 sec/step, loss=0.86580, avg_loss=0.84453]\n","Step 3859    [1.415 sec/step, loss=0.85500, avg_loss=0.84445]\n","Generated 32 batches of size 32 in 19.540 sec\n","Step 3860    [1.484 sec/step, loss=0.89605, avg_loss=0.84462]\n","Step 3861    [1.473 sec/step, loss=0.84508, avg_loss=0.84451]\n","Step 3862    [1.472 sec/step, loss=0.84885, avg_loss=0.84453]\n","Step 3863    [1.464 sec/step, loss=0.83952, avg_loss=0.84444]\n","Step 3864    [1.460 sec/step, loss=0.84597, avg_loss=0.84422]\n","Step 3865    [1.418 sec/step, loss=0.84584, avg_loss=0.84403]\n","Step 3866    [1.423 sec/step, loss=0.87685, avg_loss=0.84412]\n","Step 3867    [1.429 sec/step, loss=0.84445, avg_loss=0.84393]\n","Step 3868    [1.417 sec/step, loss=0.86664, avg_loss=0.84440]\n","Step 3869    [1.413 sec/step, loss=0.86179, avg_loss=0.84465]\n","Step 3870    [1.415 sec/step, loss=0.85876, avg_loss=0.84468]\n","Step 3871    [1.411 sec/step, loss=0.84749, avg_loss=0.84500]\n","Step 3872    [1.412 sec/step, loss=0.83812, avg_loss=0.84484]\n","Step 3873    [1.433 sec/step, loss=0.65289, avg_loss=0.84300]\n","Step 3874    [1.437 sec/step, loss=0.82018, avg_loss=0.84288]\n","Step 3875    [1.435 sec/step, loss=0.83876, avg_loss=0.84262]\n","Step 3876    [1.438 sec/step, loss=0.86550, avg_loss=0.84261]\n","Step 3877    [1.439 sec/step, loss=0.84469, avg_loss=0.84237]\n","Step 3878    [1.443 sec/step, loss=0.83125, avg_loss=0.84192]\n","Step 3879    [1.438 sec/step, loss=0.85640, avg_loss=0.84213]\n","Step 3880    [1.433 sec/step, loss=0.84769, avg_loss=0.84240]\n","Step 3881    [1.447 sec/step, loss=0.77600, avg_loss=0.84142]\n","Step 3882    [1.448 sec/step, loss=0.85068, avg_loss=0.84135]\n","Step 3883    [1.458 sec/step, loss=0.83299, avg_loss=0.84114]\n","Step 3884    [1.459 sec/step, loss=0.83754, avg_loss=0.84095]\n","Step 3885    [1.467 sec/step, loss=0.86002, avg_loss=0.84093]\n","Step 3886    [1.441 sec/step, loss=0.87834, avg_loss=0.84379]\n","Step 3887    [1.443 sec/step, loss=0.87945, avg_loss=0.84408]\n","Step 3888    [1.452 sec/step, loss=0.83977, avg_loss=0.84366]\n","Step 3889    [1.451 sec/step, loss=0.86591, avg_loss=0.84382]\n","Step 3890    [1.451 sec/step, loss=0.89382, avg_loss=0.84414]\n","Step 3891    [1.455 sec/step, loss=0.83847, avg_loss=0.84413]\n","Generated 32 batches of size 32 in 19.736 sec\n","Step 3892    [1.540 sec/step, loss=0.58757, avg_loss=0.84132]\n","Step 3893    [1.539 sec/step, loss=0.83133, avg_loss=0.84090]\n","Step 3894    [1.531 sec/step, loss=0.86857, avg_loss=0.84125]\n","Step 3895    [1.522 sec/step, loss=0.85970, avg_loss=0.84134]\n","Step 3896    [1.520 sec/step, loss=0.86038, avg_loss=0.84149]\n","Step 3897    [1.487 sec/step, loss=0.76838, avg_loss=0.84058]\n","Step 3898    [1.487 sec/step, loss=0.85503, avg_loss=0.84092]\n","Step 3899    [1.489 sec/step, loss=0.83899, avg_loss=0.84094]\n","Step 3900    [1.486 sec/step, loss=0.87951, avg_loss=0.84103]\n","Writing summary at step: 3900\n","Step 3901    [1.484 sec/step, loss=0.84115, avg_loss=0.84083]\n","Step 3902    [1.479 sec/step, loss=0.83570, avg_loss=0.84037]\n","Step 3903    [1.472 sec/step, loss=0.82926, avg_loss=0.84057]\n","Step 3904    [1.447 sec/step, loss=0.85393, avg_loss=0.84350]\n","Step 3905    [1.449 sec/step, loss=0.83399, avg_loss=0.84339]\n","Step 3906    [1.447 sec/step, loss=0.83915, avg_loss=0.84315]\n","Step 3907    [1.448 sec/step, loss=0.84457, avg_loss=0.84356]\n","Step 3908    [1.449 sec/step, loss=0.86151, avg_loss=0.84359]\n","Step 3909    [1.451 sec/step, loss=0.83942, avg_loss=0.84366]\n","Step 3910    [1.447 sec/step, loss=0.87740, avg_loss=0.84398]\n","Step 3911    [1.451 sec/step, loss=0.83742, avg_loss=0.84380]\n","Step 3912    [1.450 sec/step, loss=0.84668, avg_loss=0.84339]\n","Step 3913    [1.448 sec/step, loss=0.83706, avg_loss=0.84310]\n","Step 3914    [1.440 sec/step, loss=0.84221, avg_loss=0.84327]\n","Step 3915    [1.451 sec/step, loss=0.84528, avg_loss=0.84328]\n","Step 3916    [1.453 sec/step, loss=0.85897, avg_loss=0.84352]\n","Step 3917    [1.450 sec/step, loss=0.85047, avg_loss=0.84377]\n","Step 3918    [1.465 sec/step, loss=0.83578, avg_loss=0.84363]\n","Step 3919    [1.459 sec/step, loss=0.84411, avg_loss=0.84369]\n","Step 3920    [1.467 sec/step, loss=0.84436, avg_loss=0.84355]\n","Step 3921    [1.472 sec/step, loss=0.84600, avg_loss=0.84342]\n","Step 3922    [1.476 sec/step, loss=0.85504, avg_loss=0.84329]\n","Generated 32 batches of size 32 in 19.639 sec\n","Step 3923    [1.534 sec/step, loss=0.86086, avg_loss=0.84340]\n","Step 3924    [1.534 sec/step, loss=0.83509, avg_loss=0.84315]\n","Step 3925    [1.552 sec/step, loss=0.62447, avg_loss=0.84080]\n","Step 3926    [1.538 sec/step, loss=0.85377, avg_loss=0.84110]\n","Step 3927    [1.531 sec/step, loss=0.84715, avg_loss=0.84127]\n","Step 3928    [1.454 sec/step, loss=0.83855, avg_loss=0.84107]\n","Step 3929    [1.456 sec/step, loss=0.82227, avg_loss=0.84117]\n","Step 3930    [1.459 sec/step, loss=0.86527, avg_loss=0.84107]\n","Step 3931    [1.459 sec/step, loss=0.82380, avg_loss=0.84066]\n","Step 3932    [1.459 sec/step, loss=0.86269, avg_loss=0.84077]\n","Step 3933    [1.463 sec/step, loss=0.85721, avg_loss=0.84071]\n","Step 3934    [1.458 sec/step, loss=0.84243, avg_loss=0.84067]\n","Step 3935    [1.458 sec/step, loss=0.85862, avg_loss=0.84080]\n","Step 3936    [1.457 sec/step, loss=0.89790, avg_loss=0.84120]\n","Step 3937    [1.458 sec/step, loss=0.83120, avg_loss=0.84076]\n","Step 3938    [1.456 sec/step, loss=0.86110, avg_loss=0.84076]\n","Step 3939    [1.458 sec/step, loss=0.85932, avg_loss=0.84100]\n","Step 3940    [1.466 sec/step, loss=0.85474, avg_loss=0.84104]\n","Step 3941    [1.455 sec/step, loss=0.83593, avg_loss=0.84156]\n","Step 3942    [1.458 sec/step, loss=0.83761, avg_loss=0.84141]\n","Step 3943    [1.457 sec/step, loss=0.86484, avg_loss=0.84146]\n","Step 3944    [1.458 sec/step, loss=0.85929, avg_loss=0.84135]\n","Step 3945    [1.439 sec/step, loss=0.86603, avg_loss=0.84309]\n","Step 3946    [1.440 sec/step, loss=0.85185, avg_loss=0.84310]\n","Step 3947    [1.445 sec/step, loss=0.88197, avg_loss=0.84310]\n","Step 3948    [1.447 sec/step, loss=0.86885, avg_loss=0.84325]\n","Step 3949    [1.444 sec/step, loss=0.83983, avg_loss=0.84356]\n","Step 3950    [1.444 sec/step, loss=0.83108, avg_loss=0.84334]\n","Step 3951    [1.450 sec/step, loss=0.83988, avg_loss=0.84305]\n","Step 3952    [1.450 sec/step, loss=0.88267, avg_loss=0.84335]\n","Step 3953    [1.452 sec/step, loss=0.83779, avg_loss=0.84317]\n","Step 3954    [1.463 sec/step, loss=0.81700, avg_loss=0.84274]\n","Generated 32 batches of size 32 in 17.940 sec\n","Step 3955    [1.496 sec/step, loss=0.87389, avg_loss=0.84299]\n","Step 3956    [1.494 sec/step, loss=0.84853, avg_loss=0.84289]\n","Step 3957    [1.519 sec/step, loss=0.59474, avg_loss=0.84024]\n","Step 3958    [1.514 sec/step, loss=0.84313, avg_loss=0.84001]\n","Step 3959    [1.511 sec/step, loss=0.86867, avg_loss=0.84015]\n","Step 3960    [1.440 sec/step, loss=0.85238, avg_loss=0.83971]\n","Step 3961    [1.438 sec/step, loss=0.84538, avg_loss=0.83971]\n","Step 3962    [1.436 sec/step, loss=0.84198, avg_loss=0.83964]\n","Step 3963    [1.437 sec/step, loss=0.83571, avg_loss=0.83961]\n","Step 3964    [1.444 sec/step, loss=0.83556, avg_loss=0.83950]\n","Step 3965    [1.449 sec/step, loss=0.86501, avg_loss=0.83969]\n","Step 3966    [1.448 sec/step, loss=0.83874, avg_loss=0.83931]\n","Step 3967    [1.453 sec/step, loss=0.77702, avg_loss=0.83864]\n","Step 3968    [1.454 sec/step, loss=0.84657, avg_loss=0.83844]\n","Step 3969    [1.454 sec/step, loss=0.85666, avg_loss=0.83839]\n","Step 3970    [1.452 sec/step, loss=0.86112, avg_loss=0.83841]\n","Step 3971    [1.453 sec/step, loss=0.82831, avg_loss=0.83822]\n","Step 3972    [1.452 sec/step, loss=0.83494, avg_loss=0.83819]\n","Step 3973    [1.429 sec/step, loss=0.83597, avg_loss=0.84002]\n","Step 3974    [1.422 sec/step, loss=0.84521, avg_loss=0.84027]\n","Step 3975    [1.423 sec/step, loss=0.80737, avg_loss=0.83995]\n","Step 3976    [1.427 sec/step, loss=0.80996, avg_loss=0.83940]\n","Step 3977    [1.431 sec/step, loss=0.82974, avg_loss=0.83925]\n","Step 3978    [1.435 sec/step, loss=0.86513, avg_loss=0.83959]\n","Step 3979    [1.442 sec/step, loss=0.83535, avg_loss=0.83938]\n","Step 3980    [1.442 sec/step, loss=0.83814, avg_loss=0.83928]\n","Step 3981    [1.438 sec/step, loss=0.83260, avg_loss=0.83985]\n","Step 3982    [1.438 sec/step, loss=0.85302, avg_loss=0.83987]\n","Step 3983    [1.434 sec/step, loss=0.81813, avg_loss=0.83972]\n","Step 3984    [1.436 sec/step, loss=0.82881, avg_loss=0.83964]\n","Step 3985    [1.437 sec/step, loss=0.83235, avg_loss=0.83936]\n","Step 3986    [1.443 sec/step, loss=0.84059, avg_loss=0.83898]\n","Generated 32 batches of size 32 in 18.823 sec\n","Step 3987    [1.502 sec/step, loss=0.82998, avg_loss=0.83849]\n","Step 3988    [1.484 sec/step, loss=0.86060, avg_loss=0.83869]\n","Step 3989    [1.481 sec/step, loss=0.84674, avg_loss=0.83850]\n","Step 3990    [1.483 sec/step, loss=0.85782, avg_loss=0.83814]\n","Step 3991    [1.470 sec/step, loss=0.83433, avg_loss=0.83810]\n","Step 3992    [1.384 sec/step, loss=0.83619, avg_loss=0.84059]\n","Step 3993    [1.390 sec/step, loss=0.75999, avg_loss=0.83987]\n","Step 3994    [1.392 sec/step, loss=0.81906, avg_loss=0.83938]\n","Step 3995    [1.385 sec/step, loss=0.86999, avg_loss=0.83948]\n","Step 3996    [1.414 sec/step, loss=0.63863, avg_loss=0.83726]\n","Step 3997    [1.404 sec/step, loss=0.84484, avg_loss=0.83803]\n","Step 3998    [1.403 sec/step, loss=0.84635, avg_loss=0.83794]\n","Step 3999    [1.402 sec/step, loss=0.83938, avg_loss=0.83795]\n","Step 4000    [1.403 sec/step, loss=0.88052, avg_loss=0.83796]\n","Writing summary at step: 4000\n","Saving checkpoint to: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/model.ckpt-4000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (83700,)\n","Check wav file:  (113700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000004000-align000.png\n","100% 1/1 [00:03<00:00,  3.19s/it]\n","Test finished for step 4000.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000004000-align000.png\n"," 25% 1/4 [00:10<00:32, 10.84s/it]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000004000-align001.png\n"," 50% 2/4 [00:20<00:21, 10.63s/it]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000004000-align002.png\n"," 75% 3/4 [00:30<00:10, 10.39s/it]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000004000-align003.png\n","100% 4/4 [00:40<00:00, 10.19s/it]\n","Test finished for step 4000.\n","Step 4001    [1.404 sec/step, loss=0.85224, avg_loss=0.83807]\n","Step 4002    [1.404 sec/step, loss=0.85055, avg_loss=0.83822]\n","Step 4003    [1.410 sec/step, loss=0.82466, avg_loss=0.83817]\n","Step 4004    [1.414 sec/step, loss=0.88002, avg_loss=0.83843]\n","Step 4005    [1.413 sec/step, loss=0.84191, avg_loss=0.83851]\n","Step 4006    [1.419 sec/step, loss=0.84552, avg_loss=0.83857]\n","Step 4007    [1.413 sec/step, loss=0.84471, avg_loss=0.83857]\n","Step 4008    [1.417 sec/step, loss=0.88139, avg_loss=0.83877]\n","Step 4009    [1.426 sec/step, loss=0.84834, avg_loss=0.83886]\n","Step 4010    [1.430 sec/step, loss=0.85906, avg_loss=0.83868]\n","Step 4011    [1.440 sec/step, loss=0.86344, avg_loss=0.83894]\n","Step 4012    [1.446 sec/step, loss=0.85121, avg_loss=0.83899]\n","Step 4013    [1.449 sec/step, loss=0.84611, avg_loss=0.83908]\n","Step 4014    [1.449 sec/step, loss=0.83310, avg_loss=0.83898]\n","Step 4015    [1.447 sec/step, loss=0.83796, avg_loss=0.83891]\n","Step 4016    [1.449 sec/step, loss=0.84958, avg_loss=0.83882]\n","Generated 32 batches of size 32 in 19.542 sec\n","Step 4017    [1.512 sec/step, loss=0.85980, avg_loss=0.83891]\n","Step 4018    [1.494 sec/step, loss=0.84151, avg_loss=0.83897]\n","Step 4019    [1.490 sec/step, loss=0.85651, avg_loss=0.83909]\n","Step 4020    [1.484 sec/step, loss=0.83756, avg_loss=0.83902]\n","Step 4021    [1.477 sec/step, loss=0.85370, avg_loss=0.83910]\n","Step 4022    [1.468 sec/step, loss=0.85655, avg_loss=0.83912]\n","Step 4023    [1.435 sec/step, loss=0.57794, avg_loss=0.83629]\n","Step 4024    [1.433 sec/step, loss=0.83794, avg_loss=0.83632]\n","Step 4025    [1.413 sec/step, loss=0.84401, avg_loss=0.83851]\n","Step 4026    [1.413 sec/step, loss=0.87042, avg_loss=0.83868]\n","Step 4027    [1.411 sec/step, loss=0.84386, avg_loss=0.83864]\n","Step 4028    [1.410 sec/step, loss=0.82662, avg_loss=0.83853]\n","Step 4029    [1.404 sec/step, loss=0.85486, avg_loss=0.83885]\n","Step 4030    [1.404 sec/step, loss=0.85460, avg_loss=0.83874]\n","Step 4031    [1.408 sec/step, loss=0.83026, avg_loss=0.83881]\n","Step 4032    [1.413 sec/step, loss=0.82498, avg_loss=0.83843]\n","Step 4033    [1.412 sec/step, loss=0.84576, avg_loss=0.83832]\n","Step 4034    [1.423 sec/step, loss=0.78843, avg_loss=0.83778]\n","Step 4035    [1.424 sec/step, loss=0.83126, avg_loss=0.83750]\n","Step 4036    [1.424 sec/step, loss=0.82760, avg_loss=0.83680]\n","Step 4037    [1.420 sec/step, loss=0.82949, avg_loss=0.83678]\n","Step 4038    [1.422 sec/step, loss=0.83242, avg_loss=0.83650]\n","Step 4039    [1.428 sec/step, loss=0.80935, avg_loss=0.83600]\n","Step 4040    [1.425 sec/step, loss=0.84252, avg_loss=0.83588]\n","Step 4041    [1.437 sec/step, loss=0.83816, avg_loss=0.83590]\n","Step 4042    [1.437 sec/step, loss=0.82724, avg_loss=0.83579]\n","Step 4043    [1.441 sec/step, loss=0.82734, avg_loss=0.83542]\n","Step 4044    [1.448 sec/step, loss=0.83643, avg_loss=0.83519]\n","Step 4045    [1.453 sec/step, loss=0.83248, avg_loss=0.83485]\n","Step 4046    [1.460 sec/step, loss=0.84150, avg_loss=0.83475]\n","Step 4047    [1.458 sec/step, loss=0.84591, avg_loss=0.83439]\n","Step 4048    [1.467 sec/step, loss=0.83887, avg_loss=0.83409]\n","Generated 32 batches of size 32 in 19.845 sec\n","Step 4049    [1.523 sec/step, loss=0.86857, avg_loss=0.83438]\n","Step 4050    [1.522 sec/step, loss=0.81966, avg_loss=0.83426]\n","Step 4051    [1.512 sec/step, loss=0.82438, avg_loss=0.83411]\n","Step 4052    [1.540 sec/step, loss=0.53534, avg_loss=0.83064]\n","Step 4053    [1.538 sec/step, loss=0.82934, avg_loss=0.83055]\n","Step 4054    [1.517 sec/step, loss=0.86988, avg_loss=0.83108]\n","Step 4055    [1.486 sec/step, loss=0.79426, avg_loss=0.83028]\n","Step 4056    [1.479 sec/step, loss=0.83695, avg_loss=0.83017]\n","Step 4057    [1.451 sec/step, loss=0.82805, avg_loss=0.83250]\n","Step 4058    [1.454 sec/step, loss=0.81499, avg_loss=0.83222]\n","Step 4059    [1.456 sec/step, loss=0.84789, avg_loss=0.83201]\n","Step 4060    [1.462 sec/step, loss=0.79464, avg_loss=0.83143]\n","Step 4061    [1.462 sec/step, loss=0.82444, avg_loss=0.83122]\n","Step 4062    [1.466 sec/step, loss=0.81845, avg_loss=0.83099]\n","Step 4063    [1.461 sec/step, loss=0.84545, avg_loss=0.83109]\n","Step 4064    [1.456 sec/step, loss=0.84138, avg_loss=0.83115]\n","Step 4065    [1.457 sec/step, loss=0.84591, avg_loss=0.83095]\n","Step 4066    [1.466 sec/step, loss=0.79077, avg_loss=0.83047]\n","Step 4067    [1.461 sec/step, loss=0.83371, avg_loss=0.83104]\n","Step 4068    [1.463 sec/step, loss=0.85752, avg_loss=0.83115]\n","Step 4069    [1.463 sec/step, loss=0.86930, avg_loss=0.83128]\n","Step 4070    [1.466 sec/step, loss=0.85546, avg_loss=0.83122]\n","Step 4071    [1.469 sec/step, loss=0.83858, avg_loss=0.83132]\n","Step 4072    [1.474 sec/step, loss=0.84253, avg_loss=0.83140]\n","Step 4073    [1.473 sec/step, loss=0.84647, avg_loss=0.83150]\n","Step 4074    [1.476 sec/step, loss=0.86024, avg_loss=0.83165]\n","Step 4075    [1.483 sec/step, loss=0.85539, avg_loss=0.83213]\n","Step 4076    [1.480 sec/step, loss=0.84770, avg_loss=0.83251]\n","Step 4077    [1.477 sec/step, loss=0.84777, avg_loss=0.83269]\n","Step 4078    [1.475 sec/step, loss=0.87528, avg_loss=0.83279]\n","Step 4079    [1.474 sec/step, loss=0.82511, avg_loss=0.83269]\n","Step 4080    [1.478 sec/step, loss=0.81399, avg_loss=0.83245]\n","Generated 32 batches of size 32 in 19.608 sec\n","Step 4081    [1.555 sec/step, loss=0.85796, avg_loss=0.83270]\n","Step 4082    [1.575 sec/step, loss=0.66552, avg_loss=0.83083]\n","Step 4083    [1.567 sec/step, loss=0.83219, avg_loss=0.83097]\n","Step 4084    [1.564 sec/step, loss=0.82841, avg_loss=0.83097]\n","Step 4085    [1.553 sec/step, loss=0.88475, avg_loss=0.83149]\n","Step 4086    [1.544 sec/step, loss=0.86883, avg_loss=0.83177]\n","Step 4087    [1.483 sec/step, loss=0.83242, avg_loss=0.83180]\n","Step 4088    [1.484 sec/step, loss=0.83937, avg_loss=0.83158]\n","Step 4089    [1.487 sec/step, loss=0.83170, avg_loss=0.83143]\n","Step 4090    [1.485 sec/step, loss=0.83237, avg_loss=0.83118]\n","Step 4091    [1.489 sec/step, loss=0.83017, avg_loss=0.83114]\n","Step 4092    [1.486 sec/step, loss=0.85029, avg_loss=0.83128]\n","Step 4093    [1.483 sec/step, loss=0.85655, avg_loss=0.83224]\n","Step 4094    [1.482 sec/step, loss=0.84517, avg_loss=0.83251]\n","Step 4095    [1.488 sec/step, loss=0.84500, avg_loss=0.83226]\n","Step 4096    [1.457 sec/step, loss=0.81725, avg_loss=0.83404]\n","Step 4097    [1.455 sec/step, loss=0.85378, avg_loss=0.83413]\n","Step 4098    [1.457 sec/step, loss=0.85226, avg_loss=0.83419]\n","Step 4099    [1.457 sec/step, loss=0.84148, avg_loss=0.83421]\n","Step 4100    [1.462 sec/step, loss=0.82928, avg_loss=0.83370]\n","Writing summary at step: 4100\n","Step 4101    [1.466 sec/step, loss=0.82164, avg_loss=0.83339]\n","Step 4102    [1.467 sec/step, loss=0.85333, avg_loss=0.83342]\n","Step 4103    [1.481 sec/step, loss=0.79708, avg_loss=0.83314]\n","Step 4104    [1.478 sec/step, loss=0.84776, avg_loss=0.83282]\n","Step 4105    [1.486 sec/step, loss=0.83319, avg_loss=0.83273]\n","Step 4106    [1.489 sec/step, loss=0.81743, avg_loss=0.83245]\n","Step 4107    [1.494 sec/step, loss=0.87144, avg_loss=0.83272]\n","Step 4108    [1.502 sec/step, loss=0.80277, avg_loss=0.83194]\n","Step 4109    [1.493 sec/step, loss=0.86777, avg_loss=0.83213]\n","Step 4110    [1.491 sec/step, loss=0.82482, avg_loss=0.83179]\n","Step 4111    [1.482 sec/step, loss=0.84717, avg_loss=0.83162]\n","Generated 32 batches of size 32 in 19.338 sec\n","Step 4112    [1.532 sec/step, loss=0.85076, avg_loss=0.83162]\n","Step 4113    [1.528 sec/step, loss=0.84037, avg_loss=0.83156]\n","Step 4114    [1.529 sec/step, loss=0.84294, avg_loss=0.83166]\n","Step 4115    [1.523 sec/step, loss=0.86315, avg_loss=0.83191]\n","Step 4116    [1.522 sec/step, loss=0.84098, avg_loss=0.83183]\n","Step 4117    [1.457 sec/step, loss=0.86287, avg_loss=0.83186]\n","Step 4118    [1.459 sec/step, loss=0.82151, avg_loss=0.83166]\n","Step 4119    [1.458 sec/step, loss=0.84026, avg_loss=0.83149]\n","Step 4120    [1.455 sec/step, loss=0.85807, avg_loss=0.83170]\n","Step 4121    [1.458 sec/step, loss=0.87582, avg_loss=0.83192]\n","Step 4122    [1.459 sec/step, loss=0.81517, avg_loss=0.83151]\n","Step 4123    [1.430 sec/step, loss=0.83310, avg_loss=0.83406]\n","Step 4124    [1.430 sec/step, loss=0.83361, avg_loss=0.83402]\n","Step 4125    [1.432 sec/step, loss=0.81752, avg_loss=0.83375]\n","Step 4126    [1.434 sec/step, loss=0.85749, avg_loss=0.83362]\n","Step 4127    [1.433 sec/step, loss=0.84596, avg_loss=0.83364]\n","Step 4128    [1.431 sec/step, loss=0.85085, avg_loss=0.83388]\n","Step 4129    [1.435 sec/step, loss=0.88042, avg_loss=0.83414]\n","Step 4130    [1.434 sec/step, loss=0.87202, avg_loss=0.83431]\n","Step 4131    [1.425 sec/step, loss=0.84758, avg_loss=0.83449]\n","Step 4132    [1.428 sec/step, loss=0.80724, avg_loss=0.83431]\n","Step 4133    [1.437 sec/step, loss=0.81802, avg_loss=0.83403]\n","Step 4134    [1.431 sec/step, loss=0.82236, avg_loss=0.83437]\n","Step 4135    [1.430 sec/step, loss=0.84718, avg_loss=0.83453]\n","Step 4136    [1.434 sec/step, loss=0.87600, avg_loss=0.83502]\n","Step 4137    [1.438 sec/step, loss=0.85300, avg_loss=0.83525]\n","Step 4138    [1.443 sec/step, loss=0.83877, avg_loss=0.83531]\n","Step 4139    [1.444 sec/step, loss=0.83972, avg_loss=0.83562]\n","Step 4140    [1.455 sec/step, loss=0.80990, avg_loss=0.83529]\n","Step 4141    [1.485 sec/step, loss=0.61942, avg_loss=0.83310]\n","Step 4142    [1.492 sec/step, loss=0.82132, avg_loss=0.83304]\n","Step 4143    [1.494 sec/step, loss=0.84157, avg_loss=0.83319]\n","Generated 32 batches of size 32 in 18.625 sec\n","Step 4144    [1.504 sec/step, loss=0.83401, avg_loss=0.83316]\n","Step 4145    [1.495 sec/step, loss=0.84832, avg_loss=0.83332]\n","Step 4146    [1.485 sec/step, loss=0.84233, avg_loss=0.83333]\n","Step 4147    [1.482 sec/step, loss=0.83723, avg_loss=0.83324]\n","Step 4148    [1.478 sec/step, loss=0.81192, avg_loss=0.83297]\n","Step 4149    [1.420 sec/step, loss=0.82445, avg_loss=0.83253]\n","Step 4150    [1.418 sec/step, loss=0.80727, avg_loss=0.83241]\n","Step 4151    [1.415 sec/step, loss=0.82561, avg_loss=0.83242]\n","Step 4152    [1.386 sec/step, loss=0.84132, avg_loss=0.83548]\n","Step 4153    [1.380 sec/step, loss=0.82407, avg_loss=0.83543]\n","Step 4154    [1.384 sec/step, loss=0.81963, avg_loss=0.83492]\n","Step 4155    [1.376 sec/step, loss=0.85190, avg_loss=0.83550]\n","Step 4156    [1.377 sec/step, loss=0.82920, avg_loss=0.83542]\n","Step 4157    [1.379 sec/step, loss=0.83054, avg_loss=0.83545]\n","Step 4158    [1.375 sec/step, loss=0.84694, avg_loss=0.83577]\n","Step 4159    [1.373 sec/step, loss=0.84358, avg_loss=0.83573]\n","Step 4160    [1.397 sec/step, loss=0.59385, avg_loss=0.83372]\n","Step 4161    [1.403 sec/step, loss=0.81074, avg_loss=0.83358]\n","Step 4162    [1.399 sec/step, loss=0.82049, avg_loss=0.83360]\n","Step 4163    [1.399 sec/step, loss=0.85541, avg_loss=0.83370]\n","Step 4164    [1.397 sec/step, loss=0.83423, avg_loss=0.83363]\n","Step 4165    [1.395 sec/step, loss=0.84485, avg_loss=0.83362]\n","Step 4166    [1.385 sec/step, loss=0.81572, avg_loss=0.83387]\n","Step 4167    [1.386 sec/step, loss=0.83958, avg_loss=0.83393]\n","Step 4168    [1.392 sec/step, loss=0.84346, avg_loss=0.83379]\n","Step 4169    [1.408 sec/step, loss=0.84450, avg_loss=0.83354]\n","Step 4170    [1.427 sec/step, loss=0.78456, avg_loss=0.83283]\n","Step 4171    [1.435 sec/step, loss=0.80985, avg_loss=0.83254]\n","Step 4172    [1.437 sec/step, loss=0.81342, avg_loss=0.83225]\n","Step 4173    [1.440 sec/step, loss=0.83830, avg_loss=0.83217]\n","Step 4174    [1.448 sec/step, loss=0.84981, avg_loss=0.83206]\n","Step 4175    [1.443 sec/step, loss=0.83391, avg_loss=0.83185]\n","Generated 32 batches of size 32 in 19.148 sec\n","Step 4176    [1.475 sec/step, loss=0.85755, avg_loss=0.83195]\n","Step 4177    [1.475 sec/step, loss=0.83815, avg_loss=0.83185]\n","Step 4178    [1.471 sec/step, loss=0.83790, avg_loss=0.83148]\n","Step 4179    [1.464 sec/step, loss=0.83898, avg_loss=0.83162]\n","Step 4180    [1.460 sec/step, loss=0.82707, avg_loss=0.83175]\n","Step 4181    [1.381 sec/step, loss=0.78806, avg_loss=0.83105]\n","Step 4182    [1.359 sec/step, loss=0.81755, avg_loss=0.83257]\n","Step 4183    [1.360 sec/step, loss=0.83300, avg_loss=0.83258]\n","Step 4184    [1.384 sec/step, loss=0.63332, avg_loss=0.83063]\n","Step 4185    [1.385 sec/step, loss=0.83978, avg_loss=0.83018]\n","Step 4186    [1.385 sec/step, loss=0.83029, avg_loss=0.82979]\n","Step 4187    [1.382 sec/step, loss=0.86442, avg_loss=0.83011]\n","Step 4188    [1.385 sec/step, loss=0.84577, avg_loss=0.83017]\n","Step 4189    [1.392 sec/step, loss=0.81837, avg_loss=0.83004]\n","Step 4190    [1.387 sec/step, loss=0.84272, avg_loss=0.83014]\n","Step 4191    [1.382 sec/step, loss=0.85552, avg_loss=0.83040]\n","Step 4192    [1.385 sec/step, loss=0.85495, avg_loss=0.83044]\n","Step 4193    [1.382 sec/step, loss=0.80990, avg_loss=0.82998]\n","Step 4194    [1.384 sec/step, loss=0.80665, avg_loss=0.82959]\n","Step 4195    [1.382 sec/step, loss=0.83956, avg_loss=0.82954]\n","Step 4196    [1.383 sec/step, loss=0.86234, avg_loss=0.82999]\n","Step 4197    [1.391 sec/step, loss=0.85463, avg_loss=0.83000]\n","Step 4198    [1.391 sec/step, loss=0.85158, avg_loss=0.82999]\n","Step 4199    [1.395 sec/step, loss=0.83372, avg_loss=0.82991]\n","Step 4200    [1.394 sec/step, loss=0.84275, avg_loss=0.83005]\n","Writing summary at step: 4200\n","Step 4201    [1.396 sec/step, loss=0.83924, avg_loss=0.83022]\n","Step 4202    [1.399 sec/step, loss=0.83319, avg_loss=0.83002]\n","Step 4203    [1.382 sec/step, loss=0.80312, avg_loss=0.83008]\n","Step 4204    [1.391 sec/step, loss=0.79850, avg_loss=0.82959]\n","Step 4205    [1.386 sec/step, loss=0.83944, avg_loss=0.82965]\n","Step 4206    [1.381 sec/step, loss=0.83859, avg_loss=0.82987]\n","Generated 32 batches of size 32 in 19.719 sec\n","Step 4207    [1.448 sec/step, loss=0.83849, avg_loss=0.82954]\n","Step 4208    [1.438 sec/step, loss=0.82547, avg_loss=0.82976]\n","Step 4209    [1.439 sec/step, loss=0.84139, avg_loss=0.82950]\n","Step 4210    [1.438 sec/step, loss=0.84070, avg_loss=0.82966]\n","Step 4211    [1.435 sec/step, loss=0.84915, avg_loss=0.82968]\n","Step 4212    [1.380 sec/step, loss=0.85294, avg_loss=0.82970]\n","Step 4213    [1.385 sec/step, loss=0.81902, avg_loss=0.82949]\n","Step 4214    [1.408 sec/step, loss=0.65668, avg_loss=0.82762]\n","Step 4215    [1.405 sec/step, loss=0.86082, avg_loss=0.82760]\n","Step 4216    [1.401 sec/step, loss=0.85361, avg_loss=0.82773]\n","Step 4217    [1.402 sec/step, loss=0.83780, avg_loss=0.82748]\n","Step 4218    [1.401 sec/step, loss=0.83919, avg_loss=0.82765]\n","Step 4219    [1.403 sec/step, loss=0.86939, avg_loss=0.82794]\n","Step 4220    [1.401 sec/step, loss=0.83844, avg_loss=0.82775]\n","Step 4221    [1.400 sec/step, loss=0.83948, avg_loss=0.82738]\n","Step 4222    [1.397 sec/step, loss=0.85999, avg_loss=0.82783]\n","Step 4223    [1.402 sec/step, loss=0.83097, avg_loss=0.82781]\n","Step 4224    [1.404 sec/step, loss=0.87515, avg_loss=0.82823]\n","Step 4225    [1.404 sec/step, loss=0.83903, avg_loss=0.82844]\n","Step 4226    [1.404 sec/step, loss=0.82985, avg_loss=0.82816]\n","Step 4227    [1.407 sec/step, loss=0.81827, avg_loss=0.82789]\n","Step 4228    [1.406 sec/step, loss=0.83487, avg_loss=0.82773]\n","Step 4229    [1.405 sec/step, loss=0.84716, avg_loss=0.82740]\n","Step 4230    [1.420 sec/step, loss=0.83419, avg_loss=0.82702]\n","Step 4231    [1.422 sec/step, loss=0.82278, avg_loss=0.82677]\n","Step 4232    [1.430 sec/step, loss=0.82151, avg_loss=0.82691]\n","Step 4233    [1.441 sec/step, loss=0.78973, avg_loss=0.82663]\n","Step 4234    [1.443 sec/step, loss=0.86225, avg_loss=0.82703]\n","Step 4235    [1.451 sec/step, loss=0.83069, avg_loss=0.82686]\n","Step 4236    [1.459 sec/step, loss=0.83636, avg_loss=0.82647]\n","Step 4237    [1.459 sec/step, loss=0.83741, avg_loss=0.82631]\n","Step 4238    [1.459 sec/step, loss=0.82902, avg_loss=0.82621]\n","Generated 32 batches of size 32 in 19.569 sec\n","Step 4239    [1.482 sec/step, loss=0.85044, avg_loss=0.82632]\n","Step 4240    [1.470 sec/step, loss=0.84425, avg_loss=0.82666]\n","Step 4241    [1.430 sec/step, loss=0.82251, avg_loss=0.82869]\n","Step 4242    [1.420 sec/step, loss=0.87125, avg_loss=0.82919]\n","Step 4243    [1.420 sec/step, loss=0.82920, avg_loss=0.82907]\n","Step 4244    [1.410 sec/step, loss=0.79662, avg_loss=0.82870]\n","Step 4245    [1.408 sec/step, loss=0.83845, avg_loss=0.82860]\n","Step 4246    [1.413 sec/step, loss=0.82831, avg_loss=0.82846]\n","Step 4247    [1.418 sec/step, loss=0.83974, avg_loss=0.82848]\n","Step 4248    [1.413 sec/step, loss=0.81926, avg_loss=0.82856]\n","Step 4249    [1.411 sec/step, loss=0.82258, avg_loss=0.82854]\n","Step 4250    [1.405 sec/step, loss=0.83460, avg_loss=0.82881]\n","Step 4251    [1.405 sec/step, loss=0.82400, avg_loss=0.82879]\n","Step 4252    [1.403 sec/step, loss=0.82586, avg_loss=0.82864]\n","Step 4253    [1.409 sec/step, loss=0.84837, avg_loss=0.82888]\n","Step 4254    [1.406 sec/step, loss=0.82497, avg_loss=0.82894]\n","Step 4255    [1.409 sec/step, loss=0.80063, avg_loss=0.82842]\n","Step 4256    [1.409 sec/step, loss=0.83141, avg_loss=0.82845]\n","Step 4257    [1.413 sec/step, loss=0.82988, avg_loss=0.82844]\n","Step 4258    [1.414 sec/step, loss=0.85707, avg_loss=0.82854]\n","Step 4259    [1.416 sec/step, loss=0.82839, avg_loss=0.82839]\n","Step 4260    [1.388 sec/step, loss=0.84226, avg_loss=0.83087]\n","Step 4261    [1.380 sec/step, loss=0.82698, avg_loss=0.83104]\n","Step 4262    [1.382 sec/step, loss=0.84738, avg_loss=0.83130]\n","Step 4263    [1.387 sec/step, loss=0.81107, avg_loss=0.83086]\n","Step 4264    [1.409 sec/step, loss=0.79395, avg_loss=0.83046]\n","Step 4265    [1.415 sec/step, loss=0.83305, avg_loss=0.83034]\n","Step 4266    [1.414 sec/step, loss=0.85268, avg_loss=0.83071]\n","Step 4267    [1.453 sec/step, loss=0.57306, avg_loss=0.82804]\n","Step 4268    [1.451 sec/step, loss=0.82639, avg_loss=0.82787]\n","Step 4269    [1.437 sec/step, loss=0.82482, avg_loss=0.82768]\n","Step 4270    [1.417 sec/step, loss=0.83244, avg_loss=0.82816]\n","Generated 32 batches of size 32 in 19.916 sec\n","Step 4271    [1.444 sec/step, loss=0.84471, avg_loss=0.82850]\n","Step 4272    [1.445 sec/step, loss=0.81071, avg_loss=0.82848]\n","Step 4273    [1.439 sec/step, loss=0.80791, avg_loss=0.82817]\n","Step 4274    [1.430 sec/step, loss=0.82242, avg_loss=0.82790]\n","Step 4275    [1.428 sec/step, loss=0.84273, avg_loss=0.82799]\n","Step 4276    [1.392 sec/step, loss=0.80773, avg_loss=0.82749]\n","Step 4277    [1.390 sec/step, loss=0.82899, avg_loss=0.82740]\n","Step 4278    [1.393 sec/step, loss=0.82015, avg_loss=0.82722]\n","Step 4279    [1.392 sec/step, loss=0.84383, avg_loss=0.82727]\n","Step 4280    [1.391 sec/step, loss=0.84909, avg_loss=0.82749]\n","Step 4281    [1.386 sec/step, loss=0.83901, avg_loss=0.82800]\n","Step 4282    [1.384 sec/step, loss=0.83315, avg_loss=0.82815]\n","Step 4283    [1.386 sec/step, loss=0.81536, avg_loss=0.82798]\n","Step 4284    [1.361 sec/step, loss=0.82308, avg_loss=0.82988]\n","Step 4285    [1.385 sec/step, loss=0.65627, avg_loss=0.82804]\n","Step 4286    [1.387 sec/step, loss=0.82624, avg_loss=0.82800]\n","Step 4287    [1.394 sec/step, loss=0.82906, avg_loss=0.82765]\n","Step 4288    [1.394 sec/step, loss=0.82083, avg_loss=0.82740]\n","Step 4289    [1.385 sec/step, loss=0.85534, avg_loss=0.82777]\n","Step 4290    [1.389 sec/step, loss=0.83080, avg_loss=0.82765]\n","Step 4291    [1.402 sec/step, loss=0.73662, avg_loss=0.82646]\n","Step 4292    [1.401 sec/step, loss=0.82994, avg_loss=0.82621]\n","Step 4293    [1.395 sec/step, loss=0.84733, avg_loss=0.82658]\n","Step 4294    [1.394 sec/step, loss=0.82714, avg_loss=0.82679]\n","Step 4295    [1.398 sec/step, loss=0.82598, avg_loss=0.82665]\n","Step 4296    [1.403 sec/step, loss=0.82990, avg_loss=0.82633]\n","Step 4297    [1.401 sec/step, loss=0.83650, avg_loss=0.82615]\n","Step 4298    [1.416 sec/step, loss=0.81089, avg_loss=0.82574]\n","Step 4299    [1.419 sec/step, loss=0.82135, avg_loss=0.82562]\n","Step 4300    [1.427 sec/step, loss=0.81485, avg_loss=0.82534]\n","Writing summary at step: 4300\n","Step 4301    [1.420 sec/step, loss=0.82376, avg_loss=0.82518]\n","Generated 32 batches of size 32 in 19.280 sec\n","Step 4302    [1.470 sec/step, loss=0.82688, avg_loss=0.82512]\n","Step 4303    [1.473 sec/step, loss=0.81283, avg_loss=0.82522]\n","Step 4304    [1.459 sec/step, loss=0.82004, avg_loss=0.82543]\n","Step 4305    [1.460 sec/step, loss=0.81636, avg_loss=0.82520]\n","Step 4306    [1.463 sec/step, loss=0.83411, avg_loss=0.82516]\n","Step 4307    [1.393 sec/step, loss=0.81145, avg_loss=0.82488]\n","Step 4308    [1.393 sec/step, loss=0.81400, avg_loss=0.82477]\n","Step 4309    [1.392 sec/step, loss=0.87516, avg_loss=0.82511]\n","Step 4310    [1.391 sec/step, loss=0.84692, avg_loss=0.82517]\n","Step 4311    [1.390 sec/step, loss=0.83008, avg_loss=0.82498]\n","Step 4312    [1.390 sec/step, loss=0.86423, avg_loss=0.82509]\n","Step 4313    [1.385 sec/step, loss=0.83761, avg_loss=0.82528]\n","Step 4314    [1.364 sec/step, loss=0.84227, avg_loss=0.82713]\n","Step 4315    [1.366 sec/step, loss=0.82248, avg_loss=0.82675]\n","Step 4316    [1.370 sec/step, loss=0.84654, avg_loss=0.82668]\n","Step 4317    [1.367 sec/step, loss=0.84820, avg_loss=0.82678]\n","Step 4318    [1.368 sec/step, loss=0.82033, avg_loss=0.82660]\n","Step 4319    [1.369 sec/step, loss=0.84006, avg_loss=0.82630]\n","Step 4320    [1.368 sec/step, loss=0.82356, avg_loss=0.82615]\n","Step 4321    [1.397 sec/step, loss=0.51936, avg_loss=0.82295]\n","Step 4322    [1.400 sec/step, loss=0.81574, avg_loss=0.82251]\n","Step 4323    [1.404 sec/step, loss=0.81496, avg_loss=0.82235]\n","Step 4324    [1.401 sec/step, loss=0.81619, avg_loss=0.82176]\n","Step 4325    [1.409 sec/step, loss=0.82389, avg_loss=0.82161]\n","Step 4326    [1.414 sec/step, loss=0.84767, avg_loss=0.82179]\n","Step 4327    [1.416 sec/step, loss=0.84761, avg_loss=0.82208]\n","Step 4328    [1.424 sec/step, loss=0.84316, avg_loss=0.82216]\n","Step 4329    [1.430 sec/step, loss=0.84034, avg_loss=0.82209]\n","Step 4330    [1.416 sec/step, loss=0.85935, avg_loss=0.82235]\n","Step 4331    [1.435 sec/step, loss=0.80006, avg_loss=0.82212]\n","Step 4332    [1.427 sec/step, loss=0.86858, avg_loss=0.82259]\n","Step 4333    [1.409 sec/step, loss=0.82679, avg_loss=0.82296]\n","Generated 32 batches of size 32 in 18.529 sec\n","Step 4334    [1.450 sec/step, loss=0.82854, avg_loss=0.82262]\n","Step 4335    [1.446 sec/step, loss=0.79232, avg_loss=0.82224]\n","Step 4336    [1.442 sec/step, loss=0.82912, avg_loss=0.82217]\n","Step 4337    [1.468 sec/step, loss=0.54764, avg_loss=0.81927]\n","Step 4338    [1.464 sec/step, loss=0.81078, avg_loss=0.81909]\n","Step 4339    [1.445 sec/step, loss=0.76572, avg_loss=0.81824]\n","Step 4340    [1.443 sec/step, loss=0.84717, avg_loss=0.81827]\n","Step 4341    [1.445 sec/step, loss=0.81561, avg_loss=0.81820]\n","Step 4342    [1.446 sec/step, loss=0.83107, avg_loss=0.81780]\n","Step 4343    [1.441 sec/step, loss=0.82331, avg_loss=0.81774]\n","Step 4344    [1.435 sec/step, loss=0.84364, avg_loss=0.81821]\n","Step 4345    [1.434 sec/step, loss=0.83469, avg_loss=0.81817]\n","Step 4346    [1.438 sec/step, loss=0.82348, avg_loss=0.81812]\n","Step 4347    [1.433 sec/step, loss=0.87160, avg_loss=0.81844]\n","Step 4348    [1.434 sec/step, loss=0.82646, avg_loss=0.81851]\n","Step 4349    [1.438 sec/step, loss=0.81072, avg_loss=0.81840]\n","Step 4350    [1.440 sec/step, loss=0.82262, avg_loss=0.81828]\n","Step 4351    [1.442 sec/step, loss=0.81893, avg_loss=0.81823]\n","Step 4352    [1.442 sec/step, loss=0.84334, avg_loss=0.81840]\n","Step 4353    [1.439 sec/step, loss=0.82931, avg_loss=0.81821]\n","Step 4354    [1.437 sec/step, loss=0.83634, avg_loss=0.81832]\n","Step 4355    [1.433 sec/step, loss=0.82514, avg_loss=0.81857]\n","Step 4356    [1.430 sec/step, loss=0.85830, avg_loss=0.81884]\n","Step 4357    [1.429 sec/step, loss=0.86589, avg_loss=0.81920]\n","Step 4358    [1.435 sec/step, loss=0.81402, avg_loss=0.81877]\n","Step 4359    [1.437 sec/step, loss=0.84261, avg_loss=0.81891]\n","Step 4360    [1.439 sec/step, loss=0.85024, avg_loss=0.81899]\n","Step 4361    [1.443 sec/step, loss=0.84336, avg_loss=0.81915]\n","Step 4362    [1.445 sec/step, loss=0.82341, avg_loss=0.81891]\n","Step 4363    [1.446 sec/step, loss=0.85909, avg_loss=0.81939]\n","Step 4364    [1.428 sec/step, loss=0.81803, avg_loss=0.81963]\n","Step 4365    [1.427 sec/step, loss=0.83011, avg_loss=0.81960]\n","Generated 32 batches of size 32 in 19.654 sec\n","Step 4366    [1.514 sec/step, loss=0.82943, avg_loss=0.81937]\n","Step 4367    [1.471 sec/step, loss=0.82848, avg_loss=0.82193]\n","Step 4368    [1.465 sec/step, loss=0.84749, avg_loss=0.82214]\n","Step 4369    [1.467 sec/step, loss=0.79951, avg_loss=0.82188]\n","Step 4370    [1.466 sec/step, loss=0.84445, avg_loss=0.82200]\n","Step 4371    [1.429 sec/step, loss=0.82342, avg_loss=0.82179]\n","Step 4372    [1.422 sec/step, loss=0.83488, avg_loss=0.82203]\n","Step 4373    [1.426 sec/step, loss=0.86771, avg_loss=0.82263]\n","Step 4374    [1.424 sec/step, loss=0.81821, avg_loss=0.82259]\n","Step 4375    [1.426 sec/step, loss=0.82737, avg_loss=0.82244]\n","Step 4376    [1.433 sec/step, loss=0.82798, avg_loss=0.82264]\n","Step 4377    [1.436 sec/step, loss=0.80459, avg_loss=0.82239]\n","Step 4378    [1.431 sec/step, loss=0.82733, avg_loss=0.82247]\n","Step 4379    [1.436 sec/step, loss=0.83731, avg_loss=0.82240]\n","Step 4380    [1.436 sec/step, loss=0.81185, avg_loss=0.82203]\n","Step 4381    [1.443 sec/step, loss=0.81657, avg_loss=0.82180]\n","Step 4382    [1.443 sec/step, loss=0.83066, avg_loss=0.82178]\n","Step 4383    [1.442 sec/step, loss=0.86002, avg_loss=0.82222]\n","Step 4384    [1.445 sec/step, loss=0.85536, avg_loss=0.82255]\n","Step 4385    [1.426 sec/step, loss=0.80872, avg_loss=0.82407]\n","Step 4386    [1.425 sec/step, loss=0.86048, avg_loss=0.82441]\n","Step 4387    [1.431 sec/step, loss=0.77786, avg_loss=0.82390]\n","Step 4388    [1.428 sec/step, loss=0.83906, avg_loss=0.82408]\n","Step 4389    [1.428 sec/step, loss=0.83292, avg_loss=0.82386]\n","Step 4390    [1.431 sec/step, loss=0.85932, avg_loss=0.82415]\n","Step 4391    [1.422 sec/step, loss=0.82136, avg_loss=0.82499]\n","Step 4392    [1.425 sec/step, loss=0.81775, avg_loss=0.82487]\n","Step 4393    [1.474 sec/step, loss=0.60949, avg_loss=0.82249]\n","Step 4394    [1.480 sec/step, loss=0.83525, avg_loss=0.82257]\n","Step 4395    [1.480 sec/step, loss=0.83066, avg_loss=0.82262]\n","Step 4396    [1.487 sec/step, loss=0.80557, avg_loss=0.82238]\n","Step 4397    [1.482 sec/step, loss=0.85877, avg_loss=0.82260]\n","Generated 32 batches of size 32 in 19.813 sec\n","Step 4398    [1.496 sec/step, loss=0.83019, avg_loss=0.82279]\n","Step 4399    [1.490 sec/step, loss=0.82742, avg_loss=0.82285]\n","Step 4400    [1.479 sec/step, loss=0.82543, avg_loss=0.82296]\n","Writing summary at step: 4400\n","Step 4401    [1.480 sec/step, loss=0.85861, avg_loss=0.82331]\n","Step 4402    [1.427 sec/step, loss=0.87578, avg_loss=0.82380]\n","Step 4403    [1.420 sec/step, loss=0.83366, avg_loss=0.82401]\n","Step 4404    [1.420 sec/step, loss=0.82554, avg_loss=0.82406]\n","Step 4405    [1.424 sec/step, loss=0.81288, avg_loss=0.82403]\n","Step 4406    [1.424 sec/step, loss=0.83097, avg_loss=0.82399]\n","Step 4407    [1.427 sec/step, loss=0.84037, avg_loss=0.82428]\n","Step 4408    [1.423 sec/step, loss=0.84056, avg_loss=0.82455]\n","Step 4409    [1.428 sec/step, loss=0.82008, avg_loss=0.82400]\n","Step 4410    [1.430 sec/step, loss=0.82961, avg_loss=0.82383]\n","Step 4411    [1.433 sec/step, loss=0.83129, avg_loss=0.82384]\n","Step 4412    [1.434 sec/step, loss=0.84825, avg_loss=0.82368]\n","Step 4413    [1.433 sec/step, loss=0.83228, avg_loss=0.82362]\n","Step 4414    [1.433 sec/step, loss=0.82751, avg_loss=0.82348]\n","Step 4415    [1.430 sec/step, loss=0.82586, avg_loss=0.82351]\n","Step 4416    [1.426 sec/step, loss=0.83569, avg_loss=0.82340]\n","Step 4417    [1.427 sec/step, loss=0.82929, avg_loss=0.82321]\n","Step 4418    [1.428 sec/step, loss=0.82769, avg_loss=0.82329]\n","Step 4419    [1.431 sec/step, loss=0.83418, avg_loss=0.82323]\n","Step 4420    [1.475 sec/step, loss=0.61550, avg_loss=0.82115]\n","Step 4421    [1.465 sec/step, loss=0.75760, avg_loss=0.82353]\n","Step 4422    [1.475 sec/step, loss=0.83067, avg_loss=0.82368]\n","Step 4423    [1.478 sec/step, loss=0.82982, avg_loss=0.82383]\n","Step 4424    [1.481 sec/step, loss=0.81898, avg_loss=0.82386]\n","Step 4425    [1.473 sec/step, loss=0.81656, avg_loss=0.82378]\n","Step 4426    [1.475 sec/step, loss=0.86702, avg_loss=0.82398]\n","Step 4427    [1.480 sec/step, loss=0.84501, avg_loss=0.82395]\n","Step 4428    [1.475 sec/step, loss=0.84514, avg_loss=0.82397]\n","Generated 32 batches of size 32 in 19.853 sec\n","Step 4429    [1.481 sec/step, loss=0.83435, avg_loss=0.82391]\n","Step 4430    [1.478 sec/step, loss=0.81531, avg_loss=0.82347]\n","Step 4431    [1.455 sec/step, loss=0.78247, avg_loss=0.82329]\n","Step 4432    [1.449 sec/step, loss=0.83740, avg_loss=0.82298]\n","Step 4433    [1.446 sec/step, loss=0.85569, avg_loss=0.82327]\n","Step 4434    [1.401 sec/step, loss=0.84147, avg_loss=0.82340]\n","Step 4435    [1.399 sec/step, loss=0.81425, avg_loss=0.82362]\n","Step 4436    [1.391 sec/step, loss=0.85484, avg_loss=0.82388]\n","Step 4437    [1.364 sec/step, loss=0.85301, avg_loss=0.82693]\n","Step 4438    [1.367 sec/step, loss=0.81131, avg_loss=0.82694]\n","Step 4439    [1.354 sec/step, loss=0.81085, avg_loss=0.82739]\n","Step 4440    [1.354 sec/step, loss=0.82558, avg_loss=0.82717]\n","Step 4441    [1.350 sec/step, loss=0.85923, avg_loss=0.82761]\n","Step 4442    [1.350 sec/step, loss=0.83929, avg_loss=0.82769]\n","Step 4443    [1.352 sec/step, loss=0.84833, avg_loss=0.82794]\n","Step 4444    [1.352 sec/step, loss=0.78672, avg_loss=0.82737]\n","Step 4445    [1.356 sec/step, loss=0.81363, avg_loss=0.82716]\n","Step 4446    [1.361 sec/step, loss=0.78094, avg_loss=0.82673]\n","Step 4447    [1.362 sec/step, loss=0.83748, avg_loss=0.82639]\n","Step 4448    [1.356 sec/step, loss=0.81158, avg_loss=0.82624]\n","Step 4449    [1.353 sec/step, loss=0.83628, avg_loss=0.82650]\n","Step 4450    [1.360 sec/step, loss=0.78666, avg_loss=0.82614]\n","Step 4451    [1.382 sec/step, loss=0.62991, avg_loss=0.82425]\n","Step 4452    [1.388 sec/step, loss=0.82116, avg_loss=0.82403]\n","Step 4453    [1.395 sec/step, loss=0.83494, avg_loss=0.82408]\n","Step 4454    [1.400 sec/step, loss=0.83853, avg_loss=0.82411]\n","Step 4455    [1.415 sec/step, loss=0.79138, avg_loss=0.82377]\n","Step 4456    [1.422 sec/step, loss=0.82820, avg_loss=0.82347]\n","Step 4457    [1.425 sec/step, loss=0.82170, avg_loss=0.82303]\n","Step 4458    [1.421 sec/step, loss=0.80872, avg_loss=0.82297]\n","Step 4459    [1.431 sec/step, loss=0.80049, avg_loss=0.82255]\n","Step 4460    [1.438 sec/step, loss=0.82901, avg_loss=0.82234]\n","Generated 32 batches of size 32 in 19.931 sec\n","Step 4461    [1.491 sec/step, loss=0.83688, avg_loss=0.82227]\n","Step 4462    [1.490 sec/step, loss=0.84772, avg_loss=0.82252]\n","Step 4463    [1.490 sec/step, loss=0.81810, avg_loss=0.82211]\n","Step 4464    [1.496 sec/step, loss=0.76667, avg_loss=0.82159]\n","Step 4465    [1.496 sec/step, loss=0.81094, avg_loss=0.82140]\n","Step 4466    [1.409 sec/step, loss=0.81938, avg_loss=0.82130]\n","Step 4467    [1.409 sec/step, loss=0.84866, avg_loss=0.82150]\n","Step 4468    [1.436 sec/step, loss=0.60542, avg_loss=0.81908]\n","Step 4469    [1.439 sec/step, loss=0.83047, avg_loss=0.81939]\n","Step 4470    [1.438 sec/step, loss=0.84637, avg_loss=0.81941]\n","Step 4471    [1.442 sec/step, loss=0.81580, avg_loss=0.81934]\n","Step 4472    [1.449 sec/step, loss=0.82537, avg_loss=0.81924]\n","Step 4473    [1.449 sec/step, loss=0.81498, avg_loss=0.81871]\n","Step 4474    [1.450 sec/step, loss=0.83044, avg_loss=0.81884]\n","Step 4475    [1.449 sec/step, loss=0.79728, avg_loss=0.81854]\n","Step 4476    [1.443 sec/step, loss=0.80098, avg_loss=0.81827]\n","Step 4477    [1.439 sec/step, loss=0.82860, avg_loss=0.81851]\n","Step 4478    [1.439 sec/step, loss=0.82402, avg_loss=0.81847]\n","Step 4479    [1.440 sec/step, loss=0.79075, avg_loss=0.81801]\n","Step 4480    [1.439 sec/step, loss=0.85940, avg_loss=0.81848]\n","Step 4481    [1.431 sec/step, loss=0.83885, avg_loss=0.81870]\n","Step 4482    [1.432 sec/step, loss=0.83874, avg_loss=0.81879]\n","Step 4483    [1.429 sec/step, loss=0.83557, avg_loss=0.81854]\n","Step 4484    [1.436 sec/step, loss=0.84776, avg_loss=0.81847]\n","Step 4485    [1.442 sec/step, loss=0.81845, avg_loss=0.81856]\n","Step 4486    [1.448 sec/step, loss=0.84716, avg_loss=0.81843]\n","Step 4487    [1.445 sec/step, loss=0.82133, avg_loss=0.81886]\n","Step 4488    [1.452 sec/step, loss=0.81180, avg_loss=0.81859]\n","Step 4489    [1.454 sec/step, loss=0.83456, avg_loss=0.81861]\n","Step 4490    [1.451 sec/step, loss=0.84008, avg_loss=0.81842]\n","Step 4491    [1.462 sec/step, loss=0.84995, avg_loss=0.81870]\n","Step 4492    [1.461 sec/step, loss=0.82316, avg_loss=0.81876]\n","Generated 32 batches of size 32 in 18.572 sec\n","Step 4493    [1.460 sec/step, loss=0.82926, avg_loss=0.82095]\n","Step 4494    [1.462 sec/step, loss=0.77239, avg_loss=0.82032]\n","Step 4495    [1.458 sec/step, loss=0.82924, avg_loss=0.82031]\n","Step 4496    [1.451 sec/step, loss=0.81789, avg_loss=0.82043]\n","Step 4497    [1.448 sec/step, loss=0.81705, avg_loss=0.82002]\n","Step 4498    [1.423 sec/step, loss=0.80045, avg_loss=0.81972]\n","Step 4499    [1.420 sec/step, loss=0.83519, avg_loss=0.81980]\n","Step 4500    [1.427 sec/step, loss=0.82695, avg_loss=0.81981]\n","Writing summary at step: 4500\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (90900,)\n","Check wav file:  (120900,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000004500-align000.png\n","100% 1/1 [00:03<00:00,  3.57s/it]\n","Test finished for step 4500.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (60300,)\n","Check wav file:  (90300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000004500-align000.png\n"," 25% 1/4 [00:02<00:06,  2.21s/it]Check wav file before change:  (60300,)\n","Check wav file:  (90300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000004500-align001.png\n"," 50% 2/4 [00:04<00:04,  2.27s/it]Check wav file before change:  (60300,)\n","Check wav file:  (90300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000004500-align002.png\n"," 75% 3/4 [00:06<00:02,  2.30s/it]Check wav file before change:  (60300,)\n","Check wav file:  (90300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000004500-align003.png\n","100% 4/4 [00:09<00:00,  2.36s/it]\n","Test finished for step 4500.\n","Step 4501    [1.426 sec/step, loss=0.81402, avg_loss=0.81937]\n","Step 4502    [1.430 sec/step, loss=0.84266, avg_loss=0.81903]\n","Step 4503    [1.432 sec/step, loss=0.82103, avg_loss=0.81891]\n","Step 4504    [1.431 sec/step, loss=0.86439, avg_loss=0.81930]\n","Step 4505    [1.431 sec/step, loss=0.81738, avg_loss=0.81934]\n","Step 4506    [1.428 sec/step, loss=0.81532, avg_loss=0.81919]\n","Step 4507    [1.425 sec/step, loss=0.82352, avg_loss=0.81902]\n","Step 4508    [1.425 sec/step, loss=0.81928, avg_loss=0.81880]\n","Step 4509    [1.418 sec/step, loss=0.82589, avg_loss=0.81886]\n","Step 4510    [1.419 sec/step, loss=0.83792, avg_loss=0.81895]\n","Step 4511    [1.448 sec/step, loss=0.54359, avg_loss=0.81607]\n","Step 4512    [1.446 sec/step, loss=0.85874, avg_loss=0.81617]\n","Step 4513    [1.445 sec/step, loss=0.84214, avg_loss=0.81627]\n","Step 4514    [1.453 sec/step, loss=0.86972, avg_loss=0.81669]\n","Step 4515    [1.461 sec/step, loss=0.80745, avg_loss=0.81651]\n","Step 4516    [1.464 sec/step, loss=0.83799, avg_loss=0.81653]\n","Step 4517    [1.467 sec/step, loss=0.83053, avg_loss=0.81655]\n","Step 4518    [1.469 sec/step, loss=0.84156, avg_loss=0.81668]\n","Step 4519    [1.470 sec/step, loss=0.84361, avg_loss=0.81678]\n","Step 4520    [1.435 sec/step, loss=0.81702, avg_loss=0.81879]\n","Step 4521    [1.418 sec/step, loss=0.83922, avg_loss=0.81961]\n","Step 4522    [1.409 sec/step, loss=0.83775, avg_loss=0.81968]\n","Generated 32 batches of size 32 in 18.151 sec\n","Step 4523    [1.463 sec/step, loss=0.83476, avg_loss=0.81973]\n","Step 4524    [1.486 sec/step, loss=0.66050, avg_loss=0.81814]\n","Step 4525    [1.484 sec/step, loss=0.83582, avg_loss=0.81834]\n","Step 4526    [1.482 sec/step, loss=0.83297, avg_loss=0.81800]\n","Step 4527    [1.476 sec/step, loss=0.82743, avg_loss=0.81782]\n","Step 4528    [1.473 sec/step, loss=0.83773, avg_loss=0.81775]\n","Step 4529    [1.463 sec/step, loss=0.81413, avg_loss=0.81754]\n","Step 4530    [1.472 sec/step, loss=0.81082, avg_loss=0.81750]\n","Step 4531    [1.479 sec/step, loss=0.81514, avg_loss=0.81783]\n","Step 4532    [1.479 sec/step, loss=0.82208, avg_loss=0.81767]\n","Step 4533    [1.481 sec/step, loss=0.84744, avg_loss=0.81759]\n","Step 4534    [1.490 sec/step, loss=0.75985, avg_loss=0.81677]\n","Step 4535    [1.485 sec/step, loss=0.83581, avg_loss=0.81699]\n","Step 4536    [1.484 sec/step, loss=0.80766, avg_loss=0.81652]\n","Step 4537    [1.480 sec/step, loss=0.83335, avg_loss=0.81632]\n","Step 4538    [1.484 sec/step, loss=0.83612, avg_loss=0.81657]\n","Step 4539    [1.487 sec/step, loss=0.85984, avg_loss=0.81706]\n","Step 4540    [1.486 sec/step, loss=0.82811, avg_loss=0.81709]\n","Step 4541    [1.489 sec/step, loss=0.84673, avg_loss=0.81696]\n","Step 4542    [1.489 sec/step, loss=0.83325, avg_loss=0.81690]\n","Step 4543    [1.484 sec/step, loss=0.83981, avg_loss=0.81681]\n","Step 4544    [1.488 sec/step, loss=0.82058, avg_loss=0.81715]\n","Step 4545    [1.486 sec/step, loss=0.84577, avg_loss=0.81747]\n","Step 4546    [1.482 sec/step, loss=0.80981, avg_loss=0.81776]\n","Step 4547    [1.486 sec/step, loss=0.83305, avg_loss=0.81772]\n","Step 4548    [1.493 sec/step, loss=0.84552, avg_loss=0.81806]\n","Step 4549    [1.495 sec/step, loss=0.84150, avg_loss=0.81811]\n","Step 4550    [1.494 sec/step, loss=0.81427, avg_loss=0.81839]\n","Step 4551    [1.476 sec/step, loss=0.84497, avg_loss=0.82054]\n","Step 4552    [1.471 sec/step, loss=0.82138, avg_loss=0.82054]\n","Step 4553    [1.474 sec/step, loss=0.81392, avg_loss=0.82033]\n","Step 4554    [1.473 sec/step, loss=0.83106, avg_loss=0.82025]\n","Generated 32 batches of size 32 in 19.630 sec\n","Step 4555    [1.538 sec/step, loss=0.80555, avg_loss=0.82040]\n","Step 4556    [1.535 sec/step, loss=0.83687, avg_loss=0.82048]\n","Step 4557    [1.530 sec/step, loss=0.83525, avg_loss=0.82062]\n","Step 4558    [1.529 sec/step, loss=0.82098, avg_loss=0.82074]\n","Step 4559    [1.517 sec/step, loss=0.84263, avg_loss=0.82116]\n","Step 4560    [1.508 sec/step, loss=0.82999, avg_loss=0.82117]\n","Step 4561    [1.464 sec/step, loss=0.77764, avg_loss=0.82058]\n","Step 4562    [1.462 sec/step, loss=0.84854, avg_loss=0.82059]\n","Step 4563    [1.462 sec/step, loss=0.81420, avg_loss=0.82055]\n","Step 4564    [1.455 sec/step, loss=0.84865, avg_loss=0.82137]\n","Step 4565    [1.451 sec/step, loss=0.86131, avg_loss=0.82187]\n","Step 4566    [1.452 sec/step, loss=0.80447, avg_loss=0.82172]\n","Step 4567    [1.451 sec/step, loss=0.81537, avg_loss=0.82139]\n","Step 4568    [1.421 sec/step, loss=0.82258, avg_loss=0.82356]\n","Step 4569    [1.416 sec/step, loss=0.83661, avg_loss=0.82362]\n","Step 4570    [1.415 sec/step, loss=0.84180, avg_loss=0.82358]\n","Step 4571    [1.413 sec/step, loss=0.83033, avg_loss=0.82372]\n","Step 4572    [1.414 sec/step, loss=0.80466, avg_loss=0.82352]\n","Step 4573    [1.411 sec/step, loss=0.85154, avg_loss=0.82388]\n","Step 4574    [1.436 sec/step, loss=0.61014, avg_loss=0.82168]\n","Step 4575    [1.441 sec/step, loss=0.79113, avg_loss=0.82162]\n","Step 4576    [1.446 sec/step, loss=0.82449, avg_loss=0.82185]\n","Step 4577    [1.446 sec/step, loss=0.82886, avg_loss=0.82186]\n","Step 4578    [1.454 sec/step, loss=0.83793, avg_loss=0.82199]\n","Step 4579    [1.455 sec/step, loss=0.84615, avg_loss=0.82255]\n","Step 4580    [1.459 sec/step, loss=0.85444, avg_loss=0.82250]\n","Step 4581    [1.463 sec/step, loss=0.84353, avg_loss=0.82255]\n","Step 4582    [1.466 sec/step, loss=0.81709, avg_loss=0.82233]\n","Step 4583    [1.471 sec/step, loss=0.86584, avg_loss=0.82263]\n","Step 4584    [1.463 sec/step, loss=0.83260, avg_loss=0.82248]\n","Step 4585    [1.460 sec/step, loss=0.84894, avg_loss=0.82278]\n","Step 4586    [1.462 sec/step, loss=0.82151, avg_loss=0.82253]\n","Generated 32 batches of size 32 in 19.734 sec\n","Step 4587    [1.536 sec/step, loss=0.82596, avg_loss=0.82257]\n","Step 4588    [1.532 sec/step, loss=0.79363, avg_loss=0.82239]\n","Step 4589    [1.554 sec/step, loss=0.60102, avg_loss=0.82006]\n","Step 4590    [1.553 sec/step, loss=0.83167, avg_loss=0.81997]\n","Step 4591    [1.539 sec/step, loss=0.84721, avg_loss=0.81995]\n","Step 4592    [1.539 sec/step, loss=0.76931, avg_loss=0.81941]\n","Step 4593    [1.494 sec/step, loss=0.83082, avg_loss=0.81942]\n","Step 4594    [1.491 sec/step, loss=0.86098, avg_loss=0.82031]\n","Step 4595    [1.487 sec/step, loss=0.85666, avg_loss=0.82058]\n","Step 4596    [1.489 sec/step, loss=0.81047, avg_loss=0.82051]\n","Step 4597    [1.494 sec/step, loss=0.82586, avg_loss=0.82060]\n","Step 4598    [1.491 sec/step, loss=0.80608, avg_loss=0.82065]\n","Step 4599    [1.494 sec/step, loss=0.81067, avg_loss=0.82041]\n","Step 4600    [1.487 sec/step, loss=0.83156, avg_loss=0.82045]\n","Writing summary at step: 4600\n","Step 4601    [1.484 sec/step, loss=0.84518, avg_loss=0.82077]\n","Step 4602    [1.487 sec/step, loss=0.83001, avg_loss=0.82064]\n","Step 4603    [1.487 sec/step, loss=0.82700, avg_loss=0.82070]\n","Step 4604    [1.492 sec/step, loss=0.80856, avg_loss=0.82014]\n","Step 4605    [1.483 sec/step, loss=0.86086, avg_loss=0.82058]\n","Step 4606    [1.482 sec/step, loss=0.86317, avg_loss=0.82105]\n","Step 4607    [1.481 sec/step, loss=0.85277, avg_loss=0.82135]\n","Step 4608    [1.483 sec/step, loss=0.83786, avg_loss=0.82153]\n","Step 4609    [1.490 sec/step, loss=0.81791, avg_loss=0.82145]\n","Step 4610    [1.492 sec/step, loss=0.83925, avg_loss=0.82147]\n","Step 4611    [1.473 sec/step, loss=0.80793, avg_loss=0.82411]\n","Step 4612    [1.475 sec/step, loss=0.83871, avg_loss=0.82391]\n","Step 4613    [1.498 sec/step, loss=0.75704, avg_loss=0.82306]\n","Step 4614    [1.491 sec/step, loss=0.81973, avg_loss=0.82256]\n","Step 4615    [1.486 sec/step, loss=0.82528, avg_loss=0.82274]\n","Step 4616    [1.485 sec/step, loss=0.81580, avg_loss=0.82251]\n","Step 4617    [1.488 sec/step, loss=0.81207, avg_loss=0.82233]\n","Generated 32 batches of size 32 in 19.239 sec\n","Step 4618    [1.548 sec/step, loss=0.81893, avg_loss=0.82210]\n","Step 4619    [1.546 sec/step, loss=0.81975, avg_loss=0.82187]\n","Step 4620    [1.539 sec/step, loss=0.82517, avg_loss=0.82195]\n","Step 4621    [1.540 sec/step, loss=0.81239, avg_loss=0.82168]\n","Step 4622    [1.535 sec/step, loss=0.82029, avg_loss=0.82150]\n","Step 4623    [1.471 sec/step, loss=0.85199, avg_loss=0.82168]\n","Step 4624    [1.447 sec/step, loss=0.83000, avg_loss=0.82337]\n","Step 4625    [1.448 sec/step, loss=0.85218, avg_loss=0.82353]\n","Step 4626    [1.445 sec/step, loss=0.83680, avg_loss=0.82357]\n","Step 4627    [1.440 sec/step, loss=0.85054, avg_loss=0.82380]\n","Step 4628    [1.440 sec/step, loss=0.82870, avg_loss=0.82371]\n","Step 4629    [1.443 sec/step, loss=0.81531, avg_loss=0.82373]\n","Step 4630    [1.442 sec/step, loss=0.82930, avg_loss=0.82391]\n","Step 4631    [1.440 sec/step, loss=0.82799, avg_loss=0.82404]\n","Step 4632    [1.440 sec/step, loss=0.82818, avg_loss=0.82410]\n","Step 4633    [1.439 sec/step, loss=0.83015, avg_loss=0.82393]\n","Step 4634    [1.427 sec/step, loss=0.87306, avg_loss=0.82506]\n","Step 4635    [1.458 sec/step, loss=0.53701, avg_loss=0.82207]\n","Step 4636    [1.458 sec/step, loss=0.84856, avg_loss=0.82248]\n","Step 4637    [1.462 sec/step, loss=0.82361, avg_loss=0.82238]\n","Step 4638    [1.454 sec/step, loss=0.83075, avg_loss=0.82233]\n","Step 4639    [1.452 sec/step, loss=0.83642, avg_loss=0.82209]\n","Step 4640    [1.458 sec/step, loss=0.81543, avg_loss=0.82197]\n","Step 4641    [1.473 sec/step, loss=0.77335, avg_loss=0.82123]\n","Step 4642    [1.476 sec/step, loss=0.85680, avg_loss=0.82147]\n","Step 4643    [1.479 sec/step, loss=0.80731, avg_loss=0.82114]\n","Step 4644    [1.482 sec/step, loss=0.83222, avg_loss=0.82126]\n","Step 4645    [1.482 sec/step, loss=0.84470, avg_loss=0.82125]\n","Step 4646    [1.478 sec/step, loss=0.82461, avg_loss=0.82140]\n","Step 4647    [1.479 sec/step, loss=0.81726, avg_loss=0.82124]\n","Step 4648    [1.482 sec/step, loss=0.83039, avg_loss=0.82109]\n","Step 4649    [1.488 sec/step, loss=0.85007, avg_loss=0.82117]\n","Generated 32 batches of size 32 in 19.636 sec\n","Step 4650    [1.544 sec/step, loss=0.81669, avg_loss=0.82120]\n","Step 4651    [1.538 sec/step, loss=0.83674, avg_loss=0.82112]\n","Step 4652    [1.537 sec/step, loss=0.81606, avg_loss=0.82106]\n","Step 4653    [1.530 sec/step, loss=0.80900, avg_loss=0.82101]\n","Step 4654    [1.528 sec/step, loss=0.81271, avg_loss=0.82083]\n","Step 4655    [1.449 sec/step, loss=0.84096, avg_loss=0.82118]\n","Step 4656    [1.451 sec/step, loss=0.83357, avg_loss=0.82115]\n","Step 4657    [1.451 sec/step, loss=0.82242, avg_loss=0.82102]\n","Step 4658    [1.451 sec/step, loss=0.81527, avg_loss=0.82097]\n","Step 4659    [1.450 sec/step, loss=0.82990, avg_loss=0.82084]\n","Step 4660    [1.454 sec/step, loss=0.84354, avg_loss=0.82097]\n","Step 4661    [1.442 sec/step, loss=0.82885, avg_loss=0.82149]\n","Step 4662    [1.447 sec/step, loss=0.79846, avg_loss=0.82099]\n","Step 4663    [1.443 sec/step, loss=0.81346, avg_loss=0.82098]\n","Step 4664    [1.439 sec/step, loss=0.83860, avg_loss=0.82088]\n","Step 4665    [1.437 sec/step, loss=0.82355, avg_loss=0.82050]\n","Step 4666    [1.435 sec/step, loss=0.83675, avg_loss=0.82082]\n","Step 4667    [1.456 sec/step, loss=0.69397, avg_loss=0.81961]\n","Step 4668    [1.457 sec/step, loss=0.83387, avg_loss=0.81972]\n","Step 4669    [1.456 sec/step, loss=0.81052, avg_loss=0.81946]\n","Step 4670    [1.461 sec/step, loss=0.84376, avg_loss=0.81948]\n","Step 4671    [1.468 sec/step, loss=0.81706, avg_loss=0.81935]\n","Step 4672    [1.464 sec/step, loss=0.81723, avg_loss=0.81947]\n","Step 4673    [1.469 sec/step, loss=0.82806, avg_loss=0.81924]\n","Step 4674    [1.453 sec/step, loss=0.82218, avg_loss=0.82136]\n","Step 4675    [1.448 sec/step, loss=0.80014, avg_loss=0.82145]\n","Step 4676    [1.448 sec/step, loss=0.83359, avg_loss=0.82154]\n","Step 4677    [1.464 sec/step, loss=0.80630, avg_loss=0.82131]\n","Step 4678    [1.460 sec/step, loss=0.81356, avg_loss=0.82107]\n","Step 4679    [1.456 sec/step, loss=0.82794, avg_loss=0.82089]\n","Step 4680    [1.475 sec/step, loss=0.73561, avg_loss=0.81970]\n","Step 4681    [1.476 sec/step, loss=0.82688, avg_loss=0.81953]\n","Generated 32 batches of size 32 in 18.055 sec\n","Step 4682    [1.513 sec/step, loss=0.82777, avg_loss=0.81964]\n","Step 4683    [1.539 sec/step, loss=0.57402, avg_loss=0.81672]\n","Step 4684    [1.540 sec/step, loss=0.81160, avg_loss=0.81651]\n","Step 4685    [1.530 sec/step, loss=0.84190, avg_loss=0.81644]\n","Step 4686    [1.524 sec/step, loss=0.83821, avg_loss=0.81661]\n","Step 4687    [1.442 sec/step, loss=0.84421, avg_loss=0.81679]\n","Step 4688    [1.440 sec/step, loss=0.80002, avg_loss=0.81686]\n","Step 4689    [1.412 sec/step, loss=0.79716, avg_loss=0.81882]\n","Step 4690    [1.412 sec/step, loss=0.79687, avg_loss=0.81847]\n","Step 4691    [1.418 sec/step, loss=0.81348, avg_loss=0.81813]\n","Step 4692    [1.415 sec/step, loss=0.82962, avg_loss=0.81874]\n","Step 4693    [1.414 sec/step, loss=0.81491, avg_loss=0.81858]\n","Step 4694    [1.409 sec/step, loss=0.83767, avg_loss=0.81834]\n","Step 4695    [1.412 sec/step, loss=0.81518, avg_loss=0.81793]\n","Step 4696    [1.407 sec/step, loss=0.78354, avg_loss=0.81766]\n","Step 4697    [1.402 sec/step, loss=0.80132, avg_loss=0.81741]\n","Step 4698    [1.402 sec/step, loss=0.80686, avg_loss=0.81742]\n","Step 4699    [1.405 sec/step, loss=0.79012, avg_loss=0.81722]\n","Step 4700    [1.412 sec/step, loss=0.78906, avg_loss=0.81679]\n","Writing summary at step: 4700\n","Step 4701    [1.411 sec/step, loss=0.82804, avg_loss=0.81662]\n","Step 4702    [1.419 sec/step, loss=0.76935, avg_loss=0.81601]\n","Step 4703    [1.416 sec/step, loss=0.80173, avg_loss=0.81576]\n","Step 4704    [1.416 sec/step, loss=0.83024, avg_loss=0.81598]\n","Step 4705    [1.433 sec/step, loss=0.81192, avg_loss=0.81549]\n","Step 4706    [1.445 sec/step, loss=0.81199, avg_loss=0.81498]\n","Step 4707    [1.447 sec/step, loss=0.81345, avg_loss=0.81458]\n","Step 4708    [1.450 sec/step, loss=0.82423, avg_loss=0.81445]\n","Step 4709    [1.446 sec/step, loss=0.82415, avg_loss=0.81451]\n","Step 4710    [1.452 sec/step, loss=0.79217, avg_loss=0.81404]\n","Step 4711    [1.444 sec/step, loss=0.79930, avg_loss=0.81395]\n","Step 4712    [1.446 sec/step, loss=0.82717, avg_loss=0.81384]\n","Generated 32 batches of size 32 in 18.748 sec\n","Step 4713    [1.489 sec/step, loss=0.78201, avg_loss=0.81409]\n","Step 4714    [1.485 sec/step, loss=0.81059, avg_loss=0.81399]\n","Step 4715    [1.481 sec/step, loss=0.83010, avg_loss=0.81404]\n","Step 4716    [1.479 sec/step, loss=0.82360, avg_loss=0.81412]\n","Step 4717    [1.474 sec/step, loss=0.83482, avg_loss=0.81435]\n","Step 4718    [1.415 sec/step, loss=0.81685, avg_loss=0.81433]\n","Step 4719    [1.414 sec/step, loss=0.82740, avg_loss=0.81440]\n","Step 4720    [1.416 sec/step, loss=0.79209, avg_loss=0.81407]\n","Step 4721    [1.412 sec/step, loss=0.81338, avg_loss=0.81408]\n","Step 4722    [1.416 sec/step, loss=0.77777, avg_loss=0.81366]\n","Step 4723    [1.417 sec/step, loss=0.81586, avg_loss=0.81330]\n","Step 4724    [1.417 sec/step, loss=0.80360, avg_loss=0.81303]\n","Step 4725    [1.413 sec/step, loss=0.83458, avg_loss=0.81286]\n","Step 4726    [1.412 sec/step, loss=0.83305, avg_loss=0.81282]\n","Step 4727    [1.419 sec/step, loss=0.80041, avg_loss=0.81232]\n","Step 4728    [1.424 sec/step, loss=0.83204, avg_loss=0.81235]\n","Step 4729    [1.416 sec/step, loss=0.82404, avg_loss=0.81244]\n","Step 4730    [1.411 sec/step, loss=0.81240, avg_loss=0.81227]\n","Step 4731    [1.406 sec/step, loss=0.83612, avg_loss=0.81235]\n","Step 4732    [1.406 sec/step, loss=0.82175, avg_loss=0.81229]\n","Step 4733    [1.411 sec/step, loss=0.81153, avg_loss=0.81210]\n","Step 4734    [1.412 sec/step, loss=0.82222, avg_loss=0.81159]\n","Step 4735    [1.408 sec/step, loss=0.58314, avg_loss=0.81205]\n","Step 4736    [1.423 sec/step, loss=0.82791, avg_loss=0.81185]\n","Step 4737    [1.427 sec/step, loss=0.81580, avg_loss=0.81177]\n","Step 4738    [1.430 sec/step, loss=0.83900, avg_loss=0.81185]\n","Step 4739    [1.441 sec/step, loss=0.82654, avg_loss=0.81175]\n","Step 4740    [1.439 sec/step, loss=0.83346, avg_loss=0.81193]\n","Step 4741    [1.422 sec/step, loss=0.81359, avg_loss=0.81233]\n","Step 4742    [1.430 sec/step, loss=0.79787, avg_loss=0.81175]\n","Step 4743    [1.434 sec/step, loss=0.83931, avg_loss=0.81207]\n","Step 4744    [1.431 sec/step, loss=0.82156, avg_loss=0.81196]\n","Generated 32 batches of size 32 in 19.732 sec\n","Step 4745    [1.487 sec/step, loss=0.82777, avg_loss=0.81179]\n","Step 4746    [1.486 sec/step, loss=0.80787, avg_loss=0.81162]\n","Step 4747    [1.479 sec/step, loss=0.82248, avg_loss=0.81167]\n","Step 4748    [1.471 sec/step, loss=0.82017, avg_loss=0.81157]\n","Step 4749    [1.463 sec/step, loss=0.80382, avg_loss=0.81111]\n","Step 4750    [1.398 sec/step, loss=0.81008, avg_loss=0.81104]\n","Step 4751    [1.401 sec/step, loss=0.81089, avg_loss=0.81079]\n","Step 4752    [1.401 sec/step, loss=0.81660, avg_loss=0.81079]\n","Step 4753    [1.398 sec/step, loss=0.85359, avg_loss=0.81124]\n","Step 4754    [1.402 sec/step, loss=0.82288, avg_loss=0.81134]\n","Step 4755    [1.401 sec/step, loss=0.83450, avg_loss=0.81127]\n","Step 4756    [1.395 sec/step, loss=0.82347, avg_loss=0.81117]\n","Step 4757    [1.395 sec/step, loss=0.82028, avg_loss=0.81115]\n","Step 4758    [1.392 sec/step, loss=0.82011, avg_loss=0.81120]\n","Step 4759    [1.395 sec/step, loss=0.84305, avg_loss=0.81133]\n","Step 4760    [1.391 sec/step, loss=0.80811, avg_loss=0.81098]\n","Step 4761    [1.398 sec/step, loss=0.82214, avg_loss=0.81091]\n","Step 4762    [1.395 sec/step, loss=0.80565, avg_loss=0.81098]\n","Step 4763    [1.402 sec/step, loss=0.78640, avg_loss=0.81071]\n","Step 4764    [1.402 sec/step, loss=0.81741, avg_loss=0.81050]\n","Step 4765    [1.409 sec/step, loss=0.82208, avg_loss=0.81048]\n","Step 4766    [1.408 sec/step, loss=0.81463, avg_loss=0.81026]\n","Step 4767    [1.387 sec/step, loss=0.82485, avg_loss=0.81157]\n","Step 4768    [1.397 sec/step, loss=0.83090, avg_loss=0.81154]\n","Step 4769    [1.402 sec/step, loss=0.83159, avg_loss=0.81175]\n","Step 4770    [1.410 sec/step, loss=0.81838, avg_loss=0.81150]\n","Step 4771    [1.406 sec/step, loss=0.82441, avg_loss=0.81157]\n","Step 4772    [1.408 sec/step, loss=0.82333, avg_loss=0.81163]\n","Step 4773    [1.410 sec/step, loss=0.84608, avg_loss=0.81181]\n","Step 4774    [1.411 sec/step, loss=0.81287, avg_loss=0.81172]\n","Step 4775    [1.448 sec/step, loss=0.67243, avg_loss=0.81044]\n","Step 4776    [1.463 sec/step, loss=0.75345, avg_loss=0.80964]\n","Generated 32 batches of size 32 in 19.863 sec\n","Step 4777    [1.465 sec/step, loss=0.81911, avg_loss=0.80977]\n","Step 4778    [1.485 sec/step, loss=0.67718, avg_loss=0.80841]\n","Step 4779    [1.485 sec/step, loss=0.83797, avg_loss=0.80851]\n","Step 4780    [1.468 sec/step, loss=0.80463, avg_loss=0.80920]\n","Step 4781    [1.463 sec/step, loss=0.81218, avg_loss=0.80905]\n","Step 4782    [1.422 sec/step, loss=0.80881, avg_loss=0.80886]\n","Step 4783    [1.396 sec/step, loss=0.81035, avg_loss=0.81122]\n","Step 4784    [1.393 sec/step, loss=0.81755, avg_loss=0.81128]\n","Step 4785    [1.395 sec/step, loss=0.82485, avg_loss=0.81111]\n","Step 4786    [1.399 sec/step, loss=0.80688, avg_loss=0.81080]\n","Step 4787    [1.399 sec/step, loss=0.80635, avg_loss=0.81042]\n","Step 4788    [1.398 sec/step, loss=0.87366, avg_loss=0.81116]\n","Step 4789    [1.408 sec/step, loss=0.81164, avg_loss=0.81130]\n","Step 4790    [1.407 sec/step, loss=0.82487, avg_loss=0.81158]\n","Step 4791    [1.405 sec/step, loss=0.81239, avg_loss=0.81157]\n","Step 4792    [1.402 sec/step, loss=0.81361, avg_loss=0.81141]\n","Step 4793    [1.414 sec/step, loss=0.74169, avg_loss=0.81068]\n","Step 4794    [1.412 sec/step, loss=0.81193, avg_loss=0.81042]\n","Step 4795    [1.409 sec/step, loss=0.84170, avg_loss=0.81069]\n","Step 4796    [1.408 sec/step, loss=0.80870, avg_loss=0.81094]\n","Step 4797    [1.407 sec/step, loss=0.81415, avg_loss=0.81107]\n","Step 4798    [1.411 sec/step, loss=0.79965, avg_loss=0.81099]\n","Step 4799    [1.410 sec/step, loss=0.81771, avg_loss=0.81127]\n","Step 4800    [1.409 sec/step, loss=0.83645, avg_loss=0.81174]\n","Writing summary at step: 4800\n","Step 4801    [1.420 sec/step, loss=0.83619, avg_loss=0.81183]\n","Step 4802    [1.413 sec/step, loss=0.83589, avg_loss=0.81249]\n","Step 4803    [1.421 sec/step, loss=0.82126, avg_loss=0.81269]\n","Step 4804    [1.422 sec/step, loss=0.83039, avg_loss=0.81269]\n","Step 4805    [1.407 sec/step, loss=0.82338, avg_loss=0.81280]\n","Step 4806    [1.405 sec/step, loss=0.80134, avg_loss=0.81270]\n","Step 4807    [1.409 sec/step, loss=0.80226, avg_loss=0.81258]\n","Generated 32 batches of size 32 in 19.648 sec\n","Step 4808    [1.476 sec/step, loss=0.79773, avg_loss=0.81232]\n","Step 4809    [1.474 sec/step, loss=0.84630, avg_loss=0.81254]\n","Step 4810    [1.466 sec/step, loss=0.82413, avg_loss=0.81286]\n","Step 4811    [1.460 sec/step, loss=0.81243, avg_loss=0.81299]\n","Step 4812    [1.488 sec/step, loss=0.53514, avg_loss=0.81007]\n","Step 4813    [1.431 sec/step, loss=0.79442, avg_loss=0.81020]\n","Step 4814    [1.431 sec/step, loss=0.81872, avg_loss=0.81028]\n","Step 4815    [1.432 sec/step, loss=0.81758, avg_loss=0.81015]\n","Step 4816    [1.436 sec/step, loss=0.82480, avg_loss=0.81016]\n","Step 4817    [1.440 sec/step, loss=0.83417, avg_loss=0.81016]\n","Step 4818    [1.437 sec/step, loss=0.81810, avg_loss=0.81017]\n","Step 4819    [1.436 sec/step, loss=0.84066, avg_loss=0.81030]\n","Step 4820    [1.434 sec/step, loss=0.83387, avg_loss=0.81072]\n","Step 4821    [1.434 sec/step, loss=0.80581, avg_loss=0.81064]\n","Step 4822    [1.437 sec/step, loss=0.82530, avg_loss=0.81112]\n","Step 4823    [1.437 sec/step, loss=0.80397, avg_loss=0.81100]\n","Step 4824    [1.438 sec/step, loss=0.82550, avg_loss=0.81122]\n","Step 4825    [1.440 sec/step, loss=0.80554, avg_loss=0.81093]\n","Step 4826    [1.442 sec/step, loss=0.81987, avg_loss=0.81080]\n","Step 4827    [1.438 sec/step, loss=0.83385, avg_loss=0.81113]\n","Step 4828    [1.444 sec/step, loss=0.75598, avg_loss=0.81037]\n","Step 4829    [1.447 sec/step, loss=0.79489, avg_loss=0.81008]\n","Step 4830    [1.449 sec/step, loss=0.83324, avg_loss=0.81029]\n","Step 4831    [1.453 sec/step, loss=0.83206, avg_loss=0.81025]\n","Step 4832    [1.455 sec/step, loss=0.80655, avg_loss=0.81010]\n","Step 4833    [1.451 sec/step, loss=0.82582, avg_loss=0.81024]\n","Step 4834    [1.453 sec/step, loss=0.81843, avg_loss=0.81020]\n","Step 4835    [1.438 sec/step, loss=0.83080, avg_loss=0.81268]\n","Step 4836    [1.426 sec/step, loss=0.81734, avg_loss=0.81257]\n","Step 4837    [1.419 sec/step, loss=0.81927, avg_loss=0.81261]\n","Step 4838    [1.429 sec/step, loss=0.81314, avg_loss=0.81235]\n","Step 4839    [1.420 sec/step, loss=0.83719, avg_loss=0.81245]\n","Generated 32 batches of size 32 in 19.326 sec\n","Step 4840    [1.505 sec/step, loss=0.79699, avg_loss=0.81209]\n","Step 4841    [1.501 sec/step, loss=0.82713, avg_loss=0.81222]\n","Step 4842    [1.493 sec/step, loss=0.80262, avg_loss=0.81227]\n","Step 4843    [1.490 sec/step, loss=0.81364, avg_loss=0.81202]\n","Step 4844    [1.492 sec/step, loss=0.81815, avg_loss=0.81198]\n","Step 4845    [1.434 sec/step, loss=0.80894, avg_loss=0.81179]\n","Step 4846    [1.432 sec/step, loss=0.82860, avg_loss=0.81200]\n","Step 4847    [1.434 sec/step, loss=0.81147, avg_loss=0.81189]\n","Step 4848    [1.433 sec/step, loss=0.83393, avg_loss=0.81203]\n","Step 4849    [1.437 sec/step, loss=0.80769, avg_loss=0.81207]\n","Step 4850    [1.437 sec/step, loss=0.79614, avg_loss=0.81193]\n","Step 4851    [1.434 sec/step, loss=0.83469, avg_loss=0.81216]\n","Step 4852    [1.437 sec/step, loss=0.80199, avg_loss=0.81202]\n","Step 4853    [1.438 sec/step, loss=0.80389, avg_loss=0.81152]\n","Step 4854    [1.459 sec/step, loss=0.59158, avg_loss=0.80921]\n","Step 4855    [1.459 sec/step, loss=0.82600, avg_loss=0.80912]\n","Step 4856    [1.458 sec/step, loss=0.81773, avg_loss=0.80907]\n","Step 4857    [1.455 sec/step, loss=0.82140, avg_loss=0.80908]\n","Step 4858    [1.462 sec/step, loss=0.76994, avg_loss=0.80858]\n","Step 4859    [1.462 sec/step, loss=0.83092, avg_loss=0.80845]\n","Step 4860    [1.461 sec/step, loss=0.85676, avg_loss=0.80894]\n","Step 4861    [1.455 sec/step, loss=0.82498, avg_loss=0.80897]\n","Step 4862    [1.455 sec/step, loss=0.82854, avg_loss=0.80920]\n","Step 4863    [1.470 sec/step, loss=0.80740, avg_loss=0.80941]\n","Step 4864    [1.473 sec/step, loss=0.82493, avg_loss=0.80948]\n","Step 4865    [1.472 sec/step, loss=0.81802, avg_loss=0.80944]\n","Step 4866    [1.474 sec/step, loss=0.83833, avg_loss=0.80968]\n","Step 4867    [1.480 sec/step, loss=0.81444, avg_loss=0.80958]\n","Step 4868    [1.476 sec/step, loss=0.82459, avg_loss=0.80951]\n","Step 4869    [1.477 sec/step, loss=0.82693, avg_loss=0.80947]\n","Step 4870    [1.474 sec/step, loss=0.81892, avg_loss=0.80947]\n","Step 4871    [1.475 sec/step, loss=0.83356, avg_loss=0.80956]\n","Generated 32 batches of size 32 in 18.345 sec\n","Step 4872    [1.515 sec/step, loss=0.79332, avg_loss=0.80926]\n","Step 4873    [1.506 sec/step, loss=0.79526, avg_loss=0.80876]\n","Step 4874    [1.503 sec/step, loss=0.78094, avg_loss=0.80844]\n","Step 4875    [1.466 sec/step, loss=0.81230, avg_loss=0.80983]\n","Step 4876    [1.444 sec/step, loss=0.80763, avg_loss=0.81038]\n","Step 4877    [1.426 sec/step, loss=0.82863, avg_loss=0.81047]\n","Step 4878    [1.403 sec/step, loss=0.81271, avg_loss=0.81183]\n","Step 4879    [1.406 sec/step, loss=0.81307, avg_loss=0.81158]\n","Step 4880    [1.401 sec/step, loss=0.80717, avg_loss=0.81160]\n","Step 4881    [1.405 sec/step, loss=0.80723, avg_loss=0.81155]\n","Step 4882    [1.404 sec/step, loss=0.80867, avg_loss=0.81155]\n","Step 4883    [1.412 sec/step, loss=0.75355, avg_loss=0.81098]\n","Step 4884    [1.415 sec/step, loss=0.80056, avg_loss=0.81081]\n","Step 4885    [1.413 sec/step, loss=0.81097, avg_loss=0.81068]\n","Step 4886    [1.411 sec/step, loss=0.78290, avg_loss=0.81044]\n","Step 4887    [1.409 sec/step, loss=0.79658, avg_loss=0.81034]\n","Step 4888    [1.410 sec/step, loss=0.83487, avg_loss=0.80995]\n","Step 4889    [1.404 sec/step, loss=0.79807, avg_loss=0.80981]\n","Step 4890    [1.404 sec/step, loss=0.81082, avg_loss=0.80967]\n","Step 4891    [1.401 sec/step, loss=0.82006, avg_loss=0.80975]\n","Step 4892    [1.406 sec/step, loss=0.83190, avg_loss=0.80993]\n","Step 4893    [1.393 sec/step, loss=0.80508, avg_loss=0.81057]\n","Step 4894    [1.394 sec/step, loss=0.83053, avg_loss=0.81075]\n","Step 4895    [1.403 sec/step, loss=0.80163, avg_loss=0.81035]\n","Step 4896    [1.410 sec/step, loss=0.80590, avg_loss=0.81032]\n","Step 4897    [1.415 sec/step, loss=0.81437, avg_loss=0.81033]\n","Step 4898    [1.429 sec/step, loss=0.84498, avg_loss=0.81078]\n","Step 4899    [1.443 sec/step, loss=0.80208, avg_loss=0.81062]\n","Step 4900    [1.442 sec/step, loss=0.82353, avg_loss=0.81049]\n","Writing summary at step: 4900\n","Step 4901    [1.440 sec/step, loss=0.80832, avg_loss=0.81022]\n","Step 4902    [1.474 sec/step, loss=0.64516, avg_loss=0.80831]\n","Generated 32 batches of size 32 in 20.009 sec\n","Step 4903    [1.480 sec/step, loss=0.81928, avg_loss=0.80829]\n","Step 4904    [1.478 sec/step, loss=0.83073, avg_loss=0.80829]\n","Step 4905    [1.475 sec/step, loss=0.79035, avg_loss=0.80796]\n","Step 4906    [1.465 sec/step, loss=0.81171, avg_loss=0.80807]\n","Step 4907    [1.458 sec/step, loss=0.82296, avg_loss=0.80827]\n","Step 4908    [1.386 sec/step, loss=0.79988, avg_loss=0.80829]\n","Step 4909    [1.397 sec/step, loss=0.76507, avg_loss=0.80748]\n","Step 4910    [1.395 sec/step, loss=0.85590, avg_loss=0.80780]\n","Step 4911    [1.398 sec/step, loss=0.81252, avg_loss=0.80780]\n","Step 4912    [1.367 sec/step, loss=0.82227, avg_loss=0.81067]\n","Step 4913    [1.364 sec/step, loss=0.81337, avg_loss=0.81086]\n","Step 4914    [1.363 sec/step, loss=0.81627, avg_loss=0.81084]\n","Step 4915    [1.361 sec/step, loss=0.81947, avg_loss=0.81086]\n","Step 4916    [1.361 sec/step, loss=0.80647, avg_loss=0.81067]\n","Step 4917    [1.380 sec/step, loss=0.60393, avg_loss=0.80837]\n","Step 4918    [1.381 sec/step, loss=0.83639, avg_loss=0.80855]\n","Step 4919    [1.381 sec/step, loss=0.80829, avg_loss=0.80823]\n","Step 4920    [1.383 sec/step, loss=0.80162, avg_loss=0.80791]\n","Step 4921    [1.381 sec/step, loss=0.81948, avg_loss=0.80804]\n","Step 4922    [1.380 sec/step, loss=0.82741, avg_loss=0.80806]\n","Step 4923    [1.382 sec/step, loss=0.81420, avg_loss=0.80817]\n","Step 4924    [1.381 sec/step, loss=0.82115, avg_loss=0.80812]\n","Step 4925    [1.384 sec/step, loss=0.83295, avg_loss=0.80840]\n","Step 4926    [1.384 sec/step, loss=0.80544, avg_loss=0.80825]\n","Step 4927    [1.386 sec/step, loss=0.83366, avg_loss=0.80825]\n","Step 4928    [1.376 sec/step, loss=0.83199, avg_loss=0.80901]\n","Step 4929    [1.385 sec/step, loss=0.81342, avg_loss=0.80920]\n","Step 4930    [1.396 sec/step, loss=0.78961, avg_loss=0.80876]\n","Step 4931    [1.407 sec/step, loss=0.81126, avg_loss=0.80855]\n","Step 4932    [1.417 sec/step, loss=0.79396, avg_loss=0.80843]\n","Step 4933    [1.417 sec/step, loss=0.81497, avg_loss=0.80832]\n","Step 4934    [1.422 sec/step, loss=0.83669, avg_loss=0.80850]\n","Generated 32 batches of size 32 in 19.755 sec\n","Step 4935    [1.469 sec/step, loss=0.82898, avg_loss=0.80848]\n","Step 4936    [1.469 sec/step, loss=0.82695, avg_loss=0.80858]\n","Step 4937    [1.470 sec/step, loss=0.79515, avg_loss=0.80834]\n","Step 4938    [1.463 sec/step, loss=0.82188, avg_loss=0.80842]\n","Step 4939    [1.465 sec/step, loss=0.81117, avg_loss=0.80816]\n","Step 4940    [1.378 sec/step, loss=0.81274, avg_loss=0.80832]\n","Step 4941    [1.378 sec/step, loss=0.80424, avg_loss=0.80809]\n","Step 4942    [1.373 sec/step, loss=0.81280, avg_loss=0.80820]\n","Step 4943    [1.368 sec/step, loss=0.83315, avg_loss=0.80839]\n","Step 4944    [1.374 sec/step, loss=0.77530, avg_loss=0.80796]\n","Step 4945    [1.381 sec/step, loss=0.79957, avg_loss=0.80787]\n","Step 4946    [1.384 sec/step, loss=0.81744, avg_loss=0.80776]\n","Step 4947    [1.382 sec/step, loss=0.82778, avg_loss=0.80792]\n","Step 4948    [1.380 sec/step, loss=0.79607, avg_loss=0.80754]\n","Step 4949    [1.378 sec/step, loss=0.82945, avg_loss=0.80776]\n","Step 4950    [1.381 sec/step, loss=0.81176, avg_loss=0.80791]\n","Step 4951    [1.379 sec/step, loss=0.82814, avg_loss=0.80785]\n","Step 4952    [1.376 sec/step, loss=0.85298, avg_loss=0.80836]\n","Step 4953    [1.377 sec/step, loss=0.80808, avg_loss=0.80840]\n","Step 4954    [1.360 sec/step, loss=0.79706, avg_loss=0.81046]\n","Step 4955    [1.362 sec/step, loss=0.80733, avg_loss=0.81027]\n","Step 4956    [1.364 sec/step, loss=0.83971, avg_loss=0.81049]\n","Step 4957    [1.367 sec/step, loss=0.82626, avg_loss=0.81054]\n","Step 4958    [1.364 sec/step, loss=0.82316, avg_loss=0.81107]\n","Step 4959    [1.365 sec/step, loss=0.81571, avg_loss=0.81092]\n","Step 4960    [1.368 sec/step, loss=0.82323, avg_loss=0.81058]\n","Step 4961    [1.377 sec/step, loss=0.80894, avg_loss=0.81042]\n","Step 4962    [1.384 sec/step, loss=0.78755, avg_loss=0.81001]\n","Step 4963    [1.367 sec/step, loss=0.83315, avg_loss=0.81027]\n","Step 4964    [1.374 sec/step, loss=0.76545, avg_loss=0.80967]\n","Step 4965    [1.416 sec/step, loss=0.59584, avg_loss=0.80745]\n","Step 4966    [1.424 sec/step, loss=0.81127, avg_loss=0.80718]\n","Generated 32 batches of size 32 in 19.724 sec\n","Step 4967    [1.440 sec/step, loss=0.81251, avg_loss=0.80716]\n","Step 4968    [1.436 sec/step, loss=0.81393, avg_loss=0.80706]\n","Step 4969    [1.429 sec/step, loss=0.83612, avg_loss=0.80715]\n","Step 4970    [1.428 sec/step, loss=0.82071, avg_loss=0.80717]\n","Step 4971    [1.425 sec/step, loss=0.83493, avg_loss=0.80718]\n","Step 4972    [1.379 sec/step, loss=0.82708, avg_loss=0.80752]\n","Step 4973    [1.383 sec/step, loss=0.79778, avg_loss=0.80754]\n","Step 4974    [1.377 sec/step, loss=0.82179, avg_loss=0.80795]\n","Step 4975    [1.383 sec/step, loss=0.78636, avg_loss=0.80769]\n","Step 4976    [1.385 sec/step, loss=0.80634, avg_loss=0.80768]\n","Step 4977    [1.388 sec/step, loss=0.83088, avg_loss=0.80770]\n","Step 4978    [1.393 sec/step, loss=0.78698, avg_loss=0.80744]\n","Step 4979    [1.391 sec/step, loss=0.81436, avg_loss=0.80746]\n","Step 4980    [1.397 sec/step, loss=0.80311, avg_loss=0.80742]\n","Step 4981    [1.393 sec/step, loss=0.81589, avg_loss=0.80750]\n","Step 4982    [1.394 sec/step, loss=0.80025, avg_loss=0.80742]\n","Step 4983    [1.383 sec/step, loss=0.81036, avg_loss=0.80799]\n","Step 4984    [1.380 sec/step, loss=0.83593, avg_loss=0.80834]\n","Step 4985    [1.382 sec/step, loss=0.82046, avg_loss=0.80844]\n","Step 4986    [1.376 sec/step, loss=0.84134, avg_loss=0.80902]\n","Step 4987    [1.409 sec/step, loss=0.55162, avg_loss=0.80657]\n","Step 4988    [1.406 sec/step, loss=0.82094, avg_loss=0.80643]\n","Step 4989    [1.406 sec/step, loss=0.80541, avg_loss=0.80650]\n","Step 4990    [1.413 sec/step, loss=0.82867, avg_loss=0.80668]\n","Step 4991    [1.434 sec/step, loss=0.75800, avg_loss=0.80606]\n","Step 4992    [1.435 sec/step, loss=0.83322, avg_loss=0.80608]\n","Step 4993    [1.447 sec/step, loss=0.80998, avg_loss=0.80612]\n","Step 4994    [1.454 sec/step, loss=0.82398, avg_loss=0.80606]\n","Step 4995    [1.450 sec/step, loss=0.82966, avg_loss=0.80634]\n","Step 4996    [1.449 sec/step, loss=0.79189, avg_loss=0.80620]\n","Step 4997    [1.456 sec/step, loss=0.81981, avg_loss=0.80625]\n","Step 4998    [1.441 sec/step, loss=0.81680, avg_loss=0.80597]\n","Generated 32 batches of size 32 in 19.626 sec\n","Step 4999    [1.470 sec/step, loss=0.80683, avg_loss=0.80602]\n","Step 5000    [1.466 sec/step, loss=0.79445, avg_loss=0.80573]\n","Writing summary at step: 5000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (80100,)\n","Check wav file:  (110100,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000005000-align000.png\n","100% 1/1 [00:03<00:00,  3.26s/it]\n","Test finished for step 5000.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (76500,)\n","Check wav file:  (106500,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000005000-align000.png\n"," 25% 1/4 [00:02<00:08,  2.71s/it]Check wav file before change:  (76500,)\n","Check wav file:  (106500,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000005000-align001.png\n"," 50% 2/4 [00:05<00:05,  2.79s/it]Check wav file before change:  (76500,)\n","Check wav file:  (106500,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000005000-align002.png\n"," 75% 3/4 [00:08<00:02,  2.77s/it]Check wav file before change:  (76500,)\n","Check wav file:  (106500,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000005000-align003.png\n","100% 4/4 [00:11<00:00,  2.84s/it]\n","Test finished for step 5000.\n","Step 5001    [1.461 sec/step, loss=0.81519, avg_loss=0.80580]\n","Step 5002    [1.422 sec/step, loss=0.79944, avg_loss=0.80734]\n","Step 5003    [1.417 sec/step, loss=0.76753, avg_loss=0.80682]\n","Step 5004    [1.417 sec/step, loss=0.81003, avg_loss=0.80662]\n","Step 5005    [1.418 sec/step, loss=0.80820, avg_loss=0.80679]\n","Step 5006    [1.417 sec/step, loss=0.83125, avg_loss=0.80699]\n","Step 5007    [1.423 sec/step, loss=0.82141, avg_loss=0.80697]\n","Step 5008    [1.429 sec/step, loss=0.76621, avg_loss=0.80664]\n","Step 5009    [1.417 sec/step, loss=0.80603, avg_loss=0.80705]\n","Step 5010    [1.416 sec/step, loss=0.82361, avg_loss=0.80672]\n","Step 5011    [1.420 sec/step, loss=0.80370, avg_loss=0.80664]\n","Step 5012    [1.423 sec/step, loss=0.79131, avg_loss=0.80633]\n","Step 5013    [1.420 sec/step, loss=0.82160, avg_loss=0.80641]\n","Step 5014    [1.421 sec/step, loss=0.84287, avg_loss=0.80667]\n","Step 5015    [1.434 sec/step, loss=0.78100, avg_loss=0.80629]\n","Step 5016    [1.436 sec/step, loss=0.81711, avg_loss=0.80640]\n","Step 5017    [1.411 sec/step, loss=0.81929, avg_loss=0.80855]\n","Step 5018    [1.408 sec/step, loss=0.81228, avg_loss=0.80831]\n","Step 5019    [1.411 sec/step, loss=0.82677, avg_loss=0.80849]\n","Step 5020    [1.417 sec/step, loss=0.81247, avg_loss=0.80860]\n","Step 5021    [1.422 sec/step, loss=0.82030, avg_loss=0.80861]\n","Step 5022    [1.422 sec/step, loss=0.82125, avg_loss=0.80855]\n","Step 5023    [1.421 sec/step, loss=0.82261, avg_loss=0.80863]\n","Step 5024    [1.462 sec/step, loss=0.56796, avg_loss=0.80610]\n","Step 5025    [1.460 sec/step, loss=0.81916, avg_loss=0.80596]\n","Step 5026    [1.459 sec/step, loss=0.83408, avg_loss=0.80625]\n","Step 5027    [1.460 sec/step, loss=0.81513, avg_loss=0.80606]\n","Step 5028    [1.470 sec/step, loss=0.82053, avg_loss=0.80595]\n","Generated 32 batches of size 32 in 18.350 sec\n","Step 5029    [1.494 sec/step, loss=0.81711, avg_loss=0.80599]\n","Step 5030    [1.480 sec/step, loss=0.83328, avg_loss=0.80642]\n","Step 5031    [1.464 sec/step, loss=0.83436, avg_loss=0.80665]\n","Step 5032    [1.457 sec/step, loss=0.82311, avg_loss=0.80695]\n","Step 5033    [1.463 sec/step, loss=0.84983, avg_loss=0.80729]\n","Step 5034    [1.456 sec/step, loss=0.83285, avg_loss=0.80726]\n","Step 5035    [1.397 sec/step, loss=0.81414, avg_loss=0.80711]\n","Step 5036    [1.399 sec/step, loss=0.84979, avg_loss=0.80734]\n","Step 5037    [1.398 sec/step, loss=0.83268, avg_loss=0.80771]\n","Step 5038    [1.390 sec/step, loss=0.84225, avg_loss=0.80791]\n","Step 5039    [1.387 sec/step, loss=0.80238, avg_loss=0.80783]\n","Step 5040    [1.385 sec/step, loss=0.81716, avg_loss=0.80787]\n","Step 5041    [1.390 sec/step, loss=0.85428, avg_loss=0.80837]\n","Step 5042    [1.398 sec/step, loss=0.83976, avg_loss=0.80864]\n","Step 5043    [1.398 sec/step, loss=0.83633, avg_loss=0.80867]\n","Step 5044    [1.387 sec/step, loss=0.81312, avg_loss=0.80905]\n","Step 5045    [1.410 sec/step, loss=0.55175, avg_loss=0.80657]\n","Step 5046    [1.409 sec/step, loss=0.81238, avg_loss=0.80652]\n","Step 5047    [1.415 sec/step, loss=0.81120, avg_loss=0.80636]\n","Step 5048    [1.418 sec/step, loss=0.80476, avg_loss=0.80644]\n","Step 5049    [1.416 sec/step, loss=0.80781, avg_loss=0.80623]\n","Step 5050    [1.417 sec/step, loss=0.82103, avg_loss=0.80632]\n","Step 5051    [1.419 sec/step, loss=0.80785, avg_loss=0.80612]\n","Step 5052    [1.431 sec/step, loss=0.79905, avg_loss=0.80558]\n","Step 5053    [1.433 sec/step, loss=0.80643, avg_loss=0.80556]\n","Step 5054    [1.429 sec/step, loss=0.82814, avg_loss=0.80587]\n","Step 5055    [1.449 sec/step, loss=0.78156, avg_loss=0.80561]\n","Step 5056    [1.452 sec/step, loss=0.78473, avg_loss=0.80506]\n","Step 5057    [1.454 sec/step, loss=0.82732, avg_loss=0.80507]\n","Step 5058    [1.453 sec/step, loss=0.80006, avg_loss=0.80484]\n","Step 5059    [1.452 sec/step, loss=0.81768, avg_loss=0.80486]\n","Step 5060    [1.455 sec/step, loss=0.82062, avg_loss=0.80484]\n","Generated 32 batches of size 32 in 18.733 sec\n","Step 5061    [1.498 sec/step, loss=0.79970, avg_loss=0.80474]\n","Step 5062    [1.491 sec/step, loss=0.80020, avg_loss=0.80487]\n","Step 5063    [1.489 sec/step, loss=0.80035, avg_loss=0.80454]\n","Step 5064    [1.480 sec/step, loss=0.78243, avg_loss=0.80471]\n","Step 5065    [1.436 sec/step, loss=0.78985, avg_loss=0.80665]\n","Step 5066    [1.430 sec/step, loss=0.80467, avg_loss=0.80659]\n","Step 5067    [1.406 sec/step, loss=0.81787, avg_loss=0.80664]\n","Step 5068    [1.412 sec/step, loss=0.76965, avg_loss=0.80620]\n","Step 5069    [1.424 sec/step, loss=0.76934, avg_loss=0.80553]\n","Step 5070    [1.417 sec/step, loss=0.81549, avg_loss=0.80548]\n","Step 5071    [1.418 sec/step, loss=0.79733, avg_loss=0.80510]\n","Step 5072    [1.423 sec/step, loss=0.79192, avg_loss=0.80475]\n","Step 5073    [1.420 sec/step, loss=0.80066, avg_loss=0.80478]\n","Step 5074    [1.419 sec/step, loss=0.82494, avg_loss=0.80481]\n","Step 5075    [1.413 sec/step, loss=0.81736, avg_loss=0.80512]\n","Step 5076    [1.410 sec/step, loss=0.82991, avg_loss=0.80536]\n","Step 5077    [1.407 sec/step, loss=0.80193, avg_loss=0.80507]\n","Step 5078    [1.406 sec/step, loss=0.83896, avg_loss=0.80559]\n","Step 5079    [1.409 sec/step, loss=0.78654, avg_loss=0.80531]\n","Step 5080    [1.408 sec/step, loss=0.78270, avg_loss=0.80510]\n","Step 5081    [1.417 sec/step, loss=0.79228, avg_loss=0.80487]\n","Step 5082    [1.418 sec/step, loss=0.81793, avg_loss=0.80504]\n","Step 5083    [1.420 sec/step, loss=0.81565, avg_loss=0.80510]\n","Step 5084    [1.427 sec/step, loss=0.81617, avg_loss=0.80490]\n","Step 5085    [1.429 sec/step, loss=0.81032, avg_loss=0.80480]\n","Step 5086    [1.479 sec/step, loss=0.56971, avg_loss=0.80208]\n","Step 5087    [1.457 sec/step, loss=0.81030, avg_loss=0.80467]\n","Step 5088    [1.461 sec/step, loss=0.83215, avg_loss=0.80478]\n","Step 5089    [1.461 sec/step, loss=0.82524, avg_loss=0.80498]\n","Step 5090    [1.454 sec/step, loss=0.81816, avg_loss=0.80487]\n","Step 5091    [1.437 sec/step, loss=0.81889, avg_loss=0.80548]\n","Step 5092    [1.444 sec/step, loss=0.81095, avg_loss=0.80526]\n","Generated 32 batches of size 32 in 19.547 sec\n","Step 5093    [1.469 sec/step, loss=0.79413, avg_loss=0.80510]\n","Step 5094    [1.459 sec/step, loss=0.81271, avg_loss=0.80499]\n","Step 5095    [1.459 sec/step, loss=0.80495, avg_loss=0.80474]\n","Step 5096    [1.454 sec/step, loss=0.81510, avg_loss=0.80497]\n","Step 5097    [1.444 sec/step, loss=0.80743, avg_loss=0.80485]\n","Step 5098    [1.443 sec/step, loss=0.82520, avg_loss=0.80493]\n","Step 5099    [1.398 sec/step, loss=0.83008, avg_loss=0.80517]\n","Step 5100    [1.402 sec/step, loss=0.81477, avg_loss=0.80537]\n","Writing summary at step: 5100\n","Step 5101    [1.398 sec/step, loss=0.80560, avg_loss=0.80527]\n","Step 5102    [1.401 sec/step, loss=0.78127, avg_loss=0.80509]\n","Step 5103    [1.393 sec/step, loss=0.81420, avg_loss=0.80556]\n","Step 5104    [1.402 sec/step, loss=0.75006, avg_loss=0.80496]\n","Step 5105    [1.401 sec/step, loss=0.80985, avg_loss=0.80498]\n","Step 5106    [1.410 sec/step, loss=0.79764, avg_loss=0.80464]\n","Step 5107    [1.412 sec/step, loss=0.78957, avg_loss=0.80432]\n","Step 5108    [1.407 sec/step, loss=0.81085, avg_loss=0.80477]\n","Step 5109    [1.405 sec/step, loss=0.84582, avg_loss=0.80517]\n","Step 5110    [1.408 sec/step, loss=0.83390, avg_loss=0.80527]\n","Step 5111    [1.404 sec/step, loss=0.82815, avg_loss=0.80551]\n","Step 5112    [1.398 sec/step, loss=0.77912, avg_loss=0.80539]\n","Step 5113    [1.397 sec/step, loss=0.78175, avg_loss=0.80499]\n","Step 5114    [1.396 sec/step, loss=0.79374, avg_loss=0.80450]\n","Step 5115    [1.393 sec/step, loss=0.82206, avg_loss=0.80491]\n","Step 5116    [1.397 sec/step, loss=0.78495, avg_loss=0.80459]\n","Step 5117    [1.402 sec/step, loss=0.82454, avg_loss=0.80464]\n","Step 5118    [1.409 sec/step, loss=0.81556, avg_loss=0.80468]\n","Step 5119    [1.412 sec/step, loss=0.82835, avg_loss=0.80469]\n","Step 5120    [1.413 sec/step, loss=0.80335, avg_loss=0.80460]\n","Step 5121    [1.416 sec/step, loss=0.80603, avg_loss=0.80446]\n","Step 5122    [1.455 sec/step, loss=0.60323, avg_loss=0.80228]\n","Step 5123    [1.461 sec/step, loss=0.81097, avg_loss=0.80216]\n","Generated 32 batches of size 32 in 19.623 sec\n","Step 5124    [1.441 sec/step, loss=0.83371, avg_loss=0.80482]\n","Step 5125    [1.448 sec/step, loss=0.78289, avg_loss=0.80446]\n","Step 5126    [1.446 sec/step, loss=0.82357, avg_loss=0.80435]\n","Step 5127    [1.469 sec/step, loss=0.52482, avg_loss=0.80145]\n","Step 5128    [1.456 sec/step, loss=0.79981, avg_loss=0.80124]\n","Step 5129    [1.421 sec/step, loss=0.79581, avg_loss=0.80103]\n","Step 5130    [1.420 sec/step, loss=0.81763, avg_loss=0.80087]\n","Step 5131    [1.426 sec/step, loss=0.80185, avg_loss=0.80055]\n","Step 5132    [1.421 sec/step, loss=0.79831, avg_loss=0.80030]\n","Step 5133    [1.415 sec/step, loss=0.80300, avg_loss=0.79983]\n","Step 5134    [1.414 sec/step, loss=0.78161, avg_loss=0.79932]\n","Step 5135    [1.414 sec/step, loss=0.83552, avg_loss=0.79953]\n","Step 5136    [1.412 sec/step, loss=0.80835, avg_loss=0.79912]\n","Step 5137    [1.413 sec/step, loss=0.81087, avg_loss=0.79890]\n","Step 5138    [1.421 sec/step, loss=0.76915, avg_loss=0.79817]\n","Step 5139    [1.428 sec/step, loss=0.77066, avg_loss=0.79785]\n","Step 5140    [1.428 sec/step, loss=0.80715, avg_loss=0.79775]\n","Step 5141    [1.425 sec/step, loss=0.83289, avg_loss=0.79754]\n","Step 5142    [1.420 sec/step, loss=0.81062, avg_loss=0.79725]\n","Step 5143    [1.420 sec/step, loss=0.83302, avg_loss=0.79721]\n","Step 5144    [1.419 sec/step, loss=0.82908, avg_loss=0.79737]\n","Step 5145    [1.389 sec/step, loss=0.80096, avg_loss=0.79986]\n","Step 5146    [1.388 sec/step, loss=0.81153, avg_loss=0.79986]\n","Step 5147    [1.391 sec/step, loss=0.79398, avg_loss=0.79968]\n","Step 5148    [1.399 sec/step, loss=0.79662, avg_loss=0.79960]\n","Step 5149    [1.405 sec/step, loss=0.80484, avg_loss=0.79957]\n","Step 5150    [1.411 sec/step, loss=0.82233, avg_loss=0.79958]\n","Step 5151    [1.410 sec/step, loss=0.81319, avg_loss=0.79964]\n","Step 5152    [1.407 sec/step, loss=0.80144, avg_loss=0.79966]\n","Step 5153    [1.414 sec/step, loss=0.82179, avg_loss=0.79982]\n","Step 5154    [1.420 sec/step, loss=0.76991, avg_loss=0.79923]\n","Step 5155    [1.409 sec/step, loss=0.80394, avg_loss=0.79946]\n","Generated 32 batches of size 32 in 19.231 sec\n","Step 5156    [1.458 sec/step, loss=0.79289, avg_loss=0.79954]\n","Step 5157    [1.456 sec/step, loss=0.81775, avg_loss=0.79944]\n","Step 5158    [1.455 sec/step, loss=0.78982, avg_loss=0.79934]\n","Step 5159    [1.457 sec/step, loss=0.79237, avg_loss=0.79909]\n","Step 5160    [1.454 sec/step, loss=0.79457, avg_loss=0.79883]\n","Step 5161    [1.398 sec/step, loss=0.80008, avg_loss=0.79883]\n","Step 5162    [1.402 sec/step, loss=0.79368, avg_loss=0.79877]\n","Step 5163    [1.400 sec/step, loss=0.79309, avg_loss=0.79869]\n","Step 5164    [1.397 sec/step, loss=0.81966, avg_loss=0.79907]\n","Step 5165    [1.394 sec/step, loss=0.83078, avg_loss=0.79947]\n","Step 5166    [1.392 sec/step, loss=0.80960, avg_loss=0.79952]\n","Step 5167    [1.391 sec/step, loss=0.81101, avg_loss=0.79946]\n","Step 5168    [1.385 sec/step, loss=0.81682, avg_loss=0.79993]\n","Step 5169    [1.376 sec/step, loss=0.81576, avg_loss=0.80039]\n","Step 5170    [1.376 sec/step, loss=0.80394, avg_loss=0.80028]\n","Step 5171    [1.386 sec/step, loss=0.73897, avg_loss=0.79969]\n","Step 5172    [1.383 sec/step, loss=0.81333, avg_loss=0.79991]\n","Step 5173    [1.387 sec/step, loss=0.78639, avg_loss=0.79976]\n","Step 5174    [1.389 sec/step, loss=0.78725, avg_loss=0.79939]\n","Step 5175    [1.392 sec/step, loss=0.81623, avg_loss=0.79937]\n","Step 5176    [1.392 sec/step, loss=0.79190, avg_loss=0.79899]\n","Step 5177    [1.416 sec/step, loss=0.62770, avg_loss=0.79725]\n","Step 5178    [1.420 sec/step, loss=0.79677, avg_loss=0.79683]\n","Step 5179    [1.420 sec/step, loss=0.79626, avg_loss=0.79693]\n","Step 5180    [1.422 sec/step, loss=0.80588, avg_loss=0.79716]\n","Step 5181    [1.417 sec/step, loss=0.80489, avg_loss=0.79729]\n","Step 5182    [1.421 sec/step, loss=0.80249, avg_loss=0.79713]\n","Step 5183    [1.430 sec/step, loss=0.78998, avg_loss=0.79687]\n","Step 5184    [1.426 sec/step, loss=0.79218, avg_loss=0.79663]\n","Step 5185    [1.426 sec/step, loss=0.81259, avg_loss=0.79666]\n","Step 5186    [1.381 sec/step, loss=0.82352, avg_loss=0.79920]\n","Step 5187    [1.374 sec/step, loss=0.83725, avg_loss=0.79947]\n","Generated 32 batches of size 32 in 19.551 sec\n","Step 5188    [1.454 sec/step, loss=0.78783, avg_loss=0.79902]\n","Step 5189    [1.453 sec/step, loss=0.81801, avg_loss=0.79895]\n","Step 5190    [1.474 sec/step, loss=0.63365, avg_loss=0.79710]\n","Step 5191    [1.474 sec/step, loss=0.79526, avg_loss=0.79687]\n","Step 5192    [1.464 sec/step, loss=0.79894, avg_loss=0.79675]\n","Step 5193    [1.426 sec/step, loss=0.81667, avg_loss=0.79697]\n","Step 5194    [1.430 sec/step, loss=0.80413, avg_loss=0.79689]\n","Step 5195    [1.437 sec/step, loss=0.74418, avg_loss=0.79628]\n","Step 5196    [1.442 sec/step, loss=0.78228, avg_loss=0.79595]\n","Step 5197    [1.449 sec/step, loss=0.81025, avg_loss=0.79598]\n","Step 5198    [1.442 sec/step, loss=0.79691, avg_loss=0.79570]\n","Step 5199    [1.445 sec/step, loss=0.78765, avg_loss=0.79527]\n","Step 5200    [1.439 sec/step, loss=0.82931, avg_loss=0.79542]\n","Writing summary at step: 5200\n","Step 5201    [1.441 sec/step, loss=0.79452, avg_loss=0.79531]\n","Step 5202    [1.437 sec/step, loss=0.83956, avg_loss=0.79589]\n","Step 5203    [1.437 sec/step, loss=0.84084, avg_loss=0.79616]\n","Step 5204    [1.427 sec/step, loss=0.83264, avg_loss=0.79698]\n","Step 5205    [1.428 sec/step, loss=0.85143, avg_loss=0.79740]\n","Step 5206    [1.420 sec/step, loss=0.82222, avg_loss=0.79764]\n","Step 5207    [1.413 sec/step, loss=0.84442, avg_loss=0.79819]\n","Step 5208    [1.415 sec/step, loss=0.87164, avg_loss=0.79880]\n","Step 5209    [1.419 sec/step, loss=0.83296, avg_loss=0.79867]\n","Step 5210    [1.433 sec/step, loss=0.81377, avg_loss=0.79847]\n","Step 5211    [1.444 sec/step, loss=0.84256, avg_loss=0.79862]\n","Step 5212    [1.449 sec/step, loss=0.83307, avg_loss=0.79915]\n","Step 5213    [1.457 sec/step, loss=0.85392, avg_loss=0.79988]\n","Step 5214    [1.462 sec/step, loss=0.80115, avg_loss=0.79995]\n","Step 5215    [1.457 sec/step, loss=0.83905, avg_loss=0.80012]\n","Step 5216    [1.458 sec/step, loss=0.81712, avg_loss=0.80044]\n","Step 5217    [1.458 sec/step, loss=0.84067, avg_loss=0.80060]\n","Step 5218    [1.460 sec/step, loss=0.80969, avg_loss=0.80054]\n","Generated 32 batches of size 32 in 18.355 sec\n","Step 5219    [1.499 sec/step, loss=0.80888, avg_loss=0.80035]\n","Step 5220    [1.488 sec/step, loss=0.82221, avg_loss=0.80054]\n","Step 5221    [1.483 sec/step, loss=0.82534, avg_loss=0.80073]\n","Step 5222    [1.449 sec/step, loss=0.77861, avg_loss=0.80249]\n","Step 5223    [1.441 sec/step, loss=0.83510, avg_loss=0.80273]\n","Step 5224    [1.417 sec/step, loss=0.83093, avg_loss=0.80270]\n","Step 5225    [1.406 sec/step, loss=0.81230, avg_loss=0.80299]\n","Step 5226    [1.404 sec/step, loss=0.79716, avg_loss=0.80273]\n","Step 5227    [1.381 sec/step, loss=0.82938, avg_loss=0.80577]\n","Step 5228    [1.386 sec/step, loss=0.81036, avg_loss=0.80588]\n","Step 5229    [1.388 sec/step, loss=0.82247, avg_loss=0.80615]\n","Step 5230    [1.394 sec/step, loss=0.82434, avg_loss=0.80621]\n","Step 5231    [1.395 sec/step, loss=0.80668, avg_loss=0.80626]\n","Step 5232    [1.397 sec/step, loss=0.81020, avg_loss=0.80638]\n","Step 5233    [1.394 sec/step, loss=0.81027, avg_loss=0.80645]\n","Step 5234    [1.393 sec/step, loss=0.82561, avg_loss=0.80689]\n","Step 5235    [1.403 sec/step, loss=0.84035, avg_loss=0.80694]\n","Step 5236    [1.409 sec/step, loss=0.82657, avg_loss=0.80712]\n","Step 5237    [1.419 sec/step, loss=0.74477, avg_loss=0.80646]\n","Step 5238    [1.412 sec/step, loss=0.81402, avg_loss=0.80691]\n","Step 5239    [1.404 sec/step, loss=0.82842, avg_loss=0.80749]\n","Step 5240    [1.431 sec/step, loss=0.68573, avg_loss=0.80628]\n","Step 5241    [1.433 sec/step, loss=0.82630, avg_loss=0.80621]\n","Step 5242    [1.441 sec/step, loss=0.81467, avg_loss=0.80625]\n","Step 5243    [1.446 sec/step, loss=0.79897, avg_loss=0.80591]\n","Step 5244    [1.452 sec/step, loss=0.82320, avg_loss=0.80585]\n","Step 5245    [1.458 sec/step, loss=0.83323, avg_loss=0.80617]\n","Step 5246    [1.461 sec/step, loss=0.80361, avg_loss=0.80609]\n","Step 5247    [1.456 sec/step, loss=0.80260, avg_loss=0.80618]\n","Step 5248    [1.451 sec/step, loss=0.80221, avg_loss=0.80624]\n","Step 5249    [1.448 sec/step, loss=0.81120, avg_loss=0.80630]\n","Step 5250    [1.448 sec/step, loss=0.81024, avg_loss=0.80618]\n","Generated 32 batches of size 32 in 19.023 sec\n","Step 5251    [1.528 sec/step, loss=0.73699, avg_loss=0.80542]\n","Step 5252    [1.524 sec/step, loss=0.79556, avg_loss=0.80536]\n","Step 5253    [1.516 sec/step, loss=0.80920, avg_loss=0.80523]\n","Step 5254    [1.505 sec/step, loss=0.81316, avg_loss=0.80566]\n","Step 5255    [1.498 sec/step, loss=0.79241, avg_loss=0.80555]\n","Step 5256    [1.447 sec/step, loss=0.81369, avg_loss=0.80576]\n","Step 5257    [1.455 sec/step, loss=0.77276, avg_loss=0.80531]\n","Step 5258    [1.451 sec/step, loss=0.80713, avg_loss=0.80548]\n","Step 5259    [1.447 sec/step, loss=0.82374, avg_loss=0.80579]\n","Step 5260    [1.445 sec/step, loss=0.83466, avg_loss=0.80620]\n","Step 5261    [1.446 sec/step, loss=0.80248, avg_loss=0.80622]\n","Step 5262    [1.445 sec/step, loss=0.82514, avg_loss=0.80653]\n","Step 5263    [1.443 sec/step, loss=0.80433, avg_loss=0.80665]\n","Step 5264    [1.446 sec/step, loss=0.79899, avg_loss=0.80644]\n","Step 5265    [1.471 sec/step, loss=0.63577, avg_loss=0.80449]\n","Step 5266    [1.471 sec/step, loss=0.81210, avg_loss=0.80451]\n","Step 5267    [1.472 sec/step, loss=0.80184, avg_loss=0.80442]\n","Step 5268    [1.474 sec/step, loss=0.82937, avg_loss=0.80455]\n","Step 5269    [1.473 sec/step, loss=0.80123, avg_loss=0.80440]\n","Step 5270    [1.472 sec/step, loss=0.80700, avg_loss=0.80443]\n","Step 5271    [1.462 sec/step, loss=0.80248, avg_loss=0.80507]\n","Step 5272    [1.459 sec/step, loss=0.80316, avg_loss=0.80497]\n","Step 5273    [1.455 sec/step, loss=0.80458, avg_loss=0.80515]\n","Step 5274    [1.466 sec/step, loss=0.81247, avg_loss=0.80540]\n","Step 5275    [1.464 sec/step, loss=0.77254, avg_loss=0.80496]\n","Step 5276    [1.476 sec/step, loss=0.82438, avg_loss=0.80529]\n","Step 5277    [1.468 sec/step, loss=0.80982, avg_loss=0.80711]\n","Step 5278    [1.468 sec/step, loss=0.82195, avg_loss=0.80736]\n","Step 5279    [1.470 sec/step, loss=0.78517, avg_loss=0.80725]\n","Step 5280    [1.463 sec/step, loss=0.81895, avg_loss=0.80738]\n","Step 5281    [1.462 sec/step, loss=0.81327, avg_loss=0.80747]\n","Step 5282    [1.463 sec/step, loss=0.83246, avg_loss=0.80777]\n","Generated 32 batches of size 32 in 19.641 sec\n","Step 5283    [1.513 sec/step, loss=0.80424, avg_loss=0.80791]\n","Step 5284    [1.512 sec/step, loss=0.81554, avg_loss=0.80814]\n","Step 5285    [1.511 sec/step, loss=0.79881, avg_loss=0.80800]\n","Step 5286    [1.507 sec/step, loss=0.78612, avg_loss=0.80763]\n","Step 5287    [1.506 sec/step, loss=0.78958, avg_loss=0.80715]\n","Step 5288    [1.424 sec/step, loss=0.80255, avg_loss=0.80730]\n","Step 5289    [1.427 sec/step, loss=0.83232, avg_loss=0.80744]\n","Step 5290    [1.403 sec/step, loss=0.81671, avg_loss=0.80927]\n","Step 5291    [1.405 sec/step, loss=0.76644, avg_loss=0.80899]\n","Step 5292    [1.403 sec/step, loss=0.80448, avg_loss=0.80904]\n","Step 5293    [1.406 sec/step, loss=0.79705, avg_loss=0.80884]\n","Step 5294    [1.406 sec/step, loss=0.81352, avg_loss=0.80894]\n","Step 5295    [1.395 sec/step, loss=0.80855, avg_loss=0.80958]\n","Step 5296    [1.389 sec/step, loss=0.81611, avg_loss=0.80992]\n","Step 5297    [1.389 sec/step, loss=0.78650, avg_loss=0.80968]\n","Step 5298    [1.396 sec/step, loss=0.79352, avg_loss=0.80965]\n","Step 5299    [1.404 sec/step, loss=0.75837, avg_loss=0.80936]\n","Step 5300    [1.403 sec/step, loss=0.80833, avg_loss=0.80915]\n","Writing summary at step: 5300\n","Step 5301    [1.407 sec/step, loss=0.79602, avg_loss=0.80916]\n","Step 5302    [1.429 sec/step, loss=0.64154, avg_loss=0.80718]\n","Step 5303    [1.428 sec/step, loss=0.81295, avg_loss=0.80690]\n","Step 5304    [1.429 sec/step, loss=0.81815, avg_loss=0.80676]\n","Step 5305    [1.432 sec/step, loss=0.81527, avg_loss=0.80640]\n","Step 5306    [1.437 sec/step, loss=0.81683, avg_loss=0.80634]\n","Step 5307    [1.446 sec/step, loss=0.81029, avg_loss=0.80600]\n","Step 5308    [1.452 sec/step, loss=0.77959, avg_loss=0.80508]\n","Step 5309    [1.457 sec/step, loss=0.81041, avg_loss=0.80486]\n","Step 5310    [1.453 sec/step, loss=0.81974, avg_loss=0.80491]\n","Step 5311    [1.442 sec/step, loss=0.80147, avg_loss=0.80450]\n","Step 5312    [1.443 sec/step, loss=0.80848, avg_loss=0.80426]\n","Step 5313    [1.443 sec/step, loss=0.81185, avg_loss=0.80384]\n","Generated 32 batches of size 32 in 19.666 sec\n","Step 5314    [1.508 sec/step, loss=0.78863, avg_loss=0.80371]\n","Step 5315    [1.507 sec/step, loss=0.82946, avg_loss=0.80362]\n","Step 5316    [1.508 sec/step, loss=0.73400, avg_loss=0.80278]\n","Step 5317    [1.508 sec/step, loss=0.79400, avg_loss=0.80232]\n","Step 5318    [1.500 sec/step, loss=0.80217, avg_loss=0.80224]\n","Step 5319    [1.453 sec/step, loss=0.79859, avg_loss=0.80214]\n","Step 5320    [1.455 sec/step, loss=0.80801, avg_loss=0.80200]\n","Step 5321    [1.457 sec/step, loss=0.78970, avg_loss=0.80164]\n","Step 5322    [1.452 sec/step, loss=0.81753, avg_loss=0.80203]\n","Step 5323    [1.454 sec/step, loss=0.80078, avg_loss=0.80169]\n","Step 5324    [1.458 sec/step, loss=0.81462, avg_loss=0.80152]\n","Step 5325    [1.458 sec/step, loss=0.81755, avg_loss=0.80158]\n","Step 5326    [1.467 sec/step, loss=0.77291, avg_loss=0.80133]\n","Step 5327    [1.465 sec/step, loss=0.78736, avg_loss=0.80091]\n","Step 5328    [1.463 sec/step, loss=0.79811, avg_loss=0.80079]\n","Step 5329    [1.469 sec/step, loss=0.79101, avg_loss=0.80048]\n","Step 5330    [1.467 sec/step, loss=0.77459, avg_loss=0.79998]\n","Step 5331    [1.461 sec/step, loss=0.79780, avg_loss=0.79989]\n","Step 5332    [1.460 sec/step, loss=0.80661, avg_loss=0.79986]\n","Step 5333    [1.461 sec/step, loss=0.81617, avg_loss=0.79991]\n","Step 5334    [1.460 sec/step, loss=0.81847, avg_loss=0.79984]\n","Step 5335    [1.480 sec/step, loss=0.56407, avg_loss=0.79708]\n","Step 5336    [1.474 sec/step, loss=0.81190, avg_loss=0.79693]\n","Step 5337    [1.464 sec/step, loss=0.82180, avg_loss=0.79770]\n","Step 5338    [1.472 sec/step, loss=0.80819, avg_loss=0.79765]\n","Step 5339    [1.479 sec/step, loss=0.83339, avg_loss=0.79769]\n","Step 5340    [1.459 sec/step, loss=0.81397, avg_loss=0.79898]\n","Step 5341    [1.467 sec/step, loss=0.80991, avg_loss=0.79881]\n","Step 5342    [1.459 sec/step, loss=0.82649, avg_loss=0.79893]\n","Step 5343    [1.457 sec/step, loss=0.80839, avg_loss=0.79903]\n","Step 5344    [1.463 sec/step, loss=0.82175, avg_loss=0.79901]\n","Step 5345    [1.460 sec/step, loss=0.81184, avg_loss=0.79880]\n","Generated 32 batches of size 32 in 19.575 sec\n","Step 5346    [1.524 sec/step, loss=0.78818, avg_loss=0.79864]\n","Step 5347    [1.522 sec/step, loss=0.80224, avg_loss=0.79864]\n","Step 5348    [1.517 sec/step, loss=0.81961, avg_loss=0.79881]\n","Step 5349    [1.515 sec/step, loss=0.83455, avg_loss=0.79905]\n","Step 5350    [1.512 sec/step, loss=0.76969, avg_loss=0.79864]\n","Step 5351    [1.437 sec/step, loss=0.74817, avg_loss=0.79875]\n","Step 5352    [1.433 sec/step, loss=0.78661, avg_loss=0.79866]\n","Step 5353    [1.430 sec/step, loss=0.79629, avg_loss=0.79853]\n","Step 5354    [1.430 sec/step, loss=0.80166, avg_loss=0.79842]\n","Step 5355    [1.429 sec/step, loss=0.80193, avg_loss=0.79851]\n","Step 5356    [1.434 sec/step, loss=0.80933, avg_loss=0.79847]\n","Step 5357    [1.429 sec/step, loss=0.79364, avg_loss=0.79868]\n","Step 5358    [1.428 sec/step, loss=0.83300, avg_loss=0.79894]\n","Step 5359    [1.450 sec/step, loss=0.62599, avg_loss=0.79696]\n","Step 5360    [1.455 sec/step, loss=0.80754, avg_loss=0.79669]\n","Step 5361    [1.459 sec/step, loss=0.78818, avg_loss=0.79655]\n","Step 5362    [1.458 sec/step, loss=0.81179, avg_loss=0.79641]\n","Step 5363    [1.460 sec/step, loss=0.80731, avg_loss=0.79644]\n","Step 5364    [1.460 sec/step, loss=0.80151, avg_loss=0.79647]\n","Step 5365    [1.435 sec/step, loss=0.81430, avg_loss=0.79825]\n","Step 5366    [1.435 sec/step, loss=0.78832, avg_loss=0.79802]\n","Step 5367    [1.444 sec/step, loss=0.72480, avg_loss=0.79725]\n","Step 5368    [1.443 sec/step, loss=0.80715, avg_loss=0.79702]\n","Step 5369    [1.445 sec/step, loss=0.81927, avg_loss=0.79720]\n","Step 5370    [1.445 sec/step, loss=0.79279, avg_loss=0.79706]\n","Step 5371    [1.446 sec/step, loss=0.80564, avg_loss=0.79709]\n","Step 5372    [1.456 sec/step, loss=0.78058, avg_loss=0.79687]\n","Step 5373    [1.465 sec/step, loss=0.80747, avg_loss=0.79690]\n","Step 5374    [1.459 sec/step, loss=0.81984, avg_loss=0.79697]\n","Step 5375    [1.469 sec/step, loss=0.79335, avg_loss=0.79718]\n","Step 5376    [1.461 sec/step, loss=0.80249, avg_loss=0.79696]\n","Step 5377    [1.450 sec/step, loss=0.79090, avg_loss=0.79677]\n","Generated 32 batches of size 32 in 19.848 sec\n","Step 5378    [1.521 sec/step, loss=0.80505, avg_loss=0.79660]\n","Step 5379    [1.516 sec/step, loss=0.79878, avg_loss=0.79674]\n","Step 5380    [1.514 sec/step, loss=0.83892, avg_loss=0.79694]\n","Step 5381    [1.516 sec/step, loss=0.78483, avg_loss=0.79665]\n","Step 5382    [1.542 sec/step, loss=0.52622, avg_loss=0.79359]\n","Step 5383    [1.481 sec/step, loss=0.80643, avg_loss=0.79361]\n","Step 5384    [1.479 sec/step, loss=0.80419, avg_loss=0.79350]\n","Step 5385    [1.479 sec/step, loss=0.78056, avg_loss=0.79332]\n","Step 5386    [1.478 sec/step, loss=0.77809, avg_loss=0.79324]\n","Step 5387    [1.485 sec/step, loss=0.82293, avg_loss=0.79357]\n","Step 5388    [1.485 sec/step, loss=0.84526, avg_loss=0.79400]\n","Step 5389    [1.485 sec/step, loss=0.78543, avg_loss=0.79353]\n","Step 5390    [1.488 sec/step, loss=0.80511, avg_loss=0.79341]\n","Step 5391    [1.481 sec/step, loss=0.78163, avg_loss=0.79356]\n","Step 5392    [1.481 sec/step, loss=0.80508, avg_loss=0.79357]\n","Step 5393    [1.485 sec/step, loss=0.78282, avg_loss=0.79343]\n","Step 5394    [1.482 sec/step, loss=0.81779, avg_loss=0.79347]\n","Step 5395    [1.494 sec/step, loss=0.76519, avg_loss=0.79304]\n","Step 5396    [1.494 sec/step, loss=0.81778, avg_loss=0.79305]\n","Step 5397    [1.487 sec/step, loss=0.81248, avg_loss=0.79331]\n","Step 5398    [1.488 sec/step, loss=0.82147, avg_loss=0.79359]\n","Step 5399    [1.480 sec/step, loss=0.78801, avg_loss=0.79389]\n","Step 5400    [1.480 sec/step, loss=0.78887, avg_loss=0.79369]\n","Writing summary at step: 5400\n","Step 5401    [1.480 sec/step, loss=0.79223, avg_loss=0.79366]\n","Step 5402    [1.461 sec/step, loss=0.80886, avg_loss=0.79533]\n","Step 5403    [1.467 sec/step, loss=0.80904, avg_loss=0.79529]\n","Step 5404    [1.468 sec/step, loss=0.80208, avg_loss=0.79513]\n","Step 5405    [1.473 sec/step, loss=0.78582, avg_loss=0.79483]\n","Step 5406    [1.475 sec/step, loss=0.78354, avg_loss=0.79450]\n","Step 5407    [1.478 sec/step, loss=0.79520, avg_loss=0.79435]\n","Step 5408    [1.478 sec/step, loss=0.81667, avg_loss=0.79472]\n","Generated 32 batches of size 32 in 17.838 sec\n","Step 5409    [1.518 sec/step, loss=0.77926, avg_loss=0.79441]\n","Step 5410    [1.507 sec/step, loss=0.80611, avg_loss=0.79427]\n","Step 5411    [1.506 sec/step, loss=0.79965, avg_loss=0.79426]\n","Step 5412    [1.502 sec/step, loss=0.81133, avg_loss=0.79428]\n","Step 5413    [1.495 sec/step, loss=0.79414, avg_loss=0.79411]\n","Step 5414    [1.426 sec/step, loss=0.81161, avg_loss=0.79434]\n","Step 5415    [1.430 sec/step, loss=0.77996, avg_loss=0.79384]\n","Step 5416    [1.422 sec/step, loss=0.79496, avg_loss=0.79445]\n","Step 5417    [1.420 sec/step, loss=0.81378, avg_loss=0.79465]\n","Step 5418    [1.418 sec/step, loss=0.80619, avg_loss=0.79469]\n","Step 5419    [1.418 sec/step, loss=0.80358, avg_loss=0.79474]\n","Step 5420    [1.415 sec/step, loss=0.81265, avg_loss=0.79479]\n","Step 5421    [1.409 sec/step, loss=0.79807, avg_loss=0.79487]\n","Step 5422    [1.431 sec/step, loss=0.62647, avg_loss=0.79296]\n","Step 5423    [1.434 sec/step, loss=0.77067, avg_loss=0.79266]\n","Step 5424    [1.438 sec/step, loss=0.83528, avg_loss=0.79286]\n","Step 5425    [1.443 sec/step, loss=0.77822, avg_loss=0.79247]\n","Step 5426    [1.436 sec/step, loss=0.82226, avg_loss=0.79297]\n","Step 5427    [1.434 sec/step, loss=0.79812, avg_loss=0.79307]\n","Step 5428    [1.433 sec/step, loss=0.81633, avg_loss=0.79325]\n","Step 5429    [1.428 sec/step, loss=0.79372, avg_loss=0.79328]\n","Step 5430    [1.437 sec/step, loss=0.72207, avg_loss=0.79276]\n","Step 5431    [1.441 sec/step, loss=0.82295, avg_loss=0.79301]\n","Step 5432    [1.443 sec/step, loss=0.80534, avg_loss=0.79300]\n","Step 5433    [1.452 sec/step, loss=0.79064, avg_loss=0.79274]\n","Step 5434    [1.461 sec/step, loss=0.80251, avg_loss=0.79258]\n","Step 5435    [1.446 sec/step, loss=0.78256, avg_loss=0.79477]\n","Step 5436    [1.452 sec/step, loss=0.79514, avg_loss=0.79460]\n","Step 5437    [1.455 sec/step, loss=0.79198, avg_loss=0.79430]\n","Step 5438    [1.452 sec/step, loss=0.78563, avg_loss=0.79407]\n","Step 5439    [1.452 sec/step, loss=0.76835, avg_loss=0.79342]\n","Step 5440    [1.448 sec/step, loss=0.80592, avg_loss=0.79334]\n","Generated 32 batches of size 32 in 19.617 sec\n","Step 5441    [1.501 sec/step, loss=0.80290, avg_loss=0.79327]\n","Step 5442    [1.500 sec/step, loss=0.79874, avg_loss=0.79300]\n","Step 5443    [1.498 sec/step, loss=0.79333, avg_loss=0.79284]\n","Step 5444    [1.495 sec/step, loss=0.78802, avg_loss=0.79251]\n","Step 5445    [1.492 sec/step, loss=0.80255, avg_loss=0.79241]\n","Step 5446    [1.424 sec/step, loss=0.81289, avg_loss=0.79266]\n","Step 5447    [1.429 sec/step, loss=0.81040, avg_loss=0.79274]\n","Step 5448    [1.429 sec/step, loss=0.79547, avg_loss=0.79250]\n","Step 5449    [1.428 sec/step, loss=0.81242, avg_loss=0.79228]\n","Step 5450    [1.425 sec/step, loss=0.81114, avg_loss=0.79270]\n","Step 5451    [1.418 sec/step, loss=0.80559, avg_loss=0.79327]\n","Step 5452    [1.421 sec/step, loss=0.79151, avg_loss=0.79332]\n","Step 5453    [1.425 sec/step, loss=0.77173, avg_loss=0.79307]\n","Step 5454    [1.427 sec/step, loss=0.80068, avg_loss=0.79306]\n","Step 5455    [1.429 sec/step, loss=0.78108, avg_loss=0.79285]\n","Step 5456    [1.429 sec/step, loss=0.77040, avg_loss=0.79247]\n","Step 5457    [1.426 sec/step, loss=0.78649, avg_loss=0.79239]\n","Step 5458    [1.428 sec/step, loss=0.79000, avg_loss=0.79196]\n","Step 5459    [1.405 sec/step, loss=0.76443, avg_loss=0.79335]\n","Step 5460    [1.403 sec/step, loss=0.78045, avg_loss=0.79308]\n","Step 5461    [1.400 sec/step, loss=0.79994, avg_loss=0.79319]\n","Step 5462    [1.398 sec/step, loss=0.80771, avg_loss=0.79315]\n","Step 5463    [1.426 sec/step, loss=0.54072, avg_loss=0.79049]\n","Step 5464    [1.445 sec/step, loss=0.74470, avg_loss=0.78992]\n","Step 5465    [1.455 sec/step, loss=0.79787, avg_loss=0.78976]\n","Step 5466    [1.463 sec/step, loss=0.78013, avg_loss=0.78967]\n","Step 5467    [1.455 sec/step, loss=0.79830, avg_loss=0.79041]\n","Step 5468    [1.462 sec/step, loss=0.77361, avg_loss=0.79007]\n","Step 5469    [1.465 sec/step, loss=0.82086, avg_loss=0.79009]\n","Step 5470    [1.468 sec/step, loss=0.82324, avg_loss=0.79039]\n","Step 5471    [1.478 sec/step, loss=0.78815, avg_loss=0.79022]\n","Step 5472    [1.470 sec/step, loss=0.79794, avg_loss=0.79039]\n","Generated 32 batches of size 32 in 19.444 sec\n","Step 5473    [1.511 sec/step, loss=0.79013, avg_loss=0.79022]\n","Step 5474    [1.506 sec/step, loss=0.81750, avg_loss=0.79020]\n","Step 5475    [1.499 sec/step, loss=0.78078, avg_loss=0.79007]\n","Step 5476    [1.495 sec/step, loss=0.80483, avg_loss=0.79009]\n","Step 5477    [1.492 sec/step, loss=0.78035, avg_loss=0.78999]\n","Step 5478    [1.414 sec/step, loss=0.80730, avg_loss=0.79001]\n","Step 5479    [1.415 sec/step, loss=0.80631, avg_loss=0.79009]\n","Step 5480    [1.415 sec/step, loss=0.80977, avg_loss=0.78979]\n","Step 5481    [1.412 sec/step, loss=0.80540, avg_loss=0.79000]\n","Step 5482    [1.383 sec/step, loss=0.78453, avg_loss=0.79258]\n","Step 5483    [1.381 sec/step, loss=0.78531, avg_loss=0.79237]\n","Step 5484    [1.393 sec/step, loss=0.70234, avg_loss=0.79135]\n","Step 5485    [1.393 sec/step, loss=0.80149, avg_loss=0.79156]\n","Step 5486    [1.395 sec/step, loss=0.79733, avg_loss=0.79176]\n","Step 5487    [1.387 sec/step, loss=0.80835, avg_loss=0.79161]\n","Step 5488    [1.387 sec/step, loss=0.79885, avg_loss=0.79115]\n","Step 5489    [1.390 sec/step, loss=0.76476, avg_loss=0.79094]\n","Step 5490    [1.395 sec/step, loss=0.77937, avg_loss=0.79068]\n","Step 5491    [1.397 sec/step, loss=0.80060, avg_loss=0.79087]\n","Step 5492    [1.397 sec/step, loss=0.77945, avg_loss=0.79061]\n","Step 5493    [1.396 sec/step, loss=0.77254, avg_loss=0.79051]\n","Step 5494    [1.396 sec/step, loss=0.80342, avg_loss=0.79037]\n","Step 5495    [1.385 sec/step, loss=0.81509, avg_loss=0.79087]\n","Step 5496    [1.428 sec/step, loss=0.57912, avg_loss=0.78848]\n","Step 5497    [1.430 sec/step, loss=0.79068, avg_loss=0.78826]\n","Step 5498    [1.425 sec/step, loss=0.79370, avg_loss=0.78798]\n","Step 5499    [1.433 sec/step, loss=0.81371, avg_loss=0.78824]\n","Step 5500    [1.435 sec/step, loss=0.82751, avg_loss=0.78863]\n","Writing summary at step: 5500\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Generated 32 batches of size 32 in 20.239 sec\n","Check wav file before change:  (101700,)\n","Check wav file:  (131700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000005500-align000.png\n","100% 1/1 [00:04<00:00,  4.91s/it]\n","Test finished for step 5500.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000005500-align000.png\n"," 25% 1/4 [00:09<00:29,  9.87s/it]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000005500-align001.png\n"," 50% 2/4 [00:19<00:19,  9.90s/it]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000005500-align002.png\n"," 75% 3/4 [00:30<00:10, 10.09s/it]Check wav file before change:  (299700,)\n","Check wav file:  (329700,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000005500-align003.png\n","100% 4/4 [00:40<00:00, 10.09s/it]\n","Test finished for step 5500.\n","Step 5501    [1.430 sec/step, loss=0.81815, avg_loss=0.78889]\n","Step 5502    [1.428 sec/step, loss=0.82431, avg_loss=0.78904]\n","Step 5503    [1.423 sec/step, loss=0.79076, avg_loss=0.78886]\n","Step 5504    [1.422 sec/step, loss=0.79484, avg_loss=0.78879]\n","Step 5505    [1.411 sec/step, loss=0.78199, avg_loss=0.78875]\n","Step 5506    [1.411 sec/step, loss=0.82978, avg_loss=0.78921]\n","Step 5507    [1.399 sec/step, loss=0.79816, avg_loss=0.78924]\n","Step 5508    [1.397 sec/step, loss=0.77285, avg_loss=0.78880]\n","Step 5509    [1.350 sec/step, loss=0.79802, avg_loss=0.78899]\n","Step 5510    [1.349 sec/step, loss=0.78740, avg_loss=0.78880]\n","Step 5511    [1.349 sec/step, loss=0.81200, avg_loss=0.78893]\n","Step 5512    [1.348 sec/step, loss=0.80561, avg_loss=0.78887]\n","Step 5513    [1.352 sec/step, loss=0.79780, avg_loss=0.78891]\n","Step 5514    [1.352 sec/step, loss=0.83131, avg_loss=0.78910]\n","Step 5515    [1.351 sec/step, loss=0.80834, avg_loss=0.78939]\n","Step 5516    [1.351 sec/step, loss=0.81419, avg_loss=0.78958]\n","Step 5517    [1.353 sec/step, loss=0.78909, avg_loss=0.78933]\n","Step 5518    [1.363 sec/step, loss=0.82647, avg_loss=0.78953]\n","Step 5519    [1.362 sec/step, loss=0.80037, avg_loss=0.78950]\n","Step 5520    [1.362 sec/step, loss=0.81076, avg_loss=0.78948]\n","Step 5521    [1.365 sec/step, loss=0.78957, avg_loss=0.78940]\n","Step 5522    [1.340 sec/step, loss=0.81268, avg_loss=0.79126]\n","Step 5523    [1.338 sec/step, loss=0.81842, avg_loss=0.79174]\n","Step 5524    [1.329 sec/step, loss=0.80345, avg_loss=0.79142]\n","Step 5525    [1.330 sec/step, loss=0.77459, avg_loss=0.79138]\n","Step 5526    [1.337 sec/step, loss=0.80080, avg_loss=0.79117]\n","Step 5527    [1.341 sec/step, loss=0.80533, avg_loss=0.79124]\n","Step 5528    [1.345 sec/step, loss=0.80040, avg_loss=0.79108]\n","Step 5529    [1.363 sec/step, loss=0.72854, avg_loss=0.79043]\n","Step 5530    [1.364 sec/step, loss=0.80339, avg_loss=0.79124]\n","Step 5531    [1.404 sec/step, loss=0.56848, avg_loss=0.78870]\n","Step 5532    [1.406 sec/step, loss=0.81877, avg_loss=0.78883]\n","Step 5533    [1.402 sec/step, loss=0.79429, avg_loss=0.78887]\n","Step 5534    [1.399 sec/step, loss=0.80223, avg_loss=0.78887]\n","Generated 32 batches of size 32 in 19.612 sec\n","Step 5535    [1.402 sec/step, loss=0.80102, avg_loss=0.78905]\n","Step 5536    [1.399 sec/step, loss=0.81495, avg_loss=0.78925]\n","Step 5537    [1.401 sec/step, loss=0.78445, avg_loss=0.78917]\n","Step 5538    [1.400 sec/step, loss=0.80677, avg_loss=0.78939]\n","Step 5539    [1.394 sec/step, loss=0.80713, avg_loss=0.78977]\n","Step 5540    [1.404 sec/step, loss=0.78279, avg_loss=0.78954]\n","Step 5541    [1.341 sec/step, loss=0.77709, avg_loss=0.78928]\n","Step 5542    [1.341 sec/step, loss=0.78380, avg_loss=0.78913]\n","Step 5543    [1.338 sec/step, loss=0.80813, avg_loss=0.78928]\n","Step 5544    [1.338 sec/step, loss=0.76904, avg_loss=0.78909]\n","Step 5545    [1.342 sec/step, loss=0.78349, avg_loss=0.78890]\n","Step 5546    [1.347 sec/step, loss=0.79047, avg_loss=0.78868]\n","Step 5547    [1.345 sec/step, loss=0.82630, avg_loss=0.78884]\n","Step 5548    [1.343 sec/step, loss=0.79759, avg_loss=0.78886]\n","Step 5549    [1.346 sec/step, loss=0.80018, avg_loss=0.78874]\n","Step 5550    [1.345 sec/step, loss=0.79250, avg_loss=0.78855]\n","Step 5551    [1.348 sec/step, loss=0.78476, avg_loss=0.78834]\n","Step 5552    [1.344 sec/step, loss=0.80776, avg_loss=0.78850]\n","Step 5553    [1.346 sec/step, loss=0.81282, avg_loss=0.78891]\n","Step 5554    [1.347 sec/step, loss=0.78141, avg_loss=0.78872]\n","Step 5555    [1.341 sec/step, loss=0.81254, avg_loss=0.78904]\n","Step 5556    [1.333 sec/step, loss=0.80512, avg_loss=0.78938]\n","Step 5557    [1.335 sec/step, loss=0.80346, avg_loss=0.78955]\n","Step 5558    [1.381 sec/step, loss=0.59292, avg_loss=0.78758]\n","Step 5559    [1.387 sec/step, loss=0.79417, avg_loss=0.78788]\n","Step 5560    [1.387 sec/step, loss=0.79901, avg_loss=0.78807]\n","Step 5561    [1.392 sec/step, loss=0.80444, avg_loss=0.78811]\n","Step 5562    [1.397 sec/step, loss=0.79805, avg_loss=0.78801]\n","Step 5563    [1.368 sec/step, loss=0.78550, avg_loss=0.79046]\n","Step 5564    [1.351 sec/step, loss=0.82707, avg_loss=0.79129]\n","Step 5565    [1.344 sec/step, loss=0.79992, avg_loss=0.79131]\n","Step 5566    [1.342 sec/step, loss=0.80523, avg_loss=0.79156]\n","Generated 32 batches of size 32 in 18.840 sec\n","Step 5567    [1.378 sec/step, loss=0.80008, avg_loss=0.79157]\n","Step 5568    [1.372 sec/step, loss=0.83755, avg_loss=0.79221]\n","Step 5569    [1.367 sec/step, loss=0.80649, avg_loss=0.79207]\n","Step 5570    [1.360 sec/step, loss=0.79042, avg_loss=0.79174]\n","Step 5571    [1.348 sec/step, loss=0.80948, avg_loss=0.79196]\n","Step 5572    [1.346 sec/step, loss=0.78409, avg_loss=0.79182]\n","Step 5573    [1.325 sec/step, loss=0.53523, avg_loss=0.78927]\n","Step 5574    [1.330 sec/step, loss=0.76178, avg_loss=0.78871]\n","Step 5575    [1.324 sec/step, loss=0.80691, avg_loss=0.78897]\n","Step 5576    [1.326 sec/step, loss=0.78854, avg_loss=0.78881]\n","Step 5577    [1.329 sec/step, loss=0.79350, avg_loss=0.78894]\n","Step 5578    [1.330 sec/step, loss=0.79196, avg_loss=0.78879]\n","Step 5579    [1.331 sec/step, loss=0.80081, avg_loss=0.78873]\n","Step 5580    [1.334 sec/step, loss=0.78786, avg_loss=0.78851]\n","Step 5581    [1.335 sec/step, loss=0.82457, avg_loss=0.78870]\n","Step 5582    [1.337 sec/step, loss=0.84516, avg_loss=0.78931]\n","Step 5583    [1.336 sec/step, loss=0.78188, avg_loss=0.78928]\n","Step 5584    [1.326 sec/step, loss=0.81002, avg_loss=0.79035]\n","Step 5585    [1.324 sec/step, loss=0.80062, avg_loss=0.79034]\n","Step 5586    [1.327 sec/step, loss=0.79561, avg_loss=0.79033]\n","Step 5587    [1.329 sec/step, loss=0.79984, avg_loss=0.79024]\n","Step 5588    [1.331 sec/step, loss=0.81173, avg_loss=0.79037]\n","Step 5589    [1.327 sec/step, loss=0.76869, avg_loss=0.79041]\n","Step 5590    [1.324 sec/step, loss=0.80708, avg_loss=0.79069]\n","Step 5591    [1.329 sec/step, loss=0.80798, avg_loss=0.79076]\n","Step 5592    [1.346 sec/step, loss=0.77355, avg_loss=0.79070]\n","Step 5593    [1.345 sec/step, loss=0.81581, avg_loss=0.79114]\n","Step 5594    [1.366 sec/step, loss=0.74165, avg_loss=0.79052]\n","Step 5595    [1.370 sec/step, loss=0.78237, avg_loss=0.79019]\n","Step 5596    [1.333 sec/step, loss=0.80363, avg_loss=0.79244]\n","Step 5597    [1.335 sec/step, loss=0.78552, avg_loss=0.79238]\n","Step 5598    [1.341 sec/step, loss=0.80892, avg_loss=0.79254]\n","Generated 32 batches of size 32 in 18.434 sec\n","Step 5599    [1.369 sec/step, loss=0.80950, avg_loss=0.79249]\n","Step 5600    [1.370 sec/step, loss=0.80962, avg_loss=0.79232]\n","Writing summary at step: 5600\n","Step 5601    [1.372 sec/step, loss=0.79809, avg_loss=0.79211]\n","Step 5602    [1.372 sec/step, loss=0.81259, avg_loss=0.79200]\n","Step 5603    [1.379 sec/step, loss=0.80595, avg_loss=0.79215]\n","Step 5604    [1.402 sec/step, loss=0.60270, avg_loss=0.79023]\n","Step 5605    [1.401 sec/step, loss=0.79851, avg_loss=0.79039]\n","Step 5606    [1.398 sec/step, loss=0.79071, avg_loss=0.79000]\n","Step 5607    [1.399 sec/step, loss=0.80473, avg_loss=0.79007]\n","Step 5608    [1.395 sec/step, loss=0.82409, avg_loss=0.79058]\n","Step 5609    [1.394 sec/step, loss=0.80327, avg_loss=0.79063]\n","Step 5610    [1.395 sec/step, loss=0.80458, avg_loss=0.79080]\n","Step 5611    [1.393 sec/step, loss=0.79696, avg_loss=0.79065]\n","Step 5612    [1.394 sec/step, loss=0.79334, avg_loss=0.79053]\n","Step 5613    [1.392 sec/step, loss=0.77076, avg_loss=0.79026]\n","Step 5614    [1.392 sec/step, loss=0.79566, avg_loss=0.78990]\n","Step 5615    [1.388 sec/step, loss=0.78478, avg_loss=0.78967]\n","Step 5616    [1.386 sec/step, loss=0.83375, avg_loss=0.78986]\n","Step 5617    [1.384 sec/step, loss=0.78402, avg_loss=0.78981]\n","Step 5618    [1.378 sec/step, loss=0.80361, avg_loss=0.78959]\n","Step 5619    [1.385 sec/step, loss=0.77789, avg_loss=0.78936]\n","Step 5620    [1.385 sec/step, loss=0.79877, avg_loss=0.78924]\n","Step 5621    [1.394 sec/step, loss=0.77605, avg_loss=0.78911]\n","Step 5622    [1.408 sec/step, loss=0.77935, avg_loss=0.78877]\n","Step 5623    [1.425 sec/step, loss=0.75234, avg_loss=0.78811]\n","Step 5624    [1.428 sec/step, loss=0.79414, avg_loss=0.78802]\n","Step 5625    [1.426 sec/step, loss=0.80942, avg_loss=0.78837]\n","Step 5626    [1.432 sec/step, loss=0.79431, avg_loss=0.78830]\n","Step 5627    [1.438 sec/step, loss=0.82801, avg_loss=0.78853]\n","Step 5628    [1.443 sec/step, loss=0.78865, avg_loss=0.78841]\n","Step 5629    [1.424 sec/step, loss=0.80181, avg_loss=0.78914]\n","Generated 32 batches of size 32 in 19.809 sec\n","Step 5630    [1.463 sec/step, loss=0.78298, avg_loss=0.78894]\n","Step 5631    [1.420 sec/step, loss=0.80413, avg_loss=0.79130]\n","Step 5632    [1.420 sec/step, loss=0.79792, avg_loss=0.79109]\n","Step 5633    [1.425 sec/step, loss=0.73078, avg_loss=0.79045]\n","Step 5634    [1.449 sec/step, loss=0.56930, avg_loss=0.78812]\n","Step 5635    [1.432 sec/step, loss=0.81072, avg_loss=0.78822]\n","Step 5636    [1.432 sec/step, loss=0.80680, avg_loss=0.78814]\n","Step 5637    [1.425 sec/step, loss=0.81380, avg_loss=0.78843]\n","Step 5638    [1.419 sec/step, loss=0.79679, avg_loss=0.78833]\n","Step 5639    [1.427 sec/step, loss=0.77013, avg_loss=0.78796]\n","Step 5640    [1.416 sec/step, loss=0.80151, avg_loss=0.78815]\n","Step 5641    [1.416 sec/step, loss=0.81190, avg_loss=0.78850]\n","Step 5642    [1.418 sec/step, loss=0.79440, avg_loss=0.78860]\n","Step 5643    [1.420 sec/step, loss=0.79221, avg_loss=0.78844]\n","Step 5644    [1.413 sec/step, loss=0.80005, avg_loss=0.78875]\n","Step 5645    [1.408 sec/step, loss=0.78249, avg_loss=0.78874]\n","Step 5646    [1.403 sec/step, loss=0.77883, avg_loss=0.78863]\n","Step 5647    [1.403 sec/step, loss=0.79299, avg_loss=0.78829]\n","Step 5648    [1.405 sec/step, loss=0.78613, avg_loss=0.78818]\n","Step 5649    [1.406 sec/step, loss=0.78072, avg_loss=0.78799]\n","Step 5650    [1.405 sec/step, loss=0.77624, avg_loss=0.78782]\n","Step 5651    [1.401 sec/step, loss=0.79663, avg_loss=0.78794]\n","Step 5652    [1.404 sec/step, loss=0.80399, avg_loss=0.78790]\n","Step 5653    [1.400 sec/step, loss=0.78008, avg_loss=0.78758]\n","Step 5654    [1.409 sec/step, loss=0.78673, avg_loss=0.78763]\n","Step 5655    [1.414 sec/step, loss=0.81039, avg_loss=0.78761]\n","Step 5656    [1.425 sec/step, loss=0.76962, avg_loss=0.78725]\n","Step 5657    [1.429 sec/step, loss=0.79962, avg_loss=0.78721]\n","Step 5658    [1.386 sec/step, loss=0.78809, avg_loss=0.78917]\n","Step 5659    [1.393 sec/step, loss=0.79418, avg_loss=0.78917]\n","Step 5660    [1.393 sec/step, loss=0.77806, avg_loss=0.78896]\n","Step 5661    [1.396 sec/step, loss=0.78833, avg_loss=0.78880]\n","Generated 32 batches of size 32 in 19.235 sec\n","Step 5662    [1.458 sec/step, loss=0.78487, avg_loss=0.78866]\n","Step 5663    [1.480 sec/step, loss=0.61556, avg_loss=0.78696]\n","Step 5664    [1.477 sec/step, loss=0.78683, avg_loss=0.78656]\n","Step 5665    [1.475 sec/step, loss=0.81453, avg_loss=0.78671]\n","Step 5666    [1.466 sec/step, loss=0.78927, avg_loss=0.78655]\n","Step 5667    [1.426 sec/step, loss=0.79947, avg_loss=0.78654]\n","Step 5668    [1.425 sec/step, loss=0.79904, avg_loss=0.78616]\n","Step 5669    [1.426 sec/step, loss=0.78109, avg_loss=0.78590]\n","Step 5670    [1.429 sec/step, loss=0.81413, avg_loss=0.78614]\n","Step 5671    [1.429 sec/step, loss=0.79014, avg_loss=0.78595]\n","Step 5672    [1.433 sec/step, loss=0.77509, avg_loss=0.78586]\n","Step 5673    [1.406 sec/step, loss=0.80080, avg_loss=0.78851]\n","Step 5674    [1.411 sec/step, loss=0.77656, avg_loss=0.78866]\n","Step 5675    [1.419 sec/step, loss=0.80009, avg_loss=0.78859]\n","Step 5676    [1.418 sec/step, loss=0.80616, avg_loss=0.78877]\n","Step 5677    [1.413 sec/step, loss=0.77956, avg_loss=0.78863]\n","Step 5678    [1.412 sec/step, loss=0.77862, avg_loss=0.78850]\n","Step 5679    [1.412 sec/step, loss=0.77695, avg_loss=0.78826]\n","Step 5680    [1.412 sec/step, loss=0.79555, avg_loss=0.78833]\n","Step 5681    [1.415 sec/step, loss=0.81736, avg_loss=0.78826]\n","Step 5682    [1.414 sec/step, loss=0.77648, avg_loss=0.78758]\n","Step 5683    [1.419 sec/step, loss=0.77548, avg_loss=0.78751]\n","Step 5684    [1.420 sec/step, loss=0.79357, avg_loss=0.78735]\n","Step 5685    [1.422 sec/step, loss=0.77874, avg_loss=0.78713]\n","Step 5686    [1.419 sec/step, loss=0.77501, avg_loss=0.78692]\n","Step 5687    [1.425 sec/step, loss=0.79987, avg_loss=0.78692]\n","Step 5688    [1.435 sec/step, loss=0.78398, avg_loss=0.78664]\n","Step 5689    [1.433 sec/step, loss=0.79225, avg_loss=0.78688]\n","Step 5690    [1.433 sec/step, loss=0.76817, avg_loss=0.78649]\n","Step 5691    [1.432 sec/step, loss=0.78853, avg_loss=0.78630]\n","Step 5692    [1.422 sec/step, loss=0.78708, avg_loss=0.78643]\n","Step 5693    [1.422 sec/step, loss=0.79885, avg_loss=0.78626]\n","Generated 32 batches of size 32 in 19.524 sec\n","Step 5694    [1.480 sec/step, loss=0.80501, avg_loss=0.78690]\n","Step 5695    [1.479 sec/step, loss=0.77533, avg_loss=0.78683]\n","Step 5696    [1.478 sec/step, loss=0.79659, avg_loss=0.78676]\n","Step 5697    [1.477 sec/step, loss=0.78680, avg_loss=0.78677]\n","Step 5698    [1.468 sec/step, loss=0.79252, avg_loss=0.78660]\n","Step 5699    [1.433 sec/step, loss=0.76309, avg_loss=0.78614]\n","Step 5700    [1.431 sec/step, loss=0.78136, avg_loss=0.78586]\n","Writing summary at step: 5700\n","Step 5701    [1.431 sec/step, loss=0.77120, avg_loss=0.78559]\n","Step 5702    [1.431 sec/step, loss=0.77622, avg_loss=0.78522]\n","Step 5703    [1.424 sec/step, loss=0.80962, avg_loss=0.78526]\n","Step 5704    [1.408 sec/step, loss=0.82908, avg_loss=0.78753]\n","Step 5705    [1.440 sec/step, loss=0.52302, avg_loss=0.78477]\n","Step 5706    [1.436 sec/step, loss=0.82006, avg_loss=0.78506]\n","Step 5707    [1.437 sec/step, loss=0.77390, avg_loss=0.78476]\n","Step 5708    [1.434 sec/step, loss=0.79984, avg_loss=0.78451]\n","Step 5709    [1.434 sec/step, loss=0.80448, avg_loss=0.78453]\n","Step 5710    [1.433 sec/step, loss=0.79782, avg_loss=0.78446]\n","Step 5711    [1.437 sec/step, loss=0.79431, avg_loss=0.78443]\n","Step 5712    [1.444 sec/step, loss=0.75363, avg_loss=0.78403]\n","Step 5713    [1.448 sec/step, loss=0.77488, avg_loss=0.78408]\n","Step 5714    [1.452 sec/step, loss=0.79006, avg_loss=0.78402]\n","Step 5715    [1.452 sec/step, loss=0.80801, avg_loss=0.78425]\n","Step 5716    [1.457 sec/step, loss=0.78452, avg_loss=0.78376]\n","Step 5717    [1.459 sec/step, loss=0.80042, avg_loss=0.78392]\n","Step 5718    [1.457 sec/step, loss=0.76904, avg_loss=0.78358]\n","Step 5719    [1.456 sec/step, loss=0.80184, avg_loss=0.78382]\n","Step 5720    [1.459 sec/step, loss=0.80265, avg_loss=0.78386]\n","Step 5721    [1.456 sec/step, loss=0.76886, avg_loss=0.78378]\n","Step 5722    [1.464 sec/step, loss=0.74419, avg_loss=0.78343]\n","Step 5723    [1.452 sec/step, loss=0.81108, avg_loss=0.78402]\n","Step 5724    [1.456 sec/step, loss=0.79511, avg_loss=0.78403]\n","Generated 32 batches of size 32 in 19.550 sec\n","Step 5725    [1.518 sec/step, loss=0.79164, avg_loss=0.78385]\n","Step 5726    [1.503 sec/step, loss=0.80430, avg_loss=0.78395]\n","Step 5727    [1.497 sec/step, loss=0.79650, avg_loss=0.78364]\n","Step 5728    [1.487 sec/step, loss=0.79411, avg_loss=0.78369]\n","Step 5729    [1.487 sec/step, loss=0.78996, avg_loss=0.78357]\n","Step 5730    [1.444 sec/step, loss=0.79201, avg_loss=0.78366]\n","Step 5731    [1.455 sec/step, loss=0.72309, avg_loss=0.78285]\n","Step 5732    [1.450 sec/step, loss=0.81552, avg_loss=0.78303]\n","Step 5733    [1.441 sec/step, loss=0.78013, avg_loss=0.78352]\n","Step 5734    [1.412 sec/step, loss=0.77873, avg_loss=0.78562]\n","Step 5735    [1.413 sec/step, loss=0.83735, avg_loss=0.78588]\n","Step 5736    [1.410 sec/step, loss=0.78874, avg_loss=0.78570]\n","Step 5737    [1.415 sec/step, loss=0.79252, avg_loss=0.78549]\n","Step 5738    [1.415 sec/step, loss=0.81463, avg_loss=0.78567]\n","Step 5739    [1.413 sec/step, loss=0.78431, avg_loss=0.78581]\n","Step 5740    [1.411 sec/step, loss=0.80098, avg_loss=0.78580]\n","Step 5741    [1.412 sec/step, loss=0.78961, avg_loss=0.78558]\n","Step 5742    [1.409 sec/step, loss=0.80767, avg_loss=0.78571]\n","Step 5743    [1.411 sec/step, loss=0.81025, avg_loss=0.78589]\n","Step 5744    [1.409 sec/step, loss=0.83499, avg_loss=0.78624]\n","Step 5745    [1.410 sec/step, loss=0.83231, avg_loss=0.78674]\n","Step 5746    [1.415 sec/step, loss=0.82752, avg_loss=0.78723]\n","Step 5747    [1.417 sec/step, loss=0.77786, avg_loss=0.78708]\n","Step 5748    [1.421 sec/step, loss=0.82581, avg_loss=0.78747]\n","Step 5749    [1.427 sec/step, loss=0.81263, avg_loss=0.78779]\n","Step 5750    [1.465 sec/step, loss=0.61041, avg_loss=0.78614]\n","Step 5751    [1.477 sec/step, loss=0.81267, avg_loss=0.78630]\n","Step 5752    [1.492 sec/step, loss=0.79449, avg_loss=0.78620]\n","Step 5753    [1.495 sec/step, loss=0.80128, avg_loss=0.78641]\n","Step 5754    [1.492 sec/step, loss=0.79211, avg_loss=0.78647]\n","Step 5755    [1.491 sec/step, loss=0.81550, avg_loss=0.78652]\n","Step 5756    [1.483 sec/step, loss=0.80310, avg_loss=0.78685]\n","Generated 32 batches of size 32 in 18.654 sec\n","Step 5757    [1.496 sec/step, loss=0.81991, avg_loss=0.78706]\n","Step 5758    [1.492 sec/step, loss=0.79814, avg_loss=0.78716]\n","Step 5759    [1.480 sec/step, loss=0.80779, avg_loss=0.78729]\n","Step 5760    [1.483 sec/step, loss=0.81385, avg_loss=0.78765]\n","Step 5761    [1.476 sec/step, loss=0.78929, avg_loss=0.78766]\n","Step 5762    [1.409 sec/step, loss=0.79477, avg_loss=0.78776]\n","Step 5763    [1.384 sec/step, loss=0.78685, avg_loss=0.78947]\n","Step 5764    [1.384 sec/step, loss=0.81184, avg_loss=0.78972]\n","Step 5765    [1.383 sec/step, loss=0.81467, avg_loss=0.78972]\n","Step 5766    [1.391 sec/step, loss=0.78205, avg_loss=0.78965]\n","Step 5767    [1.394 sec/step, loss=0.80809, avg_loss=0.78974]\n","Step 5768    [1.398 sec/step, loss=0.79798, avg_loss=0.78973]\n","Step 5769    [1.405 sec/step, loss=0.79982, avg_loss=0.78991]\n","Step 5770    [1.407 sec/step, loss=0.79585, avg_loss=0.78973]\n","Step 5771    [1.408 sec/step, loss=0.78561, avg_loss=0.78969]\n","Step 5772    [1.405 sec/step, loss=0.79803, avg_loss=0.78992]\n","Step 5773    [1.413 sec/step, loss=0.75036, avg_loss=0.78941]\n","Step 5774    [1.403 sec/step, loss=0.79687, avg_loss=0.78961]\n","Step 5775    [1.398 sec/step, loss=0.79014, avg_loss=0.78951]\n","Step 5776    [1.400 sec/step, loss=0.80182, avg_loss=0.78947]\n","Step 5777    [1.399 sec/step, loss=0.79799, avg_loss=0.78966]\n","Step 5778    [1.399 sec/step, loss=0.77096, avg_loss=0.78958]\n","Step 5779    [1.394 sec/step, loss=0.81036, avg_loss=0.78991]\n","Step 5780    [1.396 sec/step, loss=0.83027, avg_loss=0.79026]\n","Step 5781    [1.395 sec/step, loss=0.77704, avg_loss=0.78986]\n","Step 5782    [1.404 sec/step, loss=0.77364, avg_loss=0.78983]\n","Step 5783    [1.434 sec/step, loss=0.65661, avg_loss=0.78864]\n","Step 5784    [1.439 sec/step, loss=0.77365, avg_loss=0.78844]\n","Step 5785    [1.445 sec/step, loss=0.78196, avg_loss=0.78847]\n","Step 5786    [1.449 sec/step, loss=0.78328, avg_loss=0.78856]\n","Step 5787    [1.445 sec/step, loss=0.79418, avg_loss=0.78850]\n","Step 5788    [1.440 sec/step, loss=0.79153, avg_loss=0.78857]\n","Generated 32 batches of size 32 in 18.808 sec\n","Step 5789    [1.467 sec/step, loss=0.77215, avg_loss=0.78837]\n","Step 5790    [1.470 sec/step, loss=0.80273, avg_loss=0.78872]\n","Step 5791    [1.465 sec/step, loss=0.77518, avg_loss=0.78858]\n","Step 5792    [1.461 sec/step, loss=0.80413, avg_loss=0.78876]\n","Step 5793    [1.459 sec/step, loss=0.78445, avg_loss=0.78861]\n","Step 5794    [1.379 sec/step, loss=0.78427, avg_loss=0.78840]\n","Step 5795    [1.375 sec/step, loss=0.78244, avg_loss=0.78848]\n","Step 5796    [1.372 sec/step, loss=0.79655, avg_loss=0.78847]\n","Step 5797    [1.373 sec/step, loss=0.77022, avg_loss=0.78831]\n","Step 5798    [1.374 sec/step, loss=0.80217, avg_loss=0.78841]\n","Step 5799    [1.382 sec/step, loss=0.75283, avg_loss=0.78830]\n","Step 5800    [1.380 sec/step, loss=0.77451, avg_loss=0.78823]\n","Writing summary at step: 5800\n","Step 5801    [1.381 sec/step, loss=0.78409, avg_loss=0.78836]\n","Step 5802    [1.384 sec/step, loss=0.77280, avg_loss=0.78833]\n","Step 5803    [1.383 sec/step, loss=0.78944, avg_loss=0.78813]\n","Step 5804    [1.379 sec/step, loss=0.78577, avg_loss=0.78769]\n","Step 5805    [1.347 sec/step, loss=0.80953, avg_loss=0.79056]\n","Step 5806    [1.352 sec/step, loss=0.78832, avg_loss=0.79024]\n","Step 5807    [1.358 sec/step, loss=0.76980, avg_loss=0.79020]\n","Step 5808    [1.358 sec/step, loss=0.78120, avg_loss=0.79001]\n","Step 5809    [1.367 sec/step, loss=0.76594, avg_loss=0.78963]\n","Step 5810    [1.371 sec/step, loss=0.77206, avg_loss=0.78937]\n","Step 5811    [1.369 sec/step, loss=0.78172, avg_loss=0.78925]\n","Step 5812    [1.373 sec/step, loss=0.77406, avg_loss=0.78945]\n","Step 5813    [1.375 sec/step, loss=0.77383, avg_loss=0.78944]\n","Step 5814    [1.375 sec/step, loss=0.77412, avg_loss=0.78928]\n","Step 5815    [1.379 sec/step, loss=0.83528, avg_loss=0.78955]\n","Step 5816    [1.375 sec/step, loss=0.76472, avg_loss=0.78935]\n","Step 5817    [1.421 sec/step, loss=0.55383, avg_loss=0.78689]\n","Step 5818    [1.427 sec/step, loss=0.77672, avg_loss=0.78697]\n","Step 5819    [1.428 sec/step, loss=0.78797, avg_loss=0.78683]\n","Generated 32 batches of size 32 in 19.541 sec\n","Step 5820    [1.459 sec/step, loss=0.78598, avg_loss=0.78666]\n","Step 5821    [1.455 sec/step, loss=0.80156, avg_loss=0.78699]\n","Step 5822    [1.432 sec/step, loss=0.78137, avg_loss=0.78736]\n","Step 5823    [1.425 sec/step, loss=0.77962, avg_loss=0.78704]\n","Step 5824    [1.417 sec/step, loss=0.79623, avg_loss=0.78706]\n","Step 5825    [1.358 sec/step, loss=0.76539, avg_loss=0.78679]\n","Step 5826    [1.363 sec/step, loss=0.79155, avg_loss=0.78667]\n","Step 5827    [1.360 sec/step, loss=0.79105, avg_loss=0.78661]\n","Step 5828    [1.364 sec/step, loss=0.78721, avg_loss=0.78654]\n","Step 5829    [1.366 sec/step, loss=0.79966, avg_loss=0.78664]\n","Step 5830    [1.358 sec/step, loss=0.79054, avg_loss=0.78662]\n","Step 5831    [1.346 sec/step, loss=0.78117, avg_loss=0.78720]\n","Step 5832    [1.357 sec/step, loss=0.73980, avg_loss=0.78645]\n","Step 5833    [1.354 sec/step, loss=0.80186, avg_loss=0.78666]\n","Step 5834    [1.355 sec/step, loss=0.78753, avg_loss=0.78675]\n","Step 5835    [1.361 sec/step, loss=0.76531, avg_loss=0.78603]\n","Step 5836    [1.362 sec/step, loss=0.77124, avg_loss=0.78586]\n","Step 5837    [1.360 sec/step, loss=0.75731, avg_loss=0.78551]\n","Step 5838    [1.362 sec/step, loss=0.78717, avg_loss=0.78523]\n","Step 5839    [1.362 sec/step, loss=0.77883, avg_loss=0.78518]\n","Step 5840    [1.364 sec/step, loss=0.79719, avg_loss=0.78514]\n","Step 5841    [1.366 sec/step, loss=0.78294, avg_loss=0.78507]\n","Step 5842    [1.367 sec/step, loss=0.78567, avg_loss=0.78485]\n","Step 5843    [1.371 sec/step, loss=0.77558, avg_loss=0.78450]\n","Step 5844    [1.378 sec/step, loss=0.79200, avg_loss=0.78407]\n","Step 5845    [1.385 sec/step, loss=0.76757, avg_loss=0.78343]\n","Step 5846    [1.383 sec/step, loss=0.78932, avg_loss=0.78305]\n","Step 5847    [1.382 sec/step, loss=0.79292, avg_loss=0.78320]\n","Step 5848    [1.382 sec/step, loss=0.77928, avg_loss=0.78273]\n","Step 5849    [1.414 sec/step, loss=0.57753, avg_loss=0.78038]\n","Step 5850    [1.378 sec/step, loss=0.77394, avg_loss=0.78201]\n","Step 5851    [1.377 sec/step, loss=0.78800, avg_loss=0.78177]\n","Generated 32 batches of size 32 in 19.818 sec\n","Step 5852    [1.402 sec/step, loss=0.80042, avg_loss=0.78183]\n","Step 5853    [1.402 sec/step, loss=0.79574, avg_loss=0.78177]\n","Step 5854    [1.395 sec/step, loss=0.79106, avg_loss=0.78176]\n","Step 5855    [1.391 sec/step, loss=0.78111, avg_loss=0.78142]\n","Step 5856    [1.392 sec/step, loss=0.79772, avg_loss=0.78136]\n","Step 5857    [1.379 sec/step, loss=0.82611, avg_loss=0.78143]\n","Step 5858    [1.377 sec/step, loss=0.76847, avg_loss=0.78113]\n","Step 5859    [1.382 sec/step, loss=0.78840, avg_loss=0.78094]\n","Step 5860    [1.378 sec/step, loss=0.82202, avg_loss=0.78102]\n","Step 5861    [1.375 sec/step, loss=0.79526, avg_loss=0.78108]\n","Step 5862    [1.374 sec/step, loss=0.77854, avg_loss=0.78091]\n","Step 5863    [1.402 sec/step, loss=0.61427, avg_loss=0.77919]\n","Step 5864    [1.403 sec/step, loss=0.80597, avg_loss=0.77913]\n","Step 5865    [1.406 sec/step, loss=0.80903, avg_loss=0.77907]\n","Step 5866    [1.401 sec/step, loss=0.81180, avg_loss=0.77937]\n","Step 5867    [1.400 sec/step, loss=0.79083, avg_loss=0.77920]\n","Step 5868    [1.398 sec/step, loss=0.76541, avg_loss=0.77887]\n","Step 5869    [1.390 sec/step, loss=0.81008, avg_loss=0.77898]\n","Step 5870    [1.388 sec/step, loss=0.79266, avg_loss=0.77894]\n","Step 5871    [1.386 sec/step, loss=0.78748, avg_loss=0.77896]\n","Step 5872    [1.390 sec/step, loss=0.78131, avg_loss=0.77879]\n","Step 5873    [1.377 sec/step, loss=0.78809, avg_loss=0.77917]\n","Step 5874    [1.379 sec/step, loss=0.79344, avg_loss=0.77914]\n","Step 5875    [1.381 sec/step, loss=0.79234, avg_loss=0.77916]\n","Step 5876    [1.402 sec/step, loss=0.72493, avg_loss=0.77839]\n","Step 5877    [1.417 sec/step, loss=0.80469, avg_loss=0.77846]\n","Step 5878    [1.422 sec/step, loss=0.81167, avg_loss=0.77887]\n","Step 5879    [1.433 sec/step, loss=0.77313, avg_loss=0.77849]\n","Step 5880    [1.435 sec/step, loss=0.77035, avg_loss=0.77789]\n","Step 5881    [1.448 sec/step, loss=0.76288, avg_loss=0.77775]\n","Step 5882    [1.436 sec/step, loss=0.79288, avg_loss=0.77794]\n","Step 5883    [1.410 sec/step, loss=0.78501, avg_loss=0.77923]\n","Generated 32 batches of size 32 in 19.773 sec\n","Step 5884    [1.442 sec/step, loss=0.79674, avg_loss=0.77946]\n","Step 5885    [1.437 sec/step, loss=0.77281, avg_loss=0.77937]\n","Step 5886    [1.433 sec/step, loss=0.79061, avg_loss=0.77944]\n","Step 5887    [1.430 sec/step, loss=0.80343, avg_loss=0.77953]\n","Step 5888    [1.423 sec/step, loss=0.80450, avg_loss=0.77966]\n","Step 5889    [1.399 sec/step, loss=0.77265, avg_loss=0.77967]\n","Step 5890    [1.401 sec/step, loss=0.77772, avg_loss=0.77942]\n","Step 5891    [1.412 sec/step, loss=0.74121, avg_loss=0.77908]\n","Step 5892    [1.411 sec/step, loss=0.77155, avg_loss=0.77875]\n","Step 5893    [1.409 sec/step, loss=0.79715, avg_loss=0.77888]\n","Step 5894    [1.412 sec/step, loss=0.82161, avg_loss=0.77925]\n","Step 5895    [1.413 sec/step, loss=0.78959, avg_loss=0.77932]\n","Step 5896    [1.416 sec/step, loss=0.81416, avg_loss=0.77950]\n","Step 5897    [1.411 sec/step, loss=0.76079, avg_loss=0.77941]\n","Step 5898    [1.410 sec/step, loss=0.76875, avg_loss=0.77907]\n","Step 5899    [1.399 sec/step, loss=0.79581, avg_loss=0.77950]\n","Step 5900    [1.424 sec/step, loss=0.64613, avg_loss=0.77822]\n","Writing summary at step: 5900\n","Step 5901    [1.420 sec/step, loss=0.80028, avg_loss=0.77838]\n","Step 5902    [1.417 sec/step, loss=0.77867, avg_loss=0.77844]\n","Step 5903    [1.418 sec/step, loss=0.79217, avg_loss=0.77847]\n","Step 5904    [1.421 sec/step, loss=0.73815, avg_loss=0.77799]\n","Step 5905    [1.424 sec/step, loss=0.79552, avg_loss=0.77785]\n","Step 5906    [1.424 sec/step, loss=0.77930, avg_loss=0.77776]\n","Step 5907    [1.425 sec/step, loss=0.78315, avg_loss=0.77789]\n","Step 5908    [1.434 sec/step, loss=0.77146, avg_loss=0.77780]\n","Step 5909    [1.428 sec/step, loss=0.78460, avg_loss=0.77798]\n","Step 5910    [1.427 sec/step, loss=0.80413, avg_loss=0.77830]\n","Step 5911    [1.436 sec/step, loss=0.77923, avg_loss=0.77828]\n","Step 5912    [1.428 sec/step, loss=0.77419, avg_loss=0.77828]\n","Step 5913    [1.426 sec/step, loss=0.78517, avg_loss=0.77839]\n","Step 5914    [1.429 sec/step, loss=0.78191, avg_loss=0.77847]\n","Generated 32 batches of size 32 in 19.456 sec\n","Step 5915    [1.518 sec/step, loss=0.68653, avg_loss=0.77698]\n","Step 5916    [1.516 sec/step, loss=0.81069, avg_loss=0.77744]\n","Step 5917    [1.468 sec/step, loss=0.80763, avg_loss=0.77998]\n","Step 5918    [1.464 sec/step, loss=0.76192, avg_loss=0.77983]\n","Step 5919    [1.460 sec/step, loss=0.79080, avg_loss=0.77986]\n","Step 5920    [1.427 sec/step, loss=0.79101, avg_loss=0.77991]\n","Step 5921    [1.427 sec/step, loss=0.76873, avg_loss=0.77958]\n","Step 5922    [1.429 sec/step, loss=0.79201, avg_loss=0.77969]\n","Step 5923    [1.432 sec/step, loss=0.79596, avg_loss=0.77985]\n","Step 5924    [1.432 sec/step, loss=0.79131, avg_loss=0.77980]\n","Step 5925    [1.426 sec/step, loss=0.76946, avg_loss=0.77984]\n","Step 5926    [1.424 sec/step, loss=0.77664, avg_loss=0.77970]\n","Step 5927    [1.427 sec/step, loss=0.81259, avg_loss=0.77991]\n","Step 5928    [1.428 sec/step, loss=0.77225, avg_loss=0.77976]\n","Step 5929    [1.426 sec/step, loss=0.81534, avg_loss=0.77992]\n","Step 5930    [1.425 sec/step, loss=0.78771, avg_loss=0.77989]\n","Step 5931    [1.424 sec/step, loss=0.79160, avg_loss=0.77999]\n","Step 5932    [1.418 sec/step, loss=0.77608, avg_loss=0.78036]\n","Step 5933    [1.418 sec/step, loss=0.81102, avg_loss=0.78045]\n","Step 5934    [1.418 sec/step, loss=0.79937, avg_loss=0.78057]\n","Step 5935    [1.418 sec/step, loss=0.76193, avg_loss=0.78053]\n","Step 5936    [1.416 sec/step, loss=0.78971, avg_loss=0.78072]\n","Step 5937    [1.418 sec/step, loss=0.79612, avg_loss=0.78111]\n","Step 5938    [1.436 sec/step, loss=0.73526, avg_loss=0.78059]\n","Step 5939    [1.433 sec/step, loss=0.81732, avg_loss=0.78097]\n","Step 5940    [1.434 sec/step, loss=0.82723, avg_loss=0.78127]\n","Step 5941    [1.433 sec/step, loss=0.79233, avg_loss=0.78137]\n","Step 5942    [1.448 sec/step, loss=0.79570, avg_loss=0.78147]\n","Step 5943    [1.448 sec/step, loss=0.76155, avg_loss=0.78133]\n","Step 5944    [1.453 sec/step, loss=0.78919, avg_loss=0.78130]\n","Step 5945    [1.450 sec/step, loss=0.79385, avg_loss=0.78156]\n","Step 5946    [1.454 sec/step, loss=0.80015, avg_loss=0.78167]\n","Generated 32 batches of size 32 in 18.166 sec\n","Step 5947    [1.489 sec/step, loss=0.77911, avg_loss=0.78153]\n","Step 5948    [1.483 sec/step, loss=0.81004, avg_loss=0.78184]\n","Step 5949    [1.445 sec/step, loss=0.79031, avg_loss=0.78397]\n","Step 5950    [1.446 sec/step, loss=0.77857, avg_loss=0.78401]\n","Step 5951    [1.439 sec/step, loss=0.79613, avg_loss=0.78409]\n","Step 5952    [1.395 sec/step, loss=0.78183, avg_loss=0.78391]\n","Step 5953    [1.391 sec/step, loss=0.78361, avg_loss=0.78379]\n","Step 5954    [1.391 sec/step, loss=0.79260, avg_loss=0.78380]\n","Step 5955    [1.395 sec/step, loss=0.77814, avg_loss=0.78377]\n","Step 5956    [1.395 sec/step, loss=0.75855, avg_loss=0.78338]\n","Step 5957    [1.395 sec/step, loss=0.77960, avg_loss=0.78292]\n","Step 5958    [1.398 sec/step, loss=0.79298, avg_loss=0.78316]\n","Step 5959    [1.391 sec/step, loss=0.79264, avg_loss=0.78320]\n","Step 5960    [1.401 sec/step, loss=0.71948, avg_loss=0.78218]\n","Step 5961    [1.401 sec/step, loss=0.77725, avg_loss=0.78200]\n","Step 5962    [1.404 sec/step, loss=0.77431, avg_loss=0.78196]\n","Step 5963    [1.377 sec/step, loss=0.78291, avg_loss=0.78364]\n","Step 5964    [1.382 sec/step, loss=0.78467, avg_loss=0.78343]\n","Step 5965    [1.381 sec/step, loss=0.78835, avg_loss=0.78322]\n","Step 5966    [1.378 sec/step, loss=0.77552, avg_loss=0.78286]\n","Step 5967    [1.378 sec/step, loss=0.77844, avg_loss=0.78273]\n","Step 5968    [1.376 sec/step, loss=0.77600, avg_loss=0.78284]\n","Step 5969    [1.381 sec/step, loss=0.78519, avg_loss=0.78259]\n","Step 5970    [1.385 sec/step, loss=0.80688, avg_loss=0.78273]\n","Step 5971    [1.401 sec/step, loss=0.77211, avg_loss=0.78258]\n","Step 5972    [1.431 sec/step, loss=0.66835, avg_loss=0.78145]\n","Step 5973    [1.437 sec/step, loss=0.78280, avg_loss=0.78140]\n","Step 5974    [1.442 sec/step, loss=0.79997, avg_loss=0.78146]\n","Step 5975    [1.440 sec/step, loss=0.78873, avg_loss=0.78143]\n","Step 5976    [1.423 sec/step, loss=0.77324, avg_loss=0.78191]\n","Step 5977    [1.422 sec/step, loss=0.77608, avg_loss=0.78162]\n","Step 5978    [1.421 sec/step, loss=0.80519, avg_loss=0.78156]\n","Generated 32 batches of size 32 in 19.015 sec\n","Step 5979    [1.470 sec/step, loss=0.50377, avg_loss=0.77887]\n","Step 5980    [1.465 sec/step, loss=0.78868, avg_loss=0.77905]\n","Step 5981    [1.451 sec/step, loss=0.79418, avg_loss=0.77936]\n","Step 5982    [1.452 sec/step, loss=0.76965, avg_loss=0.77913]\n","Step 5983    [1.445 sec/step, loss=0.79465, avg_loss=0.77923]\n","Step 5984    [1.406 sec/step, loss=0.77994, avg_loss=0.77906]\n","Step 5985    [1.403 sec/step, loss=0.78139, avg_loss=0.77914]\n","Step 5986    [1.404 sec/step, loss=0.79623, avg_loss=0.77920]\n","Step 5987    [1.405 sec/step, loss=0.80078, avg_loss=0.77917]\n","Step 5988    [1.415 sec/step, loss=0.72185, avg_loss=0.77835]\n","Step 5989    [1.410 sec/step, loss=0.79828, avg_loss=0.77860]\n","Step 5990    [1.409 sec/step, loss=0.77829, avg_loss=0.77861]\n","Step 5991    [1.402 sec/step, loss=0.75533, avg_loss=0.77875]\n","Step 5992    [1.400 sec/step, loss=0.78978, avg_loss=0.77893]\n","Step 5993    [1.401 sec/step, loss=0.77616, avg_loss=0.77872]\n","Step 5994    [1.403 sec/step, loss=0.79844, avg_loss=0.77849]\n","Step 5995    [1.404 sec/step, loss=0.79148, avg_loss=0.77851]\n","Step 5996    [1.407 sec/step, loss=0.78496, avg_loss=0.77822]\n","Step 5997    [1.413 sec/step, loss=0.78726, avg_loss=0.77848]\n","Step 5998    [1.413 sec/step, loss=0.78244, avg_loss=0.77862]\n","Step 5999    [1.413 sec/step, loss=0.79124, avg_loss=0.77857]\n","Step 6000    [1.387 sec/step, loss=0.79391, avg_loss=0.78005]\n","Writing summary at step: 6000\n","Saving checkpoint to: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/model.ckpt-6000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (75300,)\n","Check wav file:  (105300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000006000-align000.png\n","100% 1/1 [00:04<00:00,  4.54s/it]\n","Test finished for step 6000.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (153900,)\n","Check wav file:  (183900,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000006000-align000.png\n"," 25% 1/4 [00:08<00:25,  8.55s/it]Generated 32 batches of size 32 in 20.449 sec\n","Check wav file before change:  (153900,)\n","Check wav file:  (183900,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000006000-align001.png\n"," 50% 2/4 [00:15<00:16,  8.17s/it]Check wav file before change:  (153900,)\n","Check wav file:  (183900,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000006000-align002.png\n"," 75% 3/4 [00:20<00:07,  7.26s/it]Check wav file before change:  (153900,)\n","Check wav file:  (183900,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000006000-align003.png\n","100% 4/4 [00:26<00:00,  6.57s/it]\n","Test finished for step 6000.\n","Step 6001    [1.392 sec/step, loss=0.78407, avg_loss=0.77989]\n","Step 6002    [1.390 sec/step, loss=0.78599, avg_loss=0.77996]\n","Step 6003    [1.389 sec/step, loss=0.76114, avg_loss=0.77965]\n","Step 6004    [1.382 sec/step, loss=0.78978, avg_loss=0.78017]\n","Step 6005    [1.384 sec/step, loss=0.76690, avg_loss=0.77988]\n","Step 6006    [1.385 sec/step, loss=0.79046, avg_loss=0.77999]\n","Step 6007    [1.379 sec/step, loss=0.77078, avg_loss=0.77987]\n","Step 6008    [1.370 sec/step, loss=0.76543, avg_loss=0.77981]\n","Step 6009    [1.375 sec/step, loss=0.79417, avg_loss=0.77991]\n","Step 6010    [1.376 sec/step, loss=0.76684, avg_loss=0.77953]\n","Step 6011    [1.363 sec/step, loss=0.78080, avg_loss=0.77955]\n","Step 6012    [1.359 sec/step, loss=0.77853, avg_loss=0.77959]\n","Step 6013    [1.379 sec/step, loss=0.56452, avg_loss=0.77739]\n","Step 6014    [1.372 sec/step, loss=0.79170, avg_loss=0.77748]\n","Step 6015    [1.278 sec/step, loss=0.78963, avg_loss=0.77851]\n","Step 6016    [1.280 sec/step, loss=0.78437, avg_loss=0.77825]\n","Step 6017    [1.278 sec/step, loss=0.79020, avg_loss=0.77808]\n","Step 6018    [1.279 sec/step, loss=0.79822, avg_loss=0.77844]\n","Step 6019    [1.278 sec/step, loss=0.78746, avg_loss=0.77841]\n","Step 6020    [1.282 sec/step, loss=0.78045, avg_loss=0.77830]\n","Step 6021    [1.278 sec/step, loss=0.79906, avg_loss=0.77860]\n","Step 6022    [1.279 sec/step, loss=0.79804, avg_loss=0.77866]\n","Step 6023    [1.276 sec/step, loss=0.80048, avg_loss=0.77871]\n","Step 6024    [1.283 sec/step, loss=0.77357, avg_loss=0.77853]\n","Step 6025    [1.288 sec/step, loss=0.75567, avg_loss=0.77839]\n","Step 6026    [1.287 sec/step, loss=0.80601, avg_loss=0.77869]\n","Step 6027    [1.286 sec/step, loss=0.81119, avg_loss=0.77867]\n","Step 6028    [1.282 sec/step, loss=0.77658, avg_loss=0.77872]\n","Step 6029    [1.281 sec/step, loss=0.80329, avg_loss=0.77860]\n","Step 6030    [1.284 sec/step, loss=0.75523, avg_loss=0.77827]\n","Step 6031    [1.283 sec/step, loss=0.78278, avg_loss=0.77818]\n","Step 6032    [1.292 sec/step, loss=0.75836, avg_loss=0.77801]\n","Step 6033    [1.299 sec/step, loss=0.79408, avg_loss=0.77784]\n","Step 6034    [1.304 sec/step, loss=0.77791, avg_loss=0.77762]\n","Step 6035    [1.299 sec/step, loss=0.80318, avg_loss=0.77804]\n","Step 6036    [1.302 sec/step, loss=0.78372, avg_loss=0.77798]\n","Step 6037    [1.312 sec/step, loss=0.74108, avg_loss=0.77743]\n","Step 6038    [1.300 sec/step, loss=0.78937, avg_loss=0.77797]\n","Step 6039    [1.315 sec/step, loss=0.73300, avg_loss=0.77712]\n","Step 6040    [1.319 sec/step, loss=0.75995, avg_loss=0.77645]\n","Generated 32 batches of size 32 in 19.631 sec\n","Step 6041    [1.366 sec/step, loss=0.78886, avg_loss=0.77642]\n","Step 6042    [1.355 sec/step, loss=0.80249, avg_loss=0.77648]\n","Step 6043    [1.347 sec/step, loss=0.78439, avg_loss=0.77671]\n","Step 6044    [1.335 sec/step, loss=0.77985, avg_loss=0.77662]\n","Step 6045    [1.335 sec/step, loss=0.75828, avg_loss=0.77626]\n","Step 6046    [1.330 sec/step, loss=0.78573, avg_loss=0.77612]\n","Step 6047    [1.296 sec/step, loss=0.79326, avg_loss=0.77626]\n","Step 6048    [1.299 sec/step, loss=0.76902, avg_loss=0.77585]\n","Step 6049    [1.302 sec/step, loss=0.80485, avg_loss=0.77600]\n","Step 6050    [1.296 sec/step, loss=0.78623, avg_loss=0.77607]\n","Step 6051    [1.294 sec/step, loss=0.77555, avg_loss=0.77587]\n","Step 6052    [1.295 sec/step, loss=0.78329, avg_loss=0.77588]\n","Step 6053    [1.292 sec/step, loss=0.78771, avg_loss=0.77592]\n","Step 6054    [1.290 sec/step, loss=0.77600, avg_loss=0.77576]\n","Step 6055    [1.287 sec/step, loss=0.77363, avg_loss=0.77571]\n","Step 6056    [1.284 sec/step, loss=0.77539, avg_loss=0.77588]\n","Step 6057    [1.283 sec/step, loss=0.78221, avg_loss=0.77590]\n","Step 6058    [1.283 sec/step, loss=0.78832, avg_loss=0.77586]\n","Step 6059    [1.287 sec/step, loss=0.79435, avg_loss=0.77588]\n","Step 6060    [1.277 sec/step, loss=0.79027, avg_loss=0.77658]\n","Step 6061    [1.278 sec/step, loss=0.76530, avg_loss=0.77646]\n","Step 6062    [1.283 sec/step, loss=0.77842, avg_loss=0.77650]\n","Step 6063    [1.283 sec/step, loss=0.79599, avg_loss=0.77664]\n","Step 6064    [1.288 sec/step, loss=0.77667, avg_loss=0.77656]\n","Step 6065    [1.295 sec/step, loss=0.76574, avg_loss=0.77633]\n","Step 6066    [1.340 sec/step, loss=0.56577, avg_loss=0.77423]\n","Step 6067    [1.353 sec/step, loss=0.76869, avg_loss=0.77413]\n","Step 6068    [1.371 sec/step, loss=0.71092, avg_loss=0.77348]\n","Step 6069    [1.374 sec/step, loss=0.80024, avg_loss=0.77363]\n","Step 6070    [1.375 sec/step, loss=0.80158, avg_loss=0.77358]\n","Step 6071    [1.363 sec/step, loss=0.78032, avg_loss=0.77366]\n","Step 6072    [1.333 sec/step, loss=0.77812, avg_loss=0.77476]\n","Generated 32 batches of size 32 in 19.713 sec\n","Step 6073    [1.339 sec/step, loss=0.78296, avg_loss=0.77476]\n","Step 6074    [1.330 sec/step, loss=0.77410, avg_loss=0.77450]\n","Step 6075    [1.331 sec/step, loss=0.76185, avg_loss=0.77424]\n","Step 6076    [1.332 sec/step, loss=0.77086, avg_loss=0.77421]\n","Step 6077    [1.317 sec/step, loss=0.80384, avg_loss=0.77449]\n","Step 6078    [1.314 sec/step, loss=0.77241, avg_loss=0.77416]\n","Step 6079    [1.254 sec/step, loss=0.78315, avg_loss=0.77695]\n","Step 6080    [1.252 sec/step, loss=0.77613, avg_loss=0.77683]\n","Step 6081    [1.263 sec/step, loss=0.76069, avg_loss=0.77649]\n","Step 6082    [1.259 sec/step, loss=0.79983, avg_loss=0.77680]\n","Step 6083    [1.260 sec/step, loss=0.78259, avg_loss=0.77668]\n","Step 6084    [1.264 sec/step, loss=0.76747, avg_loss=0.77655]\n","Step 6085    [1.272 sec/step, loss=0.75956, avg_loss=0.77633]\n","Step 6086    [1.270 sec/step, loss=0.81647, avg_loss=0.77654]\n","Step 6087    [1.268 sec/step, loss=0.79740, avg_loss=0.77650]\n","Step 6088    [1.257 sec/step, loss=0.79315, avg_loss=0.77721]\n","Step 6089    [1.257 sec/step, loss=0.77930, avg_loss=0.77702]\n","Step 6090    [1.252 sec/step, loss=0.80368, avg_loss=0.77728]\n","Step 6091    [1.253 sec/step, loss=0.76164, avg_loss=0.77734]\n","Step 6092    [1.257 sec/step, loss=0.79733, avg_loss=0.77742]\n","Step 6093    [1.259 sec/step, loss=0.80416, avg_loss=0.77770]\n","Step 6094    [1.260 sec/step, loss=0.77416, avg_loss=0.77745]\n","Step 6095    [1.260 sec/step, loss=0.80641, avg_loss=0.77760]\n","Step 6096    [1.267 sec/step, loss=0.75451, avg_loss=0.77730]\n","Step 6097    [1.269 sec/step, loss=0.78582, avg_loss=0.77728]\n","Step 6098    [1.311 sec/step, loss=0.62318, avg_loss=0.77569]\n","Step 6099    [1.319 sec/step, loss=0.77050, avg_loss=0.77548]\n","Step 6100    [1.325 sec/step, loss=0.79863, avg_loss=0.77553]\n","Writing summary at step: 6100\n","Step 6101    [1.326 sec/step, loss=0.79181, avg_loss=0.77561]\n","Step 6102    [1.336 sec/step, loss=0.77944, avg_loss=0.77554]\n","Step 6103    [1.341 sec/step, loss=0.79174, avg_loss=0.77585]\n","Generated 32 batches of size 32 in 19.649 sec\n","Step 6104    [1.371 sec/step, loss=0.76837, avg_loss=0.77564]\n","Step 6105    [1.366 sec/step, loss=0.78689, avg_loss=0.77584]\n","Step 6106    [1.363 sec/step, loss=0.77952, avg_loss=0.77573]\n","Step 6107    [1.368 sec/step, loss=0.76662, avg_loss=0.77568]\n","Step 6108    [1.370 sec/step, loss=0.79433, avg_loss=0.77597]\n","Step 6109    [1.363 sec/step, loss=0.78870, avg_loss=0.77592]\n","Step 6110    [1.360 sec/step, loss=0.79644, avg_loss=0.77621]\n","Step 6111    [1.367 sec/step, loss=0.78952, avg_loss=0.77630]\n","Step 6112    [1.376 sec/step, loss=0.81529, avg_loss=0.77667]\n","Step 6113    [1.354 sec/step, loss=0.81310, avg_loss=0.77916]\n","Step 6114    [1.352 sec/step, loss=0.76274, avg_loss=0.77887]\n","Step 6115    [1.354 sec/step, loss=0.79817, avg_loss=0.77895]\n","Step 6116    [1.364 sec/step, loss=0.73050, avg_loss=0.77841]\n","Step 6117    [1.365 sec/step, loss=0.77812, avg_loss=0.77829]\n","Step 6118    [1.366 sec/step, loss=0.76606, avg_loss=0.77797]\n","Step 6119    [1.365 sec/step, loss=0.77220, avg_loss=0.77782]\n","Step 6120    [1.364 sec/step, loss=0.78873, avg_loss=0.77790]\n","Step 6121    [1.367 sec/step, loss=0.77978, avg_loss=0.77771]\n","Step 6122    [1.364 sec/step, loss=0.78905, avg_loss=0.77762]\n","Step 6123    [1.363 sec/step, loss=0.78488, avg_loss=0.77746]\n","Step 6124    [1.362 sec/step, loss=0.78343, avg_loss=0.77756]\n","Step 6125    [1.360 sec/step, loss=0.78662, avg_loss=0.77787]\n","Step 6126    [1.371 sec/step, loss=0.76050, avg_loss=0.77741]\n","Step 6127    [1.381 sec/step, loss=0.80348, avg_loss=0.77734]\n","Step 6128    [1.386 sec/step, loss=0.76156, avg_loss=0.77719]\n","Step 6129    [1.433 sec/step, loss=0.57684, avg_loss=0.77492]\n","Step 6130    [1.435 sec/step, loss=0.79466, avg_loss=0.77532]\n","Step 6131    [1.438 sec/step, loss=0.79836, avg_loss=0.77547]\n","Step 6132    [1.431 sec/step, loss=0.78665, avg_loss=0.77576]\n","Step 6133    [1.428 sec/step, loss=0.80357, avg_loss=0.77585]\n","Step 6134    [1.430 sec/step, loss=0.80419, avg_loss=0.77611]\n","Step 6135    [1.430 sec/step, loss=0.80997, avg_loss=0.77618]\n","Generated 32 batches of size 32 in 18.233 sec\n","Step 6136    [1.449 sec/step, loss=0.77321, avg_loss=0.77608]\n","Step 6137    [1.434 sec/step, loss=0.80113, avg_loss=0.77668]\n","Step 6138    [1.433 sec/step, loss=0.75623, avg_loss=0.77635]\n","Step 6139    [1.417 sec/step, loss=0.76626, avg_loss=0.77668]\n","Step 6140    [1.413 sec/step, loss=0.81236, avg_loss=0.77720]\n","Step 6141    [1.362 sec/step, loss=0.76726, avg_loss=0.77699]\n","Step 6142    [1.362 sec/step, loss=0.79265, avg_loss=0.77689]\n","Step 6143    [1.364 sec/step, loss=0.79176, avg_loss=0.77696]\n","Step 6144    [1.387 sec/step, loss=0.59043, avg_loss=0.77507]\n","Step 6145    [1.380 sec/step, loss=0.78299, avg_loss=0.77531]\n","Step 6146    [1.379 sec/step, loss=0.79046, avg_loss=0.77536]\n","Step 6147    [1.379 sec/step, loss=0.78744, avg_loss=0.77530]\n","Step 6148    [1.387 sec/step, loss=0.78472, avg_loss=0.77546]\n","Step 6149    [1.384 sec/step, loss=0.77669, avg_loss=0.77518]\n","Step 6150    [1.385 sec/step, loss=0.78349, avg_loss=0.77515]\n","Step 6151    [1.387 sec/step, loss=0.79403, avg_loss=0.77534]\n","Step 6152    [1.390 sec/step, loss=0.79821, avg_loss=0.77549]\n","Step 6153    [1.397 sec/step, loss=0.78775, avg_loss=0.77549]\n","Step 6154    [1.397 sec/step, loss=0.80679, avg_loss=0.77579]\n","Step 6155    [1.400 sec/step, loss=0.77886, avg_loss=0.77585]\n","Step 6156    [1.404 sec/step, loss=0.79252, avg_loss=0.77602]\n","Step 6157    [1.407 sec/step, loss=0.78761, avg_loss=0.77607]\n","Step 6158    [1.410 sec/step, loss=0.77551, avg_loss=0.77594]\n","Step 6159    [1.412 sec/step, loss=0.78266, avg_loss=0.77583]\n","Step 6160    [1.413 sec/step, loss=0.77612, avg_loss=0.77568]\n","Step 6161    [1.419 sec/step, loss=0.77728, avg_loss=0.77580]\n","Step 6162    [1.416 sec/step, loss=0.78979, avg_loss=0.77592]\n","Step 6163    [1.422 sec/step, loss=0.78112, avg_loss=0.77577]\n","Step 6164    [1.414 sec/step, loss=0.76283, avg_loss=0.77563]\n","Step 6165    [1.409 sec/step, loss=0.77624, avg_loss=0.77574]\n","Step 6166    [1.375 sec/step, loss=0.79116, avg_loss=0.77799]\n","Step 6167    [1.363 sec/step, loss=0.78829, avg_loss=0.77819]\n","Generated 32 batches of size 32 in 19.710 sec\n","Step 6168    [1.429 sec/step, loss=0.78498, avg_loss=0.77893]\n","Step 6169    [1.423 sec/step, loss=0.79186, avg_loss=0.77884]\n","Step 6170    [1.417 sec/step, loss=0.77633, avg_loss=0.77859]\n","Step 6171    [1.416 sec/step, loss=0.78193, avg_loss=0.77861]\n","Step 6172    [1.416 sec/step, loss=0.76038, avg_loss=0.77843]\n","Step 6173    [1.407 sec/step, loss=0.80614, avg_loss=0.77866]\n","Step 6174    [1.411 sec/step, loss=0.78368, avg_loss=0.77876]\n","Step 6175    [1.408 sec/step, loss=0.77704, avg_loss=0.77891]\n","Step 6176    [1.404 sec/step, loss=0.79302, avg_loss=0.77913]\n","Step 6177    [1.406 sec/step, loss=0.81136, avg_loss=0.77921]\n","Step 6178    [1.405 sec/step, loss=0.77690, avg_loss=0.77925]\n","Step 6179    [1.407 sec/step, loss=0.79123, avg_loss=0.77933]\n","Step 6180    [1.408 sec/step, loss=0.76077, avg_loss=0.77918]\n","Step 6181    [1.395 sec/step, loss=0.78312, avg_loss=0.77940]\n","Step 6182    [1.396 sec/step, loss=0.78803, avg_loss=0.77928]\n","Step 6183    [1.408 sec/step, loss=0.72613, avg_loss=0.77872]\n","Step 6184    [1.408 sec/step, loss=0.78403, avg_loss=0.77889]\n","Step 6185    [1.404 sec/step, loss=0.79362, avg_loss=0.77923]\n","Step 6186    [1.405 sec/step, loss=0.77835, avg_loss=0.77884]\n","Step 6187    [1.406 sec/step, loss=0.77826, avg_loss=0.77865]\n","Step 6188    [1.408 sec/step, loss=0.78723, avg_loss=0.77859]\n","Step 6189    [1.407 sec/step, loss=0.79091, avg_loss=0.77871]\n","Step 6190    [1.413 sec/step, loss=0.76004, avg_loss=0.77827]\n","Step 6191    [1.420 sec/step, loss=0.78276, avg_loss=0.77848]\n","Step 6192    [1.469 sec/step, loss=0.56474, avg_loss=0.77616]\n","Step 6193    [1.482 sec/step, loss=0.79316, avg_loss=0.77605]\n","Step 6194    [1.489 sec/step, loss=0.80916, avg_loss=0.77640]\n","Step 6195    [1.496 sec/step, loss=0.77457, avg_loss=0.77608]\n","Step 6196    [1.485 sec/step, loss=0.79008, avg_loss=0.77644]\n","Step 6197    [1.487 sec/step, loss=0.80034, avg_loss=0.77658]\n","Step 6198    [1.451 sec/step, loss=0.79119, avg_loss=0.77826]\n","Step 6199    [1.445 sec/step, loss=0.79433, avg_loss=0.77850]\n","Generated 32 batches of size 32 in 19.629 sec\n","Step 6200    [1.445 sec/step, loss=0.79739, avg_loss=0.77849]\n","Writing summary at step: 6200\n","Step 6201    [1.447 sec/step, loss=0.79043, avg_loss=0.77847]\n","Step 6202    [1.438 sec/step, loss=0.77934, avg_loss=0.77847]\n","Step 6203    [1.436 sec/step, loss=0.77966, avg_loss=0.77835]\n","Step 6204    [1.406 sec/step, loss=0.79825, avg_loss=0.77865]\n","Step 6205    [1.407 sec/step, loss=0.79076, avg_loss=0.77869]\n","Step 6206    [1.413 sec/step, loss=0.82567, avg_loss=0.77915]\n","Step 6207    [1.409 sec/step, loss=0.80481, avg_loss=0.77953]\n","Step 6208    [1.407 sec/step, loss=0.78377, avg_loss=0.77943]\n","Step 6209    [1.410 sec/step, loss=0.77384, avg_loss=0.77928]\n","Step 6210    [1.410 sec/step, loss=0.81021, avg_loss=0.77942]\n","Step 6211    [1.407 sec/step, loss=0.78401, avg_loss=0.77936]\n","Step 6212    [1.403 sec/step, loss=0.77870, avg_loss=0.77900]\n","Step 6213    [1.399 sec/step, loss=0.77388, avg_loss=0.77860]\n","Step 6214    [1.430 sec/step, loss=0.55875, avg_loss=0.77656]\n","Step 6215    [1.428 sec/step, loss=0.79521, avg_loss=0.77653]\n","Step 6216    [1.426 sec/step, loss=0.72555, avg_loss=0.77648]\n","Step 6217    [1.426 sec/step, loss=0.79484, avg_loss=0.77665]\n","Step 6218    [1.425 sec/step, loss=0.77508, avg_loss=0.77674]\n","Step 6219    [1.425 sec/step, loss=0.78796, avg_loss=0.77690]\n","Step 6220    [1.422 sec/step, loss=0.79396, avg_loss=0.77695]\n","Step 6221    [1.424 sec/step, loss=0.76478, avg_loss=0.77680]\n","Step 6222    [1.436 sec/step, loss=0.78913, avg_loss=0.77680]\n","Step 6223    [1.440 sec/step, loss=0.78950, avg_loss=0.77685]\n","Step 6224    [1.438 sec/step, loss=0.77636, avg_loss=0.77678]\n","Step 6225    [1.439 sec/step, loss=0.79990, avg_loss=0.77691]\n","Step 6226    [1.434 sec/step, loss=0.76328, avg_loss=0.77694]\n","Step 6227    [1.436 sec/step, loss=0.74654, avg_loss=0.77637]\n","Step 6228    [1.435 sec/step, loss=0.78673, avg_loss=0.77662]\n","Step 6229    [1.389 sec/step, loss=0.76819, avg_loss=0.77853]\n","Step 6230    [1.391 sec/step, loss=0.78118, avg_loss=0.77840]\n","Generated 32 batches of size 32 in 19.614 sec\n","Step 6231    [1.458 sec/step, loss=0.76613, avg_loss=0.77808]\n","Step 6232    [1.456 sec/step, loss=0.79896, avg_loss=0.77820]\n","Step 6233    [1.452 sec/step, loss=0.79223, avg_loss=0.77809]\n","Step 6234    [1.446 sec/step, loss=0.79027, avg_loss=0.77795]\n","Step 6235    [1.454 sec/step, loss=0.72583, avg_loss=0.77711]\n","Step 6236    [1.433 sec/step, loss=0.79063, avg_loss=0.77728]\n","Step 6237    [1.458 sec/step, loss=0.59189, avg_loss=0.77519]\n","Step 6238    [1.450 sec/step, loss=0.77623, avg_loss=0.77539]\n","Step 6239    [1.448 sec/step, loss=0.79156, avg_loss=0.77564]\n","Step 6240    [1.449 sec/step, loss=0.79937, avg_loss=0.77551]\n","Step 6241    [1.448 sec/step, loss=0.77799, avg_loss=0.77562]\n","Step 6242    [1.444 sec/step, loss=0.79730, avg_loss=0.77567]\n","Step 6243    [1.444 sec/step, loss=0.78403, avg_loss=0.77559]\n","Step 6244    [1.428 sec/step, loss=0.78505, avg_loss=0.77753]\n","Step 6245    [1.432 sec/step, loss=0.77976, avg_loss=0.77750]\n","Step 6246    [1.431 sec/step, loss=0.80462, avg_loss=0.77764]\n","Step 6247    [1.432 sec/step, loss=0.76318, avg_loss=0.77740]\n","Step 6248    [1.429 sec/step, loss=0.76569, avg_loss=0.77721]\n","Step 6249    [1.428 sec/step, loss=0.77307, avg_loss=0.77717]\n","Step 6250    [1.426 sec/step, loss=0.78637, avg_loss=0.77720]\n","Step 6251    [1.428 sec/step, loss=0.78583, avg_loss=0.77712]\n","Step 6252    [1.427 sec/step, loss=0.81296, avg_loss=0.77727]\n","Step 6253    [1.428 sec/step, loss=0.77417, avg_loss=0.77713]\n","Step 6254    [1.431 sec/step, loss=0.81342, avg_loss=0.77720]\n","Step 6255    [1.437 sec/step, loss=0.79154, avg_loss=0.77733]\n","Step 6256    [1.442 sec/step, loss=0.80068, avg_loss=0.77741]\n","Step 6257    [1.439 sec/step, loss=0.79435, avg_loss=0.77747]\n","Step 6258    [1.441 sec/step, loss=0.76211, avg_loss=0.77734]\n","Step 6259    [1.448 sec/step, loss=0.78368, avg_loss=0.77735]\n","Step 6260    [1.456 sec/step, loss=0.78398, avg_loss=0.77743]\n","Step 6261    [1.459 sec/step, loss=0.82562, avg_loss=0.77791]\n","Step 6262    [1.456 sec/step, loss=0.78758, avg_loss=0.77789]\n","Generated 32 batches of size 32 in 19.542 sec\n","Step 6263    [1.514 sec/step, loss=0.78215, avg_loss=0.77790]\n","Step 6264    [1.514 sec/step, loss=0.76796, avg_loss=0.77795]\n","Step 6265    [1.536 sec/step, loss=0.59326, avg_loss=0.77612]\n","Step 6266    [1.533 sec/step, loss=0.77550, avg_loss=0.77597]\n","Step 6267    [1.539 sec/step, loss=0.76442, avg_loss=0.77573]\n","Step 6268    [1.458 sec/step, loss=0.76392, avg_loss=0.77552]\n","Step 6269    [1.456 sec/step, loss=0.76273, avg_loss=0.77523]\n","Step 6270    [1.459 sec/step, loss=0.77029, avg_loss=0.77516]\n","Step 6271    [1.455 sec/step, loss=0.78588, avg_loss=0.77520]\n","Step 6272    [1.450 sec/step, loss=0.77282, avg_loss=0.77533]\n","Step 6273    [1.453 sec/step, loss=0.77810, avg_loss=0.77505]\n","Step 6274    [1.453 sec/step, loss=0.80243, avg_loss=0.77524]\n","Step 6275    [1.457 sec/step, loss=0.77541, avg_loss=0.77522]\n","Step 6276    [1.456 sec/step, loss=0.78150, avg_loss=0.77510]\n","Step 6277    [1.466 sec/step, loss=0.72725, avg_loss=0.77426]\n","Step 6278    [1.467 sec/step, loss=0.78372, avg_loss=0.77433]\n","Step 6279    [1.465 sec/step, loss=0.77695, avg_loss=0.77419]\n","Step 6280    [1.466 sec/step, loss=0.80818, avg_loss=0.77466]\n","Step 6281    [1.467 sec/step, loss=0.77694, avg_loss=0.77460]\n","Step 6282    [1.467 sec/step, loss=0.78761, avg_loss=0.77460]\n","Step 6283    [1.454 sec/step, loss=0.78521, avg_loss=0.77519]\n","Step 6284    [1.453 sec/step, loss=0.77511, avg_loss=0.77510]\n","Step 6285    [1.451 sec/step, loss=0.77103, avg_loss=0.77487]\n","Step 6286    [1.454 sec/step, loss=0.77144, avg_loss=0.77480]\n","Step 6287    [1.456 sec/step, loss=0.79776, avg_loss=0.77500]\n","Step 6288    [1.456 sec/step, loss=0.77338, avg_loss=0.77486]\n","Step 6289    [1.459 sec/step, loss=0.75865, avg_loss=0.77454]\n","Step 6290    [1.464 sec/step, loss=0.78801, avg_loss=0.77482]\n","Step 6291    [1.456 sec/step, loss=0.79235, avg_loss=0.77491]\n","Step 6292    [1.414 sec/step, loss=0.77354, avg_loss=0.77700]\n","Step 6293    [1.399 sec/step, loss=0.76167, avg_loss=0.77669]\n","Step 6294    [1.395 sec/step, loss=0.75716, avg_loss=0.77617]\n","Generated 32 batches of size 32 in 18.505 sec\n","Step 6295    [1.456 sec/step, loss=0.78420, avg_loss=0.77626]\n","Step 6296    [1.453 sec/step, loss=0.77220, avg_loss=0.77608]\n","Step 6297    [1.445 sec/step, loss=0.78579, avg_loss=0.77594]\n","Step 6298    [1.446 sec/step, loss=0.79763, avg_loss=0.77600]\n","Step 6299    [1.456 sec/step, loss=0.73600, avg_loss=0.77542]\n","Step 6300    [1.450 sec/step, loss=0.79413, avg_loss=0.77539]\n","Writing summary at step: 6300\n","Step 6301    [1.445 sec/step, loss=0.76992, avg_loss=0.77518]\n","Step 6302    [1.447 sec/step, loss=0.76872, avg_loss=0.77508]\n","Step 6303    [1.450 sec/step, loss=0.75305, avg_loss=0.77481]\n","Step 6304    [1.452 sec/step, loss=0.78248, avg_loss=0.77465]\n","Step 6305    [1.482 sec/step, loss=0.56362, avg_loss=0.77238]\n","Step 6306    [1.479 sec/step, loss=0.77750, avg_loss=0.77190]\n","Step 6307    [1.476 sec/step, loss=0.78359, avg_loss=0.77169]\n","Step 6308    [1.479 sec/step, loss=0.78172, avg_loss=0.77167]\n","Step 6309    [1.474 sec/step, loss=0.79074, avg_loss=0.77183]\n","Step 6310    [1.479 sec/step, loss=0.77615, avg_loss=0.77149]\n","Step 6311    [1.476 sec/step, loss=0.77110, avg_loss=0.77136]\n","Step 6312    [1.472 sec/step, loss=0.79373, avg_loss=0.77151]\n","Step 6313    [1.475 sec/step, loss=0.79051, avg_loss=0.77168]\n","Step 6314    [1.447 sec/step, loss=0.78929, avg_loss=0.77399]\n","Step 6315    [1.447 sec/step, loss=0.78768, avg_loss=0.77391]\n","Step 6316    [1.436 sec/step, loss=0.77268, avg_loss=0.77438]\n","Step 6317    [1.448 sec/step, loss=0.75981, avg_loss=0.77403]\n","Step 6318    [1.452 sec/step, loss=0.77458, avg_loss=0.77403]\n","Step 6319    [1.455 sec/step, loss=0.78560, avg_loss=0.77400]\n","Step 6320    [1.460 sec/step, loss=0.80259, avg_loss=0.77409]\n","Step 6321    [1.462 sec/step, loss=0.80529, avg_loss=0.77449]\n","Step 6322    [1.466 sec/step, loss=0.75174, avg_loss=0.77412]\n","Step 6323    [1.466 sec/step, loss=0.76729, avg_loss=0.77390]\n","Step 6324    [1.472 sec/step, loss=0.76927, avg_loss=0.77383]\n","Step 6325    [1.470 sec/step, loss=0.78025, avg_loss=0.77363]\n","Generated 32 batches of size 32 in 18.740 sec\n","Step 6326    [1.522 sec/step, loss=0.77831, avg_loss=0.77378]\n","Step 6327    [1.509 sec/step, loss=0.79418, avg_loss=0.77426]\n","Step 6328    [1.516 sec/step, loss=0.72983, avg_loss=0.77369]\n","Step 6329    [1.513 sec/step, loss=0.77395, avg_loss=0.77375]\n","Step 6330    [1.511 sec/step, loss=0.78527, avg_loss=0.77379]\n","Step 6331    [1.442 sec/step, loss=0.76300, avg_loss=0.77376]\n","Step 6332    [1.443 sec/step, loss=0.78905, avg_loss=0.77366]\n","Step 6333    [1.445 sec/step, loss=0.78369, avg_loss=0.77357]\n","Step 6334    [1.451 sec/step, loss=0.74499, avg_loss=0.77312]\n","Step 6335    [1.442 sec/step, loss=0.77254, avg_loss=0.77359]\n","Step 6336    [1.447 sec/step, loss=0.78952, avg_loss=0.77357]\n","Step 6337    [1.425 sec/step, loss=0.79246, avg_loss=0.77558]\n","Step 6338    [1.424 sec/step, loss=0.78872, avg_loss=0.77571]\n","Step 6339    [1.429 sec/step, loss=0.78137, avg_loss=0.77560]\n","Step 6340    [1.427 sec/step, loss=0.77659, avg_loss=0.77538]\n","Step 6341    [1.458 sec/step, loss=0.49545, avg_loss=0.77255]\n","Step 6342    [1.462 sec/step, loss=0.78949, avg_loss=0.77247]\n","Step 6343    [1.462 sec/step, loss=0.77408, avg_loss=0.77237]\n","Step 6344    [1.455 sec/step, loss=0.77658, avg_loss=0.77229]\n","Step 6345    [1.453 sec/step, loss=0.77859, avg_loss=0.77228]\n","Step 6346    [1.453 sec/step, loss=0.77401, avg_loss=0.77197]\n","Step 6347    [1.451 sec/step, loss=0.78153, avg_loss=0.77215]\n","Step 6348    [1.445 sec/step, loss=0.77253, avg_loss=0.77222]\n","Step 6349    [1.450 sec/step, loss=0.77862, avg_loss=0.77228]\n","Step 6350    [1.452 sec/step, loss=0.76728, avg_loss=0.77209]\n","Step 6351    [1.452 sec/step, loss=0.78802, avg_loss=0.77211]\n","Step 6352    [1.455 sec/step, loss=0.78891, avg_loss=0.77187]\n","Step 6353    [1.454 sec/step, loss=0.80469, avg_loss=0.77217]\n","Step 6354    [1.466 sec/step, loss=0.78366, avg_loss=0.77188]\n","Step 6355    [1.466 sec/step, loss=0.79237, avg_loss=0.77188]\n","Step 6356    [1.460 sec/step, loss=0.77914, avg_loss=0.77167]\n","Step 6357    [1.460 sec/step, loss=0.81784, avg_loss=0.77190]\n","Generated 32 batches of size 32 in 20.068 sec\n","Step 6358    [1.533 sec/step, loss=0.77708, avg_loss=0.77205]\n","Step 6359    [1.523 sec/step, loss=0.77679, avg_loss=0.77198]\n","Step 6360    [1.515 sec/step, loss=0.78298, avg_loss=0.77197]\n","Step 6361    [1.507 sec/step, loss=0.77599, avg_loss=0.77148]\n","Step 6362    [1.516 sec/step, loss=0.74158, avg_loss=0.77102]\n","Step 6363    [1.456 sec/step, loss=0.80502, avg_loss=0.77125]\n","Step 6364    [1.457 sec/step, loss=0.78001, avg_loss=0.77137]\n","Step 6365    [1.435 sec/step, loss=0.78434, avg_loss=0.77328]\n","Step 6366    [1.426 sec/step, loss=0.78860, avg_loss=0.77341]\n","Step 6367    [1.421 sec/step, loss=0.77188, avg_loss=0.77348]\n","Step 6368    [1.415 sec/step, loss=0.76080, avg_loss=0.77345]\n","Step 6369    [1.413 sec/step, loss=0.77975, avg_loss=0.77362]\n","Step 6370    [1.412 sec/step, loss=0.79578, avg_loss=0.77388]\n","Step 6371    [1.418 sec/step, loss=0.79886, avg_loss=0.77401]\n","Step 6372    [1.418 sec/step, loss=0.78767, avg_loss=0.77416]\n","Step 6373    [1.416 sec/step, loss=0.80181, avg_loss=0.77439]\n","Step 6374    [1.435 sec/step, loss=0.66184, avg_loss=0.77299]\n","Step 6375    [1.430 sec/step, loss=0.82927, avg_loss=0.77353]\n","Step 6376    [1.432 sec/step, loss=0.79604, avg_loss=0.77367]\n","Step 6377    [1.421 sec/step, loss=0.79333, avg_loss=0.77433]\n","Step 6378    [1.421 sec/step, loss=0.84262, avg_loss=0.77492]\n","Step 6379    [1.426 sec/step, loss=0.80431, avg_loss=0.77519]\n","Step 6380    [1.431 sec/step, loss=0.83193, avg_loss=0.77543]\n","Step 6381    [1.447 sec/step, loss=0.80755, avg_loss=0.77574]\n","Step 6382    [1.450 sec/step, loss=0.89905, avg_loss=0.77685]\n","Step 6383    [1.463 sec/step, loss=0.82159, avg_loss=0.77722]\n","Step 6384    [1.470 sec/step, loss=0.84041, avg_loss=0.77787]\n","Step 6385    [1.470 sec/step, loss=0.84320, avg_loss=0.77859]\n","Step 6386    [1.475 sec/step, loss=0.83038, avg_loss=0.77918]\n","Step 6387    [1.482 sec/step, loss=0.82847, avg_loss=0.77949]\n","Step 6388    [1.489 sec/step, loss=0.80237, avg_loss=0.77978]\n","Step 6389    [1.491 sec/step, loss=0.85670, avg_loss=0.78076]\n","Generated 32 batches of size 32 in 19.789 sec\n","Step 6390    [1.530 sec/step, loss=0.83431, avg_loss=0.78122]\n","Step 6391    [1.529 sec/step, loss=0.84416, avg_loss=0.78174]\n","Step 6392    [1.519 sec/step, loss=0.80012, avg_loss=0.78201]\n","Step 6393    [1.530 sec/step, loss=0.77112, avg_loss=0.78210]\n","Step 6394    [1.547 sec/step, loss=0.64605, avg_loss=0.78099]\n","Step 6395    [1.478 sec/step, loss=0.85190, avg_loss=0.78167]\n","Step 6396    [1.478 sec/step, loss=0.80900, avg_loss=0.78203]\n","Step 6397    [1.478 sec/step, loss=0.84309, avg_loss=0.78261]\n","Step 6398    [1.475 sec/step, loss=0.79922, avg_loss=0.78262]\n","Step 6399    [1.463 sec/step, loss=0.83375, avg_loss=0.78360]\n","Step 6400    [1.466 sec/step, loss=0.81556, avg_loss=0.78381]\n","Writing summary at step: 6400\n","Step 6401    [1.473 sec/step, loss=0.79732, avg_loss=0.78409]\n","Step 6402    [1.474 sec/step, loss=0.81719, avg_loss=0.78457]\n","Step 6403    [1.467 sec/step, loss=0.80132, avg_loss=0.78506]\n","Step 6404    [1.466 sec/step, loss=0.82003, avg_loss=0.78543]\n","Step 6405    [1.441 sec/step, loss=0.81192, avg_loss=0.78791]\n","Step 6406    [1.435 sec/step, loss=0.80318, avg_loss=0.78817]\n","Step 6407    [1.435 sec/step, loss=0.80613, avg_loss=0.78840]\n","Step 6408    [1.431 sec/step, loss=0.81017, avg_loss=0.78868]\n","Step 6409    [1.436 sec/step, loss=0.81215, avg_loss=0.78890]\n","Step 6410    [1.438 sec/step, loss=0.83893, avg_loss=0.78952]\n","Step 6411    [1.438 sec/step, loss=0.80172, avg_loss=0.78983]\n","Step 6412    [1.443 sec/step, loss=0.78506, avg_loss=0.78974]\n","Step 6413    [1.445 sec/step, loss=0.77870, avg_loss=0.78962]\n","Step 6414    [1.452 sec/step, loss=0.81421, avg_loss=0.78987]\n","Step 6415    [1.466 sec/step, loss=0.77330, avg_loss=0.78973]\n","Step 6416    [1.476 sec/step, loss=0.79302, avg_loss=0.78993]\n","Step 6417    [1.468 sec/step, loss=0.84351, avg_loss=0.79077]\n","Step 6418    [1.468 sec/step, loss=0.78515, avg_loss=0.79088]\n","Step 6419    [1.471 sec/step, loss=0.81304, avg_loss=0.79115]\n","Step 6420    [1.472 sec/step, loss=0.77332, avg_loss=0.79086]\n","Generated 32 batches of size 32 in 19.754 sec\n","Step 6421    [1.533 sec/step, loss=0.78702, avg_loss=0.79068]\n","Step 6422    [1.519 sec/step, loss=0.79147, avg_loss=0.79107]\n","Step 6423    [1.516 sec/step, loss=0.80279, avg_loss=0.79143]\n","Step 6424    [1.511 sec/step, loss=0.80287, avg_loss=0.79176]\n","Step 6425    [1.520 sec/step, loss=0.73339, avg_loss=0.79129]\n","Step 6426    [1.468 sec/step, loss=0.80013, avg_loss=0.79151]\n","Step 6427    [1.469 sec/step, loss=0.80090, avg_loss=0.79158]\n","Step 6428    [1.458 sec/step, loss=0.76459, avg_loss=0.79193]\n","Step 6429    [1.462 sec/step, loss=0.78818, avg_loss=0.79207]\n","Step 6430    [1.458 sec/step, loss=0.79499, avg_loss=0.79217]\n","Step 6431    [1.458 sec/step, loss=0.81878, avg_loss=0.79273]\n","Step 6432    [1.455 sec/step, loss=0.80347, avg_loss=0.79287]\n","Step 6433    [1.453 sec/step, loss=0.80263, avg_loss=0.79306]\n","Step 6434    [1.453 sec/step, loss=0.77177, avg_loss=0.79333]\n","Step 6435    [1.453 sec/step, loss=0.80402, avg_loss=0.79364]\n","Step 6436    [1.450 sec/step, loss=0.80116, avg_loss=0.79376]\n","Step 6437    [1.468 sec/step, loss=0.69223, avg_loss=0.79276]\n","Step 6438    [1.474 sec/step, loss=0.79423, avg_loss=0.79281]\n","Step 6439    [1.467 sec/step, loss=0.77746, avg_loss=0.79277]\n","Step 6440    [1.469 sec/step, loss=0.81686, avg_loss=0.79317]\n","Step 6441    [1.442 sec/step, loss=0.78016, avg_loss=0.79602]\n","Step 6442    [1.439 sec/step, loss=0.79984, avg_loss=0.79612]\n","Step 6443    [1.445 sec/step, loss=0.81222, avg_loss=0.79651]\n","Step 6444    [1.458 sec/step, loss=0.77746, avg_loss=0.79651]\n","Step 6445    [1.469 sec/step, loss=0.80430, avg_loss=0.79677]\n","Step 6446    [1.469 sec/step, loss=0.77608, avg_loss=0.79679]\n","Step 6447    [1.475 sec/step, loss=0.80050, avg_loss=0.79698]\n","Step 6448    [1.474 sec/step, loss=0.79034, avg_loss=0.79716]\n","Step 6449    [1.471 sec/step, loss=0.78325, avg_loss=0.79721]\n","Step 6450    [1.472 sec/step, loss=0.78254, avg_loss=0.79736]\n","Step 6451    [1.472 sec/step, loss=0.77589, avg_loss=0.79724]\n","Step 6452    [1.471 sec/step, loss=0.77437, avg_loss=0.79709]\n","Generated 32 batches of size 32 in 19.566 sec\n","Step 6453    [1.545 sec/step, loss=0.78242, avg_loss=0.79687]\n","Step 6454    [1.529 sec/step, loss=0.81735, avg_loss=0.79721]\n","Step 6455    [1.529 sec/step, loss=0.79498, avg_loss=0.79723]\n","Step 6456    [1.553 sec/step, loss=0.54736, avg_loss=0.79492]\n","Step 6457    [1.552 sec/step, loss=0.79474, avg_loss=0.79468]\n","Step 6458    [1.472 sec/step, loss=0.80127, avg_loss=0.79493]\n","Step 6459    [1.475 sec/step, loss=0.78102, avg_loss=0.79497]\n","Step 6460    [1.476 sec/step, loss=0.78268, avg_loss=0.79497]\n","Step 6461    [1.476 sec/step, loss=0.80340, avg_loss=0.79524]\n","Step 6462    [1.464 sec/step, loss=0.80246, avg_loss=0.79585]\n","Step 6463    [1.465 sec/step, loss=0.75754, avg_loss=0.79537]\n","Step 6464    [1.462 sec/step, loss=0.78877, avg_loss=0.79546]\n","Step 6465    [1.459 sec/step, loss=0.79201, avg_loss=0.79554]\n","Step 6466    [1.460 sec/step, loss=0.79226, avg_loss=0.79557]\n","Step 6467    [1.462 sec/step, loss=0.77044, avg_loss=0.79556]\n","Step 6468    [1.463 sec/step, loss=0.79191, avg_loss=0.79587]\n","Step 6469    [1.466 sec/step, loss=0.79802, avg_loss=0.79605]\n","Step 6470    [1.468 sec/step, loss=0.76959, avg_loss=0.79579]\n","Step 6471    [1.467 sec/step, loss=0.78902, avg_loss=0.79569]\n","Step 6472    [1.467 sec/step, loss=0.78553, avg_loss=0.79567]\n","Step 6473    [1.466 sec/step, loss=0.77707, avg_loss=0.79542]\n","Step 6474    [1.447 sec/step, loss=0.76431, avg_loss=0.79645]\n","Step 6475    [1.451 sec/step, loss=0.75153, avg_loss=0.79567]\n","Step 6476    [1.451 sec/step, loss=0.78200, avg_loss=0.79553]\n","Step 6477    [1.456 sec/step, loss=0.77724, avg_loss=0.79537]\n","Step 6478    [1.469 sec/step, loss=0.76467, avg_loss=0.79459]\n","Step 6479    [1.477 sec/step, loss=0.75784, avg_loss=0.79413]\n","Step 6480    [1.478 sec/step, loss=0.79153, avg_loss=0.79372]\n","Step 6481    [1.466 sec/step, loss=0.78119, avg_loss=0.79346]\n","Step 6482    [1.467 sec/step, loss=0.76822, avg_loss=0.79215]\n","Step 6483    [1.473 sec/step, loss=0.76340, avg_loss=0.79157]\n","Step 6484    [1.466 sec/step, loss=0.78591, avg_loss=0.79102]\n","Generated 32 batches of size 32 in 18.048 sec\n","Step 6485    [1.506 sec/step, loss=0.75086, avg_loss=0.79010]\n","Step 6486    [1.497 sec/step, loss=0.78149, avg_loss=0.78961]\n","Step 6487    [1.489 sec/step, loss=0.80230, avg_loss=0.78935]\n","Step 6488    [1.479 sec/step, loss=0.79262, avg_loss=0.78925]\n","Step 6489    [1.475 sec/step, loss=0.76199, avg_loss=0.78830]\n","Step 6490    [1.431 sec/step, loss=0.82102, avg_loss=0.78817]\n","Step 6491    [1.428 sec/step, loss=0.76438, avg_loss=0.78737]\n","Step 6492    [1.428 sec/step, loss=0.79180, avg_loss=0.78729]\n","Step 6493    [1.417 sec/step, loss=0.78633, avg_loss=0.78744]\n","Step 6494    [1.391 sec/step, loss=0.77486, avg_loss=0.78873]\n","Step 6495    [1.391 sec/step, loss=0.77054, avg_loss=0.78792]\n","Step 6496    [1.395 sec/step, loss=0.77497, avg_loss=0.78758]\n","Step 6497    [1.392 sec/step, loss=0.78421, avg_loss=0.78699]\n","Step 6498    [1.394 sec/step, loss=0.77327, avg_loss=0.78673]\n","Step 6499    [1.405 sec/step, loss=0.74619, avg_loss=0.78585]\n","Step 6500    [1.406 sec/step, loss=0.77719, avg_loss=0.78547]\n","Writing summary at step: 6500\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (93300,)\n","Check wav file:  (123300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000006500-align000.png\n","100% 1/1 [00:03<00:00,  3.74s/it]\n","Test finished for step 6500.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (96300,)\n","Check wav file:  (126300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000006500-align000.png\n"," 25% 1/4 [00:03<00:10,  3.37s/it]Check wav file before change:  (96300,)\n","Check wav file:  (126300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000006500-align001.png\n"," 50% 2/4 [00:06<00:06,  3.42s/it]Check wav file before change:  (96300,)\n","Check wav file:  (126300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000006500-align002.png\n"," 75% 3/4 [00:10<00:03,  3.41s/it]Check wav file before change:  (96300,)\n","Check wav file:  (126300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000006500-align003.png\n","100% 4/4 [00:13<00:00,  3.48s/it]\n","Test finished for step 6500.\n","Step 6501    [1.400 sec/step, loss=0.79255, avg_loss=0.78542]\n","Step 6502    [1.399 sec/step, loss=0.78315, avg_loss=0.78508]\n","Step 6503    [1.407 sec/step, loss=0.77779, avg_loss=0.78485]\n","Step 6504    [1.408 sec/step, loss=0.80048, avg_loss=0.78465]\n","Step 6505    [1.410 sec/step, loss=0.78117, avg_loss=0.78434]\n","Step 6506    [1.413 sec/step, loss=0.77401, avg_loss=0.78405]\n","Step 6507    [1.417 sec/step, loss=0.78462, avg_loss=0.78384]\n","Step 6508    [1.423 sec/step, loss=0.78019, avg_loss=0.78354]\n","Step 6509    [1.421 sec/step, loss=0.76542, avg_loss=0.78307]\n","Step 6510    [1.456 sec/step, loss=0.56278, avg_loss=0.78031]\n","Step 6511    [1.464 sec/step, loss=0.77733, avg_loss=0.78006]\n","Step 6512    [1.463 sec/step, loss=0.76996, avg_loss=0.77991]\n","Step 6513    [1.466 sec/step, loss=0.78840, avg_loss=0.78001]\n","Step 6514    [1.460 sec/step, loss=0.79098, avg_loss=0.77978]\n","Generated 32 batches of size 32 in 18.760 sec\n","Step 6515    [1.491 sec/step, loss=0.76903, avg_loss=0.77973]\n","Step 6516    [1.480 sec/step, loss=0.79559, avg_loss=0.77976]\n","Step 6517    [1.477 sec/step, loss=0.78809, avg_loss=0.77921]\n","Step 6518    [1.476 sec/step, loss=0.78351, avg_loss=0.77919]\n","Step 6519    [1.470 sec/step, loss=0.77539, avg_loss=0.77881]\n","Step 6520    [1.467 sec/step, loss=0.78187, avg_loss=0.77890]\n","Step 6521    [1.401 sec/step, loss=0.78532, avg_loss=0.77888]\n","Step 6522    [1.401 sec/step, loss=0.77491, avg_loss=0.77872]\n","Step 6523    [1.399 sec/step, loss=0.78327, avg_loss=0.77852]\n","Step 6524    [1.395 sec/step, loss=0.76859, avg_loss=0.77818]\n","Step 6525    [1.396 sec/step, loss=0.75057, avg_loss=0.77835]\n","Step 6526    [1.392 sec/step, loss=0.76869, avg_loss=0.77804]\n","Step 6527    [1.395 sec/step, loss=0.76297, avg_loss=0.77766]\n","Step 6528    [1.396 sec/step, loss=0.80000, avg_loss=0.77801]\n","Step 6529    [1.401 sec/step, loss=0.78707, avg_loss=0.77800]\n","Step 6530    [1.402 sec/step, loss=0.77363, avg_loss=0.77779]\n","Step 6531    [1.400 sec/step, loss=0.79437, avg_loss=0.77754]\n","Step 6532    [1.399 sec/step, loss=0.77847, avg_loss=0.77729]\n","Step 6533    [1.404 sec/step, loss=0.78730, avg_loss=0.77714]\n","Step 6534    [1.401 sec/step, loss=0.76653, avg_loss=0.77709]\n","Step 6535    [1.402 sec/step, loss=0.76814, avg_loss=0.77673]\n","Step 6536    [1.399 sec/step, loss=0.77675, avg_loss=0.77648]\n","Step 6537    [1.378 sec/step, loss=0.78505, avg_loss=0.77741]\n","Step 6538    [1.378 sec/step, loss=0.78552, avg_loss=0.77732]\n","Step 6539    [1.384 sec/step, loss=0.76547, avg_loss=0.77720]\n","Step 6540    [1.385 sec/step, loss=0.76992, avg_loss=0.77673]\n","Step 6541    [1.385 sec/step, loss=0.77953, avg_loss=0.77673]\n","Step 6542    [1.389 sec/step, loss=0.78000, avg_loss=0.77653]\n","Step 6543    [1.391 sec/step, loss=0.76652, avg_loss=0.77607]\n","Step 6544    [1.392 sec/step, loss=0.74192, avg_loss=0.77572]\n","Step 6545    [1.398 sec/step, loss=0.77481, avg_loss=0.77542]\n","Step 6546    [1.442 sec/step, loss=0.58453, avg_loss=0.77351]\n","Generated 32 batches of size 32 in 19.562 sec\n","Step 6547    [1.452 sec/step, loss=0.80079, avg_loss=0.77351]\n","Step 6548    [1.456 sec/step, loss=0.75758, avg_loss=0.77318]\n","Step 6549    [1.462 sec/step, loss=0.75739, avg_loss=0.77292]\n","Step 6550    [1.459 sec/step, loss=0.76652, avg_loss=0.77276]\n","Step 6551    [1.455 sec/step, loss=0.79100, avg_loss=0.77292]\n","Step 6552    [1.458 sec/step, loss=0.74730, avg_loss=0.77264]\n","Step 6553    [1.379 sec/step, loss=0.81078, avg_loss=0.77293]\n","Step 6554    [1.382 sec/step, loss=0.76357, avg_loss=0.77239]\n","Step 6555    [1.375 sec/step, loss=0.80226, avg_loss=0.77246]\n","Step 6556    [1.348 sec/step, loss=0.77175, avg_loss=0.77471]\n","Step 6557    [1.345 sec/step, loss=0.79066, avg_loss=0.77467]\n","Step 6558    [1.344 sec/step, loss=0.77936, avg_loss=0.77445]\n","Step 6559    [1.351 sec/step, loss=0.74982, avg_loss=0.77414]\n","Step 6560    [1.349 sec/step, loss=0.77678, avg_loss=0.77408]\n","Step 6561    [1.348 sec/step, loss=0.80129, avg_loss=0.77405]\n","Step 6562    [1.352 sec/step, loss=0.77087, avg_loss=0.77374]\n","Step 6563    [1.350 sec/step, loss=0.77000, avg_loss=0.77386]\n","Step 6564    [1.354 sec/step, loss=0.77482, avg_loss=0.77372]\n","Step 6565    [1.356 sec/step, loss=0.78510, avg_loss=0.77366]\n","Step 6566    [1.354 sec/step, loss=0.76686, avg_loss=0.77340]\n","Step 6567    [1.374 sec/step, loss=0.61767, avg_loss=0.77187]\n","Step 6568    [1.373 sec/step, loss=0.80604, avg_loss=0.77201]\n","Step 6569    [1.373 sec/step, loss=0.77312, avg_loss=0.77177]\n","Step 6570    [1.375 sec/step, loss=0.79243, avg_loss=0.77199]\n","Step 6571    [1.374 sec/step, loss=0.78130, avg_loss=0.77192]\n","Step 6572    [1.386 sec/step, loss=0.75477, avg_loss=0.77161]\n","Step 6573    [1.391 sec/step, loss=0.78496, avg_loss=0.77169]\n","Step 6574    [1.395 sec/step, loss=0.76554, avg_loss=0.77170]\n","Step 6575    [1.402 sec/step, loss=0.78875, avg_loss=0.77207]\n","Step 6576    [1.405 sec/step, loss=0.78167, avg_loss=0.77207]\n","Step 6577    [1.406 sec/step, loss=0.78401, avg_loss=0.77214]\n","Step 6578    [1.400 sec/step, loss=0.78295, avg_loss=0.77232]\n","Generated 32 batches of size 32 in 19.934 sec\n","Step 6579    [1.467 sec/step, loss=0.70251, avg_loss=0.77177]\n","Step 6580    [1.465 sec/step, loss=0.78081, avg_loss=0.77166]\n","Step 6581    [1.461 sec/step, loss=0.78493, avg_loss=0.77170]\n","Step 6582    [1.458 sec/step, loss=0.78416, avg_loss=0.77186]\n","Step 6583    [1.443 sec/step, loss=0.77918, avg_loss=0.77201]\n","Step 6584    [1.443 sec/step, loss=0.77406, avg_loss=0.77190]\n","Step 6585    [1.405 sec/step, loss=0.75540, avg_loss=0.77194]\n","Step 6586    [1.407 sec/step, loss=0.78237, avg_loss=0.77195]\n","Step 6587    [1.411 sec/step, loss=0.77643, avg_loss=0.77169]\n","Step 6588    [1.441 sec/step, loss=0.55144, avg_loss=0.76928]\n","Step 6589    [1.443 sec/step, loss=0.79475, avg_loss=0.76961]\n","Step 6590    [1.440 sec/step, loss=0.80593, avg_loss=0.76946]\n","Step 6591    [1.437 sec/step, loss=0.77193, avg_loss=0.76953]\n","Step 6592    [1.443 sec/step, loss=0.74973, avg_loss=0.76911]\n","Step 6593    [1.442 sec/step, loss=0.78985, avg_loss=0.76915]\n","Step 6594    [1.442 sec/step, loss=0.78900, avg_loss=0.76929]\n","Step 6595    [1.446 sec/step, loss=0.74101, avg_loss=0.76899]\n","Step 6596    [1.445 sec/step, loss=0.76341, avg_loss=0.76888]\n","Step 6597    [1.445 sec/step, loss=0.78027, avg_loss=0.76884]\n","Step 6598    [1.444 sec/step, loss=0.77433, avg_loss=0.76885]\n","Step 6599    [1.435 sec/step, loss=0.77727, avg_loss=0.76916]\n","Step 6600    [1.434 sec/step, loss=0.78512, avg_loss=0.76924]\n","Writing summary at step: 6600\n","Step 6601    [1.435 sec/step, loss=0.77269, avg_loss=0.76904]\n","Step 6602    [1.441 sec/step, loss=0.77181, avg_loss=0.76893]\n","Step 6603    [1.436 sec/step, loss=0.77820, avg_loss=0.76893]\n","Step 6604    [1.436 sec/step, loss=0.77228, avg_loss=0.76865]\n","Step 6605    [1.433 sec/step, loss=0.77968, avg_loss=0.76863]\n","Step 6606    [1.435 sec/step, loss=0.78263, avg_loss=0.76872]\n","Step 6607    [1.433 sec/step, loss=0.79487, avg_loss=0.76882]\n","Step 6608    [1.443 sec/step, loss=0.77116, avg_loss=0.76873]\n","Step 6609    [1.446 sec/step, loss=0.77912, avg_loss=0.76887]\n","Generated 32 batches of size 32 in 19.569 sec\n","Step 6610    [1.484 sec/step, loss=0.77004, avg_loss=0.77094]\n","Step 6611    [1.478 sec/step, loss=0.78983, avg_loss=0.77107]\n","Step 6612    [1.473 sec/step, loss=0.78194, avg_loss=0.77119]\n","Step 6613    [1.468 sec/step, loss=0.78238, avg_loss=0.77113]\n","Step 6614    [1.469 sec/step, loss=0.78164, avg_loss=0.77103]\n","Step 6615    [1.428 sec/step, loss=0.78802, avg_loss=0.77122]\n","Step 6616    [1.430 sec/step, loss=0.76924, avg_loss=0.77096]\n","Step 6617    [1.429 sec/step, loss=0.79560, avg_loss=0.77103]\n","Step 6618    [1.430 sec/step, loss=0.76915, avg_loss=0.77089]\n","Step 6619    [1.432 sec/step, loss=0.77774, avg_loss=0.77091]\n","Step 6620    [1.440 sec/step, loss=0.72107, avg_loss=0.77031]\n","Step 6621    [1.438 sec/step, loss=0.77937, avg_loss=0.77025]\n","Step 6622    [1.442 sec/step, loss=0.77840, avg_loss=0.77028]\n","Step 6623    [1.445 sec/step, loss=0.79150, avg_loss=0.77036]\n","Step 6624    [1.445 sec/step, loss=0.78025, avg_loss=0.77048]\n","Step 6625    [1.434 sec/step, loss=0.75675, avg_loss=0.77054]\n","Step 6626    [1.432 sec/step, loss=0.76726, avg_loss=0.77053]\n","Step 6627    [1.436 sec/step, loss=0.76694, avg_loss=0.77057]\n","Step 6628    [1.457 sec/step, loss=0.61811, avg_loss=0.76875]\n","Step 6629    [1.451 sec/step, loss=0.81195, avg_loss=0.76900]\n","Step 6630    [1.449 sec/step, loss=0.77262, avg_loss=0.76899]\n","Step 6631    [1.447 sec/step, loss=0.77262, avg_loss=0.76877]\n","Step 6632    [1.453 sec/step, loss=0.75793, avg_loss=0.76856]\n","Step 6633    [1.450 sec/step, loss=0.78281, avg_loss=0.76852]\n","Step 6634    [1.449 sec/step, loss=0.77730, avg_loss=0.76863]\n","Step 6635    [1.451 sec/step, loss=0.79659, avg_loss=0.76891]\n","Step 6636    [1.466 sec/step, loss=0.75373, avg_loss=0.76868]\n","Step 6637    [1.473 sec/step, loss=0.79927, avg_loss=0.76882]\n","Step 6638    [1.471 sec/step, loss=0.78427, avg_loss=0.76881]\n","Step 6639    [1.475 sec/step, loss=0.75471, avg_loss=0.76870]\n","Step 6640    [1.481 sec/step, loss=0.77369, avg_loss=0.76874]\n","Step 6641    [1.487 sec/step, loss=0.76251, avg_loss=0.76857]\n","Generated 32 batches of size 32 in 19.703 sec\n","Step 6642    [1.549 sec/step, loss=0.75802, avg_loss=0.76835]\n","Step 6643    [1.541 sec/step, loss=0.79783, avg_loss=0.76866]\n","Step 6644    [1.530 sec/step, loss=0.77261, avg_loss=0.76897]\n","Step 6645    [1.544 sec/step, loss=0.49686, avg_loss=0.76619]\n","Step 6646    [1.510 sec/step, loss=0.75177, avg_loss=0.76786]\n","Step 6647    [1.494 sec/step, loss=0.79645, avg_loss=0.76782]\n","Step 6648    [1.488 sec/step, loss=0.76907, avg_loss=0.76793]\n","Step 6649    [1.483 sec/step, loss=0.78617, avg_loss=0.76822]\n","Step 6650    [1.482 sec/step, loss=0.76947, avg_loss=0.76825]\n","Step 6651    [1.483 sec/step, loss=0.79357, avg_loss=0.76828]\n","Step 6652    [1.482 sec/step, loss=0.80742, avg_loss=0.76888]\n","Step 6653    [1.482 sec/step, loss=0.78492, avg_loss=0.76862]\n","Step 6654    [1.477 sec/step, loss=0.76505, avg_loss=0.76864]\n","Step 6655    [1.484 sec/step, loss=0.75578, avg_loss=0.76817]\n","Step 6656    [1.483 sec/step, loss=0.80194, avg_loss=0.76847]\n","Step 6657    [1.490 sec/step, loss=0.78606, avg_loss=0.76843]\n","Step 6658    [1.494 sec/step, loss=0.77777, avg_loss=0.76841]\n","Step 6659    [1.486 sec/step, loss=0.76432, avg_loss=0.76856]\n","Step 6660    [1.488 sec/step, loss=0.77785, avg_loss=0.76857]\n","Step 6661    [1.496 sec/step, loss=0.75876, avg_loss=0.76814]\n","Step 6662    [1.494 sec/step, loss=0.75515, avg_loss=0.76798]\n","Step 6663    [1.492 sec/step, loss=0.78349, avg_loss=0.76812]\n","Step 6664    [1.494 sec/step, loss=0.79821, avg_loss=0.76835]\n","Step 6665    [1.496 sec/step, loss=0.76557, avg_loss=0.76816]\n","Step 6666    [1.503 sec/step, loss=0.77622, avg_loss=0.76825]\n","Step 6667    [1.486 sec/step, loss=0.76139, avg_loss=0.76969]\n","Step 6668    [1.494 sec/step, loss=0.76252, avg_loss=0.76925]\n","Step 6669    [1.502 sec/step, loss=0.74373, avg_loss=0.76896]\n","Step 6670    [1.500 sec/step, loss=0.78287, avg_loss=0.76886]\n","Step 6671    [1.500 sec/step, loss=0.74640, avg_loss=0.76851]\n","Step 6672    [1.494 sec/step, loss=0.78919, avg_loss=0.76886]\n","Step 6673    [1.491 sec/step, loss=0.77909, avg_loss=0.76880]\n","Generated 32 batches of size 32 in 18.104 sec\n","Step 6674    [1.550 sec/step, loss=0.78363, avg_loss=0.76898]\n","Step 6675    [1.539 sec/step, loss=0.77165, avg_loss=0.76881]\n","Step 6676    [1.549 sec/step, loss=0.67668, avg_loss=0.76776]\n","Step 6677    [1.547 sec/step, loss=0.76087, avg_loss=0.76753]\n","Step 6678    [1.542 sec/step, loss=0.76740, avg_loss=0.76737]\n","Step 6679    [1.459 sec/step, loss=0.78138, avg_loss=0.76816]\n","Step 6680    [1.460 sec/step, loss=0.77369, avg_loss=0.76809]\n","Step 6681    [1.466 sec/step, loss=0.75754, avg_loss=0.76782]\n","Step 6682    [1.465 sec/step, loss=0.77971, avg_loss=0.76777]\n","Step 6683    [1.464 sec/step, loss=0.76542, avg_loss=0.76763]\n","Step 6684    [1.462 sec/step, loss=0.76968, avg_loss=0.76759]\n","Step 6685    [1.457 sec/step, loss=0.76997, avg_loss=0.76774]\n","Step 6686    [1.461 sec/step, loss=0.75322, avg_loss=0.76745]\n","Step 6687    [1.458 sec/step, loss=0.77539, avg_loss=0.76743]\n","Step 6688    [1.429 sec/step, loss=0.75671, avg_loss=0.76949]\n","Step 6689    [1.428 sec/step, loss=0.75995, avg_loss=0.76914]\n","Step 6690    [1.448 sec/step, loss=0.62857, avg_loss=0.76737]\n","Step 6691    [1.448 sec/step, loss=0.78250, avg_loss=0.76747]\n","Step 6692    [1.443 sec/step, loss=0.78113, avg_loss=0.76779]\n","Step 6693    [1.441 sec/step, loss=0.73090, avg_loss=0.76720]\n","Step 6694    [1.445 sec/step, loss=0.78859, avg_loss=0.76719]\n","Step 6695    [1.437 sec/step, loss=0.77677, avg_loss=0.76755]\n","Step 6696    [1.435 sec/step, loss=0.77880, avg_loss=0.76770]\n","Step 6697    [1.443 sec/step, loss=0.76947, avg_loss=0.76760]\n","Step 6698    [1.453 sec/step, loss=0.76561, avg_loss=0.76751]\n","Step 6699    [1.462 sec/step, loss=0.77674, avg_loss=0.76750]\n","Step 6700    [1.469 sec/step, loss=0.77095, avg_loss=0.76736]\n","Writing summary at step: 6700\n","Step 6701    [1.470 sec/step, loss=0.76234, avg_loss=0.76726]\n","Step 6702    [1.470 sec/step, loss=0.77096, avg_loss=0.76725]\n","Step 6703    [1.482 sec/step, loss=0.77529, avg_loss=0.76722]\n","Step 6704    [1.482 sec/step, loss=0.77041, avg_loss=0.76720]\n","Generated 32 batches of size 32 in 19.238 sec\n","Step 6705    [1.529 sec/step, loss=0.76269, avg_loss=0.76703]\n","Step 6706    [1.529 sec/step, loss=0.77372, avg_loss=0.76694]\n","Step 6707    [1.529 sec/step, loss=0.78390, avg_loss=0.76683]\n","Step 6708    [1.518 sec/step, loss=0.77942, avg_loss=0.76692]\n","Step 6709    [1.542 sec/step, loss=0.54781, avg_loss=0.76460]\n","Step 6710    [1.462 sec/step, loss=0.76657, avg_loss=0.76457]\n","Step 6711    [1.461 sec/step, loss=0.77096, avg_loss=0.76438]\n","Step 6712    [1.464 sec/step, loss=0.76157, avg_loss=0.76417]\n","Step 6713    [1.464 sec/step, loss=0.77500, avg_loss=0.76410]\n","Step 6714    [1.466 sec/step, loss=0.73936, avg_loss=0.76368]\n","Step 6715    [1.468 sec/step, loss=0.77757, avg_loss=0.76357]\n","Step 6716    [1.475 sec/step, loss=0.76156, avg_loss=0.76350]\n","Step 6717    [1.473 sec/step, loss=0.76385, avg_loss=0.76318]\n","Step 6718    [1.467 sec/step, loss=0.77224, avg_loss=0.76321]\n","Step 6719    [1.468 sec/step, loss=0.78009, avg_loss=0.76323]\n","Step 6720    [1.459 sec/step, loss=0.76502, avg_loss=0.76367]\n","Step 6721    [1.459 sec/step, loss=0.77593, avg_loss=0.76364]\n","Step 6722    [1.460 sec/step, loss=0.78308, avg_loss=0.76369]\n","Step 6723    [1.458 sec/step, loss=0.79490, avg_loss=0.76372]\n","Step 6724    [1.466 sec/step, loss=0.77481, avg_loss=0.76367]\n","Step 6725    [1.464 sec/step, loss=0.75829, avg_loss=0.76368]\n","Step 6726    [1.465 sec/step, loss=0.77589, avg_loss=0.76377]\n","Step 6727    [1.456 sec/step, loss=0.74880, avg_loss=0.76359]\n","Step 6728    [1.455 sec/step, loss=0.71055, avg_loss=0.76451]\n","Step 6729    [1.457 sec/step, loss=0.76794, avg_loss=0.76407]\n","Step 6730    [1.461 sec/step, loss=0.76278, avg_loss=0.76397]\n","Step 6731    [1.472 sec/step, loss=0.76557, avg_loss=0.76390]\n","Step 6732    [1.470 sec/step, loss=0.78286, avg_loss=0.76415]\n","Step 6733    [1.474 sec/step, loss=0.76702, avg_loss=0.76399]\n","Step 6734    [1.476 sec/step, loss=0.78831, avg_loss=0.76410]\n","Step 6735    [1.479 sec/step, loss=0.76326, avg_loss=0.76377]\n","Step 6736    [1.469 sec/step, loss=0.77810, avg_loss=0.76401]\n","Generated 32 batches of size 32 in 19.630 sec\n","Step 6737    [1.528 sec/step, loss=0.77240, avg_loss=0.76374]\n","Step 6738    [1.528 sec/step, loss=0.76350, avg_loss=0.76354]\n","Step 6739    [1.520 sec/step, loss=0.76492, avg_loss=0.76364]\n","Step 6740    [1.543 sec/step, loss=0.50421, avg_loss=0.76094]\n","Step 6741    [1.537 sec/step, loss=0.79291, avg_loss=0.76125]\n","Step 6742    [1.470 sec/step, loss=0.77049, avg_loss=0.76137]\n","Step 6743    [1.468 sec/step, loss=0.77006, avg_loss=0.76110]\n","Step 6744    [1.464 sec/step, loss=0.74363, avg_loss=0.76081]\n","Step 6745    [1.437 sec/step, loss=0.74647, avg_loss=0.76330]\n","Step 6746    [1.427 sec/step, loss=0.78526, avg_loss=0.76364]\n","Step 6747    [1.432 sec/step, loss=0.77069, avg_loss=0.76338]\n","Step 6748    [1.439 sec/step, loss=0.76922, avg_loss=0.76338]\n","Step 6749    [1.437 sec/step, loss=0.76713, avg_loss=0.76319]\n","Step 6750    [1.438 sec/step, loss=0.76699, avg_loss=0.76317]\n","Step 6751    [1.436 sec/step, loss=0.76719, avg_loss=0.76290]\n","Step 6752    [1.443 sec/step, loss=0.74419, avg_loss=0.76227]\n","Step 6753    [1.441 sec/step, loss=0.76454, avg_loss=0.76207]\n","Step 6754    [1.442 sec/step, loss=0.78288, avg_loss=0.76224]\n","Step 6755    [1.439 sec/step, loss=0.79008, avg_loss=0.76259]\n","Step 6756    [1.440 sec/step, loss=0.76173, avg_loss=0.76218]\n","Step 6757    [1.433 sec/step, loss=0.76927, avg_loss=0.76202]\n","Step 6758    [1.438 sec/step, loss=0.74228, avg_loss=0.76166]\n","Step 6759    [1.440 sec/step, loss=0.77567, avg_loss=0.76177]\n","Step 6760    [1.441 sec/step, loss=0.75226, avg_loss=0.76152]\n","Step 6761    [1.445 sec/step, loss=0.77332, avg_loss=0.76166]\n","Step 6762    [1.446 sec/step, loss=0.76366, avg_loss=0.76175]\n","Step 6763    [1.448 sec/step, loss=0.79245, avg_loss=0.76184]\n","Step 6764    [1.452 sec/step, loss=0.74468, avg_loss=0.76130]\n","Step 6765    [1.452 sec/step, loss=0.77335, avg_loss=0.76138]\n","Step 6766    [1.451 sec/step, loss=0.76288, avg_loss=0.76125]\n","Step 6767    [1.452 sec/step, loss=0.75249, avg_loss=0.76116]\n","Step 6768    [1.451 sec/step, loss=0.79592, avg_loss=0.76149]\n","Generated 32 batches of size 32 in 19.705 sec\n","Step 6769    [1.519 sec/step, loss=0.76539, avg_loss=0.76171]\n","Step 6770    [1.516 sec/step, loss=0.76952, avg_loss=0.76158]\n","Step 6771    [1.516 sec/step, loss=0.76593, avg_loss=0.76177]\n","Step 6772    [1.515 sec/step, loss=0.76455, avg_loss=0.76153]\n","Step 6773    [1.517 sec/step, loss=0.75690, avg_loss=0.76130]\n","Step 6774    [1.458 sec/step, loss=0.75588, avg_loss=0.76103]\n","Step 6775    [1.466 sec/step, loss=0.76684, avg_loss=0.76098]\n","Step 6776    [1.451 sec/step, loss=0.76491, avg_loss=0.76186]\n","Step 6777    [1.451 sec/step, loss=0.75484, avg_loss=0.76180]\n","Step 6778    [1.448 sec/step, loss=0.76514, avg_loss=0.76178]\n","Step 6779    [1.450 sec/step, loss=0.76718, avg_loss=0.76164]\n","Step 6780    [1.448 sec/step, loss=0.77161, avg_loss=0.76161]\n","Step 6781    [1.443 sec/step, loss=0.76216, avg_loss=0.76166]\n","Step 6782    [1.444 sec/step, loss=0.79282, avg_loss=0.76179]\n","Step 6783    [1.441 sec/step, loss=0.76863, avg_loss=0.76182]\n","Step 6784    [1.466 sec/step, loss=0.55903, avg_loss=0.75972]\n","Step 6785    [1.467 sec/step, loss=0.77486, avg_loss=0.75977]\n","Step 6786    [1.461 sec/step, loss=0.80498, avg_loss=0.76028]\n","Step 6787    [1.463 sec/step, loss=0.77942, avg_loss=0.76032]\n","Step 6788    [1.464 sec/step, loss=0.78801, avg_loss=0.76064]\n","Step 6789    [1.466 sec/step, loss=0.74509, avg_loss=0.76049]\n","Step 6790    [1.441 sec/step, loss=0.76664, avg_loss=0.76187]\n","Step 6791    [1.442 sec/step, loss=0.77233, avg_loss=0.76177]\n","Step 6792    [1.454 sec/step, loss=0.73876, avg_loss=0.76134]\n","Step 6793    [1.477 sec/step, loss=0.74883, avg_loss=0.76152]\n","Step 6794    [1.481 sec/step, loss=0.78188, avg_loss=0.76146]\n","Step 6795    [1.489 sec/step, loss=0.78557, avg_loss=0.76154]\n","Step 6796    [1.491 sec/step, loss=0.77202, avg_loss=0.76148]\n","Step 6797    [1.484 sec/step, loss=0.76474, avg_loss=0.76143]\n","Step 6798    [1.477 sec/step, loss=0.77938, avg_loss=0.76157]\n","Step 6799    [1.470 sec/step, loss=0.78444, avg_loss=0.76164]\n","Step 6800    [1.468 sec/step, loss=0.76215, avg_loss=0.76156]\n","Writing summary at step: 6800\n","Generated 32 batches of size 32 in 19.650 sec\n","Step 6801    [1.467 sec/step, loss=0.78112, avg_loss=0.76174]\n","Step 6802    [1.467 sec/step, loss=0.74612, avg_loss=0.76150]\n","Step 6803    [1.452 sec/step, loss=0.78583, avg_loss=0.76160]\n","Step 6804    [1.450 sec/step, loss=0.77364, avg_loss=0.76163]\n","Step 6805    [1.405 sec/step, loss=0.77565, avg_loss=0.76176]\n","Step 6806    [1.404 sec/step, loss=0.77880, avg_loss=0.76181]\n","Step 6807    [1.401 sec/step, loss=0.80296, avg_loss=0.76200]\n","Step 6808    [1.396 sec/step, loss=0.77294, avg_loss=0.76194]\n","Step 6809    [1.368 sec/step, loss=0.77460, avg_loss=0.76421]\n","Step 6810    [1.368 sec/step, loss=0.76352, avg_loss=0.76418]\n","Step 6811    [1.373 sec/step, loss=0.76033, avg_loss=0.76407]\n","Step 6812    [1.382 sec/step, loss=0.72422, avg_loss=0.76370]\n","Step 6813    [1.386 sec/step, loss=0.75507, avg_loss=0.76350]\n","Step 6814    [1.385 sec/step, loss=0.74716, avg_loss=0.76358]\n","Step 6815    [1.383 sec/step, loss=0.78423, avg_loss=0.76364]\n","Step 6816    [1.378 sec/step, loss=0.78734, avg_loss=0.76390]\n","Step 6817    [1.408 sec/step, loss=0.54412, avg_loss=0.76170]\n","Step 6818    [1.409 sec/step, loss=0.77018, avg_loss=0.76168]\n","Step 6819    [1.406 sec/step, loss=0.78526, avg_loss=0.76173]\n","Step 6820    [1.403 sec/step, loss=0.74201, avg_loss=0.76150]\n","Step 6821    [1.404 sec/step, loss=0.77553, avg_loss=0.76150]\n","Step 6822    [1.404 sec/step, loss=0.77087, avg_loss=0.76138]\n","Step 6823    [1.409 sec/step, loss=0.76016, avg_loss=0.76103]\n","Step 6824    [1.407 sec/step, loss=0.76857, avg_loss=0.76097]\n","Step 6825    [1.411 sec/step, loss=0.76924, avg_loss=0.76108]\n","Step 6826    [1.411 sec/step, loss=0.77689, avg_loss=0.76109]\n","Step 6827    [1.418 sec/step, loss=0.76792, avg_loss=0.76128]\n","Step 6828    [1.400 sec/step, loss=0.77607, avg_loss=0.76193]\n","Step 6829    [1.399 sec/step, loss=0.78452, avg_loss=0.76210]\n","Step 6830    [1.401 sec/step, loss=0.77561, avg_loss=0.76223]\n","Step 6831    [1.408 sec/step, loss=0.77144, avg_loss=0.76229]\n","Generated 32 batches of size 32 in 18.459 sec\n","Step 6832    [1.469 sec/step, loss=0.78497, avg_loss=0.76231]\n","Step 6833    [1.466 sec/step, loss=0.78227, avg_loss=0.76246]\n","Step 6834    [1.466 sec/step, loss=0.75997, avg_loss=0.76218]\n","Step 6835    [1.458 sec/step, loss=0.76514, avg_loss=0.76220]\n","Step 6836    [1.455 sec/step, loss=0.76523, avg_loss=0.76207]\n","Step 6837    [1.393 sec/step, loss=0.78202, avg_loss=0.76216]\n","Step 6838    [1.388 sec/step, loss=0.76776, avg_loss=0.76221]\n","Step 6839    [1.390 sec/step, loss=0.78974, avg_loss=0.76245]\n","Step 6840    [1.360 sec/step, loss=0.79078, avg_loss=0.76532]\n","Step 6841    [1.363 sec/step, loss=0.74782, avg_loss=0.76487]\n","Step 6842    [1.366 sec/step, loss=0.74026, avg_loss=0.76457]\n","Step 6843    [1.375 sec/step, loss=0.75547, avg_loss=0.76442]\n","Step 6844    [1.379 sec/step, loss=0.76319, avg_loss=0.76462]\n","Step 6845    [1.380 sec/step, loss=0.79640, avg_loss=0.76511]\n","Step 6846    [1.383 sec/step, loss=0.76352, avg_loss=0.76490]\n","Step 6847    [1.378 sec/step, loss=0.75285, avg_loss=0.76472]\n","Step 6848    [1.374 sec/step, loss=0.77418, avg_loss=0.76477]\n","Step 6849    [1.372 sec/step, loss=0.77879, avg_loss=0.76489]\n","Step 6850    [1.372 sec/step, loss=0.78880, avg_loss=0.76510]\n","Step 6851    [1.385 sec/step, loss=0.72010, avg_loss=0.76463]\n","Step 6852    [1.372 sec/step, loss=0.78950, avg_loss=0.76509]\n","Step 6853    [1.401 sec/step, loss=0.54108, avg_loss=0.76285]\n","Step 6854    [1.402 sec/step, loss=0.76390, avg_loss=0.76266]\n","Step 6855    [1.402 sec/step, loss=0.78932, avg_loss=0.76265]\n","Step 6856    [1.410 sec/step, loss=0.76722, avg_loss=0.76271]\n","Step 6857    [1.413 sec/step, loss=0.77075, avg_loss=0.76272]\n","Step 6858    [1.413 sec/step, loss=0.76861, avg_loss=0.76299]\n","Step 6859    [1.414 sec/step, loss=0.75628, avg_loss=0.76279]\n","Step 6860    [1.418 sec/step, loss=0.77698, avg_loss=0.76304]\n","Step 6861    [1.409 sec/step, loss=0.77510, avg_loss=0.76306]\n","Step 6862    [1.413 sec/step, loss=0.75568, avg_loss=0.76298]\n","Step 6863    [1.411 sec/step, loss=0.76401, avg_loss=0.76269]\n","Generated 32 batches of size 32 in 18.326 sec\n","Step 6864    [1.465 sec/step, loss=0.76670, avg_loss=0.76291]\n","Step 6865    [1.463 sec/step, loss=0.75027, avg_loss=0.76268]\n","Step 6866    [1.457 sec/step, loss=0.75123, avg_loss=0.76257]\n","Step 6867    [1.451 sec/step, loss=0.78043, avg_loss=0.76285]\n","Step 6868    [1.451 sec/step, loss=0.77891, avg_loss=0.76268]\n","Step 6869    [1.374 sec/step, loss=0.78014, avg_loss=0.76282]\n","Step 6870    [1.376 sec/step, loss=0.77053, avg_loss=0.76283]\n","Step 6871    [1.374 sec/step, loss=0.78292, avg_loss=0.76300]\n","Step 6872    [1.369 sec/step, loss=0.76593, avg_loss=0.76302]\n","Step 6873    [1.362 sec/step, loss=0.74867, avg_loss=0.76293]\n","Step 6874    [1.362 sec/step, loss=0.72920, avg_loss=0.76267]\n","Step 6875    [1.356 sec/step, loss=0.77207, avg_loss=0.76272]\n","Step 6876    [1.358 sec/step, loss=0.80458, avg_loss=0.76312]\n","Step 6877    [1.356 sec/step, loss=0.76037, avg_loss=0.76317]\n","Step 6878    [1.358 sec/step, loss=0.76738, avg_loss=0.76319]\n","Step 6879    [1.360 sec/step, loss=0.77718, avg_loss=0.76329]\n","Step 6880    [1.358 sec/step, loss=0.76231, avg_loss=0.76320]\n","Step 6881    [1.356 sec/step, loss=0.78351, avg_loss=0.76342]\n","Step 6882    [1.355 sec/step, loss=0.76135, avg_loss=0.76310]\n","Step 6883    [1.359 sec/step, loss=0.77619, avg_loss=0.76318]\n","Step 6884    [1.339 sec/step, loss=0.74639, avg_loss=0.76505]\n","Step 6885    [1.346 sec/step, loss=0.73972, avg_loss=0.76470]\n","Step 6886    [1.358 sec/step, loss=0.70324, avg_loss=0.76368]\n","Step 6887    [1.359 sec/step, loss=0.78428, avg_loss=0.76373]\n","Step 6888    [1.367 sec/step, loss=0.75219, avg_loss=0.76337]\n","Step 6889    [1.373 sec/step, loss=0.77010, avg_loss=0.76362]\n","Step 6890    [1.375 sec/step, loss=0.77654, avg_loss=0.76372]\n","Step 6891    [1.387 sec/step, loss=0.76877, avg_loss=0.76368]\n","Step 6892    [1.378 sec/step, loss=0.79002, avg_loss=0.76420]\n","Step 6893    [1.363 sec/step, loss=0.77235, avg_loss=0.76443]\n","Step 6894    [1.401 sec/step, loss=0.54912, avg_loss=0.76210]\n","Step 6895    [1.401 sec/step, loss=0.79928, avg_loss=0.76224]\n","Generated 32 batches of size 32 in 20.384 sec\n","Step 6896    [1.438 sec/step, loss=0.75365, avg_loss=0.76206]\n","Step 6897    [1.440 sec/step, loss=0.75530, avg_loss=0.76196]\n","Step 6898    [1.436 sec/step, loss=0.79521, avg_loss=0.76212]\n","Step 6899    [1.433 sec/step, loss=0.75769, avg_loss=0.76185]\n","Step 6900    [1.427 sec/step, loss=0.78169, avg_loss=0.76205]\n","Writing summary at step: 6900\n","Step 6901    [1.431 sec/step, loss=0.76349, avg_loss=0.76187]\n","Step 6902    [1.424 sec/step, loss=0.77089, avg_loss=0.76212]\n","Step 6903    [1.424 sec/step, loss=0.76306, avg_loss=0.76189]\n","Step 6904    [1.422 sec/step, loss=0.76986, avg_loss=0.76186]\n","Step 6905    [1.416 sec/step, loss=0.77971, avg_loss=0.76190]\n","Step 6906    [1.415 sec/step, loss=0.76239, avg_loss=0.76173]\n","Step 6907    [1.416 sec/step, loss=0.77709, avg_loss=0.76147]\n","Step 6908    [1.419 sec/step, loss=0.76261, avg_loss=0.76137]\n","Step 6909    [1.419 sec/step, loss=0.75576, avg_loss=0.76118]\n","Step 6910    [1.421 sec/step, loss=0.74222, avg_loss=0.76097]\n","Step 6911    [1.424 sec/step, loss=0.76375, avg_loss=0.76100]\n","Step 6912    [1.415 sec/step, loss=0.75345, avg_loss=0.76130]\n","Step 6913    [1.410 sec/step, loss=0.79584, avg_loss=0.76170]\n","Step 6914    [1.418 sec/step, loss=0.73431, avg_loss=0.76157]\n","Step 6915    [1.415 sec/step, loss=0.76452, avg_loss=0.76138]\n","Step 6916    [1.415 sec/step, loss=0.76578, avg_loss=0.76116]\n","Step 6917    [1.388 sec/step, loss=0.74175, avg_loss=0.76314]\n","Step 6918    [1.395 sec/step, loss=0.76542, avg_loss=0.76309]\n","Step 6919    [1.398 sec/step, loss=0.75258, avg_loss=0.76276]\n","Step 6920    [1.403 sec/step, loss=0.76369, avg_loss=0.76298]\n","Step 6921    [1.413 sec/step, loss=0.74155, avg_loss=0.76264]\n","Step 6922    [1.411 sec/step, loss=0.77317, avg_loss=0.76266]\n","Step 6923    [1.411 sec/step, loss=0.77341, avg_loss=0.76280]\n","Step 6924    [1.428 sec/step, loss=0.73739, avg_loss=0.76248]\n","Step 6925    [1.431 sec/step, loss=0.77645, avg_loss=0.76256]\n","Step 6926    [1.438 sec/step, loss=0.77851, avg_loss=0.76257]\n","Generated 32 batches of size 32 in 19.510 sec\n","Step 6927    [1.484 sec/step, loss=0.78056, avg_loss=0.76270]\n","Step 6928    [1.482 sec/step, loss=0.76813, avg_loss=0.76262]\n","Step 6929    [1.480 sec/step, loss=0.75195, avg_loss=0.76229]\n","Step 6930    [1.487 sec/step, loss=0.73229, avg_loss=0.76186]\n","Step 6931    [1.473 sec/step, loss=0.77890, avg_loss=0.76194]\n","Step 6932    [1.417 sec/step, loss=0.77770, avg_loss=0.76186]\n","Step 6933    [1.416 sec/step, loss=0.75626, avg_loss=0.76160]\n","Step 6934    [1.413 sec/step, loss=0.74910, avg_loss=0.76149]\n","Step 6935    [1.415 sec/step, loss=0.77277, avg_loss=0.76157]\n","Step 6936    [1.417 sec/step, loss=0.75745, avg_loss=0.76149]\n","Step 6937    [1.414 sec/step, loss=0.76897, avg_loss=0.76136]\n","Step 6938    [1.415 sec/step, loss=0.77087, avg_loss=0.76139]\n","Step 6939    [1.416 sec/step, loss=0.77389, avg_loss=0.76123]\n","Step 6940    [1.417 sec/step, loss=0.77753, avg_loss=0.76110]\n","Step 6941    [1.413 sec/step, loss=0.76542, avg_loss=0.76128]\n","Step 6942    [1.414 sec/step, loss=0.75189, avg_loss=0.76139]\n","Step 6943    [1.413 sec/step, loss=0.74389, avg_loss=0.76128]\n","Step 6944    [1.411 sec/step, loss=0.75167, avg_loss=0.76116]\n","Step 6945    [1.406 sec/step, loss=0.76270, avg_loss=0.76083]\n","Step 6946    [1.403 sec/step, loss=0.78116, avg_loss=0.76100]\n","Step 6947    [1.402 sec/step, loss=0.76064, avg_loss=0.76108]\n","Step 6948    [1.400 sec/step, loss=0.78327, avg_loss=0.76117]\n","Step 6949    [1.399 sec/step, loss=0.75393, avg_loss=0.76092]\n","Step 6950    [1.401 sec/step, loss=0.75267, avg_loss=0.76056]\n","Step 6951    [1.401 sec/step, loss=0.75452, avg_loss=0.76091]\n","Step 6952    [1.404 sec/step, loss=0.78211, avg_loss=0.76083]\n","Step 6953    [1.381 sec/step, loss=0.78678, avg_loss=0.76329]\n","Step 6954    [1.382 sec/step, loss=0.75982, avg_loss=0.76325]\n","Step 6955    [1.420 sec/step, loss=0.58032, avg_loss=0.76116]\n","Step 6956    [1.423 sec/step, loss=0.74157, avg_loss=0.76090]\n","Step 6957    [1.430 sec/step, loss=0.77333, avg_loss=0.76093]\n","Step 6958    [1.427 sec/step, loss=0.74646, avg_loss=0.76071]\n","Generated 32 batches of size 32 in 19.746 sec\n","Step 6959    [1.455 sec/step, loss=0.75959, avg_loss=0.76074]\n","Step 6960    [1.450 sec/step, loss=0.76869, avg_loss=0.76066]\n","Step 6961    [1.446 sec/step, loss=0.77196, avg_loss=0.76062]\n","Step 6962    [1.448 sec/step, loss=0.76628, avg_loss=0.76073]\n","Step 6963    [1.454 sec/step, loss=0.76961, avg_loss=0.76079]\n","Step 6964    [1.397 sec/step, loss=0.75831, avg_loss=0.76070]\n","Step 6965    [1.403 sec/step, loss=0.79157, avg_loss=0.76112]\n","Step 6966    [1.403 sec/step, loss=0.78518, avg_loss=0.76146]\n","Step 6967    [1.405 sec/step, loss=0.75737, avg_loss=0.76122]\n","Step 6968    [1.400 sec/step, loss=0.74808, avg_loss=0.76092]\n","Step 6969    [1.402 sec/step, loss=0.77263, avg_loss=0.76084]\n","Step 6970    [1.402 sec/step, loss=0.74521, avg_loss=0.76059]\n","Step 6971    [1.406 sec/step, loss=0.75261, avg_loss=0.76029]\n","Step 6972    [1.412 sec/step, loss=0.77324, avg_loss=0.76036]\n","Step 6973    [1.415 sec/step, loss=0.78580, avg_loss=0.76073]\n","Step 6974    [1.419 sec/step, loss=0.71394, avg_loss=0.76058]\n","Step 6975    [1.417 sec/step, loss=0.78215, avg_loss=0.76068]\n","Step 6976    [1.421 sec/step, loss=0.77797, avg_loss=0.76041]\n","Step 6977    [1.444 sec/step, loss=0.58936, avg_loss=0.75870]\n","Step 6978    [1.446 sec/step, loss=0.75215, avg_loss=0.75855]\n","Step 6979    [1.444 sec/step, loss=0.78519, avg_loss=0.75863]\n","Step 6980    [1.446 sec/step, loss=0.77768, avg_loss=0.75878]\n","Step 6981    [1.447 sec/step, loss=0.76754, avg_loss=0.75862]\n","Step 6982    [1.449 sec/step, loss=0.76474, avg_loss=0.75866]\n","Step 6983    [1.449 sec/step, loss=0.77135, avg_loss=0.75861]\n","Step 6984    [1.445 sec/step, loss=0.74874, avg_loss=0.75863]\n","Step 6985    [1.438 sec/step, loss=0.76032, avg_loss=0.75884]\n","Step 6986    [1.433 sec/step, loss=0.76528, avg_loss=0.75946]\n","Step 6987    [1.432 sec/step, loss=0.77271, avg_loss=0.75934]\n","Step 6988    [1.426 sec/step, loss=0.75732, avg_loss=0.75939]\n","Step 6989    [1.423 sec/step, loss=0.76119, avg_loss=0.75930]\n","Step 6990    [1.424 sec/step, loss=0.77851, avg_loss=0.75932]\n","Generated 32 batches of size 32 in 19.432 sec\n","Step 6991    [1.508 sec/step, loss=0.76110, avg_loss=0.75925]\n","Step 6992    [1.503 sec/step, loss=0.76926, avg_loss=0.75904]\n","Step 6993    [1.498 sec/step, loss=0.76699, avg_loss=0.75899]\n","Step 6994    [1.455 sec/step, loss=0.76834, avg_loss=0.76118]\n","Step 6995    [1.449 sec/step, loss=0.77729, avg_loss=0.76096]\n","Step 6996    [1.411 sec/step, loss=0.75734, avg_loss=0.76100]\n","Step 6997    [1.406 sec/step, loss=0.77531, avg_loss=0.76120]\n","Step 6998    [1.432 sec/step, loss=0.60689, avg_loss=0.75931]\n","Step 6999    [1.431 sec/step, loss=0.77792, avg_loss=0.75952]\n","Step 7000    [1.430 sec/step, loss=0.75392, avg_loss=0.75924]\n","Writing summary at step: 7000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (79500,)\n","Check wav file:  (109500,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000007000-align000.png\n","100% 1/1 [00:03<00:00,  3.21s/it]\n","Test finished for step 7000.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (108300,)\n","Check wav file:  (138300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000007000-align000.png\n"," 25% 1/4 [00:03<00:11,  3.71s/it]Check wav file before change:  (108300,)\n","Check wav file:  (138300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000007000-align001.png\n"," 50% 2/4 [00:07<00:07,  3.79s/it]Check wav file before change:  (108300,)\n","Check wav file:  (138300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000007000-align002.png\n"," 75% 3/4 [00:11<00:03,  3.77s/it]Check wav file before change:  (108300,)\n","Check wav file:  (138300,)\n","Training korean : Use jamo\n"," [*] Plot saved: logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000007000-align003.png\n","100% 4/4 [00:15<00:00,  3.85s/it]\n","Test finished for step 7000.\n","Step 7001    [1.427 sec/step, loss=0.76168, avg_loss=0.75922]\n","Step 7002    [1.434 sec/step, loss=0.76316, avg_loss=0.75914]\n","Step 7003    [1.435 sec/step, loss=0.75368, avg_loss=0.75905]\n","Step 7004    [1.436 sec/step, loss=0.75881, avg_loss=0.75894]\n","Step 7005    [1.439 sec/step, loss=0.76137, avg_loss=0.75875]\n","Step 7006    [1.438 sec/step, loss=0.77306, avg_loss=0.75886]\n","Step 7007    [1.439 sec/step, loss=0.78015, avg_loss=0.75889]\n","Step 7008    [1.437 sec/step, loss=0.77966, avg_loss=0.75906]\n","Step 7009    [1.441 sec/step, loss=0.77239, avg_loss=0.75923]\n","Step 7010    [1.438 sec/step, loss=0.78052, avg_loss=0.75961]\n","Step 7011    [1.431 sec/step, loss=0.75889, avg_loss=0.75956]\n","Step 7012    [1.429 sec/step, loss=0.77384, avg_loss=0.75977]\n","Step 7013    [1.442 sec/step, loss=0.76973, avg_loss=0.75951]\n","Step 7014    [1.435 sec/step, loss=0.75434, avg_loss=0.75971]\n","Step 7015    [1.444 sec/step, loss=0.74616, avg_loss=0.75952]\n","Step 7016    [1.443 sec/step, loss=0.73851, avg_loss=0.75925]\n","Step 7017    [1.446 sec/step, loss=0.76253, avg_loss=0.75946]\n","Step 7018    [1.459 sec/step, loss=0.67798, avg_loss=0.75858]\n","Step 7019    [1.459 sec/step, loss=0.76178, avg_loss=0.75868]\n","Step 7020    [1.472 sec/step, loss=0.75383, avg_loss=0.75858]\n","Generated 32 batches of size 32 in 17.936 sec\n","Step 7021    [1.493 sec/step, loss=0.74712, avg_loss=0.75863]\n","Step 7022    [1.491 sec/step, loss=0.77076, avg_loss=0.75861]\n","Step 7023    [1.496 sec/step, loss=0.70923, avg_loss=0.75797]\n","Step 7024    [1.483 sec/step, loss=0.75355, avg_loss=0.75813]\n","Step 7025    [1.477 sec/step, loss=0.76738, avg_loss=0.75804]\n","Step 7026    [1.467 sec/step, loss=0.74969, avg_loss=0.75775]\n","Step 7027    [1.414 sec/step, loss=0.77551, avg_loss=0.75770]\n","Step 7028    [1.412 sec/step, loss=0.77156, avg_loss=0.75773]\n","Step 7029    [1.415 sec/step, loss=0.76744, avg_loss=0.75789]\n","Step 7030    [1.406 sec/step, loss=0.77463, avg_loss=0.75831]\n","Step 7031    [1.409 sec/step, loss=0.74863, avg_loss=0.75801]\n","Step 7032    [1.404 sec/step, loss=0.74487, avg_loss=0.75768]\n","Step 7033    [1.400 sec/step, loss=0.73940, avg_loss=0.75751]\n","Step 7034    [1.402 sec/step, loss=0.76649, avg_loss=0.75769]\n","Step 7035    [1.403 sec/step, loss=0.77758, avg_loss=0.75773]\n","Step 7036    [1.401 sec/step, loss=0.77599, avg_loss=0.75792]\n","Step 7037    [1.404 sec/step, loss=0.76911, avg_loss=0.75792]\n","Step 7038    [1.404 sec/step, loss=0.75779, avg_loss=0.75779]\n","Step 7039    [1.424 sec/step, loss=0.57983, avg_loss=0.75585]\n","Step 7040    [1.425 sec/step, loss=0.77744, avg_loss=0.75585]\n","Step 7041    [1.425 sec/step, loss=0.75058, avg_loss=0.75570]\n","Step 7042    [1.425 sec/step, loss=0.76977, avg_loss=0.75588]\n","Step 7043    [1.417 sec/step, loss=0.77345, avg_loss=0.75617]\n","Step 7044    [1.425 sec/step, loss=0.76174, avg_loss=0.75628]\n","Step 7045    [1.428 sec/step, loss=0.76853, avg_loss=0.75633]\n","Step 7046    [1.441 sec/step, loss=0.73265, avg_loss=0.75585]\n","Step 7047    [1.446 sec/step, loss=0.76325, avg_loss=0.75587]\n","Step 7048    [1.451 sec/step, loss=0.76058, avg_loss=0.75565]\n","Step 7049    [1.459 sec/step, loss=0.77762, avg_loss=0.75588]\n","Step 7050    [1.469 sec/step, loss=0.76058, avg_loss=0.75596]\n","Step 7051    [1.463 sec/step, loss=0.75894, avg_loss=0.75601]\n","Step 7052    [1.464 sec/step, loss=0.75471, avg_loss=0.75573]\n","Generated 32 batches of size 32 in 18.918 sec\n","Step 7053    [1.515 sec/step, loss=0.75142, avg_loss=0.75538]\n","Step 7054    [1.517 sec/step, loss=0.75802, avg_loss=0.75536]\n","Step 7055    [1.480 sec/step, loss=0.75034, avg_loss=0.75706]\n","Step 7056    [1.469 sec/step, loss=0.76583, avg_loss=0.75730]\n","Step 7057    [1.462 sec/step, loss=0.76862, avg_loss=0.75726]\n","Step 7058    [1.459 sec/step, loss=0.76316, avg_loss=0.75742]\n","Step 7059    [1.425 sec/step, loss=0.75351, avg_loss=0.75736]\n","Step 7060    [1.426 sec/step, loss=0.75906, avg_loss=0.75727]\n","Step 7061    [1.426 sec/step, loss=0.75379, avg_loss=0.75709]\n","Step 7062    [1.426 sec/step, loss=0.73079, avg_loss=0.75673]\n","Step 7063    [1.418 sec/step, loss=0.74400, avg_loss=0.75648]\n","Step 7064    [1.412 sec/step, loss=0.76794, avg_loss=0.75657]\n","Step 7065    [1.406 sec/step, loss=0.75929, avg_loss=0.75625]\n","Step 7066    [1.417 sec/step, loss=0.73848, avg_loss=0.75578]\n","Step 7067    [1.417 sec/step, loss=0.77503, avg_loss=0.75596]\n","Step 7068    [1.415 sec/step, loss=0.78955, avg_loss=0.75637]\n","Step 7069    [1.417 sec/step, loss=0.74422, avg_loss=0.75609]\n","Step 7070    [1.415 sec/step, loss=0.73682, avg_loss=0.75600]\n","Step 7071    [1.418 sec/step, loss=0.74630, avg_loss=0.75594]\n","Step 7072    [1.415 sec/step, loss=0.77283, avg_loss=0.75594]\n","Step 7073    [1.423 sec/step, loss=0.75052, avg_loss=0.75558]\n","Step 7074    [1.411 sec/step, loss=0.75632, avg_loss=0.75601]\n","Step 7075    [1.410 sec/step, loss=0.75483, avg_loss=0.75574]\n","Step 7076    [1.408 sec/step, loss=0.78035, avg_loss=0.75576]\n","Step 7077    [1.385 sec/step, loss=0.75777, avg_loss=0.75744]\n","Step 7078    [1.389 sec/step, loss=0.77029, avg_loss=0.75762]\n","Step 7079    [1.392 sec/step, loss=0.76125, avg_loss=0.75739]\n","Step 7080    [1.438 sec/step, loss=0.52646, avg_loss=0.75487]\n","Step 7081    [1.443 sec/step, loss=0.77080, avg_loss=0.75491]\n","Step 7082    [1.444 sec/step, loss=0.77456, avg_loss=0.75500]\n","Step 7083    [1.452 sec/step, loss=0.74231, avg_loss=0.75471]\n","Step 7084    [1.451 sec/step, loss=0.75824, avg_loss=0.75481]\n","Generated 32 batches of size 32 in 19.566 sec\n","Step 7085    [1.488 sec/step, loss=0.77699, avg_loss=0.75498]\n","Step 7086    [1.482 sec/step, loss=0.74711, avg_loss=0.75479]\n","Step 7087    [1.477 sec/step, loss=0.76292, avg_loss=0.75470]\n","Step 7088    [1.473 sec/step, loss=0.77437, avg_loss=0.75487]\n","Step 7089    [1.474 sec/step, loss=0.75422, avg_loss=0.75480]\n","Step 7090    [1.476 sec/step, loss=0.76534, avg_loss=0.75467]\n","Step 7091    [1.392 sec/step, loss=0.71049, avg_loss=0.75416]\n","Step 7092    [1.393 sec/step, loss=0.76659, avg_loss=0.75413]\n","Step 7093    [1.392 sec/step, loss=0.76893, avg_loss=0.75415]\n","Step 7094    [1.397 sec/step, loss=0.75479, avg_loss=0.75402]\n","Step 7095    [1.400 sec/step, loss=0.77664, avg_loss=0.75401]\n","Step 7096    [1.398 sec/step, loss=0.74617, avg_loss=0.75390]\n","Step 7097    [1.399 sec/step, loss=0.77994, avg_loss=0.75394]\n","Step 7098    [1.375 sec/step, loss=0.75535, avg_loss=0.75543]\n","Step 7099    [1.379 sec/step, loss=0.76758, avg_loss=0.75533]\n","Step 7100    [1.379 sec/step, loss=0.77285, avg_loss=0.75551]\n","Writing summary at step: 7100\n","Step 7101    [1.378 sec/step, loss=0.75725, avg_loss=0.75547]\n","Step 7102    [1.370 sec/step, loss=0.79852, avg_loss=0.75582]\n","Step 7103    [1.370 sec/step, loss=0.76055, avg_loss=0.75589]\n","Step 7104    [1.371 sec/step, loss=0.76483, avg_loss=0.75595]\n","Step 7105    [1.395 sec/step, loss=0.54565, avg_loss=0.75380]\n","Step 7106    [1.394 sec/step, loss=0.77842, avg_loss=0.75385]\n","Step 7107    [1.404 sec/step, loss=0.78458, avg_loss=0.75389]\n","Step 7108    [1.409 sec/step, loss=0.77453, avg_loss=0.75384]\n","Step 7109    [1.412 sec/step, loss=0.77003, avg_loss=0.75382]\n","Step 7110    [1.425 sec/step, loss=0.78554, avg_loss=0.75387]\n","Step 7111    [1.436 sec/step, loss=0.74719, avg_loss=0.75375]\n","Step 7112    [1.444 sec/step, loss=0.78616, avg_loss=0.75388]\n","Step 7113    [1.439 sec/step, loss=0.75334, avg_loss=0.75371]\n","Step 7114    [1.436 sec/step, loss=0.75345, avg_loss=0.75370]\n","Step 7115    [1.429 sec/step, loss=0.77247, avg_loss=0.75397]\n","Generated 32 batches of size 32 in 19.466 sec\n","Step 7116    [1.478 sec/step, loss=0.75175, avg_loss=0.75410]\n","Step 7117    [1.475 sec/step, loss=0.76480, avg_loss=0.75412]\n","Step 7118    [1.453 sec/step, loss=0.76261, avg_loss=0.75497]\n","Step 7119    [1.450 sec/step, loss=0.79482, avg_loss=0.75530]\n","Step 7120    [1.434 sec/step, loss=0.75924, avg_loss=0.75535]\n","Step 7121    [1.408 sec/step, loss=0.77218, avg_loss=0.75560]\n","Step 7122    [1.411 sec/step, loss=0.77465, avg_loss=0.75564]\n","Step 7123    [1.409 sec/step, loss=0.72551, avg_loss=0.75580]\n","Step 7124    [1.404 sec/step, loss=0.77339, avg_loss=0.75600]\n","Step 7125    [1.404 sec/step, loss=0.76774, avg_loss=0.75601]\n","Step 7126    [1.429 sec/step, loss=0.59955, avg_loss=0.75450]\n","Step 7127    [1.434 sec/step, loss=0.77519, avg_loss=0.75450]\n","Step 7128    [1.436 sec/step, loss=0.76113, avg_loss=0.75440]\n","Step 7129    [1.440 sec/step, loss=0.77711, avg_loss=0.75449]\n","Step 7130    [1.437 sec/step, loss=0.75316, avg_loss=0.75428]\n","Step 7131    [1.437 sec/step, loss=0.73859, avg_loss=0.75418]\n","Step 7132    [1.434 sec/step, loss=0.77383, avg_loss=0.75447]\n","Step 7133    [1.435 sec/step, loss=0.77507, avg_loss=0.75482]\n","Step 7134    [1.436 sec/step, loss=0.75363, avg_loss=0.75470]\n","Step 7135    [1.436 sec/step, loss=0.78325, avg_loss=0.75475]\n","Step 7136    [1.436 sec/step, loss=0.75146, avg_loss=0.75451]\n","Step 7137    [1.434 sec/step, loss=0.79377, avg_loss=0.75475]\n","Step 7138    [1.436 sec/step, loss=0.76206, avg_loss=0.75480]\n","Step 7139    [1.417 sec/step, loss=0.76018, avg_loss=0.75660]\n","Step 7140    [1.424 sec/step, loss=0.75833, avg_loss=0.75641]\n","Step 7141    [1.423 sec/step, loss=0.74960, avg_loss=0.75640]\n","Step 7142    [1.422 sec/step, loss=0.76205, avg_loss=0.75632]\n","Step 7143    [1.428 sec/step, loss=0.76475, avg_loss=0.75624]\n","Step 7144    [1.425 sec/step, loss=0.79332, avg_loss=0.75655]\n","Step 7145    [1.430 sec/step, loss=0.76216, avg_loss=0.75649]\n","Step 7146    [1.421 sec/step, loss=0.78648, avg_loss=0.75703]\n","Step 7147    [1.425 sec/step, loss=0.75989, avg_loss=0.75699]\n","Generated 32 batches of size 32 in 19.851 sec\n","Step 7148    [1.498 sec/step, loss=0.75434, avg_loss=0.75693]\n","Step 7149    [1.496 sec/step, loss=0.74741, avg_loss=0.75663]\n","Step 7150    [1.484 sec/step, loss=0.78734, avg_loss=0.75690]\n","Step 7151    [1.484 sec/step, loss=0.75150, avg_loss=0.75682]\n","Step 7152    [1.481 sec/step, loss=0.77047, avg_loss=0.75698]\n","Step 7153    [1.424 sec/step, loss=0.75772, avg_loss=0.75704]\n","Step 7154    [1.420 sec/step, loss=0.76916, avg_loss=0.75715]\n","Step 7155    [1.418 sec/step, loss=0.77358, avg_loss=0.75739]\n","Step 7156    [1.418 sec/step, loss=0.76609, avg_loss=0.75739]\n","Step 7157    [1.419 sec/step, loss=0.77147, avg_loss=0.75742]\n","Step 7158    [1.416 sec/step, loss=0.75107, avg_loss=0.75730]\n","Step 7159    [1.416 sec/step, loss=0.76192, avg_loss=0.75738]\n","Step 7160    [1.421 sec/step, loss=0.76316, avg_loss=0.75742]\n","Step 7161    [1.420 sec/step, loss=0.76131, avg_loss=0.75750]\n","Step 7162    [1.412 sec/step, loss=0.75413, avg_loss=0.75773]\n","Step 7163    [1.414 sec/step, loss=0.74759, avg_loss=0.75777]\n","Step 7164    [1.421 sec/step, loss=0.77271, avg_loss=0.75781]\n","Step 7165    [1.422 sec/step, loss=0.78958, avg_loss=0.75812]\n","Step 7166    [1.418 sec/step, loss=0.78430, avg_loss=0.75857]\n","Step 7167    [1.413 sec/step, loss=0.77630, avg_loss=0.75859]\n","Step 7168    [1.415 sec/step, loss=0.77827, avg_loss=0.75847]\n","Step 7169    [1.442 sec/step, loss=0.53545, avg_loss=0.75639]\n","Step 7170    [1.443 sec/step, loss=0.77650, avg_loss=0.75678]\n","Step 7171    [1.445 sec/step, loss=0.78683, avg_loss=0.75719]\n","Step 7172    [1.448 sec/step, loss=0.75142, avg_loss=0.75697]\n","Step 7173    [1.447 sec/step, loss=0.74530, avg_loss=0.75692]\n","Step 7174    [1.454 sec/step, loss=0.75475, avg_loss=0.75691]\n","Step 7175    [1.460 sec/step, loss=0.75801, avg_loss=0.75694]\n","Step 7176    [1.461 sec/step, loss=0.77309, avg_loss=0.75687]\n","Step 7177    [1.479 sec/step, loss=0.73763, avg_loss=0.75666]\n","Step 7178    [1.475 sec/step, loss=0.76825, avg_loss=0.75664]\n","Step 7179    [1.487 sec/step, loss=0.75224, avg_loss=0.75655]\n","Generated 32 batches of size 32 in 19.637 sec\n","Step 7180    [1.490 sec/step, loss=0.76543, avg_loss=0.75894]\n","Step 7181    [1.487 sec/step, loss=0.76185, avg_loss=0.75885]\n","Step 7182    [1.482 sec/step, loss=0.78642, avg_loss=0.75897]\n","Step 7183    [1.495 sec/step, loss=0.58078, avg_loss=0.75736]\n","Step 7184    [1.493 sec/step, loss=0.77680, avg_loss=0.75754]\n","Step 7185    [1.461 sec/step, loss=0.75742, avg_loss=0.75735]\n","Step 7186    [1.463 sec/step, loss=0.78070, avg_loss=0.75768]\n","Step 7187    [1.464 sec/step, loss=0.77199, avg_loss=0.75777]\n","Step 7188    [1.464 sec/step, loss=0.78470, avg_loss=0.75788]\n","Step 7189    [1.459 sec/step, loss=0.76098, avg_loss=0.75794]\n","Step 7190    [1.460 sec/step, loss=0.77052, avg_loss=0.75800]\n","Step 7191    [1.449 sec/step, loss=0.75736, avg_loss=0.75846]\n","Step 7192    [1.448 sec/step, loss=0.76005, avg_loss=0.75840]\n","Step 7193    [1.448 sec/step, loss=0.76827, avg_loss=0.75839]\n","Step 7194    [1.442 sec/step, loss=0.75147, avg_loss=0.75836]\n","Step 7195    [1.440 sec/step, loss=0.76722, avg_loss=0.75827]\n","Step 7196    [1.446 sec/step, loss=0.76154, avg_loss=0.75842]\n","Step 7197    [1.452 sec/step, loss=0.72088, avg_loss=0.75783]\n","Step 7198    [1.451 sec/step, loss=0.80495, avg_loss=0.75832]\n","Step 7199    [1.452 sec/step, loss=0.76045, avg_loss=0.75825]\n","Step 7200    [1.452 sec/step, loss=0.78135, avg_loss=0.75834]\n","Writing summary at step: 7200\n","Step 7201    [1.449 sec/step, loss=0.78323, avg_loss=0.75860]\n","Step 7202    [1.453 sec/step, loss=0.76285, avg_loss=0.75824]\n","Step 7203    [1.455 sec/step, loss=0.76454, avg_loss=0.75828]\n","Step 7204    [1.477 sec/step, loss=0.68266, avg_loss=0.75746]\n","Step 7205    [1.460 sec/step, loss=0.77259, avg_loss=0.75973]\n","Step 7206    [1.475 sec/step, loss=0.70700, avg_loss=0.75901]\n","Step 7207    [1.471 sec/step, loss=0.77515, avg_loss=0.75892]\n","Step 7208    [1.472 sec/step, loss=0.78452, avg_loss=0.75902]\n","Step 7209    [1.468 sec/step, loss=0.78193, avg_loss=0.75914]\n","Step 7210    [1.457 sec/step, loss=0.76401, avg_loss=0.75892]\n","Generated 32 batches of size 32 in 17.628 sec\n","Step 7211    [1.478 sec/step, loss=0.75927, avg_loss=0.75904]\n","Step 7212    [1.492 sec/step, loss=0.54090, avg_loss=0.75659]\n","Step 7213    [1.489 sec/step, loss=0.75678, avg_loss=0.75663]\n","Step 7214    [1.492 sec/step, loss=0.75280, avg_loss=0.75662]\n","Step 7215    [1.491 sec/step, loss=0.77698, avg_loss=0.75666]\n","Step 7216    [1.440 sec/step, loss=0.75286, avg_loss=0.75668]\n","Step 7217    [1.446 sec/step, loss=0.75489, avg_loss=0.75658]\n","Step 7218    [1.447 sec/step, loss=0.79548, avg_loss=0.75691]\n","Step 7219    [1.449 sec/step, loss=0.74074, avg_loss=0.75636]\n","Step 7220    [1.447 sec/step, loss=0.74947, avg_loss=0.75627]\n","Step 7221    [1.444 sec/step, loss=0.76076, avg_loss=0.75615]\n","Step 7222    [1.439 sec/step, loss=0.76699, avg_loss=0.75608]\n","Step 7223    [1.430 sec/step, loss=0.76637, avg_loss=0.75648]\n","Step 7224    [1.428 sec/step, loss=0.77216, avg_loss=0.75647]\n","Step 7225    [1.431 sec/step, loss=0.77621, avg_loss=0.75656]\n","Step 7226    [1.406 sec/step, loss=0.78162, avg_loss=0.75838]\n","Step 7227    [1.403 sec/step, loss=0.76989, avg_loss=0.75832]\n","Step 7228    [1.409 sec/step, loss=0.74316, avg_loss=0.75815]\n","Step 7229    [1.400 sec/step, loss=0.77020, avg_loss=0.75808]\n","Step 7230    [1.404 sec/step, loss=0.74968, avg_loss=0.75804]\n","Step 7231    [1.399 sec/step, loss=0.79278, avg_loss=0.75858]\n","Step 7232    [1.399 sec/step, loss=0.75438, avg_loss=0.75839]\n","Step 7233    [1.405 sec/step, loss=0.73889, avg_loss=0.75803]\n","Step 7234    [1.410 sec/step, loss=0.76182, avg_loss=0.75811]\n","Step 7235    [1.414 sec/step, loss=0.74670, avg_loss=0.75774]\n","Step 7236    [1.422 sec/step, loss=0.76309, avg_loss=0.75786]\n","Step 7237    [1.426 sec/step, loss=0.77252, avg_loss=0.75765]\n","Step 7238    [1.430 sec/step, loss=0.76260, avg_loss=0.75765]\n","Step 7239    [1.429 sec/step, loss=0.75228, avg_loss=0.75757]\n","Step 7240    [1.445 sec/step, loss=0.74806, avg_loss=0.75747]\n","Step 7241    [1.446 sec/step, loss=0.75933, avg_loss=0.75757]\n","Step 7242    [1.444 sec/step, loss=0.75966, avg_loss=0.75754]\n","Generated 32 batches of size 32 in 19.334 sec\n","Step 7243    [1.497 sec/step, loss=0.73607, avg_loss=0.75726]\n","Step 7244    [1.494 sec/step, loss=0.76315, avg_loss=0.75696]\n","Step 7245    [1.485 sec/step, loss=0.77949, avg_loss=0.75713]\n","Step 7246    [1.488 sec/step, loss=0.74723, avg_loss=0.75674]\n","Step 7247    [1.480 sec/step, loss=0.75303, avg_loss=0.75667]\n","Step 7248    [1.401 sec/step, loss=0.77173, avg_loss=0.75684]\n","Step 7249    [1.399 sec/step, loss=0.72478, avg_loss=0.75662]\n","Step 7250    [1.399 sec/step, loss=0.74927, avg_loss=0.75623]\n","Step 7251    [1.393 sec/step, loss=0.76560, avg_loss=0.75638]\n","Step 7252    [1.396 sec/step, loss=0.76224, avg_loss=0.75629]\n","Step 7253    [1.398 sec/step, loss=0.76070, avg_loss=0.75632]\n","Step 7254    [1.401 sec/step, loss=0.74760, avg_loss=0.75611]\n","Step 7255    [1.398 sec/step, loss=0.73920, avg_loss=0.75576]\n","Step 7256    [1.399 sec/step, loss=0.76807, avg_loss=0.75578]\n","Step 7257    [1.403 sec/step, loss=0.75108, avg_loss=0.75558]\n","Step 7258    [1.407 sec/step, loss=0.74221, avg_loss=0.75549]\n","Step 7259    [1.413 sec/step, loss=0.74023, avg_loss=0.75527]\n","Step 7260    [1.404 sec/step, loss=0.76061, avg_loss=0.75525]\n","Step 7261    [1.405 sec/step, loss=0.76482, avg_loss=0.75528]\n","Step 7262    [1.405 sec/step, loss=0.72936, avg_loss=0.75504]\n","Step 7263    [1.413 sec/step, loss=0.70917, avg_loss=0.75465]\n","Step 7264    [1.410 sec/step, loss=0.76314, avg_loss=0.75456]\n","Step 7265    [1.412 sec/step, loss=0.76869, avg_loss=0.75435]\n","Step 7266    [1.408 sec/step, loss=0.76145, avg_loss=0.75412]\n","Step 7267    [1.415 sec/step, loss=0.75959, avg_loss=0.75395]\n","Step 7268    [1.427 sec/step, loss=0.74344, avg_loss=0.75360]\n","Step 7269    [1.397 sec/step, loss=0.75686, avg_loss=0.75582]\n","Step 7270    [1.399 sec/step, loss=0.76887, avg_loss=0.75574]\n","Step 7271    [1.395 sec/step, loss=0.75964, avg_loss=0.75547]\n","Step 7272    [1.396 sec/step, loss=0.75376, avg_loss=0.75549]\n","Step 7273    [1.428 sec/step, loss=0.58313, avg_loss=0.75387]\n","Step 7274    [1.425 sec/step, loss=0.77636, avg_loss=0.75409]\n","Generated 32 batches of size 32 in 19.729 sec\n","Step 7275    [1.469 sec/step, loss=0.74445, avg_loss=0.75395]\n","Step 7276    [1.466 sec/step, loss=0.76431, avg_loss=0.75386]\n","Step 7277    [1.452 sec/step, loss=0.76251, avg_loss=0.75411]\n","Step 7278    [1.457 sec/step, loss=0.75825, avg_loss=0.75401]\n","Step 7279    [1.453 sec/step, loss=0.72403, avg_loss=0.75373]\n","Step 7280    [1.400 sec/step, loss=0.75145, avg_loss=0.75359]\n","Step 7281    [1.400 sec/step, loss=0.74991, avg_loss=0.75347]\n","Step 7282    [1.404 sec/step, loss=0.77692, avg_loss=0.75338]\n","Step 7283    [1.384 sec/step, loss=0.76848, avg_loss=0.75525]\n","Step 7284    [1.409 sec/step, loss=0.57501, avg_loss=0.75324]\n","Step 7285    [1.405 sec/step, loss=0.75403, avg_loss=0.75320]\n","Step 7286    [1.405 sec/step, loss=0.75363, avg_loss=0.75293]\n","Step 7287    [1.405 sec/step, loss=0.76209, avg_loss=0.75283]\n","Step 7288    [1.407 sec/step, loss=0.76613, avg_loss=0.75265]\n","Step 7289    [1.407 sec/step, loss=0.75559, avg_loss=0.75259]\n","Step 7290    [1.401 sec/step, loss=0.77157, avg_loss=0.75260]\n","Step 7291    [1.407 sec/step, loss=0.74005, avg_loss=0.75243]\n","Step 7292    [1.409 sec/step, loss=0.77359, avg_loss=0.75257]\n","Step 7293    [1.408 sec/step, loss=0.74794, avg_loss=0.75236]\n","Step 7294    [1.412 sec/step, loss=0.75573, avg_loss=0.75240]\n","Step 7295    [1.410 sec/step, loss=0.74771, avg_loss=0.75221]\n","Step 7296    [1.406 sec/step, loss=0.78077, avg_loss=0.75240]\n","Step 7297    [1.397 sec/step, loss=0.74877, avg_loss=0.75268]\n","Step 7298    [1.404 sec/step, loss=0.74291, avg_loss=0.75206]\n","Step 7299    [1.407 sec/step, loss=0.74320, avg_loss=0.75189]\n","Step 7300    [1.411 sec/step, loss=0.75128, avg_loss=0.75159]\n","Writing summary at step: 7300\n","Step 7301    [1.413 sec/step, loss=0.74986, avg_loss=0.75125]\n","Step 7302    [1.423 sec/step, loss=0.75745, avg_loss=0.75120]\n","Step 7303    [1.420 sec/step, loss=0.74983, avg_loss=0.75105]\n","Step 7304    [1.400 sec/step, loss=0.74335, avg_loss=0.75166]\n","Step 7305    [1.401 sec/step, loss=0.74172, avg_loss=0.75135]\n","Generated 32 batches of size 32 in 19.607 sec\n","Step 7306    [1.458 sec/step, loss=0.77596, avg_loss=0.75204]\n","Step 7307    [1.449 sec/step, loss=0.78439, avg_loss=0.75213]\n","Step 7308    [1.446 sec/step, loss=0.75051, avg_loss=0.75179]\n","Step 7309    [1.443 sec/step, loss=0.79222, avg_loss=0.75190]\n","Step 7310    [1.439 sec/step, loss=0.75845, avg_loss=0.75184]\n","Step 7311    [1.407 sec/step, loss=0.75051, avg_loss=0.75175]\n","Step 7312    [1.382 sec/step, loss=0.76551, avg_loss=0.75400]\n","Step 7313    [1.381 sec/step, loss=0.77981, avg_loss=0.75423]\n","Step 7314    [1.378 sec/step, loss=0.76281, avg_loss=0.75433]\n","Step 7315    [1.374 sec/step, loss=0.73191, avg_loss=0.75388]\n","Step 7316    [1.374 sec/step, loss=0.76179, avg_loss=0.75397]\n","Step 7317    [1.367 sec/step, loss=0.76523, avg_loss=0.75407]\n","Step 7318    [1.375 sec/step, loss=0.74806, avg_loss=0.75360]\n","Step 7319    [1.376 sec/step, loss=0.75416, avg_loss=0.75373]\n","Step 7320    [1.377 sec/step, loss=0.77604, avg_loss=0.75400]\n","Step 7321    [1.373 sec/step, loss=0.76657, avg_loss=0.75405]\n","Step 7322    [1.379 sec/step, loss=0.74866, avg_loss=0.75387]\n","Step 7323    [1.377 sec/step, loss=0.75549, avg_loss=0.75376]\n","Step 7324    [1.381 sec/step, loss=0.75502, avg_loss=0.75359]\n","Step 7325    [1.382 sec/step, loss=0.76347, avg_loss=0.75346]\n","Step 7326    [1.384 sec/step, loss=0.77349, avg_loss=0.75338]\n","Step 7327    [1.383 sec/step, loss=0.77439, avg_loss=0.75343]\n","Step 7328    [1.384 sec/step, loss=0.76191, avg_loss=0.75361]\n","Step 7329    [1.391 sec/step, loss=0.74452, avg_loss=0.75336]\n","Step 7330    [1.399 sec/step, loss=0.75040, avg_loss=0.75337]\n","Step 7331    [1.405 sec/step, loss=0.75667, avg_loss=0.75300]\n","Step 7332    [1.409 sec/step, loss=0.77739, avg_loss=0.75323]\n","Step 7333    [1.411 sec/step, loss=0.77906, avg_loss=0.75364]\n","Step 7334    [1.447 sec/step, loss=0.55717, avg_loss=0.75159]\n","Step 7335    [1.462 sec/step, loss=0.70204, avg_loss=0.75114]\n","Step 7336    [1.463 sec/step, loss=0.76569, avg_loss=0.75117]\n","Step 7337    [1.468 sec/step, loss=0.76582, avg_loss=0.75110]\n","Generated 32 batches of size 32 in 19.721 sec\n","Step 7338    [1.469 sec/step, loss=0.78471, avg_loss=0.75132]\n","Step 7339    [1.464 sec/step, loss=0.75901, avg_loss=0.75139]\n","Step 7340    [1.441 sec/step, loss=0.76980, avg_loss=0.75161]\n","Step 7341    [1.444 sec/step, loss=0.73082, avg_loss=0.75132]\n","Step 7342    [1.443 sec/step, loss=0.75184, avg_loss=0.75124]\n","Step 7343    [1.390 sec/step, loss=0.76641, avg_loss=0.75155]\n","Step 7344    [1.388 sec/step, loss=0.74924, avg_loss=0.75141]\n","Step 7345    [1.387 sec/step, loss=0.77561, avg_loss=0.75137]\n","Step 7346    [1.378 sec/step, loss=0.75577, avg_loss=0.75146]\n","Step 7347    [1.379 sec/step, loss=0.76267, avg_loss=0.75155]\n","Step 7348    [1.378 sec/step, loss=0.74939, avg_loss=0.75133]\n","Step 7349    [1.375 sec/step, loss=0.76653, avg_loss=0.75175]\n","Step 7350    [1.377 sec/step, loss=0.77620, avg_loss=0.75201]\n","Step 7351    [1.379 sec/step, loss=0.76803, avg_loss=0.75204]\n","Step 7352    [1.381 sec/step, loss=0.77185, avg_loss=0.75214]\n","Step 7353    [1.382 sec/step, loss=0.75961, avg_loss=0.75212]\n","Step 7354    [1.384 sec/step, loss=0.73770, avg_loss=0.75203]\n","Step 7355    [1.399 sec/step, loss=0.68584, avg_loss=0.75149]\n","Step 7356    [1.394 sec/step, loss=0.77483, avg_loss=0.75156]\n","Step 7357    [1.387 sec/step, loss=0.76050, avg_loss=0.75165]\n","Step 7358    [1.388 sec/step, loss=0.77550, avg_loss=0.75199]\n","Step 7359    [1.382 sec/step, loss=0.75111, avg_loss=0.75210]\n","Step 7360    [1.382 sec/step, loss=0.73341, avg_loss=0.75182]\n","Step 7361    [1.394 sec/step, loss=0.75772, avg_loss=0.75175]\n","Step 7362    [1.403 sec/step, loss=0.77427, avg_loss=0.75220]\n","Step 7363    [1.399 sec/step, loss=0.78563, avg_loss=0.75297]\n","Step 7364    [1.447 sec/step, loss=0.54962, avg_loss=0.75083]\n","Step 7365    [1.445 sec/step, loss=0.75446, avg_loss=0.75069]\n","Step 7366    [1.458 sec/step, loss=0.73652, avg_loss=0.75044]\n","Step 7367    [1.456 sec/step, loss=0.77627, avg_loss=0.75061]\n","Step 7368    [1.453 sec/step, loss=0.75526, avg_loss=0.75072]\n","Step 7369    [1.458 sec/step, loss=0.74423, avg_loss=0.75060]\n","Generated 32 batches of size 32 in 19.295 sec\n","Step 7370    [1.463 sec/step, loss=0.75705, avg_loss=0.75048]\n","Step 7371    [1.461 sec/step, loss=0.74880, avg_loss=0.75037]\n","Step 7372    [1.457 sec/step, loss=0.77368, avg_loss=0.75057]\n","Step 7373    [1.420 sec/step, loss=0.77741, avg_loss=0.75251]\n","Step 7374    [1.418 sec/step, loss=0.77032, avg_loss=0.75245]\n","Step 7375    [1.369 sec/step, loss=0.76285, avg_loss=0.75264]\n","Step 7376    [1.368 sec/step, loss=0.75686, avg_loss=0.75256]\n","Step 7377    [1.362 sec/step, loss=0.76118, avg_loss=0.75255]\n","Step 7378    [1.361 sec/step, loss=0.75432, avg_loss=0.75251]\n","Step 7379    [1.356 sec/step, loss=0.74335, avg_loss=0.75270]\n","Step 7380    [1.355 sec/step, loss=0.76168, avg_loss=0.75281]\n","Step 7381    [1.356 sec/step, loss=0.76982, avg_loss=0.75300]\n","Step 7382    [1.358 sec/step, loss=0.76312, avg_loss=0.75287]\n","Step 7383    [1.355 sec/step, loss=0.76588, avg_loss=0.75284]\n","Step 7384    [1.338 sec/step, loss=0.76607, avg_loss=0.75475]\n","Step 7385    [1.340 sec/step, loss=0.79402, avg_loss=0.75515]\n","Step 7386    [1.337 sec/step, loss=0.76099, avg_loss=0.75522]\n","Step 7387    [1.338 sec/step, loss=0.75282, avg_loss=0.75513]\n","Step 7388    [1.338 sec/step, loss=0.76039, avg_loss=0.75507]\n","Step 7389    [1.335 sec/step, loss=0.76550, avg_loss=0.75517]\n","Step 7390    [1.341 sec/step, loss=0.76676, avg_loss=0.75513]\n","Step 7391    [1.333 sec/step, loss=0.75394, avg_loss=0.75526]\n","Step 7392    [1.332 sec/step, loss=0.75936, avg_loss=0.75512]\n","Step 7393    [1.333 sec/step, loss=0.75094, avg_loss=0.75515]\n","Step 7394    [1.338 sec/step, loss=0.76789, avg_loss=0.75527]\n","Step 7395    [1.342 sec/step, loss=0.75825, avg_loss=0.75538]\n","Step 7396    [1.387 sec/step, loss=0.57382, avg_loss=0.75331]\n","Step 7397    [1.393 sec/step, loss=0.76224, avg_loss=0.75344]\n","Step 7398    [1.389 sec/step, loss=0.76273, avg_loss=0.75364]\n","Step 7399    [1.393 sec/step, loss=0.78040, avg_loss=0.75401]\n","Step 7400    [1.394 sec/step, loss=0.76778, avg_loss=0.75418]\n","Writing summary at step: 7400\n","Generated 32 batches of size 32 in 18.364 sec\n","Step 7401    [1.401 sec/step, loss=0.76375, avg_loss=0.75432]\n","Step 7402    [1.394 sec/step, loss=0.75018, avg_loss=0.75425]\n","Step 7403    [1.392 sec/step, loss=0.75447, avg_loss=0.75429]\n","Step 7404    [1.391 sec/step, loss=0.75566, avg_loss=0.75442]\n","Step 7405    [1.382 sec/step, loss=0.75353, avg_loss=0.75453]\n","Step 7406    [1.318 sec/step, loss=0.74395, avg_loss=0.75421]\n","Step 7407    [1.322 sec/step, loss=0.75202, avg_loss=0.75389]\n","Step 7408    [1.319 sec/step, loss=0.75992, avg_loss=0.75398]\n","Step 7409    [1.321 sec/step, loss=0.75310, avg_loss=0.75359]\n","Step 7410    [1.320 sec/step, loss=0.76186, avg_loss=0.75363]\n","Step 7411    [1.345 sec/step, loss=0.55380, avg_loss=0.75166]\n","Step 7412    [1.346 sec/step, loss=0.76816, avg_loss=0.75169]\n","Step 7413    [1.346 sec/step, loss=0.76437, avg_loss=0.75153]\n","Step 7414    [1.344 sec/step, loss=0.76467, avg_loss=0.75155]\n","Step 7415    [1.348 sec/step, loss=0.74882, avg_loss=0.75172]\n","Step 7416    [1.348 sec/step, loss=0.76096, avg_loss=0.75171]\n","Step 7417    [1.355 sec/step, loss=0.77038, avg_loss=0.75176]\n","Step 7418    [1.347 sec/step, loss=0.74219, avg_loss=0.75170]\n","Step 7419    [1.347 sec/step, loss=0.74924, avg_loss=0.75165]\n","Step 7420    [1.346 sec/step, loss=0.77416, avg_loss=0.75164]\n","Step 7421    [1.351 sec/step, loss=0.75788, avg_loss=0.75155]\n","Step 7422    [1.345 sec/step, loss=0.73484, avg_loss=0.75141]\n","Step 7423    [1.348 sec/step, loss=0.77250, avg_loss=0.75158]\n","Step 7424    [1.344 sec/step, loss=0.75699, avg_loss=0.75160]\n","Step 7425    [1.348 sec/step, loss=0.75162, avg_loss=0.75148]\n","Step 7426    [1.349 sec/step, loss=0.74302, avg_loss=0.75118]\n","Step 7427    [1.362 sec/step, loss=0.74617, avg_loss=0.75089]\n","Step 7428    [1.357 sec/step, loss=0.72919, avg_loss=0.75057]\n","Step 7429    [1.363 sec/step, loss=0.72704, avg_loss=0.75039]\n","Step 7430    [1.371 sec/step, loss=0.72738, avg_loss=0.75016]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PpslsnzXWzZl","outputId":"cd6e8098-9b8b-4dcc-d0dc-d84d0ba3d47c"},"source":["#### Use this code if you want to resume. (training with trained models)\n","!python train_tacotron2.py --data_paths ./data/kss,./data/iu --batch_size 32 --load_path ./logdir-tacotron2/pretrained_checkpoint --checkpoint_interval 500"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From train_tacotron2.py:27: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","WARNING:tensorflow:From train_tacotron2.py:27: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n","\n","UPDATE attention_kernel: (31,) -> [31]\n","UPDATE postnet_kernel_size: (5,) -> [5]\n","['../../../data/kss/kss_preprocess_result', '../../../data/Voice_IU/preprocess_result']\n","==================================================\n","==================================================\n"," [*] Checkpoint path: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/model.ckpt\n"," [*] Loading training data from: ['../../../data/kss/kss_preprocess_result', '../../../data/Voice_IU/preprocess_result']\n"," [*] Using model: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39\n","Hyperparameters:\n","  adam_beta1: 0.9\n","  adam_beta2: 0.999\n","  allow_clipping_in_normalization: True\n","  attention_dim: 128\n","  attention_filters: 32\n","  attention_kernel: [31]\n","  attention_size: 128\n","  attention_type: bah_mon_norm\n","  attention_win_size: 7\n","  cleaners: korean_cleaners\n","  clip_mels_length: True\n","  cumulative_weights: True\n","  dec_prenet_sizes: [256, 256]\n","  decoder_layers: 2\n","  decoder_lstm_units: 1024\n","  dilation_channels: 256\n","  dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n","  dropout_prob: 0.5\n","  embedding_size: 512\n","  enc_conv_channels: 512\n","  enc_conv_kernel_size: 5\n","  enc_conv_num_layers: 3\n","  encoder_lstm_units: 256\n","  fft_size: 2048\n","  filter_width: 3\n","  gc_channels: 32\n","  griffin_lim_iters: 60\n","  hop_size: 300\n","  inference_prenet_dropout: True\n","  initial_data_greedy: True\n","  initial_phase_step: 8000\n","  input_type: raw\n","  l2_regularization_strength: 0\n","  legacy: True\n","  main_data: ['']\n","  main_data_greedy_factor: 0\n","  mask_encoder: True\n","  max_abs_value: 4.0\n","  max_checkpoints: 3\n","  max_mel_frames: 1000\n","  max_n_frame: 1000\n","  min_level_db: -100\n","  min_n_frame: 150\n","  min_tokens: 30\n","  model_type: multi-speaker\n","  momentum: 0.9\n","  name: Tacotron-2\n","  num_mels: 80\n","  num_steps: 1000000\n","  optimizer: adam\n","  out_channels: 30\n","  post_bank_channel_size: 128\n","  post_bank_size: 8\n","  post_highway_depth: 4\n","  post_maxpool_width: 2\n","  post_proj_sizes: [256, 80]\n","  post_proj_width: 3\n","  post_rnn_size: 128\n","  postnet_channels: 512\n","  postnet_kernel_size: [5]\n","  postnet_num_layers: 5\n","  power: 1.5\n","  preemphasis: 0.97\n","  preemphasize: True\n","  prenet_layers: [256, 256]\n","  prioritize_loss: False\n","  quantization_channels: 256\n","  reduction_factor: 2\n","  ref_level_db: 20\n","  rescaling: True\n","  rescaling_max: 0.999\n","  residual_channels: 128\n","  residual_legacy: True\n","  sample_rate: 24000\n","  sample_size: 9000\n","  scalar_input: True\n","  signal_normalization: True\n","  silence_threshold: 0\n","  skip_channels: 128\n","  skip_inadequate: False\n","  skip_path_filter: False\n","  smoothing: False\n","  speaker_embedding_size: 16\n","  store_metadata: False\n","  symmetric_mels: True\n","  synthesis_constraint: False\n","  synthesis_constraint_type: window\n","  tacotron_decay_learning_rate: True\n","  tacotron_decay_rate: 0.5\n","  tacotron_decay_steps: 18000\n","  tacotron_final_learning_rate: 0.0001\n","  tacotron_initial_learning_rate: 0.001\n","  tacotron_reg_weight: 1e-06\n","  tacotron_start_decay: 40000\n","  tacotron_zoneout_rate: 0.1\n","  trim_fft_size: 512\n","  trim_hop_size: 128\n","  trim_silence: True\n","  trim_top_db: 23\n","  upsample_factor: [12, 25]\n","  upsample_type: SubPixel\n","  use_biases: True\n","  use_lws: False\n","  wavenet_batch_size: 2\n","  wavenet_clip_gradients: True\n","  wavenet_decay_rate: 0.5\n","  wavenet_decay_steps: 300000\n","  wavenet_dropout: 0.05\n","  wavenet_learning_rate: 0.001\n","  win_size: 1200\n","filter_by_min_max_frame_batch: 100% 12835/12835 [03:48<00:00, 56.23it/s]\n"," [../../../data/kss/kss_preprocess_result] Loaded metadata for 8377 examples (6.51 hours)\n"," [../../../data/kss/kss_preprocess_result] Max length: 608\n"," [../../../data/kss/kss_preprocess_result] Min length: 150\n","filter_by_min_max_frame_batch: 100% 4334/4334 [01:10<00:00, 61.37it/s]\n"," [../../../data/Voice_IU/preprocess_result] Loaded metadata for 2992 examples (2.89 hours)\n"," [../../../data/Voice_IU/preprocess_result] Max length: 996\n"," [../../../data/Voice_IU/preprocess_result] Min length: 150\n","========================================\n","Data Amount:\n","{   '../../../data/Voice_IU/preprocess_result': 0.5,\n","    '../../../data/kss/kss_preprocess_result': 0.5}\n","========================================\n","filter_by_min_max_frame_batch: 100% 12835/12835 [02:57<00:00, 72.21it/s]\n"," [../../../data/kss/kss_preprocess_result] Loaded metadata for 8377 examples (6.51 hours)\n"," [../../../data/kss/kss_preprocess_result] Max length: 608\n"," [../../../data/kss/kss_preprocess_result] Min length: 150\n","filter_by_min_max_frame_batch: 100% 4334/4334 [01:10<00:00, 61.91it/s]\n"," [../../../data/Voice_IU/preprocess_result] Loaded metadata for 2992 examples (2.89 hours)\n"," [../../../data/Voice_IU/preprocess_result] Max length: 996\n"," [../../../data/Voice_IU/preprocess_result] Min length: 150\n","========================================\n","Data Amount:\n","{   '../../../data/Voice_IU/preprocess_result': 0.5,\n","    '../../../data/kss/kss_preprocess_result': 0.5}\n","========================================\n","========================================\n"," model_type: multi-speaker\n","========================================\n","Initialized Tacotron model. Dimensions: \n","    embedding:                512\n","    encoder conv out:               512\n","    encoder out:              512\n","    attention out:            1024\n","    decoder prenet lstm concat out :        1536\n","    decoder cell out:         162\n","    decoder out (2 frames):  162\n","    decoder mel out:    80\n","    mel out:    80\n","    postnet out:              256\n","    linear out:               1025\n","  Tacotron Parameters       29.229 Million.\n","========================================\n"," model_type: multi-speaker\n","========================================\n","Initialized Tacotron model. Dimensions: \n","    embedding:                512\n","    encoder conv out:               512\n","    encoder out:              512\n","    attention out:            1024\n","    decoder prenet lstm concat out :        1536\n","    decoder cell out:         162\n","    decoder out (2 frames):  162\n","    decoder mel out:    80\n","    mel out:    80\n","    postnet out:              256\n","    linear out:               1025\n","  Tacotron Parameters       29.229 Million.\n","2021-05-29 03:35:30.222478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-05-29 03:35:30.350963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-29 03:35:30.355109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-05-29 03:35:30.382476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-05-29 03:35:30.603018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-05-29 03:35:30.721099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-05-29 03:35:30.741371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-05-29 03:35:30.952317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-05-29 03:35:30.984495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-05-29 03:35:31.423378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-05-29 03:35:31.423662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-29 03:35:31.424700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-29 03:35:31.425593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-05-29 03:35:31.530144: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2021-05-29 03:35:31.532058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5563fec01180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-05-29 03:35:31.532113: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-05-29 03:35:31.827103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-29 03:35:31.828486: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5563fec016c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-05-29 03:35:31.828543: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2021-05-29 03:35:31.828818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-29 03:35:31.829792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-05-29 03:35:31.829887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-05-29 03:35:31.829940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-05-29 03:35:31.829995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-05-29 03:35:31.830046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-05-29 03:35:31.830088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-05-29 03:35:31.830128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-05-29 03:35:31.830169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-05-29 03:35:31.830266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-29 03:35:31.831210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-29 03:35:31.832049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-05-29 03:35:31.835815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-05-29 03:35:31.837901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-05-29 03:35:31.837936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-05-29 03:35:31.837961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-05-29 03:35:31.841733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-29 03:35:31.842820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-05-29 03:35:31.843699: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-05-29 03:35:31.843759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","2021-05-29 03:35:34.041675: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 29360128 exceeds 10% of system memory.\n","2021-05-29 03:35:34.058098: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 29360128 exceeds 10% of system memory.\n","2021-05-29 03:35:34.064456: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of system memory.\n","2021-05-29 03:35:34.073591: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 33554432 exceeds 10% of system memory.\n","2021-05-29 03:35:34.176603: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 29360128 exceeds 10% of system memory.\n"," [*] Found lastest checkpoint: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/model.ckpt-28000\n","Resuming from checkpoint: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/model.ckpt-28000 at commit: None\n","Generated 8 batches of size 4 in 0.000 sec\n","2021-05-29 03:35:54.744761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","Generated 32 batches of size 32 in 18.822 sec\n","2021-05-29 03:36:04.353991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","Step 28001   [25.322 sec/step, loss=0.63495, avg_loss=0.63495]\n","Step 28002   [13.460 sec/step, loss=0.62509, avg_loss=0.63002]\n","Step 28003   [9.513 sec/step, loss=0.64790, avg_loss=0.63598]\n","Step 28004   [7.836 sec/step, loss=0.61076, avg_loss=0.62968]\n","Step 28005   [6.781 sec/step, loss=0.61858, avg_loss=0.62746]\n","Step 28006   [5.886 sec/step, loss=0.61523, avg_loss=0.62542]\n","Step 28007   [5.342 sec/step, loss=0.62482, avg_loss=0.62533]\n","Step 28008   [4.817 sec/step, loss=0.60859, avg_loss=0.62324]\n","Step 28009   [4.399 sec/step, loss=0.60968, avg_loss=0.62173]\n","Step 28010   [4.081 sec/step, loss=0.61555, avg_loss=0.62112]\n","Step 28011   [3.825 sec/step, loss=0.60936, avg_loss=0.62005]\n","Step 28012   [3.646 sec/step, loss=0.61362, avg_loss=0.61951]\n","Step 28013   [3.747 sec/step, loss=0.50026, avg_loss=0.61034]\n","Step 28014   [3.575 sec/step, loss=0.63055, avg_loss=0.61178]\n","Step 28015   [3.432 sec/step, loss=0.64023, avg_loss=0.61368]\n","Step 28016   [3.318 sec/step, loss=0.64109, avg_loss=0.61539]\n","Step 28017   [3.262 sec/step, loss=0.62611, avg_loss=0.61602]\n","Step 28018   [3.179 sec/step, loss=0.63487, avg_loss=0.61707]\n","Step 28019   [3.097 sec/step, loss=0.63013, avg_loss=0.61776]\n","Step 28020   [3.035 sec/step, loss=0.61386, avg_loss=0.61756]\n","Step 28021   [2.964 sec/step, loss=0.61968, avg_loss=0.61766]\n","Step 28022   [2.888 sec/step, loss=0.61807, avg_loss=0.61768]\n","Step 28023   [2.847 sec/step, loss=0.64735, avg_loss=0.61897]\n","Step 28024   [2.860 sec/step, loss=0.61203, avg_loss=0.61868]\n","Step 28025   [2.833 sec/step, loss=0.61454, avg_loss=0.61852]\n","Step 28026   [2.860 sec/step, loss=0.61340, avg_loss=0.61832]\n","Step 28027   [2.823 sec/step, loss=0.62379, avg_loss=0.61852]\n","Step 28028   [2.818 sec/step, loss=0.61936, avg_loss=0.61855]\n","Step 28029   [2.880 sec/step, loss=0.61435, avg_loss=0.61841]\n","Step 28030   [2.885 sec/step, loss=0.61575, avg_loss=0.61832]\n","Generated 32 batches of size 32 in 21.547 sec\n","Step 28031   [2.845 sec/step, loss=0.61658, avg_loss=0.61826]\n","Step 28032   [2.799 sec/step, loss=0.61789, avg_loss=0.61825]\n","Step 28033   [2.747 sec/step, loss=0.62462, avg_loss=0.61844]\n","Step 28034   [2.716 sec/step, loss=0.62973, avg_loss=0.61878]\n","Step 28035   [2.684 sec/step, loss=0.62149, avg_loss=0.61885]\n","Step 28036   [2.645 sec/step, loss=0.61971, avg_loss=0.61888]\n","Step 28037   [2.625 sec/step, loss=0.63697, avg_loss=0.61937]\n","Step 28038   [2.624 sec/step, loss=0.61424, avg_loss=0.61923]\n","Step 28039   [2.587 sec/step, loss=0.61527, avg_loss=0.61913]\n","Step 28040   [2.570 sec/step, loss=0.63632, avg_loss=0.61956]\n","Step 28041   [2.543 sec/step, loss=0.63410, avg_loss=0.61991]\n","Step 28042   [2.509 sec/step, loss=0.60419, avg_loss=0.61954]\n","Step 28043   [2.490 sec/step, loss=0.62902, avg_loss=0.61976]\n","Step 28044   [2.479 sec/step, loss=0.62880, avg_loss=0.61997]\n","Step 28045   [2.451 sec/step, loss=0.62815, avg_loss=0.62015]\n","Step 28046   [2.418 sec/step, loss=0.61019, avg_loss=0.61993]\n","Step 28047   [2.414 sec/step, loss=0.63167, avg_loss=0.62018]\n","Step 28048   [2.392 sec/step, loss=0.61777, avg_loss=0.62013]\n","Step 28049   [2.406 sec/step, loss=0.58351, avg_loss=0.61938]\n","Step 28050   [2.393 sec/step, loss=0.64372, avg_loss=0.61987]\n","Step 28051   [2.396 sec/step, loss=0.61628, avg_loss=0.61980]\n","Step 28052   [2.388 sec/step, loss=0.61898, avg_loss=0.61978]\n","Step 28053   [2.370 sec/step, loss=0.61997, avg_loss=0.61979]\n","Step 28054   [2.350 sec/step, loss=0.62528, avg_loss=0.61989]\n","Step 28055   [2.330 sec/step, loss=0.63244, avg_loss=0.62012]\n","Step 28056   [2.323 sec/step, loss=0.62433, avg_loss=0.62019]\n","Step 28057   [2.412 sec/step, loss=0.52599, avg_loss=0.61854]\n","Step 28058   [2.407 sec/step, loss=0.63382, avg_loss=0.61880]\n","Step 28059   [2.396 sec/step, loss=0.61351, avg_loss=0.61871]\n","Step 28060   [2.393 sec/step, loss=0.64926, avg_loss=0.61922]\n","Step 28061   [2.389 sec/step, loss=0.63665, avg_loss=0.61951]\n","Step 28062   [2.385 sec/step, loss=0.62174, avg_loss=0.61954]\n","Generated 32 batches of size 32 in 22.016 sec\n","Step 28063   [2.391 sec/step, loss=0.62669, avg_loss=0.61966]\n","Step 28064   [2.383 sec/step, loss=0.63410, avg_loss=0.61988]\n","Step 28065   [2.429 sec/step, loss=0.48358, avg_loss=0.61779]\n","Step 28066   [2.418 sec/step, loss=0.63562, avg_loss=0.61806]\n","Step 28067   [2.406 sec/step, loss=0.62045, avg_loss=0.61809]\n","Step 28068   [2.391 sec/step, loss=0.62715, avg_loss=0.61823]\n","Step 28069   [2.379 sec/step, loss=0.61738, avg_loss=0.61821]\n","Step 28070   [2.376 sec/step, loss=0.62571, avg_loss=0.61832]\n","Step 28071   [2.376 sec/step, loss=0.62802, avg_loss=0.61846]\n","Step 28072   [2.364 sec/step, loss=0.62821, avg_loss=0.61859]\n","Step 28073   [2.349 sec/step, loss=0.61860, avg_loss=0.61859]\n","Step 28074   [2.337 sec/step, loss=0.61793, avg_loss=0.61858]\n","Step 28075   [2.330 sec/step, loss=0.63198, avg_loss=0.61876]\n","Step 28076   [2.318 sec/step, loss=0.63594, avg_loss=0.61899]\n","Step 28077   [2.303 sec/step, loss=0.65512, avg_loss=0.61946]\n","Step 28078   [2.295 sec/step, loss=0.63358, avg_loss=0.61964]\n","Step 28079   [2.283 sec/step, loss=0.62632, avg_loss=0.61972]\n","Step 28080   [2.268 sec/step, loss=0.64388, avg_loss=0.62003]\n","Step 28081   [2.253 sec/step, loss=0.62811, avg_loss=0.62012]\n","Step 28082   [2.250 sec/step, loss=0.63139, avg_loss=0.62026]\n","Step 28083   [2.236 sec/step, loss=0.62853, avg_loss=0.62036]\n","Step 28084   [2.230 sec/step, loss=0.64590, avg_loss=0.62067]\n","Step 28085   [2.228 sec/step, loss=0.64067, avg_loss=0.62090]\n","Step 28086   [2.215 sec/step, loss=0.62721, avg_loss=0.62097]\n","Step 28087   [2.205 sec/step, loss=0.64791, avg_loss=0.62128]\n","Step 28088   [2.209 sec/step, loss=0.63348, avg_loss=0.62142]\n","Step 28089   [2.225 sec/step, loss=0.63136, avg_loss=0.62153]\n","Step 28090   [2.256 sec/step, loss=0.59527, avg_loss=0.62124]\n","Step 28091   [2.254 sec/step, loss=0.63958, avg_loss=0.62144]\n","Step 28092   [2.246 sec/step, loss=0.63617, avg_loss=0.62160]\n","Step 28093   [2.239 sec/step, loss=0.61901, avg_loss=0.62158]\n","Step 28094   [2.233 sec/step, loss=0.62385, avg_loss=0.62160]\n","Step 28095   [2.225 sec/step, loss=0.64588, avg_loss=0.62186]\n","Step 28096   [2.219 sec/step, loss=0.62239, avg_loss=0.62186]\n","Generated 32 batches of size 32 in 21.737 sec\n","Step 28097   [2.221 sec/step, loss=0.63037, avg_loss=0.62195]\n","Step 28098   [2.223 sec/step, loss=0.61635, avg_loss=0.62189]\n","Step 28099   [2.218 sec/step, loss=0.63554, avg_loss=0.62203]\n","Step 28100   [2.210 sec/step, loss=0.64472, avg_loss=0.62226]\n","Writing summary at step: 28100\n","Step 28101   [1.968 sec/step, loss=0.63018, avg_loss=0.62221]\n","Step 28102   [1.969 sec/step, loss=0.63609, avg_loss=0.62232]\n","Step 28103   [1.978 sec/step, loss=0.61642, avg_loss=0.62200]\n","Step 28104   [1.961 sec/step, loss=0.64014, avg_loss=0.62230]\n","Step 28105   [1.945 sec/step, loss=0.60697, avg_loss=0.62218]\n","Step 28106   [1.943 sec/step, loss=0.64145, avg_loss=0.62244]\n","Step 28107   [1.942 sec/step, loss=0.63886, avg_loss=0.62258]\n","Step 28108   [1.945 sec/step, loss=0.62666, avg_loss=0.62277]\n","Step 28109   [1.963 sec/step, loss=0.57990, avg_loss=0.62247]\n","Step 28110   [1.962 sec/step, loss=0.60949, avg_loss=0.62241]\n","Step 28111   [1.965 sec/step, loss=0.62373, avg_loss=0.62255]\n","Step 28112   [2.003 sec/step, loss=0.46542, avg_loss=0.62107]\n","Step 28113   [1.966 sec/step, loss=0.62161, avg_loss=0.62228]\n","Step 28114   [1.968 sec/step, loss=0.63616, avg_loss=0.62234]\n","Step 28115   [1.974 sec/step, loss=0.63838, avg_loss=0.62232]\n","Step 28116   [1.970 sec/step, loss=0.63727, avg_loss=0.62228]\n","Step 28117   [1.961 sec/step, loss=0.63262, avg_loss=0.62235]\n","Step 28118   [1.962 sec/step, loss=0.64754, avg_loss=0.62247]\n","Step 28119   [1.970 sec/step, loss=0.64582, avg_loss=0.62263]\n","Step 28120   [1.986 sec/step, loss=0.63108, avg_loss=0.62280]\n","Step 28121   [1.995 sec/step, loss=0.63725, avg_loss=0.62298]\n","Step 28122   [2.002 sec/step, loss=0.63456, avg_loss=0.62314]\n","Step 28123   [2.000 sec/step, loss=0.60867, avg_loss=0.62276]\n","Step 28124   [1.985 sec/step, loss=0.62335, avg_loss=0.62287]\n","Step 28125   [1.979 sec/step, loss=0.62914, avg_loss=0.62302]\n","Step 28126   [1.972 sec/step, loss=0.63251, avg_loss=0.62321]\n","Step 28127   [1.970 sec/step, loss=0.63389, avg_loss=0.62331]\n","Generated 32 batches of size 32 in 20.967 sec\n","Step 28128   [2.019 sec/step, loss=0.41433, avg_loss=0.62126]\n","Step 28129   [1.989 sec/step, loss=0.62947, avg_loss=0.62141]\n","Step 28130   [1.971 sec/step, loss=0.63555, avg_loss=0.62161]\n","Step 28131   [1.970 sec/step, loss=0.62559, avg_loss=0.62170]\n","Step 28132   [1.966 sec/step, loss=0.61399, avg_loss=0.62166]\n","Step 28133   [1.973 sec/step, loss=0.63239, avg_loss=0.62174]\n","Step 28134   [1.967 sec/step, loss=0.62327, avg_loss=0.62167]\n","Step 28135   [1.981 sec/step, loss=0.61059, avg_loss=0.62156]\n","Step 28136   [1.979 sec/step, loss=0.61909, avg_loss=0.62156]\n","Step 28137   [1.973 sec/step, loss=0.62165, avg_loss=0.62140]\n","Step 28138   [1.956 sec/step, loss=0.61003, avg_loss=0.62136]\n","Step 28139   [1.954 sec/step, loss=0.61649, avg_loss=0.62137]\n","Step 28140   [1.960 sec/step, loss=0.61830, avg_loss=0.62119]\n","Step 28141   [1.958 sec/step, loss=0.63826, avg_loss=0.62123]\n","Step 28142   [1.960 sec/step, loss=0.63227, avg_loss=0.62151]\n","Step 28143   [1.961 sec/step, loss=0.62008, avg_loss=0.62143]\n","Step 28144   [1.955 sec/step, loss=0.62491, avg_loss=0.62139]\n","Step 28145   [1.955 sec/step, loss=0.63236, avg_loss=0.62143]\n","Step 28146   [1.955 sec/step, loss=0.60859, avg_loss=0.62141]\n","Step 28147   [1.946 sec/step, loss=0.62303, avg_loss=0.62133]\n","Step 28148   [1.947 sec/step, loss=0.62232, avg_loss=0.62137]\n","Step 28149   [1.939 sec/step, loss=0.62689, avg_loss=0.62181]\n","Step 28150   [1.932 sec/step, loss=0.62666, avg_loss=0.62163]\n","Step 28151   [1.922 sec/step, loss=0.61938, avg_loss=0.62167]\n","Step 28152   [1.921 sec/step, loss=0.63274, avg_loss=0.62180]\n","Step 28153   [1.926 sec/step, loss=0.63004, avg_loss=0.62190]\n","Step 28154   [1.941 sec/step, loss=0.63779, avg_loss=0.62203]\n","Step 28155   [1.951 sec/step, loss=0.64151, avg_loss=0.62212]\n","Step 28156   [1.965 sec/step, loss=0.63523, avg_loss=0.62223]\n","Step 28157   [1.913 sec/step, loss=0.62211, avg_loss=0.62319]\n","Step 28158   [1.924 sec/step, loss=0.64505, avg_loss=0.62330]\n","Generated 32 batches of size 32 in 21.095 sec\n","Step 28159   [1.930 sec/step, loss=0.62906, avg_loss=0.62346]\n","Step 28160   [1.938 sec/step, loss=0.60501, avg_loss=0.62302]\n","Step 28161   [1.927 sec/step, loss=0.61860, avg_loss=0.62283]\n","Step 28162   [1.929 sec/step, loss=0.61699, avg_loss=0.62279]\n","Step 28163   [1.951 sec/step, loss=0.49409, avg_loss=0.62146]\n","Step 28164   [1.941 sec/step, loss=0.59468, avg_loss=0.62107]\n","Step 28165   [1.898 sec/step, loss=0.62909, avg_loss=0.62252]\n","Step 28166   [1.896 sec/step, loss=0.62809, avg_loss=0.62245]\n","Step 28167   [1.893 sec/step, loss=0.62141, avg_loss=0.62246]\n","Step 28168   [1.896 sec/step, loss=0.61295, avg_loss=0.62231]\n","Step 28169   [1.890 sec/step, loss=0.62301, avg_loss=0.62237]\n","Step 28170   [1.888 sec/step, loss=0.63184, avg_loss=0.62243]\n","Step 28171   [1.873 sec/step, loss=0.62559, avg_loss=0.62241]\n","Step 28172   [1.873 sec/step, loss=0.62908, avg_loss=0.62242]\n","Step 28173   [1.872 sec/step, loss=0.62042, avg_loss=0.62243]\n","Step 28174   [1.878 sec/step, loss=0.62123, avg_loss=0.62247]\n","Step 28175   [1.873 sec/step, loss=0.63964, avg_loss=0.62254]\n","Step 28176   [1.872 sec/step, loss=0.62034, avg_loss=0.62239]\n","Step 28177   [1.871 sec/step, loss=0.61996, avg_loss=0.62204]\n","Step 28178   [1.868 sec/step, loss=0.63190, avg_loss=0.62202]\n","Step 28179   [1.874 sec/step, loss=0.62236, avg_loss=0.62198]\n","Step 28180   [1.875 sec/step, loss=0.63020, avg_loss=0.62184]\n","Step 28181   [1.876 sec/step, loss=0.63038, avg_loss=0.62187]\n","Step 28182   [1.874 sec/step, loss=0.62391, avg_loss=0.62179]\n","Step 28183   [1.880 sec/step, loss=0.64473, avg_loss=0.62195]\n","Step 28184   [1.882 sec/step, loss=0.63126, avg_loss=0.62181]\n","Step 28185   [1.879 sec/step, loss=0.60903, avg_loss=0.62149]\n","Step 28186   [1.898 sec/step, loss=0.63579, avg_loss=0.62158]\n","Step 28187   [1.905 sec/step, loss=0.65434, avg_loss=0.62164]\n","Step 28188   [1.902 sec/step, loss=0.63610, avg_loss=0.62167]\n","Step 28189   [1.904 sec/step, loss=0.65584, avg_loss=0.62191]\n","Step 28190   [1.875 sec/step, loss=0.62474, avg_loss=0.62221]\n","Step 28191   [1.879 sec/step, loss=0.63696, avg_loss=0.62218]\n","Generated 32 batches of size 32 in 21.222 sec\n","Step 28192   [1.892 sec/step, loss=0.62182, avg_loss=0.62204]\n","Step 28193   [1.901 sec/step, loss=0.62552, avg_loss=0.62210]\n","Step 28194   [1.903 sec/step, loss=0.64126, avg_loss=0.62228]\n","Step 28195   [1.900 sec/step, loss=0.64460, avg_loss=0.62226]\n","Step 28196   [1.893 sec/step, loss=0.61906, avg_loss=0.62223]\n","Step 28197   [1.886 sec/step, loss=0.62732, avg_loss=0.62220]\n","Step 28198   [1.882 sec/step, loss=0.63847, avg_loss=0.62242]\n","Step 28199   [1.878 sec/step, loss=0.63159, avg_loss=0.62238]\n","Step 28200   [1.874 sec/step, loss=0.63497, avg_loss=0.62228]\n","Writing summary at step: 28200\n","Step 28201   [1.877 sec/step, loss=0.62506, avg_loss=0.62223]\n","Step 28202   [1.874 sec/step, loss=0.63468, avg_loss=0.62222]\n","Step 28203   [1.860 sec/step, loss=0.60857, avg_loss=0.62214]\n","Step 28204   [1.860 sec/step, loss=0.61352, avg_loss=0.62187]\n","Step 28205   [1.860 sec/step, loss=0.61124, avg_loss=0.62192]\n","Step 28206   [1.897 sec/step, loss=0.46424, avg_loss=0.62014]\n","Step 28207   [1.892 sec/step, loss=0.62183, avg_loss=0.61997]\n","Step 28208   [1.888 sec/step, loss=0.61822, avg_loss=0.61989]\n","Step 28209   [1.877 sec/step, loss=0.62582, avg_loss=0.62035]\n","Step 28210   [1.882 sec/step, loss=0.62546, avg_loss=0.62051]\n","Step 28211   [1.880 sec/step, loss=0.62813, avg_loss=0.62055]\n","Step 28212   [1.836 sec/step, loss=0.61644, avg_loss=0.62206]\n","Step 28213   [1.834 sec/step, loss=0.62309, avg_loss=0.62208]\n","Step 28214   [1.835 sec/step, loss=0.60182, avg_loss=0.62173]\n","Step 28215   [1.862 sec/step, loss=0.58842, avg_loss=0.62123]\n","Step 28216   [1.872 sec/step, loss=0.62685, avg_loss=0.62113]\n","Step 28217   [1.882 sec/step, loss=0.61943, avg_loss=0.62100]\n","Step 28218   [1.891 sec/step, loss=0.62110, avg_loss=0.62073]\n","Step 28219   [1.885 sec/step, loss=0.63137, avg_loss=0.62059]\n","Step 28220   [1.885 sec/step, loss=0.61939, avg_loss=0.62047]\n","Generated 32 batches of size 32 in 21.108 sec\n","Step 28221   [1.889 sec/step, loss=0.62453, avg_loss=0.62034]\n","Step 28222   [1.879 sec/step, loss=0.60659, avg_loss=0.62007]\n","Step 28223   [1.873 sec/step, loss=0.63826, avg_loss=0.62036]\n","Step 28224   [1.867 sec/step, loss=0.60697, avg_loss=0.62020]\n","Step 28225   [1.867 sec/step, loss=0.63374, avg_loss=0.62024]\n","Step 28226   [1.852 sec/step, loss=0.62098, avg_loss=0.62013]\n","Step 28227   [1.851 sec/step, loss=0.64759, avg_loss=0.62026]\n","Step 28228   [1.787 sec/step, loss=0.62411, avg_loss=0.62236]\n","Step 28229   [1.782 sec/step, loss=0.62424, avg_loss=0.62231]\n","Step 28230   [1.780 sec/step, loss=0.62447, avg_loss=0.62220]\n","Step 28231   [1.795 sec/step, loss=0.59857, avg_loss=0.62193]\n","Step 28232   [1.806 sec/step, loss=0.60952, avg_loss=0.62188]\n","Step 28233   [1.813 sec/step, loss=0.62250, avg_loss=0.62179]\n","Step 28234   [1.812 sec/step, loss=0.59797, avg_loss=0.62153]\n","Step 28235   [1.795 sec/step, loss=0.63795, avg_loss=0.62181]\n","Step 28236   [1.803 sec/step, loss=0.62627, avg_loss=0.62188]\n","Step 28237   [1.800 sec/step, loss=0.61525, avg_loss=0.62181]\n","Step 28238   [1.801 sec/step, loss=0.62378, avg_loss=0.62195]\n","Step 28239   [1.803 sec/step, loss=0.62698, avg_loss=0.62206]\n","Step 28240   [1.790 sec/step, loss=0.62850, avg_loss=0.62216]\n","Step 28241   [1.793 sec/step, loss=0.63015, avg_loss=0.62208]\n","Step 28242   [1.793 sec/step, loss=0.64064, avg_loss=0.62216]\n","Step 28243   [1.789 sec/step, loss=0.62493, avg_loss=0.62221]\n","Step 28244   [1.794 sec/step, loss=0.61681, avg_loss=0.62213]\n","Step 28245   [1.802 sec/step, loss=0.62883, avg_loss=0.62209]\n","Step 28246   [1.813 sec/step, loss=0.62471, avg_loss=0.62225]\n","Step 28247   [1.866 sec/step, loss=0.54014, avg_loss=0.62143]\n","Step 28248   [1.876 sec/step, loss=0.62977, avg_loss=0.62150]\n","Step 28249   [1.872 sec/step, loss=0.63432, avg_loss=0.62157]\n","Step 28250   [1.878 sec/step, loss=0.62492, avg_loss=0.62156]\n","Step 28251   [1.887 sec/step, loss=0.62863, avg_loss=0.62165]\n","Step 28252   [1.897 sec/step, loss=0.61655, avg_loss=0.62149]\n","Step 28253   [1.900 sec/step, loss=0.63424, avg_loss=0.62153]\n","Generated 32 batches of size 32 in 22.340 sec\n","Step 28254   [1.887 sec/step, loss=0.63317, avg_loss=0.62148]\n","Step 28255   [1.916 sec/step, loss=0.43896, avg_loss=0.61946]\n","Step 28256   [1.892 sec/step, loss=0.62793, avg_loss=0.61939]\n","Step 28257   [1.882 sec/step, loss=0.62401, avg_loss=0.61940]\n","Step 28258   [1.865 sec/step, loss=0.62264, avg_loss=0.61918]\n","Step 28259   [1.855 sec/step, loss=0.62265, avg_loss=0.61912]\n","Step 28260   [1.841 sec/step, loss=0.63372, avg_loss=0.61940]\n","Step 28261   [1.845 sec/step, loss=0.62005, avg_loss=0.61942]\n","Step 28262   [1.851 sec/step, loss=0.58958, avg_loss=0.61914]\n","Step 28263   [1.813 sec/step, loss=0.65098, avg_loss=0.62071]\n","Step 28264   [1.816 sec/step, loss=0.62789, avg_loss=0.62104]\n","Step 28265   [1.816 sec/step, loss=0.61839, avg_loss=0.62094]\n","Step 28266   [1.814 sec/step, loss=0.61869, avg_loss=0.62084]\n","Step 28267   [1.817 sec/step, loss=0.62839, avg_loss=0.62091]\n","Step 28268   [1.811 sec/step, loss=0.62268, avg_loss=0.62101]\n","Step 28269   [1.825 sec/step, loss=0.63661, avg_loss=0.62115]\n","Step 28270   [1.817 sec/step, loss=0.60975, avg_loss=0.62093]\n","Step 28271   [1.826 sec/step, loss=0.61833, avg_loss=0.62085]\n","Step 28272   [1.823 sec/step, loss=0.64741, avg_loss=0.62104]\n","Step 28273   [1.827 sec/step, loss=0.62876, avg_loss=0.62112]\n","Step 28274   [1.818 sec/step, loss=0.63317, avg_loss=0.62124]\n","Step 28275   [1.817 sec/step, loss=0.62603, avg_loss=0.62110]\n","Step 28276   [1.820 sec/step, loss=0.65558, avg_loss=0.62146]\n","Step 28277   [1.819 sec/step, loss=0.61753, avg_loss=0.62143]\n","Step 28278   [1.829 sec/step, loss=0.62722, avg_loss=0.62138]\n","Step 28279   [1.827 sec/step, loss=0.61709, avg_loss=0.62133]\n","Step 28280   [1.849 sec/step, loss=0.62188, avg_loss=0.62125]\n","Step 28281   [1.865 sec/step, loss=0.63188, avg_loss=0.62126]\n","Step 28282   [1.861 sec/step, loss=0.61871, avg_loss=0.62121]\n","Step 28283   [1.859 sec/step, loss=0.59662, avg_loss=0.62073]\n","Step 28284   [1.860 sec/step, loss=0.61701, avg_loss=0.62059]\n","Step 28285   [1.879 sec/step, loss=0.62705, avg_loss=0.62077]\n","Step 28286   [1.879 sec/step, loss=0.63098, avg_loss=0.62072]\n","Generated 32 batches of size 32 in 21.661 sec\n","Step 28287   [1.874 sec/step, loss=0.62870, avg_loss=0.62046]\n","Step 28288   [1.868 sec/step, loss=0.62892, avg_loss=0.62039]\n","Step 28289   [1.844 sec/step, loss=0.64162, avg_loss=0.62025]\n","Step 28290   [1.833 sec/step, loss=0.61258, avg_loss=0.62013]\n","Step 28291   [1.837 sec/step, loss=0.60672, avg_loss=0.61983]\n","Step 28292   [1.819 sec/step, loss=0.62793, avg_loss=0.61989]\n","Step 28293   [1.807 sec/step, loss=0.64572, avg_loss=0.62009]\n","Step 28294   [1.809 sec/step, loss=0.62946, avg_loss=0.61997]\n","Step 28295   [1.806 sec/step, loss=0.62945, avg_loss=0.61982]\n","Step 28296   [1.812 sec/step, loss=0.62845, avg_loss=0.61991]\n","Step 28297   [1.805 sec/step, loss=0.63799, avg_loss=0.62002]\n","Step 28298   [1.800 sec/step, loss=0.61866, avg_loss=0.61982]\n","Step 28299   [1.806 sec/step, loss=0.63209, avg_loss=0.61983]\n","Step 28300   [1.808 sec/step, loss=0.64398, avg_loss=0.61992]\n","Writing summary at step: 28300\n","Step 28301   [1.805 sec/step, loss=0.61285, avg_loss=0.61979]\n","Step 28302   [1.802 sec/step, loss=0.62824, avg_loss=0.61973]\n","Step 28303   [1.812 sec/step, loss=0.62686, avg_loss=0.61991]\n","Step 28304   [1.814 sec/step, loss=0.61440, avg_loss=0.61992]\n","Step 28305   [1.820 sec/step, loss=0.60553, avg_loss=0.61987]\n","Step 28306   [1.780 sec/step, loss=0.60557, avg_loss=0.62128]\n","Step 28307   [1.778 sec/step, loss=0.62771, avg_loss=0.62134]\n","Step 28308   [1.783 sec/step, loss=0.62699, avg_loss=0.62142]\n","Step 28309   [1.783 sec/step, loss=0.62276, avg_loss=0.62139]\n","Step 28310   [1.796 sec/step, loss=0.62030, avg_loss=0.62134]\n","Step 28311   [1.857 sec/step, loss=0.47248, avg_loss=0.61979]\n","Step 28312   [1.878 sec/step, loss=0.60823, avg_loss=0.61970]\n","Step 28313   [1.888 sec/step, loss=0.64813, avg_loss=0.61995]\n","Step 28314   [1.886 sec/step, loss=0.61060, avg_loss=0.62004]\n","Step 28315   [1.858 sec/step, loss=0.63832, avg_loss=0.62054]\n","Generated 32 batches of size 32 in 22.082 sec\n","Step 28316   [1.868 sec/step, loss=0.63057, avg_loss=0.62058]\n","Step 28317   [1.854 sec/step, loss=0.62236, avg_loss=0.62061]\n","Step 28318   [1.840 sec/step, loss=0.63071, avg_loss=0.62070]\n","Step 28319   [1.835 sec/step, loss=0.63590, avg_loss=0.62075]\n","Step 28320   [1.817 sec/step, loss=0.64710, avg_loss=0.62103]\n","Step 28321   [1.800 sec/step, loss=0.63348, avg_loss=0.62112]\n","Step 28322   [1.809 sec/step, loss=0.62681, avg_loss=0.62132]\n","Step 28323   [1.816 sec/step, loss=0.62166, avg_loss=0.62115]\n","Step 28324   [1.815 sec/step, loss=0.62099, avg_loss=0.62129]\n","Step 28325   [1.815 sec/step, loss=0.63818, avg_loss=0.62134]\n","Step 28326   [1.813 sec/step, loss=0.62071, avg_loss=0.62133]\n","Step 28327   [1.806 sec/step, loss=0.62163, avg_loss=0.62107]\n","Step 28328   [1.809 sec/step, loss=0.65198, avg_loss=0.62135]\n","Step 28329   [1.826 sec/step, loss=0.58932, avg_loss=0.62100]\n","Step 28330   [1.827 sec/step, loss=0.61343, avg_loss=0.62089]\n","Step 28331   [1.811 sec/step, loss=0.63970, avg_loss=0.62130]\n","Step 28332   [1.802 sec/step, loss=0.63191, avg_loss=0.62153]\n","Step 28333   [1.786 sec/step, loss=0.61144, avg_loss=0.62142]\n","Step 28334   [1.794 sec/step, loss=0.63528, avg_loss=0.62179]\n","Step 28335   [1.796 sec/step, loss=0.62873, avg_loss=0.62170]\n","Step 28336   [1.790 sec/step, loss=0.63895, avg_loss=0.62183]\n","Step 28337   [1.792 sec/step, loss=0.63432, avg_loss=0.62202]\n","Step 28338   [1.797 sec/step, loss=0.62470, avg_loss=0.62203]\n","Step 28339   [1.796 sec/step, loss=0.63214, avg_loss=0.62208]\n","Step 28340   [1.801 sec/step, loss=0.63232, avg_loss=0.62212]\n","Step 28341   [1.805 sec/step, loss=0.62717, avg_loss=0.62209]\n","Step 28342   [1.815 sec/step, loss=0.63880, avg_loss=0.62207]\n","Step 28343   [1.839 sec/step, loss=0.62234, avg_loss=0.62204]\n","Step 28344   [1.905 sec/step, loss=0.46249, avg_loss=0.62050]\n","Step 28345   [1.917 sec/step, loss=0.61502, avg_loss=0.62036]\n","Generated 32 batches of size 32 in 21.032 sec\n","Step 28346   [1.913 sec/step, loss=0.63664, avg_loss=0.62048]\n","Step 28347   [1.869 sec/step, loss=0.63537, avg_loss=0.62143]\n","Step 28348   [1.858 sec/step, loss=0.63526, avg_loss=0.62149]\n","Step 28349   [1.850 sec/step, loss=0.61117, avg_loss=0.62126]\n","Step 28350   [1.876 sec/step, loss=0.51447, avg_loss=0.62015]\n","Step 28351   [1.865 sec/step, loss=0.62696, avg_loss=0.62013]\n","Step 28352   [1.854 sec/step, loss=0.61295, avg_loss=0.62010]\n","Step 28353   [1.853 sec/step, loss=0.64726, avg_loss=0.62023]\n","Step 28354   [1.849 sec/step, loss=0.62018, avg_loss=0.62010]\n","Step 28355   [1.810 sec/step, loss=0.63300, avg_loss=0.62204]\n","Step 28356   [1.812 sec/step, loss=0.62542, avg_loss=0.62201]\n","Step 28357   [1.815 sec/step, loss=0.61623, avg_loss=0.62194]\n","Step 28358   [1.809 sec/step, loss=0.61071, avg_loss=0.62182]\n","Step 28359   [1.806 sec/step, loss=0.60137, avg_loss=0.62160]\n","Step 28360   [1.806 sec/step, loss=0.62147, avg_loss=0.62148]\n","Step 28361   [1.804 sec/step, loss=0.63109, avg_loss=0.62159]\n","Step 28362   [1.789 sec/step, loss=0.62325, avg_loss=0.62193]\n","Step 28363   [1.794 sec/step, loss=0.62768, avg_loss=0.62170]\n","Step 28364   [1.807 sec/step, loss=0.61826, avg_loss=0.62160]\n","Step 28365   [1.823 sec/step, loss=0.62411, avg_loss=0.62166]\n","Step 28366   [1.820 sec/step, loss=0.61508, avg_loss=0.62162]\n","Step 28367   [1.816 sec/step, loss=0.60382, avg_loss=0.62137]\n","Step 28368   [1.822 sec/step, loss=0.63675, avg_loss=0.62151]\n","Step 28369   [1.811 sec/step, loss=0.62571, avg_loss=0.62141]\n","Step 28370   [1.817 sec/step, loss=0.63026, avg_loss=0.62161]\n","Step 28371   [1.816 sec/step, loss=0.62807, avg_loss=0.62171]\n","Step 28372   [1.815 sec/step, loss=0.63536, avg_loss=0.62159]\n","Step 28373   [1.816 sec/step, loss=0.62675, avg_loss=0.62157]\n","Step 28374   [1.828 sec/step, loss=0.62158, avg_loss=0.62145]\n","Step 28375   [1.834 sec/step, loss=0.62155, avg_loss=0.62141]\n","Step 28376   [1.836 sec/step, loss=0.61400, avg_loss=0.62099]\n","Step 28377   [1.845 sec/step, loss=0.63433, avg_loss=0.62116]\n","Step 28378   [1.844 sec/step, loss=0.62910, avg_loss=0.62118]\n","Step 28379   [1.849 sec/step, loss=0.63173, avg_loss=0.62132]\n","Step 28380   [1.841 sec/step, loss=0.63537, avg_loss=0.62146]\n","Step 28381   [1.832 sec/step, loss=0.61588, avg_loss=0.62130]\n","Generated 32 batches of size 32 in 20.507 sec\n","Step 28382   [1.854 sec/step, loss=0.61684, avg_loss=0.62128]\n","Step 28383   [1.855 sec/step, loss=0.62387, avg_loss=0.62155]\n","Step 28384   [1.843 sec/step, loss=0.59902, avg_loss=0.62137]\n","Step 28385   [1.818 sec/step, loss=0.61859, avg_loss=0.62129]\n","Step 28386   [1.799 sec/step, loss=0.61935, avg_loss=0.62117]\n","Step 28387   [1.803 sec/step, loss=0.62428, avg_loss=0.62113]\n","Step 28388   [1.804 sec/step, loss=0.62001, avg_loss=0.62104]\n","Step 28389   [1.810 sec/step, loss=0.63074, avg_loss=0.62093]\n","Step 28390   [1.813 sec/step, loss=0.63247, avg_loss=0.62113]\n","Step 28391   [1.798 sec/step, loss=0.61724, avg_loss=0.62123]\n","Step 28392   [1.811 sec/step, loss=0.61779, avg_loss=0.62113]\n","Step 28393   [1.815 sec/step, loss=0.62879, avg_loss=0.62096]\n","Step 28394   [1.807 sec/step, loss=0.62848, avg_loss=0.62095]\n","Step 28395   [1.828 sec/step, loss=0.58119, avg_loss=0.62047]\n","Step 28396   [1.828 sec/step, loss=0.63259, avg_loss=0.62051]\n","Step 28397   [1.829 sec/step, loss=0.62849, avg_loss=0.62042]\n","Step 28398   [1.860 sec/step, loss=0.46511, avg_loss=0.61888]\n","Step 28399   [1.853 sec/step, loss=0.61577, avg_loss=0.61872]\n","Step 28400   [1.858 sec/step, loss=0.62776, avg_loss=0.61856]\n","Writing summary at step: 28400\n","Step 28401   [1.856 sec/step, loss=0.62121, avg_loss=0.61864]\n","Step 28402   [1.856 sec/step, loss=0.61854, avg_loss=0.61854]\n","Step 28403   [1.848 sec/step, loss=0.63378, avg_loss=0.61861]\n","Step 28404   [1.856 sec/step, loss=0.61657, avg_loss=0.61863]\n","Step 28405   [1.860 sec/step, loss=0.63346, avg_loss=0.61891]\n","Step 28406   [1.876 sec/step, loss=0.61771, avg_loss=0.61903]\n","Step 28407   [1.884 sec/step, loss=0.62114, avg_loss=0.61897]\n","Step 28408   [1.884 sec/step, loss=0.60035, avg_loss=0.61870]\n","Step 28409   [1.884 sec/step, loss=0.62955, avg_loss=0.61877]\n","Step 28410   [1.880 sec/step, loss=0.62727, avg_loss=0.61884]\n","Step 28411   [1.837 sec/step, loss=0.62086, avg_loss=0.62032]\n","Step 28412   [1.827 sec/step, loss=0.63104, avg_loss=0.62055]\n","Generated 32 batches of size 32 in 21.536 sec\n","Step 28413   [1.843 sec/step, loss=0.64009, avg_loss=0.62047]\n","Step 28414   [1.840 sec/step, loss=0.62255, avg_loss=0.62059]\n","Step 28415   [1.828 sec/step, loss=0.62825, avg_loss=0.62049]\n","Step 28416   [1.816 sec/step, loss=0.63908, avg_loss=0.62058]\n","Step 28417   [1.826 sec/step, loss=0.60128, avg_loss=0.62036]\n","Step 28418   [1.827 sec/step, loss=0.61811, avg_loss=0.62024]\n","Step 28419   [1.829 sec/step, loss=0.62582, avg_loss=0.62014]\n","Step 28420   [1.826 sec/step, loss=0.62330, avg_loss=0.61990]\n","Step 28421   [1.824 sec/step, loss=0.61993, avg_loss=0.61976]\n","Step 28422   [1.860 sec/step, loss=0.42447, avg_loss=0.61774]\n","Step 28423   [1.867 sec/step, loss=0.61446, avg_loss=0.61767]\n","Step 28424   [1.869 sec/step, loss=0.63716, avg_loss=0.61783]\n","Step 28425   [1.866 sec/step, loss=0.63388, avg_loss=0.61779]\n","Step 28426   [1.865 sec/step, loss=0.62715, avg_loss=0.61785]\n","Step 28427   [1.867 sec/step, loss=0.64071, avg_loss=0.61804]\n","Step 28428   [1.866 sec/step, loss=0.63818, avg_loss=0.61791]\n","Step 28429   [1.852 sec/step, loss=0.63610, avg_loss=0.61837]\n","Step 28430   [1.852 sec/step, loss=0.63174, avg_loss=0.61856]\n","Step 28431   [1.869 sec/step, loss=0.59650, avg_loss=0.61812]\n","Step 28432   [1.876 sec/step, loss=0.62330, avg_loss=0.61804]\n","Step 28433   [1.881 sec/step, loss=0.63002, avg_loss=0.61822]\n","Step 28434   [1.881 sec/step, loss=0.62222, avg_loss=0.61809]\n","Step 28435   [1.889 sec/step, loss=0.61533, avg_loss=0.61796]\n","Step 28436   [1.900 sec/step, loss=0.62406, avg_loss=0.61781]\n","Step 28437   [1.912 sec/step, loss=0.63228, avg_loss=0.61779]\n","Step 28438   [1.914 sec/step, loss=0.62199, avg_loss=0.61776]\n","Step 28439   [1.928 sec/step, loss=0.63130, avg_loss=0.61775]\n","Step 28440   [1.927 sec/step, loss=0.62717, avg_loss=0.61770]\n","Step 28441   [1.929 sec/step, loss=0.63738, avg_loss=0.61780]\n","Step 28442   [1.923 sec/step, loss=0.62669, avg_loss=0.61768]\n","Step 28443   [1.907 sec/step, loss=0.63740, avg_loss=0.61783]\n","Step 28444   [1.835 sec/step, loss=0.60516, avg_loss=0.61926]\n","Generated 32 batches of size 32 in 21.528 sec\n","Step 28445   [1.853 sec/step, loss=0.61272, avg_loss=0.61924]\n","Step 28446   [1.889 sec/step, loss=0.44756, avg_loss=0.61735]\n","Step 28447   [1.881 sec/step, loss=0.63920, avg_loss=0.61739]\n","Step 28448   [1.882 sec/step, loss=0.63779, avg_loss=0.61741]\n","Step 28449   [1.883 sec/step, loss=0.62902, avg_loss=0.61759]\n","Step 28450   [1.853 sec/step, loss=0.63469, avg_loss=0.61879]\n","Step 28451   [1.871 sec/step, loss=0.60613, avg_loss=0.61858]\n","Step 28452   [1.866 sec/step, loss=0.64081, avg_loss=0.61886]\n","Step 28453   [1.859 sec/step, loss=0.64352, avg_loss=0.61882]\n","Step 28454   [1.861 sec/step, loss=0.61427, avg_loss=0.61877]\n","Step 28455   [1.868 sec/step, loss=0.62996, avg_loss=0.61873]\n","Step 28456   [1.878 sec/step, loss=0.61744, avg_loss=0.61866]\n","Step 28457   [1.883 sec/step, loss=0.62538, avg_loss=0.61875]\n","Step 28458   [1.885 sec/step, loss=0.63215, avg_loss=0.61896]\n","Step 28459   [1.885 sec/step, loss=0.61682, avg_loss=0.61912]\n","Step 28460   [1.886 sec/step, loss=0.61925, avg_loss=0.61909]\n","Step 28461   [1.884 sec/step, loss=0.61493, avg_loss=0.61893]\n","Step 28462   [1.880 sec/step, loss=0.63096, avg_loss=0.61901]\n","Step 28463   [1.876 sec/step, loss=0.62298, avg_loss=0.61896]\n","Step 28464   [1.863 sec/step, loss=0.61504, avg_loss=0.61893]\n","Step 28465   [1.846 sec/step, loss=0.62625, avg_loss=0.61895]\n","Step 28466   [1.849 sec/step, loss=0.61682, avg_loss=0.61897]\n","Step 28467   [1.853 sec/step, loss=0.62415, avg_loss=0.61917]\n","Step 28468   [1.856 sec/step, loss=0.62874, avg_loss=0.61909]\n","Step 28469   [1.857 sec/step, loss=0.61107, avg_loss=0.61895]\n","Step 28470   [1.865 sec/step, loss=0.61917, avg_loss=0.61883]\n","Step 28471   [1.878 sec/step, loss=0.63266, avg_loss=0.61888]\n","Step 28472   [1.889 sec/step, loss=0.63656, avg_loss=0.61889]\n","Step 28473   [1.893 sec/step, loss=0.62115, avg_loss=0.61884]\n","Step 28474   [1.899 sec/step, loss=0.61716, avg_loss=0.61879]\n","Step 28475   [1.898 sec/step, loss=0.61218, avg_loss=0.61870]\n","Step 28476   [1.908 sec/step, loss=0.62273, avg_loss=0.61879]\n","Generated 32 batches of size 32 in 21.652 sec\n","Step 28477   [1.921 sec/step, loss=0.61991, avg_loss=0.61864]\n","Step 28478   [1.909 sec/step, loss=0.61940, avg_loss=0.61854]\n","Step 28479   [1.900 sec/step, loss=0.62913, avg_loss=0.61852]\n","Step 28480   [1.888 sec/step, loss=0.62403, avg_loss=0.61840]\n","Step 28481   [1.884 sec/step, loss=0.63154, avg_loss=0.61856]\n","Step 28482   [1.862 sec/step, loss=0.63109, avg_loss=0.61870]\n","Step 28483   [1.863 sec/step, loss=0.62437, avg_loss=0.61871]\n","Step 28484   [1.865 sec/step, loss=0.61976, avg_loss=0.61892]\n","Step 28485   [1.866 sec/step, loss=0.62575, avg_loss=0.61899]\n","Step 28486   [1.869 sec/step, loss=0.62680, avg_loss=0.61906]\n","Step 28487   [1.862 sec/step, loss=0.63395, avg_loss=0.61916]\n","Step 28488   [1.856 sec/step, loss=0.64024, avg_loss=0.61936]\n","Step 28489   [1.851 sec/step, loss=0.62925, avg_loss=0.61935]\n","Step 28490   [1.849 sec/step, loss=0.61895, avg_loss=0.61921]\n","Step 28491   [1.854 sec/step, loss=0.61487, avg_loss=0.61919]\n","Step 28492   [1.848 sec/step, loss=0.62471, avg_loss=0.61926]\n","Step 28493   [1.841 sec/step, loss=0.62095, avg_loss=0.61918]\n","Step 28494   [1.838 sec/step, loss=0.60466, avg_loss=0.61894]\n","Step 28495   [1.818 sec/step, loss=0.61845, avg_loss=0.61931]\n","Step 28496   [1.820 sec/step, loss=0.60016, avg_loss=0.61899]\n","Step 28497   [1.821 sec/step, loss=0.62276, avg_loss=0.61893]\n","Step 28498   [1.821 sec/step, loss=0.51915, avg_loss=0.61947]\n","Step 28499   [1.832 sec/step, loss=0.59914, avg_loss=0.61931]\n","Step 28500   [1.843 sec/step, loss=0.62368, avg_loss=0.61926]\n","Writing summary at step: 28500\n","Saving checkpoint to: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/model.ckpt-28500\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (85500,)\n","Check wav file:  (115500,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000028500-align000.png\n","100% 1/1 [00:09<00:00,  9.65s/it]\n","Test finished for step 28500.\n","  0% 0/4 [00:00<?, ?it/s]Generated 32 batches of size 32 in 25.125 sec\n","Check wav file before change:  (67500,)\n","Check wav file:  (97500,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000028500-align000.png\n"," 25% 1/4 [00:02<00:08,  2.92s/it]Check wav file before change:  (67500,)\n","Check wav file:  (97500,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000028500-align001.png\n"," 50% 2/4 [00:05<00:05,  2.83s/it]Check wav file before change:  (67500,)\n","Check wav file:  (97500,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000028500-align002.png\n"," 75% 3/4 [00:08<00:02,  2.81s/it]Check wav file before change:  (67500,)\n","Check wav file:  (97500,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000028500-align003.png\n","100% 4/4 [00:10<00:00,  2.75s/it]\n","Test finished for step 28500.\n","Step 28501   [1.847 sec/step, loss=0.61391, avg_loss=0.61919]\n","Step 28502   [1.863 sec/step, loss=0.60347, avg_loss=0.61904]\n","Step 28503   [1.861 sec/step, loss=0.63124, avg_loss=0.61902]\n","Step 28504   [1.850 sec/step, loss=0.59659, avg_loss=0.61882]\n","Step 28505   [1.846 sec/step, loss=0.63067, avg_loss=0.61879]\n","Step 28506   [1.831 sec/step, loss=0.62174, avg_loss=0.61883]\n","Step 28507   [1.825 sec/step, loss=0.62199, avg_loss=0.61884]\n","Step 28508   [1.839 sec/step, loss=0.59210, avg_loss=0.61875]\n","Step 28509   [1.834 sec/step, loss=0.61664, avg_loss=0.61863]\n","Step 28510   [1.828 sec/step, loss=0.64142, avg_loss=0.61877]\n","Step 28511   [1.809 sec/step, loss=0.62689, avg_loss=0.61883]\n","Step 28512   [1.795 sec/step, loss=0.62230, avg_loss=0.61874]\n","Step 28513   [1.783 sec/step, loss=0.60917, avg_loss=0.61843]\n","Step 28514   [1.782 sec/step, loss=0.61610, avg_loss=0.61837]\n","Step 28515   [1.784 sec/step, loss=0.62288, avg_loss=0.61831]\n","Step 28516   [1.777 sec/step, loss=0.61792, avg_loss=0.61810]\n","Step 28517   [1.765 sec/step, loss=0.61279, avg_loss=0.61822]\n","Step 28518   [1.761 sec/step, loss=0.62423, avg_loss=0.61828]\n","Step 28519   [1.758 sec/step, loss=0.62828, avg_loss=0.61830]\n","Step 28520   [1.794 sec/step, loss=0.46985, avg_loss=0.61677]\n","Step 28521   [1.798 sec/step, loss=0.62777, avg_loss=0.61685]\n","Step 28522   [1.761 sec/step, loss=0.62993, avg_loss=0.61890]\n","Step 28523   [1.750 sec/step, loss=0.63185, avg_loss=0.61907]\n","Step 28524   [1.751 sec/step, loss=0.61314, avg_loss=0.61883]\n","Step 28525   [1.749 sec/step, loss=0.61947, avg_loss=0.61869]\n","Step 28526   [1.751 sec/step, loss=0.64003, avg_loss=0.61882]\n","Step 28527   [1.756 sec/step, loss=0.62637, avg_loss=0.61867]\n","Step 28528   [1.766 sec/step, loss=0.60224, avg_loss=0.61832]\n","Step 28529   [1.770 sec/step, loss=0.61336, avg_loss=0.61809]\n","Step 28530   [1.781 sec/step, loss=0.63586, avg_loss=0.61813]\n","Step 28531   [1.768 sec/step, loss=0.62234, avg_loss=0.61839]\n","Step 28532   [1.768 sec/step, loss=0.61817, avg_loss=0.61834]\n","Step 28533   [1.782 sec/step, loss=0.60340, avg_loss=0.61807]\n","Step 28534   [1.781 sec/step, loss=0.61985, avg_loss=0.61805]\n","Step 28535   [1.785 sec/step, loss=0.61589, avg_loss=0.61805]\n","Step 28536   [1.775 sec/step, loss=0.61257, avg_loss=0.61794]\n","Step 28537   [1.772 sec/step, loss=0.62527, avg_loss=0.61787]\n","Step 28538   [1.776 sec/step, loss=0.62631, avg_loss=0.61791]\n","Generated 32 batches of size 32 in 21.010 sec\n","Step 28539   [1.788 sec/step, loss=0.61227, avg_loss=0.61772]\n","Step 28540   [1.782 sec/step, loss=0.60930, avg_loss=0.61754]\n","Step 28541   [1.775 sec/step, loss=0.64154, avg_loss=0.61758]\n","Step 28542   [1.768 sec/step, loss=0.61539, avg_loss=0.61747]\n","Step 28543   [1.759 sec/step, loss=0.61811, avg_loss=0.61728]\n","Step 28544   [1.769 sec/step, loss=0.61046, avg_loss=0.61733]\n","Step 28545   [1.768 sec/step, loss=0.44652, avg_loss=0.61567]\n","Step 28546   [1.727 sec/step, loss=0.59947, avg_loss=0.61719]\n","Step 28547   [1.726 sec/step, loss=0.63209, avg_loss=0.61712]\n","Step 28548   [1.738 sec/step, loss=0.60887, avg_loss=0.61683]\n","Step 28549   [1.739 sec/step, loss=0.62610, avg_loss=0.61680]\n","Step 28550   [1.743 sec/step, loss=0.62345, avg_loss=0.61669]\n","Step 28551   [1.734 sec/step, loss=0.62342, avg_loss=0.61686]\n","Step 28552   [1.739 sec/step, loss=0.61328, avg_loss=0.61658]\n","Step 28553   [1.742 sec/step, loss=0.63204, avg_loss=0.61647]\n","Step 28554   [1.744 sec/step, loss=0.62891, avg_loss=0.61661]\n","Step 28555   [1.735 sec/step, loss=0.62870, avg_loss=0.61660]\n","Step 28556   [1.724 sec/step, loss=0.61115, avg_loss=0.61654]\n","Step 28557   [1.716 sec/step, loss=0.61738, avg_loss=0.61646]\n","Step 28558   [1.720 sec/step, loss=0.62226, avg_loss=0.61636]\n","Step 28559   [1.724 sec/step, loss=0.61337, avg_loss=0.61633]\n","Step 28560   [1.719 sec/step, loss=0.62936, avg_loss=0.61643]\n","Step 28561   [1.724 sec/step, loss=0.62949, avg_loss=0.61657]\n","Step 28562   [1.742 sec/step, loss=0.62946, avg_loss=0.61656]\n","Step 28563   [1.757 sec/step, loss=0.62225, avg_loss=0.61655]\n","Step 28564   [1.771 sec/step, loss=0.63116, avg_loss=0.61671]\n","Step 28565   [1.780 sec/step, loss=0.61714, avg_loss=0.61662]\n","Step 28566   [1.783 sec/step, loss=0.60728, avg_loss=0.61652]\n","Step 28567   [1.785 sec/step, loss=0.61303, avg_loss=0.61641]\n","Step 28568   [1.792 sec/step, loss=0.63493, avg_loss=0.61648]\n","Step 28569   [1.792 sec/step, loss=0.61949, avg_loss=0.61656]\n","Step 28570   [1.788 sec/step, loss=0.62259, avg_loss=0.61659]\n","Generated 32 batches of size 32 in 22.343 sec\n","Step 28571   [1.805 sec/step, loss=0.62654, avg_loss=0.61653]\n","Step 28572   [1.801 sec/step, loss=0.61822, avg_loss=0.61635]\n","Step 28573   [1.832 sec/step, loss=0.47683, avg_loss=0.61491]\n","Step 28574   [1.820 sec/step, loss=0.61495, avg_loss=0.61488]\n","Step 28575   [1.814 sec/step, loss=0.61118, avg_loss=0.61487]\n","Step 28576   [1.798 sec/step, loss=0.62270, avg_loss=0.61487]\n","Step 28577   [1.777 sec/step, loss=0.61091, avg_loss=0.61478]\n","Step 28578   [1.777 sec/step, loss=0.61154, avg_loss=0.61470]\n","Step 28579   [1.774 sec/step, loss=0.62202, avg_loss=0.61463]\n","Step 28580   [1.786 sec/step, loss=0.60287, avg_loss=0.61442]\n","Step 28581   [1.783 sec/step, loss=0.62861, avg_loss=0.61439]\n","Step 28582   [1.787 sec/step, loss=0.63194, avg_loss=0.61440]\n","Step 28583   [1.785 sec/step, loss=0.61862, avg_loss=0.61434]\n","Step 28584   [1.802 sec/step, loss=0.59995, avg_loss=0.61415]\n","Step 28585   [1.803 sec/step, loss=0.63216, avg_loss=0.61421]\n","Step 28586   [1.799 sec/step, loss=0.59602, avg_loss=0.61390]\n","Step 28587   [1.799 sec/step, loss=0.62446, avg_loss=0.61381]\n","Step 28588   [1.802 sec/step, loss=0.61213, avg_loss=0.61353]\n","Step 28589   [1.805 sec/step, loss=0.61089, avg_loss=0.61334]\n","Step 28590   [1.821 sec/step, loss=0.59290, avg_loss=0.61308]\n","Step 28591   [1.817 sec/step, loss=0.62627, avg_loss=0.61320]\n","Step 28592   [1.811 sec/step, loss=0.61026, avg_loss=0.61305]\n","Step 28593   [1.816 sec/step, loss=0.61296, avg_loss=0.61297]\n","Step 28594   [1.821 sec/step, loss=0.59711, avg_loss=0.61290]\n","Step 28595   [1.829 sec/step, loss=0.61019, avg_loss=0.61281]\n","Step 28596   [1.832 sec/step, loss=0.62114, avg_loss=0.61302]\n","Step 28597   [1.838 sec/step, loss=0.62751, avg_loss=0.61307]\n","Step 28598   [1.810 sec/step, loss=0.61741, avg_loss=0.61405]\n","Step 28599   [1.814 sec/step, loss=0.62047, avg_loss=0.61427]\n","Step 28600   [1.808 sec/step, loss=0.62497, avg_loss=0.61428]\n","Writing summary at step: 28600\n","Step 28601   [1.810 sec/step, loss=0.62374, avg_loss=0.61438]\n","Generated 32 batches of size 32 in 21.956 sec\n","Step 28602   [1.842 sec/step, loss=0.61056, avg_loss=0.61445]\n","Step 28603   [1.861 sec/step, loss=0.58190, avg_loss=0.61396]\n","Step 28604   [1.861 sec/step, loss=0.61477, avg_loss=0.61414]\n","Step 28605   [1.864 sec/step, loss=0.60931, avg_loss=0.61392]\n","Step 28606   [1.872 sec/step, loss=0.62117, avg_loss=0.61392]\n","Step 28607   [1.868 sec/step, loss=0.60944, avg_loss=0.61379]\n","Step 28608   [1.849 sec/step, loss=0.62444, avg_loss=0.61412]\n","Step 28609   [1.849 sec/step, loss=0.62699, avg_loss=0.61422]\n","Step 28610   [1.845 sec/step, loss=0.63533, avg_loss=0.61416]\n","Step 28611   [1.841 sec/step, loss=0.59288, avg_loss=0.61382]\n","Step 28612   [1.842 sec/step, loss=0.62606, avg_loss=0.61386]\n","Step 28613   [1.841 sec/step, loss=0.61630, avg_loss=0.61393]\n","Step 28614   [1.846 sec/step, loss=0.63331, avg_loss=0.61410]\n","Step 28615   [1.847 sec/step, loss=0.62732, avg_loss=0.61414]\n","Step 28616   [1.856 sec/step, loss=0.62209, avg_loss=0.61419]\n","Step 28617   [1.857 sec/step, loss=0.63719, avg_loss=0.61443]\n","Step 28618   [1.861 sec/step, loss=0.60223, avg_loss=0.61421]\n","Step 28619   [1.868 sec/step, loss=0.64159, avg_loss=0.61434]\n","Step 28620   [1.840 sec/step, loss=0.61387, avg_loss=0.61578]\n","Step 28621   [1.851 sec/step, loss=0.61639, avg_loss=0.61567]\n","Step 28622   [1.850 sec/step, loss=0.63112, avg_loss=0.61568]\n","Step 28623   [1.845 sec/step, loss=0.62345, avg_loss=0.61560]\n","Step 28624   [1.845 sec/step, loss=0.61804, avg_loss=0.61565]\n","Step 28625   [1.852 sec/step, loss=0.61233, avg_loss=0.61557]\n","Step 28626   [1.864 sec/step, loss=0.62004, avg_loss=0.61537]\n","Step 28627   [1.870 sec/step, loss=0.63011, avg_loss=0.61541]\n","Step 28628   [1.864 sec/step, loss=0.62406, avg_loss=0.61563]\n","Step 28629   [1.862 sec/step, loss=0.63007, avg_loss=0.61580]\n","Step 28630   [1.859 sec/step, loss=0.60956, avg_loss=0.61553]\n","Step 28631   [1.860 sec/step, loss=0.61278, avg_loss=0.61544]\n","Step 28632   [1.868 sec/step, loss=0.63093, avg_loss=0.61557]\n","Generated 32 batches of size 32 in 22.523 sec\n","Step 28633   [1.915 sec/step, loss=0.51776, avg_loss=0.61471]\n","Step 28634   [1.913 sec/step, loss=0.62041, avg_loss=0.61472]\n","Step 28635   [1.897 sec/step, loss=0.62933, avg_loss=0.61485]\n","Step 28636   [1.897 sec/step, loss=0.61801, avg_loss=0.61490]\n","Step 28637   [1.887 sec/step, loss=0.61541, avg_loss=0.61481]\n","Step 28638   [1.885 sec/step, loss=0.62463, avg_loss=0.61479]\n","Step 28639   [1.874 sec/step, loss=0.58663, avg_loss=0.61453]\n","Step 28640   [1.880 sec/step, loss=0.63686, avg_loss=0.61481]\n","Step 28641   [1.875 sec/step, loss=0.61230, avg_loss=0.61452]\n","Step 28642   [1.874 sec/step, loss=0.61586, avg_loss=0.61452]\n","Step 28643   [1.881 sec/step, loss=0.62027, avg_loss=0.61454]\n","Step 28644   [1.868 sec/step, loss=0.59946, avg_loss=0.61443]\n","Step 28645   [1.835 sec/step, loss=0.60989, avg_loss=0.61607]\n","Step 28646   [1.844 sec/step, loss=0.62349, avg_loss=0.61631]\n","Step 28647   [1.846 sec/step, loss=0.63597, avg_loss=0.61634]\n","Step 28648   [1.864 sec/step, loss=0.51475, avg_loss=0.61540]\n","Step 28649   [1.876 sec/step, loss=0.62402, avg_loss=0.61538]\n","Step 28650   [1.872 sec/step, loss=0.62315, avg_loss=0.61538]\n","Step 28651   [1.862 sec/step, loss=0.61511, avg_loss=0.61530]\n","Step 28652   [1.851 sec/step, loss=0.61879, avg_loss=0.61535]\n","Step 28653   [1.848 sec/step, loss=0.60773, avg_loss=0.61511]\n","Step 28654   [1.848 sec/step, loss=0.63193, avg_loss=0.61514]\n","Step 28655   [1.853 sec/step, loss=0.62210, avg_loss=0.61507]\n","Step 28656   [1.855 sec/step, loss=0.61371, avg_loss=0.61510]\n","Step 28657   [1.873 sec/step, loss=0.61847, avg_loss=0.61511]\n","Step 28658   [1.877 sec/step, loss=0.63435, avg_loss=0.61523]\n","Step 28659   [1.882 sec/step, loss=0.62920, avg_loss=0.61539]\n","Step 28660   [1.891 sec/step, loss=0.61869, avg_loss=0.61528]\n","Step 28661   [1.902 sec/step, loss=0.62774, avg_loss=0.61526]\n","Step 28662   [1.910 sec/step, loss=0.63885, avg_loss=0.61536]\n","Step 28663   [1.897 sec/step, loss=0.61282, avg_loss=0.61526]\n","Step 28664   [1.889 sec/step, loss=0.62954, avg_loss=0.61525]\n","Step 28665   [1.884 sec/step, loss=0.61512, avg_loss=0.61523]\n","Generated 32 batches of size 32 in 22.139 sec\n","Step 28666   [1.909 sec/step, loss=0.61795, avg_loss=0.61533]\n","Step 28667   [1.904 sec/step, loss=0.63183, avg_loss=0.61552]\n","Step 28668   [1.897 sec/step, loss=0.63089, avg_loss=0.61548]\n","Step 28669   [1.892 sec/step, loss=0.58534, avg_loss=0.61514]\n","Step 28670   [1.890 sec/step, loss=0.63828, avg_loss=0.61530]\n","Step 28671   [1.857 sec/step, loss=0.63186, avg_loss=0.61535]\n","Step 28672   [1.853 sec/step, loss=0.61732, avg_loss=0.61534]\n","Step 28673   [1.812 sec/step, loss=0.61508, avg_loss=0.61672]\n","Step 28674   [1.811 sec/step, loss=0.62850, avg_loss=0.61686]\n","Step 28675   [1.813 sec/step, loss=0.63110, avg_loss=0.61706]\n","Step 28676   [1.812 sec/step, loss=0.62488, avg_loss=0.61708]\n","Step 28677   [1.815 sec/step, loss=0.63429, avg_loss=0.61731]\n","Step 28678   [1.814 sec/step, loss=0.61286, avg_loss=0.61733]\n","Step 28679   [1.855 sec/step, loss=0.40274, avg_loss=0.61513]\n","Step 28680   [1.842 sec/step, loss=0.62073, avg_loss=0.61531]\n","Step 28681   [1.840 sec/step, loss=0.63272, avg_loss=0.61535]\n","Step 28682   [1.833 sec/step, loss=0.61232, avg_loss=0.61516]\n","Step 28683   [1.835 sec/step, loss=0.62497, avg_loss=0.61522]\n","Step 28684   [1.836 sec/step, loss=0.60767, avg_loss=0.61530]\n","Step 28685   [1.840 sec/step, loss=0.62149, avg_loss=0.61519]\n","Step 28686   [1.846 sec/step, loss=0.62735, avg_loss=0.61551]\n","Step 28687   [1.847 sec/step, loss=0.60782, avg_loss=0.61534]\n","Step 28688   [1.844 sec/step, loss=0.62667, avg_loss=0.61548]\n","Step 28689   [1.862 sec/step, loss=0.60199, avg_loss=0.61540]\n","Step 28690   [1.855 sec/step, loss=0.63221, avg_loss=0.61579]\n","Step 28691   [1.871 sec/step, loss=0.61501, avg_loss=0.61568]\n","Step 28692   [1.881 sec/step, loss=0.61831, avg_loss=0.61576]\n","Step 28693   [1.884 sec/step, loss=0.62048, avg_loss=0.61583]\n","Step 28694   [1.893 sec/step, loss=0.63647, avg_loss=0.61623]\n","Step 28695   [1.894 sec/step, loss=0.63396, avg_loss=0.61646]\n","Step 28696   [1.900 sec/step, loss=0.63075, avg_loss=0.61656]\n","Step 28697   [1.896 sec/step, loss=0.61290, avg_loss=0.61641]\n","Generated 32 batches of size 32 in 22.317 sec\n","Step 28698   [1.914 sec/step, loss=0.62159, avg_loss=0.61646]\n","Step 28699   [1.911 sec/step, loss=0.64090, avg_loss=0.61666]\n","Step 28700   [1.900 sec/step, loss=0.63428, avg_loss=0.61675]\n","Writing summary at step: 28700\n","Step 28701   [1.912 sec/step, loss=0.59852, avg_loss=0.61650]\n","Step 28702   [1.866 sec/step, loss=0.63602, avg_loss=0.61676]\n","Step 28703   [1.851 sec/step, loss=0.63275, avg_loss=0.61726]\n","Step 28704   [1.850 sec/step, loss=0.61427, avg_loss=0.61726]\n","Step 28705   [1.843 sec/step, loss=0.62251, avg_loss=0.61739]\n","Step 28706   [1.835 sec/step, loss=0.61274, avg_loss=0.61731]\n","Step 28707   [1.843 sec/step, loss=0.61393, avg_loss=0.61735]\n","Step 28708   [1.846 sec/step, loss=0.62402, avg_loss=0.61735]\n","Step 28709   [1.847 sec/step, loss=0.61897, avg_loss=0.61727]\n","Step 28710   [1.843 sec/step, loss=0.61999, avg_loss=0.61711]\n","Step 28711   [1.846 sec/step, loss=0.62371, avg_loss=0.61742]\n","Step 28712   [1.855 sec/step, loss=0.61723, avg_loss=0.61733]\n","Step 28713   [1.850 sec/step, loss=0.59327, avg_loss=0.61710]\n","Step 28714   [1.848 sec/step, loss=0.63412, avg_loss=0.61711]\n","Step 28715   [1.844 sec/step, loss=0.61459, avg_loss=0.61698]\n","Step 28716   [1.837 sec/step, loss=0.62988, avg_loss=0.61706]\n","Step 28717   [1.847 sec/step, loss=0.62401, avg_loss=0.61693]\n","Step 28718   [1.848 sec/step, loss=0.63111, avg_loss=0.61722]\n","Step 28719   [1.844 sec/step, loss=0.61566, avg_loss=0.61696]\n","Step 28720   [1.851 sec/step, loss=0.61998, avg_loss=0.61702]\n","Step 28721   [1.852 sec/step, loss=0.64144, avg_loss=0.61727]\n","Step 28722   [1.860 sec/step, loss=0.63929, avg_loss=0.61735]\n","Step 28723   [1.865 sec/step, loss=0.62400, avg_loss=0.61736]\n","Step 28724   [1.875 sec/step, loss=0.62335, avg_loss=0.61741]\n","Step 28725   [1.947 sec/step, loss=0.41786, avg_loss=0.61547]\n","Generated 32 batches of size 32 in 22.034 sec\n","Step 28726   [1.946 sec/step, loss=0.62619, avg_loss=0.61553]\n","Step 28727   [1.938 sec/step, loss=0.62556, avg_loss=0.61548]\n","Step 28728   [1.935 sec/step, loss=0.62282, avg_loss=0.61547]\n","Step 28729   [1.932 sec/step, loss=0.62260, avg_loss=0.61540]\n","Step 28730   [1.926 sec/step, loss=0.62201, avg_loss=0.61552]\n","Step 28731   [1.918 sec/step, loss=0.60712, avg_loss=0.61546]\n","Step 28732   [1.903 sec/step, loss=0.62334, avg_loss=0.61539]\n","Step 28733   [1.837 sec/step, loss=0.60333, avg_loss=0.61624]\n","Step 28734   [1.837 sec/step, loss=0.63183, avg_loss=0.61636]\n","Step 28735   [1.838 sec/step, loss=0.61702, avg_loss=0.61623]\n","Step 28736   [1.834 sec/step, loss=0.60746, avg_loss=0.61613]\n","Step 28737   [1.841 sec/step, loss=0.62540, avg_loss=0.61623]\n","Step 28738   [1.847 sec/step, loss=0.63617, avg_loss=0.61634]\n","Step 28739   [1.837 sec/step, loss=0.61604, avg_loss=0.61664]\n","Step 28740   [1.836 sec/step, loss=0.63081, avg_loss=0.61658]\n","Step 28741   [1.837 sec/step, loss=0.60982, avg_loss=0.61655]\n","Step 28742   [1.841 sec/step, loss=0.61844, avg_loss=0.61658]\n","Step 28743   [1.837 sec/step, loss=0.62431, avg_loss=0.61662]\n","Step 28744   [1.842 sec/step, loss=0.62511, avg_loss=0.61688]\n","Step 28745   [1.840 sec/step, loss=0.62150, avg_loss=0.61699]\n","Step 28746   [1.831 sec/step, loss=0.61771, avg_loss=0.61693]\n","Step 28747   [1.844 sec/step, loss=0.56751, avg_loss=0.61625]\n","Step 28748   [1.813 sec/step, loss=0.62198, avg_loss=0.61732]\n","Step 28749   [1.801 sec/step, loss=0.61479, avg_loss=0.61723]\n","Step 28750   [1.840 sec/step, loss=0.45087, avg_loss=0.61551]\n","Step 28751   [1.839 sec/step, loss=0.62598, avg_loss=0.61562]\n","Step 28752   [1.850 sec/step, loss=0.62231, avg_loss=0.61565]\n","Step 28753   [1.851 sec/step, loss=0.61886, avg_loss=0.61576]\n","Step 28754   [1.860 sec/step, loss=0.62977, avg_loss=0.61574]\n","Step 28755   [1.862 sec/step, loss=0.61876, avg_loss=0.61571]\n","Step 28756   [1.878 sec/step, loss=0.62622, avg_loss=0.61583]\n","Step 28757   [1.880 sec/step, loss=0.62200, avg_loss=0.61587]\n","Step 28758   [1.874 sec/step, loss=0.62348, avg_loss=0.61576]\n","Step 28759   [1.889 sec/step, loss=0.60625, avg_loss=0.61553]\n","Step 28760   [1.898 sec/step, loss=0.62929, avg_loss=0.61563]\n","Generated 32 batches of size 32 in 21.982 sec\n","Step 28761   [1.893 sec/step, loss=0.60713, avg_loss=0.61543]\n","Step 28762   [1.869 sec/step, loss=0.62381, avg_loss=0.61528]\n","Step 28763   [1.866 sec/step, loss=0.61428, avg_loss=0.61529]\n","Step 28764   [1.859 sec/step, loss=0.60604, avg_loss=0.61506]\n","Step 28765   [1.860 sec/step, loss=0.60928, avg_loss=0.61500]\n","Step 28766   [1.830 sec/step, loss=0.61900, avg_loss=0.61501]\n","Step 28767   [1.834 sec/step, loss=0.62578, avg_loss=0.61495]\n","Step 28768   [1.825 sec/step, loss=0.62789, avg_loss=0.61492]\n","Step 28769   [1.843 sec/step, loss=0.59903, avg_loss=0.61506]\n","Step 28770   [1.875 sec/step, loss=0.42783, avg_loss=0.61295]\n","Step 28771   [1.879 sec/step, loss=0.62668, avg_loss=0.61290]\n","Step 28772   [1.878 sec/step, loss=0.62754, avg_loss=0.61300]\n","Step 28773   [1.885 sec/step, loss=0.64124, avg_loss=0.61326]\n","Step 28774   [1.880 sec/step, loss=0.62799, avg_loss=0.61326]\n","Step 28775   [1.878 sec/step, loss=0.60397, avg_loss=0.61299]\n","Step 28776   [1.885 sec/step, loss=0.60932, avg_loss=0.61283]\n","Step 28777   [1.885 sec/step, loss=0.62098, avg_loss=0.61270]\n","Step 28778   [1.887 sec/step, loss=0.63832, avg_loss=0.61295]\n","Step 28779   [1.848 sec/step, loss=0.60673, avg_loss=0.61499]\n","Step 28780   [1.858 sec/step, loss=0.61055, avg_loss=0.61489]\n","Step 28781   [1.857 sec/step, loss=0.62684, avg_loss=0.61483]\n","Step 28782   [1.857 sec/step, loss=0.61206, avg_loss=0.61483]\n","Step 28783   [1.852 sec/step, loss=0.62822, avg_loss=0.61486]\n","Step 28784   [1.841 sec/step, loss=0.62829, avg_loss=0.61507]\n","Step 28785   [1.848 sec/step, loss=0.61954, avg_loss=0.61505]\n","Step 28786   [1.857 sec/step, loss=0.64694, avg_loss=0.61525]\n","Step 28787   [1.877 sec/step, loss=0.60746, avg_loss=0.61524]\n","Step 28788   [1.896 sec/step, loss=0.61699, avg_loss=0.61514]\n","Step 28789   [1.886 sec/step, loss=0.63072, avg_loss=0.61543]\n","Step 28790   [1.881 sec/step, loss=0.61577, avg_loss=0.61527]\n","Step 28791   [1.867 sec/step, loss=0.62461, avg_loss=0.61536]\n","Step 28792   [1.869 sec/step, loss=0.61244, avg_loss=0.61530]\n","Generated 32 batches of size 32 in 22.846 sec\n","Step 28793   [1.883 sec/step, loss=0.61469, avg_loss=0.61525]\n","Step 28794   [1.869 sec/step, loss=0.62454, avg_loss=0.61513]\n","Step 28795   [1.880 sec/step, loss=0.58935, avg_loss=0.61468]\n","Step 28796   [1.866 sec/step, loss=0.63367, avg_loss=0.61471]\n","Step 28797   [1.861 sec/step, loss=0.61547, avg_loss=0.61474]\n","Step 28798   [1.835 sec/step, loss=0.60084, avg_loss=0.61453]\n","Step 28799   [1.825 sec/step, loss=0.63589, avg_loss=0.61448]\n","Step 28800   [1.829 sec/step, loss=0.62934, avg_loss=0.61443]\n","Writing summary at step: 28800\n","Step 28801   [1.812 sec/step, loss=0.63546, avg_loss=0.61480]\n","Step 28802   [1.817 sec/step, loss=0.62232, avg_loss=0.61466]\n","Step 28803   [1.817 sec/step, loss=0.63501, avg_loss=0.61468]\n","Step 28804   [1.821 sec/step, loss=0.63622, avg_loss=0.61490]\n","Step 28805   [1.829 sec/step, loss=0.61364, avg_loss=0.61482]\n","Step 28806   [1.839 sec/step, loss=0.61734, avg_loss=0.61486]\n","Step 28807   [1.830 sec/step, loss=0.60792, avg_loss=0.61480]\n","Step 28808   [1.831 sec/step, loss=0.61733, avg_loss=0.61473]\n","Step 28809   [1.837 sec/step, loss=0.62875, avg_loss=0.61483]\n","Step 28810   [1.839 sec/step, loss=0.62114, avg_loss=0.61484]\n","Step 28811   [1.844 sec/step, loss=0.63839, avg_loss=0.61499]\n","Step 28812   [1.840 sec/step, loss=0.62094, avg_loss=0.61503]\n","Step 28813   [1.837 sec/step, loss=0.63475, avg_loss=0.61544]\n","Step 28814   [1.838 sec/step, loss=0.62276, avg_loss=0.61533]\n","Step 28815   [1.848 sec/step, loss=0.62673, avg_loss=0.61545]\n","Step 28816   [1.853 sec/step, loss=0.61266, avg_loss=0.61528]\n","Step 28817   [1.846 sec/step, loss=0.61152, avg_loss=0.61515]\n","Step 28818   [1.847 sec/step, loss=0.61598, avg_loss=0.61500]\n","Step 28819   [1.849 sec/step, loss=0.62663, avg_loss=0.61511]\n","Step 28820   [1.842 sec/step, loss=0.62788, avg_loss=0.61519]\n","Step 28821   [1.846 sec/step, loss=0.62090, avg_loss=0.61499]\n","Step 28822   [1.848 sec/step, loss=0.63271, avg_loss=0.61492]\n","Step 28823   [1.870 sec/step, loss=0.62419, avg_loss=0.61492]\n","Generated 32 batches of size 32 in 22.253 sec\n","Step 28824   [1.888 sec/step, loss=0.63437, avg_loss=0.61503]\n","Step 28825   [1.809 sec/step, loss=0.62237, avg_loss=0.61708]\n","Step 28826   [1.802 sec/step, loss=0.61604, avg_loss=0.61697]\n","Step 28827   [1.802 sec/step, loss=0.63432, avg_loss=0.61706]\n","Step 28828   [1.806 sec/step, loss=0.60115, avg_loss=0.61685]\n","Step 28829   [1.802 sec/step, loss=0.61228, avg_loss=0.61674]\n","Step 28830   [1.800 sec/step, loss=0.63098, avg_loss=0.61683]\n","Step 28831   [1.801 sec/step, loss=0.61082, avg_loss=0.61687]\n","Step 28832   [1.799 sec/step, loss=0.60367, avg_loss=0.61667]\n","Step 28833   [1.818 sec/step, loss=0.57993, avg_loss=0.61644]\n","Step 28834   [1.816 sec/step, loss=0.63034, avg_loss=0.61642]\n","Step 28835   [1.817 sec/step, loss=0.61653, avg_loss=0.61642]\n","Step 28836   [1.827 sec/step, loss=0.60365, avg_loss=0.61638]\n","Step 28837   [1.820 sec/step, loss=0.59942, avg_loss=0.61612]\n","Step 28838   [1.809 sec/step, loss=0.62039, avg_loss=0.61596]\n","Step 28839   [1.802 sec/step, loss=0.62761, avg_loss=0.61608]\n","Step 28840   [1.799 sec/step, loss=0.61714, avg_loss=0.61594]\n","Step 28841   [1.812 sec/step, loss=0.60320, avg_loss=0.61588]\n","Step 28842   [1.814 sec/step, loss=0.61723, avg_loss=0.61586]\n","Step 28843   [1.814 sec/step, loss=0.62895, avg_loss=0.61591]\n","Step 28844   [1.812 sec/step, loss=0.60835, avg_loss=0.61574]\n","Step 28845   [1.810 sec/step, loss=0.62014, avg_loss=0.61573]\n","Step 28846   [1.808 sec/step, loss=0.60631, avg_loss=0.61561]\n","Step 28847   [1.796 sec/step, loss=0.63305, avg_loss=0.61627]\n","Step 28848   [1.809 sec/step, loss=0.62749, avg_loss=0.61633]\n","Step 28849   [1.822 sec/step, loss=0.61615, avg_loss=0.61634]\n","Step 28850   [1.845 sec/step, loss=0.50358, avg_loss=0.61687]\n","Step 28851   [1.863 sec/step, loss=0.63429, avg_loss=0.61695]\n","Step 28852   [1.866 sec/step, loss=0.62697, avg_loss=0.61700]\n","Step 28853   [1.870 sec/step, loss=0.62413, avg_loss=0.61705]\n","Generated 32 batches of size 32 in 23.074 sec\n","Step 28854   [1.876 sec/step, loss=0.60899, avg_loss=0.61684]\n","Step 28855   [1.866 sec/step, loss=0.61181, avg_loss=0.61677]\n","Step 28856   [1.884 sec/step, loss=0.50346, avg_loss=0.61554]\n","Step 28857   [1.868 sec/step, loss=0.62563, avg_loss=0.61558]\n","Step 28858   [1.865 sec/step, loss=0.61024, avg_loss=0.61545]\n","Step 28859   [1.841 sec/step, loss=0.59910, avg_loss=0.61538]\n","Step 28860   [1.824 sec/step, loss=0.61285, avg_loss=0.61521]\n","Step 28861   [1.821 sec/step, loss=0.61971, avg_loss=0.61534]\n","Step 28862   [1.820 sec/step, loss=0.62392, avg_loss=0.61534]\n","Step 28863   [1.818 sec/step, loss=0.62195, avg_loss=0.61542]\n","Step 28864   [1.823 sec/step, loss=0.63369, avg_loss=0.61569]\n","Step 28865   [1.816 sec/step, loss=0.61463, avg_loss=0.61575]\n","Step 28866   [1.817 sec/step, loss=0.62357, avg_loss=0.61579]\n","Step 28867   [1.812 sec/step, loss=0.61072, avg_loss=0.61564]\n","Step 28868   [1.820 sec/step, loss=0.61649, avg_loss=0.61553]\n","Step 28869   [1.806 sec/step, loss=0.62188, avg_loss=0.61575]\n","Step 28870   [1.783 sec/step, loss=0.58338, avg_loss=0.61731]\n","Step 28871   [1.791 sec/step, loss=0.61846, avg_loss=0.61723]\n","Step 28872   [1.791 sec/step, loss=0.63451, avg_loss=0.61730]\n","Step 28873   [1.787 sec/step, loss=0.62892, avg_loss=0.61717]\n","Step 28874   [1.789 sec/step, loss=0.63571, avg_loss=0.61725]\n","Step 28875   [1.794 sec/step, loss=0.62698, avg_loss=0.61748]\n","Step 28876   [1.788 sec/step, loss=0.63418, avg_loss=0.61773]\n","Step 28877   [1.794 sec/step, loss=0.60896, avg_loss=0.61761]\n","Step 28878   [1.792 sec/step, loss=0.60928, avg_loss=0.61732]\n","Step 28879   [1.799 sec/step, loss=0.61677, avg_loss=0.61742]\n","Step 28880   [1.792 sec/step, loss=0.60750, avg_loss=0.61739]\n","Step 28881   [1.798 sec/step, loss=0.63385, avg_loss=0.61746]\n","Step 28882   [1.814 sec/step, loss=0.64362, avg_loss=0.61778]\n","Step 28883   [1.833 sec/step, loss=0.61511, avg_loss=0.61764]\n","Step 28884   [1.833 sec/step, loss=0.62400, avg_loss=0.61760]\n","Step 28885   [1.833 sec/step, loss=0.62858, avg_loss=0.61769]\n","Step 28886   [1.837 sec/step, loss=0.60546, avg_loss=0.61728]\n","Step 28887   [1.824 sec/step, loss=0.64568, avg_loss=0.61766]\n","Generated 32 batches of size 32 in 22.180 sec\n","Step 28888   [1.835 sec/step, loss=0.63383, avg_loss=0.61783]\n","Step 28889   [1.823 sec/step, loss=0.62560, avg_loss=0.61778]\n","Step 28890   [1.818 sec/step, loss=0.60379, avg_loss=0.61766]\n","Step 28891   [1.810 sec/step, loss=0.62675, avg_loss=0.61768]\n","Step 28892   [1.806 sec/step, loss=0.63115, avg_loss=0.61787]\n","Step 28893   [1.792 sec/step, loss=0.63572, avg_loss=0.61808]\n","Step 28894   [1.794 sec/step, loss=0.63432, avg_loss=0.61817]\n","Step 28895   [1.775 sec/step, loss=0.62560, avg_loss=0.61854]\n","Step 28896   [1.774 sec/step, loss=0.62287, avg_loss=0.61843]\n","Step 28897   [1.786 sec/step, loss=0.62935, avg_loss=0.61857]\n","Step 28898   [1.788 sec/step, loss=0.61010, avg_loss=0.61866]\n","Step 28899   [1.790 sec/step, loss=0.61246, avg_loss=0.61842]\n","Step 28900   [1.786 sec/step, loss=0.61794, avg_loss=0.61831]\n","Writing summary at step: 28900\n","Step 28901   [1.783 sec/step, loss=0.61574, avg_loss=0.61811]\n","Step 28902   [1.794 sec/step, loss=0.60903, avg_loss=0.61798]\n","Step 28903   [1.792 sec/step, loss=0.63195, avg_loss=0.61795]\n","Step 28904   [1.800 sec/step, loss=0.62069, avg_loss=0.61779]\n","Step 28905   [1.795 sec/step, loss=0.64053, avg_loss=0.61806]\n","Step 28906   [1.789 sec/step, loss=0.62433, avg_loss=0.61813]\n","Step 28907   [1.788 sec/step, loss=0.61261, avg_loss=0.61818]\n","Step 28908   [1.794 sec/step, loss=0.62841, avg_loss=0.61829]\n","Step 28909   [1.791 sec/step, loss=0.61218, avg_loss=0.61813]\n","Step 28910   [1.795 sec/step, loss=0.61004, avg_loss=0.61801]\n","Step 28911   [1.799 sec/step, loss=0.62478, avg_loss=0.61788]\n","Step 28912   [1.812 sec/step, loss=0.62027, avg_loss=0.61787]\n","Step 28913   [1.819 sec/step, loss=0.63032, avg_loss=0.61783]\n","Step 28914   [1.825 sec/step, loss=0.60509, avg_loss=0.61765]\n","Step 28915   [1.820 sec/step, loss=0.60965, avg_loss=0.61748]\n","Step 28916   [1.825 sec/step, loss=0.63220, avg_loss=0.61768]\n","Generated 32 batches of size 32 in 22.357 sec\n","Step 28917   [1.902 sec/step, loss=0.38236, avg_loss=0.61538]\n","Step 28918   [1.903 sec/step, loss=0.64726, avg_loss=0.61570]\n","Step 28919   [1.900 sec/step, loss=0.61995, avg_loss=0.61563]\n","Step 28920   [1.892 sec/step, loss=0.62899, avg_loss=0.61564]\n","Step 28921   [1.885 sec/step, loss=0.63270, avg_loss=0.61576]\n","Step 28922   [1.871 sec/step, loss=0.59790, avg_loss=0.61541]\n","Step 28923   [1.849 sec/step, loss=0.61973, avg_loss=0.61537]\n","Step 28924   [1.824 sec/step, loss=0.62739, avg_loss=0.61530]\n","Step 28925   [1.824 sec/step, loss=0.62307, avg_loss=0.61530]\n","Step 28926   [1.857 sec/step, loss=0.48785, avg_loss=0.61402]\n","Step 28927   [1.852 sec/step, loss=0.61213, avg_loss=0.61380]\n","Step 28928   [1.861 sec/step, loss=0.60900, avg_loss=0.61388]\n","Step 28929   [1.861 sec/step, loss=0.62206, avg_loss=0.61398]\n","Step 28930   [1.861 sec/step, loss=0.61973, avg_loss=0.61386]\n","Step 28931   [1.861 sec/step, loss=0.62626, avg_loss=0.61402]\n","Step 28932   [1.867 sec/step, loss=0.61792, avg_loss=0.61416]\n","Step 28933   [1.854 sec/step, loss=0.61677, avg_loss=0.61453]\n","Step 28934   [1.850 sec/step, loss=0.61951, avg_loss=0.61442]\n","Step 28935   [1.851 sec/step, loss=0.61796, avg_loss=0.61443]\n","Step 28936   [1.845 sec/step, loss=0.64031, avg_loss=0.61480]\n","Step 28937   [1.849 sec/step, loss=0.62735, avg_loss=0.61508]\n","Step 28938   [1.857 sec/step, loss=0.62658, avg_loss=0.61514]\n","Step 28939   [1.860 sec/step, loss=0.63373, avg_loss=0.61520]\n","Step 28940   [1.859 sec/step, loss=0.59622, avg_loss=0.61499]\n","Step 28941   [1.848 sec/step, loss=0.62642, avg_loss=0.61523]\n","Step 28942   [1.860 sec/step, loss=0.62236, avg_loss=0.61528]\n","Step 28943   [1.867 sec/step, loss=0.63411, avg_loss=0.61533]\n","Step 28944   [1.897 sec/step, loss=0.57462, avg_loss=0.61499]\n","Step 28945   [1.917 sec/step, loss=0.61489, avg_loss=0.61494]\n","Step 28946   [1.924 sec/step, loss=0.60961, avg_loss=0.61497]\n","Step 28947   [1.925 sec/step, loss=0.62808, avg_loss=0.61492]\n","Step 28948   [1.926 sec/step, loss=0.61042, avg_loss=0.61475]\n","Step 28949   [1.917 sec/step, loss=0.62506, avg_loss=0.61484]\n","Generated 32 batches of size 32 in 22.307 sec\n","Step 28950   [1.865 sec/step, loss=0.61316, avg_loss=0.61594]\n","Step 28951   [1.852 sec/step, loss=0.63045, avg_loss=0.61590]\n","Step 28952   [1.858 sec/step, loss=0.59200, avg_loss=0.61555]\n","Step 28953   [1.863 sec/step, loss=0.61630, avg_loss=0.61547]\n","Step 28954   [1.849 sec/step, loss=0.62547, avg_loss=0.61564]\n","Step 28955   [1.854 sec/step, loss=0.62305, avg_loss=0.61575]\n","Step 28956   [1.820 sec/step, loss=0.62868, avg_loss=0.61700]\n","Step 28957   [1.818 sec/step, loss=0.62404, avg_loss=0.61698]\n","Step 28958   [1.824 sec/step, loss=0.62547, avg_loss=0.61714]\n","Step 28959   [1.826 sec/step, loss=0.62246, avg_loss=0.61737]\n","Step 28960   [1.822 sec/step, loss=0.62500, avg_loss=0.61749]\n","Step 28961   [1.816 sec/step, loss=0.62142, avg_loss=0.61751]\n","Step 28962   [1.821 sec/step, loss=0.62608, avg_loss=0.61753]\n","Step 28963   [1.824 sec/step, loss=0.62347, avg_loss=0.61755]\n","Step 28964   [1.829 sec/step, loss=0.60729, avg_loss=0.61728]\n","Step 28965   [1.829 sec/step, loss=0.61826, avg_loss=0.61732]\n","Step 28966   [1.830 sec/step, loss=0.61371, avg_loss=0.61722]\n","Step 28967   [1.831 sec/step, loss=0.61138, avg_loss=0.61723]\n","Step 28968   [1.825 sec/step, loss=0.62723, avg_loss=0.61733]\n","Step 28969   [1.822 sec/step, loss=0.60002, avg_loss=0.61711]\n","Step 28970   [1.811 sec/step, loss=0.63033, avg_loss=0.61758]\n","Step 28971   [1.801 sec/step, loss=0.62472, avg_loss=0.61765]\n","Step 28972   [1.796 sec/step, loss=0.61331, avg_loss=0.61743]\n","Step 28973   [1.794 sec/step, loss=0.61420, avg_loss=0.61729]\n","Step 28974   [1.797 sec/step, loss=0.63348, avg_loss=0.61727]\n","Step 28975   [1.798 sec/step, loss=0.60731, avg_loss=0.61707]\n","Step 28976   [1.807 sec/step, loss=0.63826, avg_loss=0.61711]\n","Step 28977   [1.820 sec/step, loss=0.59819, avg_loss=0.61700]\n","Step 28978   [1.828 sec/step, loss=0.62075, avg_loss=0.61712]\n","Step 28979   [1.827 sec/step, loss=0.61906, avg_loss=0.61714]\n","Step 28980   [1.832 sec/step, loss=0.63441, avg_loss=0.61741]\n","Step 28981   [1.843 sec/step, loss=0.63738, avg_loss=0.61744]\n","Generated 32 batches of size 32 in 23.065 sec\n","Step 28982   [1.891 sec/step, loss=0.44953, avg_loss=0.61550]\n","Step 28983   [1.871 sec/step, loss=0.62982, avg_loss=0.61565]\n","Step 28984   [1.869 sec/step, loss=0.62147, avg_loss=0.61562]\n","Step 28985   [1.859 sec/step, loss=0.62736, avg_loss=0.61561]\n","Step 28986   [1.848 sec/step, loss=0.61984, avg_loss=0.61576]\n","Step 28987   [1.850 sec/step, loss=0.61450, avg_loss=0.61544]\n","Step 28988   [1.819 sec/step, loss=0.62288, avg_loss=0.61533]\n","Step 28989   [1.818 sec/step, loss=0.62514, avg_loss=0.61533]\n","Step 28990   [1.827 sec/step, loss=0.62268, avg_loss=0.61552]\n","Step 28991   [1.831 sec/step, loss=0.62813, avg_loss=0.61553]\n","Step 28992   [1.822 sec/step, loss=0.62174, avg_loss=0.61544]\n","Step 28993   [1.815 sec/step, loss=0.60679, avg_loss=0.61515]\n","Step 28994   [1.815 sec/step, loss=0.60934, avg_loss=0.61490]\n","Step 28995   [1.818 sec/step, loss=0.62473, avg_loss=0.61489]\n","Step 28996   [1.820 sec/step, loss=0.63144, avg_loss=0.61498]\n","Step 28997   [1.816 sec/step, loss=0.60956, avg_loss=0.61478]\n","Step 28998   [1.816 sec/step, loss=0.62824, avg_loss=0.61496]\n","Step 28999   [1.813 sec/step, loss=0.62044, avg_loss=0.61504]\n","Step 29000   [1.812 sec/step, loss=0.61346, avg_loss=0.61500]\n","Writing summary at step: 29000\n","Saving checkpoint to: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/model.ckpt-29000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (76500,)\n","Check wav file:  (106500,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000029000-align000.png\n","100% 1/1 [00:03<00:00,  3.37s/it]\n","Test finished for step 29000.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (68100,)\n","Check wav file:  (98100,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000029000-align000.png\n"," 25% 1/4 [00:04<00:12,  4.17s/it]Check wav file before change:  (68100,)\n","Check wav file:  (98100,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000029000-align001.png\n"," 50% 2/4 [00:07<00:07,  3.82s/it]Check wav file before change:  (68100,)\n","Check wav file:  (98100,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000029000-align002.png\n"," 75% 3/4 [00:10<00:03,  3.55s/it]Check wav file before change:  (68100,)\n","Check wav file:  (98100,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000029000-align003.png\n","100% 4/4 [00:12<00:00,  3.24s/it]\n","Test finished for step 29000.\n","Step 29001   [1.816 sec/step, loss=0.62218, avg_loss=0.61506]\n","Step 29002   [1.802 sec/step, loss=0.62517, avg_loss=0.61522]\n","Step 29003   [1.811 sec/step, loss=0.60491, avg_loss=0.61495]\n","Step 29004   [1.809 sec/step, loss=0.63058, avg_loss=0.61505]\n","Step 29005   [1.838 sec/step, loss=0.59566, avg_loss=0.61460]\n","Step 29006   [1.896 sec/step, loss=0.51205, avg_loss=0.61348]\n","Step 29007   [1.904 sec/step, loss=0.61402, avg_loss=0.61349]\n","Step 29008   [1.907 sec/step, loss=0.62996, avg_loss=0.61351]\n","Step 29009   [1.912 sec/step, loss=0.63726, avg_loss=0.61376]\n","Step 29010   [1.918 sec/step, loss=0.63277, avg_loss=0.61399]\n","Generated 32 batches of size 32 in 22.672 sec\n","Step 29011   [1.928 sec/step, loss=0.62919, avg_loss=0.61403]\n","Step 29012   [1.916 sec/step, loss=0.62573, avg_loss=0.61408]\n","Step 29013   [1.908 sec/step, loss=0.60746, avg_loss=0.61386]\n","Step 29014   [1.900 sec/step, loss=0.62718, avg_loss=0.61408]\n","Step 29015   [1.896 sec/step, loss=0.60179, avg_loss=0.61400]\n","Step 29016   [1.894 sec/step, loss=0.61095, avg_loss=0.61379]\n","Step 29017   [1.816 sec/step, loss=0.63413, avg_loss=0.61630]\n","Step 29018   [1.822 sec/step, loss=0.60029, avg_loss=0.61583]\n","Step 29019   [1.819 sec/step, loss=0.62631, avg_loss=0.61590]\n","Step 29020   [1.819 sec/step, loss=0.62577, avg_loss=0.61587]\n","Step 29021   [1.806 sec/step, loss=0.61034, avg_loss=0.61564]\n","Step 29022   [1.807 sec/step, loss=0.63309, avg_loss=0.61599]\n","Step 29023   [1.800 sec/step, loss=0.60038, avg_loss=0.61580]\n","Step 29024   [1.799 sec/step, loss=0.62566, avg_loss=0.61578]\n","Step 29025   [1.803 sec/step, loss=0.62094, avg_loss=0.61576]\n","Step 29026   [1.779 sec/step, loss=0.61599, avg_loss=0.61704]\n","Step 29027   [1.786 sec/step, loss=0.61753, avg_loss=0.61710]\n","Step 29028   [1.771 sec/step, loss=0.62245, avg_loss=0.61723]\n","Step 29029   [1.778 sec/step, loss=0.62592, avg_loss=0.61727]\n","Step 29030   [1.820 sec/step, loss=0.45725, avg_loss=0.61565]\n","Step 29031   [1.825 sec/step, loss=0.62705, avg_loss=0.61565]\n","Step 29032   [1.821 sec/step, loss=0.63829, avg_loss=0.61586]\n","Step 29033   [1.820 sec/step, loss=0.63159, avg_loss=0.61600]\n","Step 29034   [1.821 sec/step, loss=0.61740, avg_loss=0.61598]\n","Step 29035   [1.818 sec/step, loss=0.61754, avg_loss=0.61598]\n","Step 29036   [1.822 sec/step, loss=0.63824, avg_loss=0.61596]\n","Step 29037   [1.822 sec/step, loss=0.62504, avg_loss=0.61594]\n","Step 29038   [1.825 sec/step, loss=0.62846, avg_loss=0.61595]\n","Step 29039   [1.830 sec/step, loss=0.61101, avg_loss=0.61573]\n","Step 29040   [1.842 sec/step, loss=0.63315, avg_loss=0.61610]\n","Step 29041   [1.852 sec/step, loss=0.62123, avg_loss=0.61604]\n","Step 29042   [1.853 sec/step, loss=0.62075, avg_loss=0.61603]\n","Step 29043   [1.875 sec/step, loss=0.58830, avg_loss=0.61557]\n","Step 29044   [1.858 sec/step, loss=0.61856, avg_loss=0.61601]\n","Generated 32 batches of size 32 in 22.558 sec\n","Step 29045   [1.852 sec/step, loss=0.63161, avg_loss=0.61618]\n","Step 29046   [1.853 sec/step, loss=0.62621, avg_loss=0.61634]\n","Step 29047   [1.848 sec/step, loss=0.62230, avg_loss=0.61629]\n","Step 29048   [1.828 sec/step, loss=0.61477, avg_loss=0.61633]\n","Step 29049   [1.824 sec/step, loss=0.61619, avg_loss=0.61624]\n","Step 29050   [1.815 sec/step, loss=0.61166, avg_loss=0.61623]\n","Step 29051   [1.820 sec/step, loss=0.62245, avg_loss=0.61615]\n","Step 29052   [1.801 sec/step, loss=0.61952, avg_loss=0.61642]\n","Step 29053   [1.791 sec/step, loss=0.63136, avg_loss=0.61657]\n","Step 29054   [1.789 sec/step, loss=0.61689, avg_loss=0.61649]\n","Step 29055   [1.788 sec/step, loss=0.61777, avg_loss=0.61643]\n","Step 29056   [1.786 sec/step, loss=0.61634, avg_loss=0.61631]\n","Step 29057   [1.786 sec/step, loss=0.62874, avg_loss=0.61636]\n","Step 29058   [1.783 sec/step, loss=0.63083, avg_loss=0.61641]\n","Step 29059   [1.798 sec/step, loss=0.59073, avg_loss=0.61609]\n","Step 29060   [1.799 sec/step, loss=0.61738, avg_loss=0.61602]\n","Step 29061   [1.843 sec/step, loss=0.40970, avg_loss=0.61390]\n","Step 29062   [1.838 sec/step, loss=0.63066, avg_loss=0.61394]\n","Step 29063   [1.841 sec/step, loss=0.63136, avg_loss=0.61402]\n","Step 29064   [1.840 sec/step, loss=0.62473, avg_loss=0.61420]\n","Step 29065   [1.843 sec/step, loss=0.61633, avg_loss=0.61418]\n","Step 29066   [1.849 sec/step, loss=0.63414, avg_loss=0.61438]\n","Step 29067   [1.854 sec/step, loss=0.63356, avg_loss=0.61460]\n","Step 29068   [1.858 sec/step, loss=0.62954, avg_loss=0.61463]\n","Step 29069   [1.882 sec/step, loss=0.62966, avg_loss=0.61492]\n","Step 29070   [1.879 sec/step, loss=0.59027, avg_loss=0.61452]\n","Step 29071   [1.880 sec/step, loss=0.61969, avg_loss=0.61447]\n","Step 29072   [1.886 sec/step, loss=0.61637, avg_loss=0.61450]\n","Step 29073   [1.897 sec/step, loss=0.62110, avg_loss=0.61457]\n","Step 29074   [1.908 sec/step, loss=0.62497, avg_loss=0.61449]\n","Step 29075   [1.911 sec/step, loss=0.62966, avg_loss=0.61471]\n","Step 29076   [1.910 sec/step, loss=0.62248, avg_loss=0.61455]\n","Generated 32 batches of size 32 in 21.740 sec\n","Step 29077   [1.931 sec/step, loss=0.62425, avg_loss=0.61481]\n","Step 29078   [1.921 sec/step, loss=0.60049, avg_loss=0.61461]\n","Step 29079   [1.918 sec/step, loss=0.60663, avg_loss=0.61449]\n","Step 29080   [1.941 sec/step, loss=0.53971, avg_loss=0.61354]\n","Step 29081   [1.932 sec/step, loss=0.62377, avg_loss=0.61340]\n","Step 29082   [1.869 sec/step, loss=0.60988, avg_loss=0.61501]\n","Step 29083   [1.871 sec/step, loss=0.62651, avg_loss=0.61497]\n","Step 29084   [1.870 sec/step, loss=0.62546, avg_loss=0.61501]\n","Step 29085   [1.871 sec/step, loss=0.62147, avg_loss=0.61496]\n","Step 29086   [1.864 sec/step, loss=0.60894, avg_loss=0.61485]\n","Step 29087   [1.853 sec/step, loss=0.62309, avg_loss=0.61493]\n","Step 29088   [1.856 sec/step, loss=0.64081, avg_loss=0.61511]\n","Step 29089   [1.854 sec/step, loss=0.61834, avg_loss=0.61504]\n","Step 29090   [1.865 sec/step, loss=0.59523, avg_loss=0.61477]\n","Step 29091   [1.869 sec/step, loss=0.63597, avg_loss=0.61485]\n","Step 29092   [1.869 sec/step, loss=0.62799, avg_loss=0.61491]\n","Step 29093   [1.872 sec/step, loss=0.61265, avg_loss=0.61497]\n","Step 29094   [1.873 sec/step, loss=0.62443, avg_loss=0.61512]\n","Step 29095   [1.879 sec/step, loss=0.60598, avg_loss=0.61493]\n","Step 29096   [1.892 sec/step, loss=0.62452, avg_loss=0.61486]\n","Step 29097   [1.884 sec/step, loss=0.60684, avg_loss=0.61484]\n","Step 29098   [1.889 sec/step, loss=0.62008, avg_loss=0.61475]\n","Step 29099   [1.888 sec/step, loss=0.61047, avg_loss=0.61465]\n","Step 29100   [1.898 sec/step, loss=0.63803, avg_loss=0.61490]\n","Writing summary at step: 29100\n","Step 29101   [1.899 sec/step, loss=0.60675, avg_loss=0.61475]\n","Step 29102   [1.906 sec/step, loss=0.61473, avg_loss=0.61464]\n","Step 29103   [1.903 sec/step, loss=0.63147, avg_loss=0.61491]\n","Step 29104   [1.906 sec/step, loss=0.63308, avg_loss=0.61493]\n","Step 29105   [1.882 sec/step, loss=0.61390, avg_loss=0.61511]\n","Step 29106   [1.828 sec/step, loss=0.63321, avg_loss=0.61633]\n","Step 29107   [1.841 sec/step, loss=0.62735, avg_loss=0.61646]\n","Generated 32 batches of size 32 in 21.871 sec\n","Step 29108   [1.865 sec/step, loss=0.62457, avg_loss=0.61641]\n","Step 29109   [1.854 sec/step, loss=0.61360, avg_loss=0.61617]\n","Step 29110   [1.846 sec/step, loss=0.63774, avg_loss=0.61622]\n","Step 29111   [1.837 sec/step, loss=0.62421, avg_loss=0.61617]\n","Step 29112   [1.834 sec/step, loss=0.61906, avg_loss=0.61610]\n","Step 29113   [1.841 sec/step, loss=0.62893, avg_loss=0.61632]\n","Step 29114   [1.841 sec/step, loss=0.62841, avg_loss=0.61633]\n","Step 29115   [1.842 sec/step, loss=0.61374, avg_loss=0.61645]\n","Step 29116   [1.844 sec/step, loss=0.61715, avg_loss=0.61651]\n","Step 29117   [1.848 sec/step, loss=0.62505, avg_loss=0.61642]\n","Step 29118   [1.837 sec/step, loss=0.61311, avg_loss=0.61655]\n","Step 29119   [1.841 sec/step, loss=0.62381, avg_loss=0.61652]\n","Step 29120   [1.842 sec/step, loss=0.62575, avg_loss=0.61652]\n","Step 29121   [1.846 sec/step, loss=0.63878, avg_loss=0.61681]\n","Step 29122   [1.889 sec/step, loss=0.43356, avg_loss=0.61481]\n","Step 29123   [1.890 sec/step, loss=0.60689, avg_loss=0.61488]\n","Step 29124   [1.893 sec/step, loss=0.62681, avg_loss=0.61489]\n","Step 29125   [1.890 sec/step, loss=0.62252, avg_loss=0.61490]\n","Step 29126   [1.876 sec/step, loss=0.61628, avg_loss=0.61491]\n","Step 29127   [1.887 sec/step, loss=0.57816, avg_loss=0.61451]\n","Step 29128   [1.893 sec/step, loss=0.64068, avg_loss=0.61470]\n","Step 29129   [1.887 sec/step, loss=0.62908, avg_loss=0.61473]\n","Step 29130   [1.850 sec/step, loss=0.61920, avg_loss=0.61635]\n","Step 29131   [1.855 sec/step, loss=0.63320, avg_loss=0.61641]\n","Step 29132   [1.857 sec/step, loss=0.61267, avg_loss=0.61615]\n","Step 29133   [1.861 sec/step, loss=0.62826, avg_loss=0.61612]\n","Step 29134   [1.879 sec/step, loss=0.61846, avg_loss=0.61613]\n","Step 29135   [1.888 sec/step, loss=0.61479, avg_loss=0.61610]\n","Step 29136   [1.887 sec/step, loss=0.60102, avg_loss=0.61573]\n","Step 29137   [1.889 sec/step, loss=0.63079, avg_loss=0.61579]\n","Step 29138   [1.884 sec/step, loss=0.62374, avg_loss=0.61574]\n","Step 29139   [1.891 sec/step, loss=0.62659, avg_loss=0.61590]\n","Generated 32 batches of size 32 in 22.366 sec\n","Step 29140   [1.931 sec/step, loss=0.63213, avg_loss=0.61589]\n","Step 29141   [1.923 sec/step, loss=0.62986, avg_loss=0.61597]\n","Step 29142   [1.942 sec/step, loss=0.45411, avg_loss=0.61431]\n","Step 29143   [1.910 sec/step, loss=0.62450, avg_loss=0.61467]\n","Step 29144   [1.898 sec/step, loss=0.62490, avg_loss=0.61473]\n","Step 29145   [1.889 sec/step, loss=0.63575, avg_loss=0.61477]\n","Step 29146   [1.891 sec/step, loss=0.61273, avg_loss=0.61464]\n","Step 29147   [1.894 sec/step, loss=0.62540, avg_loss=0.61467]\n","Step 29148   [1.899 sec/step, loss=0.61831, avg_loss=0.61470]\n","Step 29149   [1.899 sec/step, loss=0.60812, avg_loss=0.61462]\n","Step 29150   [1.902 sec/step, loss=0.62045, avg_loss=0.61471]\n","Step 29151   [1.890 sec/step, loss=0.60423, avg_loss=0.61453]\n","Step 29152   [1.890 sec/step, loss=0.61657, avg_loss=0.61450]\n","Step 29153   [1.888 sec/step, loss=0.63030, avg_loss=0.61449]\n","Step 29154   [1.885 sec/step, loss=0.61241, avg_loss=0.61444]\n","Step 29155   [1.884 sec/step, loss=0.62148, avg_loss=0.61448]\n","Step 29156   [1.886 sec/step, loss=0.62932, avg_loss=0.61461]\n","Step 29157   [1.886 sec/step, loss=0.62795, avg_loss=0.61460]\n","Step 29158   [1.883 sec/step, loss=0.63257, avg_loss=0.61462]\n","Step 29159   [1.879 sec/step, loss=0.60826, avg_loss=0.61480]\n","Step 29160   [1.879 sec/step, loss=0.61426, avg_loss=0.61476]\n","Step 29161   [1.845 sec/step, loss=0.61248, avg_loss=0.61679]\n","Step 29162   [1.844 sec/step, loss=0.61261, avg_loss=0.61661]\n","Step 29163   [1.851 sec/step, loss=0.63354, avg_loss=0.61663]\n","Step 29164   [1.861 sec/step, loss=0.62349, avg_loss=0.61662]\n","Step 29165   [1.866 sec/step, loss=0.62519, avg_loss=0.61671]\n","Step 29166   [1.866 sec/step, loss=0.63134, avg_loss=0.61668]\n","Step 29167   [1.891 sec/step, loss=0.59716, avg_loss=0.61632]\n","Step 29168   [1.885 sec/step, loss=0.61154, avg_loss=0.61614]\n","Step 29169   [1.880 sec/step, loss=0.61673, avg_loss=0.61601]\n","Step 29170   [1.882 sec/step, loss=0.60384, avg_loss=0.61614]\n","Step 29171   [1.895 sec/step, loss=0.62430, avg_loss=0.61619]\n","Generated 32 batches of size 32 in 23.257 sec\n","Step 29172   [1.913 sec/step, loss=0.61934, avg_loss=0.61622]\n","Step 29173   [1.904 sec/step, loss=0.62735, avg_loss=0.61628]\n","Step 29174   [1.885 sec/step, loss=0.61749, avg_loss=0.61621]\n","Step 29175   [1.881 sec/step, loss=0.62929, avg_loss=0.61620]\n","Step 29176   [1.879 sec/step, loss=0.61790, avg_loss=0.61616]\n","Step 29177   [1.848 sec/step, loss=0.61198, avg_loss=0.61604]\n","Step 29178   [1.850 sec/step, loss=0.60379, avg_loss=0.61607]\n","Step 29179   [1.850 sec/step, loss=0.62601, avg_loss=0.61626]\n","Step 29180   [1.821 sec/step, loss=0.62909, avg_loss=0.61716]\n","Step 29181   [1.814 sec/step, loss=0.60144, avg_loss=0.61693]\n","Step 29182   [1.819 sec/step, loss=0.61582, avg_loss=0.61699]\n","Step 29183   [1.823 sec/step, loss=0.63070, avg_loss=0.61703]\n","Step 29184   [1.834 sec/step, loss=0.59343, avg_loss=0.61671]\n","Step 29185   [1.827 sec/step, loss=0.60839, avg_loss=0.61658]\n","Step 29186   [1.836 sec/step, loss=0.61881, avg_loss=0.61668]\n","Step 29187   [1.835 sec/step, loss=0.63035, avg_loss=0.61675]\n","Step 29188   [1.842 sec/step, loss=0.61137, avg_loss=0.61646]\n","Step 29189   [1.842 sec/step, loss=0.61089, avg_loss=0.61639]\n","Step 29190   [1.820 sec/step, loss=0.60499, avg_loss=0.61648]\n","Step 29191   [1.815 sec/step, loss=0.62892, avg_loss=0.61641]\n","Step 29192   [1.815 sec/step, loss=0.63077, avg_loss=0.61644]\n","Step 29193   [1.821 sec/step, loss=0.63675, avg_loss=0.61668]\n","Step 29194   [1.818 sec/step, loss=0.61694, avg_loss=0.61661]\n","Step 29195   [1.817 sec/step, loss=0.62849, avg_loss=0.61683]\n","Step 29196   [1.812 sec/step, loss=0.63221, avg_loss=0.61691]\n","Step 29197   [1.819 sec/step, loss=0.61629, avg_loss=0.61700]\n","Step 29198   [1.822 sec/step, loss=0.60511, avg_loss=0.61685]\n","Step 29199   [1.835 sec/step, loss=0.61570, avg_loss=0.61691]\n","Step 29200   [1.847 sec/step, loss=0.61807, avg_loss=0.61671]\n","Writing summary at step: 29200\n","Step 29201   [1.903 sec/step, loss=0.44456, avg_loss=0.61508]\n","Generated 32 batches of size 32 in 23.053 sec\n","Step 29202   [1.901 sec/step, loss=0.61800, avg_loss=0.61512]\n","Step 29203   [1.895 sec/step, loss=0.62045, avg_loss=0.61501]\n","Step 29204   [1.887 sec/step, loss=0.61992, avg_loss=0.61487]\n","Step 29205   [1.878 sec/step, loss=0.60800, avg_loss=0.61482]\n","Step 29206   [1.873 sec/step, loss=0.61916, avg_loss=0.61468]\n","Step 29207   [1.856 sec/step, loss=0.62020, avg_loss=0.61460]\n","Step 29208   [1.825 sec/step, loss=0.62854, avg_loss=0.61464]\n","Step 29209   [1.834 sec/step, loss=0.61974, avg_loss=0.61470]\n","Step 29210   [1.832 sec/step, loss=0.61368, avg_loss=0.61446]\n","Step 29211   [1.827 sec/step, loss=0.63683, avg_loss=0.61459]\n","Step 29212   [1.825 sec/step, loss=0.62657, avg_loss=0.61467]\n","Step 29213   [1.827 sec/step, loss=0.62175, avg_loss=0.61459]\n","Step 29214   [1.837 sec/step, loss=0.62096, avg_loss=0.61452]\n","Step 29215   [1.842 sec/step, loss=0.61513, avg_loss=0.61453]\n","Step 29216   [1.834 sec/step, loss=0.62585, avg_loss=0.61462]\n","Step 29217   [1.828 sec/step, loss=0.63342, avg_loss=0.61470]\n","Step 29218   [1.832 sec/step, loss=0.62418, avg_loss=0.61481]\n","Step 29219   [1.825 sec/step, loss=0.61767, avg_loss=0.61475]\n","Step 29220   [1.823 sec/step, loss=0.61442, avg_loss=0.61464]\n","Step 29221   [1.826 sec/step, loss=0.62328, avg_loss=0.61448]\n","Step 29222   [1.779 sec/step, loss=0.58085, avg_loss=0.61596]\n","Step 29223   [1.782 sec/step, loss=0.61693, avg_loss=0.61606]\n","Step 29224   [1.775 sec/step, loss=0.60645, avg_loss=0.61585]\n","Step 29225   [1.794 sec/step, loss=0.59845, avg_loss=0.61561]\n","Step 29226   [1.817 sec/step, loss=0.61935, avg_loss=0.61564]\n","Step 29227   [1.806 sec/step, loss=0.63063, avg_loss=0.61617]\n","Step 29228   [1.804 sec/step, loss=0.60501, avg_loss=0.61581]\n","Step 29229   [1.816 sec/step, loss=0.62739, avg_loss=0.61580]\n","Step 29230   [1.829 sec/step, loss=0.62216, avg_loss=0.61583]\n","Step 29231   [1.826 sec/step, loss=0.62673, avg_loss=0.61576]\n","Step 29232   [1.834 sec/step, loss=0.62631, avg_loss=0.61590]\n","Step 29233   [1.888 sec/step, loss=0.51764, avg_loss=0.61479]\n","Generated 32 batches of size 32 in 23.026 sec\n","Step 29234   [1.874 sec/step, loss=0.61149, avg_loss=0.61472]\n","Step 29235   [1.863 sec/step, loss=0.61292, avg_loss=0.61470]\n","Step 29236   [1.863 sec/step, loss=0.62188, avg_loss=0.61491]\n","Step 29237   [1.858 sec/step, loss=0.61973, avg_loss=0.61480]\n","Step 29238   [1.887 sec/step, loss=0.45718, avg_loss=0.61313]\n","Step 29239   [1.871 sec/step, loss=0.61763, avg_loss=0.61305]\n","Step 29240   [1.819 sec/step, loss=0.60317, avg_loss=0.61276]\n","Step 29241   [1.827 sec/step, loss=0.63071, avg_loss=0.61276]\n","Step 29242   [1.787 sec/step, loss=0.60368, avg_loss=0.61426]\n","Step 29243   [1.789 sec/step, loss=0.63173, avg_loss=0.61433]\n","Step 29244   [1.786 sec/step, loss=0.62796, avg_loss=0.61436]\n","Step 29245   [1.781 sec/step, loss=0.61810, avg_loss=0.61419]\n","Step 29246   [1.778 sec/step, loss=0.61150, avg_loss=0.61417]\n","Step 29247   [1.779 sec/step, loss=0.63020, avg_loss=0.61422]\n","Step 29248   [1.780 sec/step, loss=0.61281, avg_loss=0.61417]\n","Step 29249   [1.778 sec/step, loss=0.60500, avg_loss=0.61414]\n","Step 29250   [1.775 sec/step, loss=0.61462, avg_loss=0.61408]\n","Step 29251   [1.779 sec/step, loss=0.62902, avg_loss=0.61433]\n","Step 29252   [1.782 sec/step, loss=0.61659, avg_loss=0.61433]\n","Step 29253   [1.784 sec/step, loss=0.62474, avg_loss=0.61427]\n","Step 29254   [1.788 sec/step, loss=0.62748, avg_loss=0.61442]\n","Step 29255   [1.788 sec/step, loss=0.63029, avg_loss=0.61451]\n","Step 29256   [1.787 sec/step, loss=0.62901, avg_loss=0.61451]\n","Step 29257   [1.791 sec/step, loss=0.62422, avg_loss=0.61447]\n","Step 29258   [1.802 sec/step, loss=0.62855, avg_loss=0.61443]\n","Step 29259   [1.809 sec/step, loss=0.62124, avg_loss=0.61456]\n","Step 29260   [1.828 sec/step, loss=0.63249, avg_loss=0.61474]\n","Step 29261   [1.833 sec/step, loss=0.62300, avg_loss=0.61485]\n","Step 29262   [1.865 sec/step, loss=0.57682, avg_loss=0.61449]\n","Step 29263   [1.861 sec/step, loss=0.61252, avg_loss=0.61428]\n","Step 29264   [1.850 sec/step, loss=0.61935, avg_loss=0.61424]\n","Step 29265   [1.850 sec/step, loss=0.63036, avg_loss=0.61429]\n","Generated 32 batches of size 32 in 22.499 sec\n","Step 29266   [1.862 sec/step, loss=0.60209, avg_loss=0.61400]\n","Step 29267   [1.833 sec/step, loss=0.63270, avg_loss=0.61435]\n","Step 29268   [1.832 sec/step, loss=0.61637, avg_loss=0.61440]\n","Step 29269   [1.814 sec/step, loss=0.60249, avg_loss=0.61426]\n","Step 29270   [1.818 sec/step, loss=0.61239, avg_loss=0.61434]\n","Step 29271   [1.802 sec/step, loss=0.63726, avg_loss=0.61447]\n","Step 29272   [1.778 sec/step, loss=0.60260, avg_loss=0.61430]\n","Step 29273   [1.776 sec/step, loss=0.62388, avg_loss=0.61427]\n","Step 29274   [1.788 sec/step, loss=0.61866, avg_loss=0.61428]\n","Step 29275   [1.788 sec/step, loss=0.61313, avg_loss=0.61412]\n","Step 29276   [1.785 sec/step, loss=0.63057, avg_loss=0.61425]\n","Step 29277   [1.776 sec/step, loss=0.63297, avg_loss=0.61446]\n","Step 29278   [1.776 sec/step, loss=0.61776, avg_loss=0.61460]\n","Step 29279   [1.770 sec/step, loss=0.61103, avg_loss=0.61445]\n","Step 29280   [1.768 sec/step, loss=0.61483, avg_loss=0.61430]\n","Step 29281   [1.774 sec/step, loss=0.63700, avg_loss=0.61466]\n","Step 29282   [1.767 sec/step, loss=0.62295, avg_loss=0.61473]\n","Step 29283   [1.761 sec/step, loss=0.61097, avg_loss=0.61453]\n","Step 29284   [1.782 sec/step, loss=0.44997, avg_loss=0.61310]\n","Step 29285   [1.791 sec/step, loss=0.61722, avg_loss=0.61319]\n","Step 29286   [1.786 sec/step, loss=0.62581, avg_loss=0.61326]\n","Step 29287   [1.790 sec/step, loss=0.62960, avg_loss=0.61325]\n","Step 29288   [1.787 sec/step, loss=0.60049, avg_loss=0.61314]\n","Step 29289   [1.793 sec/step, loss=0.61271, avg_loss=0.61316]\n","Step 29290   [1.823 sec/step, loss=0.59362, avg_loss=0.61305]\n","Step 29291   [1.838 sec/step, loss=0.63307, avg_loss=0.61309]\n","Step 29292   [1.847 sec/step, loss=0.61574, avg_loss=0.61294]\n","Step 29293   [1.844 sec/step, loss=0.61452, avg_loss=0.61271]\n","Step 29294   [1.855 sec/step, loss=0.61845, avg_loss=0.61273]\n","Step 29295   [1.870 sec/step, loss=0.61287, avg_loss=0.61257]\n","Step 29296   [1.868 sec/step, loss=0.61620, avg_loss=0.61241]\n","Step 29297   [1.866 sec/step, loss=0.60757, avg_loss=0.61233]\n","Step 29298   [1.873 sec/step, loss=0.62662, avg_loss=0.61254]\n","Generated 32 batches of size 32 in 22.543 sec\n","Step 29299   [1.881 sec/step, loss=0.60420, avg_loss=0.61243]\n","Step 29300   [1.863 sec/step, loss=0.61875, avg_loss=0.61243]\n","Writing summary at step: 29300\n","Step 29301   [1.802 sec/step, loss=0.61003, avg_loss=0.61409]\n","Step 29302   [1.796 sec/step, loss=0.62033, avg_loss=0.61411]\n","Step 29303   [1.805 sec/step, loss=0.60772, avg_loss=0.61398]\n","Step 29304   [1.807 sec/step, loss=0.62563, avg_loss=0.61404]\n","Step 29305   [1.807 sec/step, loss=0.61923, avg_loss=0.61415]\n","Step 29306   [1.804 sec/step, loss=0.63385, avg_loss=0.61430]\n","Step 29307   [1.804 sec/step, loss=0.61439, avg_loss=0.61424]\n","Step 29308   [1.804 sec/step, loss=0.60598, avg_loss=0.61402]\n","Step 29309   [1.795 sec/step, loss=0.62596, avg_loss=0.61408]\n","Step 29310   [1.795 sec/step, loss=0.62672, avg_loss=0.61421]\n","Step 29311   [1.790 sec/step, loss=0.61556, avg_loss=0.61400]\n","Step 29312   [1.793 sec/step, loss=0.61093, avg_loss=0.61384]\n","Step 29313   [1.787 sec/step, loss=0.63435, avg_loss=0.61397]\n","Step 29314   [1.780 sec/step, loss=0.63160, avg_loss=0.61407]\n","Step 29315   [1.777 sec/step, loss=0.62286, avg_loss=0.61415]\n","Step 29316   [1.782 sec/step, loss=0.62399, avg_loss=0.61413]\n","Step 29317   [1.782 sec/step, loss=0.62760, avg_loss=0.61407]\n","Step 29318   [1.784 sec/step, loss=0.61916, avg_loss=0.61402]\n","Step 29319   [1.789 sec/step, loss=0.62352, avg_loss=0.61408]\n","Step 29320   [1.789 sec/step, loss=0.60271, avg_loss=0.61396]\n","Step 29321   [1.794 sec/step, loss=0.61465, avg_loss=0.61388]\n","Step 29322   [1.815 sec/step, loss=0.61675, avg_loss=0.61424]\n","Step 29323   [1.816 sec/step, loss=0.58770, avg_loss=0.61394]\n","Step 29324   [1.822 sec/step, loss=0.61419, avg_loss=0.61402]\n","Step 29325   [1.807 sec/step, loss=0.62763, avg_loss=0.61431]\n","Step 29326   [1.793 sec/step, loss=0.59946, avg_loss=0.61411]\n","Step 29327   [1.794 sec/step, loss=0.61754, avg_loss=0.61398]\n","Step 29328   [1.823 sec/step, loss=0.57443, avg_loss=0.61368]\n","Step 29329   [1.828 sec/step, loss=0.62797, avg_loss=0.61368]\n","Generated 32 batches of size 32 in 22.454 sec\n","Step 29330   [1.838 sec/step, loss=0.61159, avg_loss=0.61358]\n","Step 29331   [1.832 sec/step, loss=0.61720, avg_loss=0.61348]\n","Step 29332   [1.819 sec/step, loss=0.61576, avg_loss=0.61338]\n","Step 29333   [1.760 sec/step, loss=0.61616, avg_loss=0.61436]\n","Step 29334   [1.759 sec/step, loss=0.63684, avg_loss=0.61462]\n","Step 29335   [1.764 sec/step, loss=0.63156, avg_loss=0.61480]\n","Step 29336   [1.757 sec/step, loss=0.61055, avg_loss=0.61469]\n","Step 29337   [1.762 sec/step, loss=0.61530, avg_loss=0.61464]\n","Step 29338   [1.726 sec/step, loss=0.62325, avg_loss=0.61630]\n","Step 29339   [1.731 sec/step, loss=0.63238, avg_loss=0.61645]\n","Step 29340   [1.736 sec/step, loss=0.61675, avg_loss=0.61659]\n","Step 29341   [1.727 sec/step, loss=0.63191, avg_loss=0.61660]\n","Step 29342   [1.731 sec/step, loss=0.62196, avg_loss=0.61678]\n","Step 29343   [1.737 sec/step, loss=0.60794, avg_loss=0.61655]\n","Step 29344   [1.741 sec/step, loss=0.61824, avg_loss=0.61645]\n","Step 29345   [1.741 sec/step, loss=0.62447, avg_loss=0.61651]\n","Step 29346   [1.739 sec/step, loss=0.63082, avg_loss=0.61670]\n","Step 29347   [1.739 sec/step, loss=0.62958, avg_loss=0.61670]\n","Step 29348   [1.739 sec/step, loss=0.62470, avg_loss=0.61682]\n","Step 29349   [1.755 sec/step, loss=0.59236, avg_loss=0.61669]\n","Step 29350   [1.755 sec/step, loss=0.61045, avg_loss=0.61665]\n","Step 29351   [1.751 sec/step, loss=0.61477, avg_loss=0.61651]\n","Step 29352   [1.751 sec/step, loss=0.63054, avg_loss=0.61665]\n","Step 29353   [1.768 sec/step, loss=0.63274, avg_loss=0.61673]\n","Step 29354   [1.777 sec/step, loss=0.62855, avg_loss=0.61674]\n","Step 29355   [1.783 sec/step, loss=0.61612, avg_loss=0.61660]\n","Step 29356   [1.806 sec/step, loss=0.62428, avg_loss=0.61655]\n","Step 29357   [1.807 sec/step, loss=0.62135, avg_loss=0.61652]\n","Step 29358   [1.802 sec/step, loss=0.63124, avg_loss=0.61655]\n","Step 29359   [1.858 sec/step, loss=0.40402, avg_loss=0.61437]\n","Generated 32 batches of size 32 in 23.030 sec\n","Step 29360   [1.843 sec/step, loss=0.61166, avg_loss=0.61417]\n","Step 29361   [1.828 sec/step, loss=0.63025, avg_loss=0.61424]\n","Step 29362   [1.798 sec/step, loss=0.63116, avg_loss=0.61478]\n","Step 29363   [1.788 sec/step, loss=0.62237, avg_loss=0.61488]\n","Step 29364   [1.785 sec/step, loss=0.63107, avg_loss=0.61500]\n","Step 29365   [1.776 sec/step, loss=0.61955, avg_loss=0.61489]\n","Step 29366   [1.757 sec/step, loss=0.62443, avg_loss=0.61511]\n","Step 29367   [1.761 sec/step, loss=0.61384, avg_loss=0.61492]\n","Step 29368   [1.765 sec/step, loss=0.63690, avg_loss=0.61513]\n","Step 29369   [1.772 sec/step, loss=0.61782, avg_loss=0.61528]\n","Step 29370   [1.764 sec/step, loss=0.62711, avg_loss=0.61543]\n","Step 29371   [1.766 sec/step, loss=0.63568, avg_loss=0.61541]\n","Step 29372   [1.766 sec/step, loss=0.58569, avg_loss=0.61525]\n","Step 29373   [1.772 sec/step, loss=0.62864, avg_loss=0.61529]\n","Step 29374   [1.767 sec/step, loss=0.62518, avg_loss=0.61536]\n","Step 29375   [1.762 sec/step, loss=0.63671, avg_loss=0.61559]\n","Step 29376   [1.775 sec/step, loss=0.58313, avg_loss=0.61512]\n","Step 29377   [1.807 sec/step, loss=0.50528, avg_loss=0.61384]\n","Step 29378   [1.807 sec/step, loss=0.60870, avg_loss=0.61375]\n","Step 29379   [1.809 sec/step, loss=0.62050, avg_loss=0.61385]\n","Step 29380   [1.809 sec/step, loss=0.62864, avg_loss=0.61398]\n","Step 29381   [1.814 sec/step, loss=0.61043, avg_loss=0.61372]\n","Step 29382   [1.819 sec/step, loss=0.60498, avg_loss=0.61354]\n","Step 29383   [1.822 sec/step, loss=0.64272, avg_loss=0.61386]\n","Step 29384   [1.787 sec/step, loss=0.63511, avg_loss=0.61571]\n","Step 29385   [1.805 sec/step, loss=0.61245, avg_loss=0.61566]\n","Step 29386   [1.822 sec/step, loss=0.60514, avg_loss=0.61545]\n","Step 29387   [1.822 sec/step, loss=0.60748, avg_loss=0.61523]\n","Step 29388   [1.823 sec/step, loss=0.61225, avg_loss=0.61535]\n","Step 29389   [1.832 sec/step, loss=0.62613, avg_loss=0.61548]\n","Step 29390   [1.825 sec/step, loss=0.60729, avg_loss=0.61562]\n","Step 29391   [1.816 sec/step, loss=0.62669, avg_loss=0.61556]\n","Step 29392   [1.813 sec/step, loss=0.61008, avg_loss=0.61550]\n","Step 29393   [1.825 sec/step, loss=0.62390, avg_loss=0.61559]\n","Generated 32 batches of size 32 in 22.370 sec\n","Step 29394   [1.829 sec/step, loss=0.64638, avg_loss=0.61587]\n","Step 29395   [1.807 sec/step, loss=0.62750, avg_loss=0.61602]\n","Step 29396   [1.801 sec/step, loss=0.61921, avg_loss=0.61605]\n","Step 29397   [1.808 sec/step, loss=0.62366, avg_loss=0.61621]\n","Step 29398   [1.797 sec/step, loss=0.61333, avg_loss=0.61608]\n","Step 29399   [1.777 sec/step, loss=0.61158, avg_loss=0.61615]\n","Step 29400   [1.775 sec/step, loss=0.61766, avg_loss=0.61614]\n","Writing summary at step: 29400\n","Step 29401   [1.781 sec/step, loss=0.61105, avg_loss=0.61615]\n","Step 29402   [1.787 sec/step, loss=0.62102, avg_loss=0.61616]\n","Step 29403   [1.776 sec/step, loss=0.62378, avg_loss=0.61632]\n","Step 29404   [1.774 sec/step, loss=0.62398, avg_loss=0.61630]\n","Step 29405   [1.772 sec/step, loss=0.59972, avg_loss=0.61611]\n","Step 29406   [1.811 sec/step, loss=0.45284, avg_loss=0.61430]\n","Step 29407   [1.812 sec/step, loss=0.62357, avg_loss=0.61439]\n","Step 29408   [1.807 sec/step, loss=0.60765, avg_loss=0.61441]\n","Step 29409   [1.811 sec/step, loss=0.63082, avg_loss=0.61445]\n","Step 29410   [1.824 sec/step, loss=0.59139, avg_loss=0.61410]\n","Step 29411   [1.826 sec/step, loss=0.62647, avg_loss=0.61421]\n","Step 29412   [1.832 sec/step, loss=0.61442, avg_loss=0.61425]\n","Step 29413   [1.830 sec/step, loss=0.61708, avg_loss=0.61407]\n","Step 29414   [1.833 sec/step, loss=0.61897, avg_loss=0.61395]\n","Step 29415   [1.834 sec/step, loss=0.61637, avg_loss=0.61388]\n","Step 29416   [1.831 sec/step, loss=0.62224, avg_loss=0.61386]\n","Step 29417   [1.834 sec/step, loss=0.63381, avg_loss=0.61393]\n","Step 29418   [1.834 sec/step, loss=0.60411, avg_loss=0.61378]\n","Step 29419   [1.833 sec/step, loss=0.61373, avg_loss=0.61368]\n","Step 29420   [1.836 sec/step, loss=0.59356, avg_loss=0.61359]\n","Step 29421   [1.841 sec/step, loss=0.62528, avg_loss=0.61369]\n","Step 29422   [1.828 sec/step, loss=0.63057, avg_loss=0.61383]\n","Step 29423   [1.836 sec/step, loss=0.63102, avg_loss=0.61426]\n","Step 29424   [1.847 sec/step, loss=0.62129, avg_loss=0.61433]\n","Generated 32 batches of size 32 in 22.110 sec\n","Step 29425   [1.898 sec/step, loss=0.61931, avg_loss=0.61425]\n","Step 29426   [1.891 sec/step, loss=0.63324, avg_loss=0.61459]\n","Step 29427   [1.885 sec/step, loss=0.63829, avg_loss=0.61480]\n","Step 29428   [1.855 sec/step, loss=0.62471, avg_loss=0.61530]\n","Step 29429   [1.842 sec/step, loss=0.63911, avg_loss=0.61541]\n","Step 29430   [1.823 sec/step, loss=0.62371, avg_loss=0.61553]\n","Step 29431   [1.824 sec/step, loss=0.61933, avg_loss=0.61555]\n","Step 29432   [1.829 sec/step, loss=0.64008, avg_loss=0.61580]\n","Step 29433   [1.831 sec/step, loss=0.63651, avg_loss=0.61600]\n","Step 29434   [1.844 sec/step, loss=0.60853, avg_loss=0.61572]\n","Step 29435   [1.839 sec/step, loss=0.62171, avg_loss=0.61562]\n","Step 29436   [1.839 sec/step, loss=0.61612, avg_loss=0.61567]\n","Step 29437   [1.835 sec/step, loss=0.63058, avg_loss=0.61583]\n","Step 29438   [1.844 sec/step, loss=0.62533, avg_loss=0.61585]\n","Step 29439   [1.841 sec/step, loss=0.62669, avg_loss=0.61579]\n","Step 29440   [1.836 sec/step, loss=0.61222, avg_loss=0.61575]\n","Step 29441   [1.840 sec/step, loss=0.62335, avg_loss=0.61566]\n","Step 29442   [1.853 sec/step, loss=0.63831, avg_loss=0.61582]\n","Step 29443   [1.844 sec/step, loss=0.62019, avg_loss=0.61595]\n","Step 29444   [1.838 sec/step, loss=0.59497, avg_loss=0.61571]\n","Step 29445   [1.837 sec/step, loss=0.59900, avg_loss=0.61546]\n","Step 29446   [1.833 sec/step, loss=0.61249, avg_loss=0.61528]\n","Step 29447   [1.833 sec/step, loss=0.61597, avg_loss=0.61514]\n","Step 29448   [1.844 sec/step, loss=0.63114, avg_loss=0.61520]\n","Step 29449   [1.841 sec/step, loss=0.63743, avg_loss=0.61565]\n","Step 29450   [1.845 sec/step, loss=0.62779, avg_loss=0.61583]\n","Step 29451   [1.862 sec/step, loss=0.63865, avg_loss=0.61607]\n","Step 29452   [1.870 sec/step, loss=0.62346, avg_loss=0.61600]\n","Step 29453   [1.857 sec/step, loss=0.63061, avg_loss=0.61597]\n","Step 29454   [1.853 sec/step, loss=0.62766, avg_loss=0.61597]\n","Step 29455   [1.862 sec/step, loss=0.62994, avg_loss=0.61610]\n","Generated 32 batches of size 32 in 22.308 sec\n","Step 29456   [1.894 sec/step, loss=0.47152, avg_loss=0.61458]\n","Step 29457   [1.891 sec/step, loss=0.62954, avg_loss=0.61466]\n","Step 29458   [1.884 sec/step, loss=0.63204, avg_loss=0.61467]\n","Step 29459   [1.811 sec/step, loss=0.62410, avg_loss=0.61687]\n","Step 29460   [1.810 sec/step, loss=0.63549, avg_loss=0.61711]\n","Step 29461   [1.840 sec/step, loss=0.51619, avg_loss=0.61596]\n","Step 29462   [1.839 sec/step, loss=0.64023, avg_loss=0.61606]\n","Step 29463   [1.841 sec/step, loss=0.63321, avg_loss=0.61616]\n","Step 29464   [1.841 sec/step, loss=0.62393, avg_loss=0.61609]\n","Step 29465   [1.844 sec/step, loss=0.63271, avg_loss=0.61622]\n","Step 29466   [1.843 sec/step, loss=0.62524, avg_loss=0.61623]\n","Step 29467   [1.840 sec/step, loss=0.61752, avg_loss=0.61627]\n","Step 29468   [1.839 sec/step, loss=0.63218, avg_loss=0.61622]\n","Step 29469   [1.831 sec/step, loss=0.60497, avg_loss=0.61609]\n","Step 29470   [1.831 sec/step, loss=0.63063, avg_loss=0.61613]\n","Step 29471   [1.832 sec/step, loss=0.62564, avg_loss=0.61603]\n","Step 29472   [1.840 sec/step, loss=0.64218, avg_loss=0.61659]\n","Step 29473   [1.840 sec/step, loss=0.62522, avg_loss=0.61656]\n","Step 29474   [1.833 sec/step, loss=0.61423, avg_loss=0.61645]\n","Step 29475   [1.838 sec/step, loss=0.61954, avg_loss=0.61628]\n","Step 29476   [1.824 sec/step, loss=0.62291, avg_loss=0.61667]\n","Step 29477   [1.790 sec/step, loss=0.61319, avg_loss=0.61775]\n","Step 29478   [1.808 sec/step, loss=0.60868, avg_loss=0.61775]\n","Step 29479   [1.818 sec/step, loss=0.61268, avg_loss=0.61768]\n","Step 29480   [1.825 sec/step, loss=0.62532, avg_loss=0.61764]\n","Step 29481   [1.829 sec/step, loss=0.63177, avg_loss=0.61786]\n","Step 29482   [1.853 sec/step, loss=0.61479, avg_loss=0.61795]\n","Step 29483   [1.855 sec/step, loss=0.61525, avg_loss=0.61768]\n","Step 29484   [1.865 sec/step, loss=0.60880, avg_loss=0.61742]\n","Step 29485   [1.858 sec/step, loss=0.61152, avg_loss=0.61741]\n","Step 29486   [1.847 sec/step, loss=0.62471, avg_loss=0.61760]\n","Step 29487   [1.847 sec/step, loss=0.61338, avg_loss=0.61766]\n","Step 29488   [1.858 sec/step, loss=0.61045, avg_loss=0.61764]\n","Generated 32 batches of size 32 in 22.409 sec\n","Step 29489   [1.858 sec/step, loss=0.62841, avg_loss=0.61767]\n","Step 29490   [1.852 sec/step, loss=0.58587, avg_loss=0.61745]\n","Step 29491   [1.846 sec/step, loss=0.62968, avg_loss=0.61748]\n","Step 29492   [1.848 sec/step, loss=0.60647, avg_loss=0.61745]\n","Step 29493   [1.836 sec/step, loss=0.63696, avg_loss=0.61758]\n","Step 29494   [1.821 sec/step, loss=0.62422, avg_loss=0.61735]\n","Step 29495   [1.818 sec/step, loss=0.61837, avg_loss=0.61726]\n","Step 29496   [1.822 sec/step, loss=0.62675, avg_loss=0.61734]\n","Step 29497   [1.812 sec/step, loss=0.61837, avg_loss=0.61729]\n","Step 29498   [1.810 sec/step, loss=0.61768, avg_loss=0.61733]\n","Step 29499   [1.813 sec/step, loss=0.61984, avg_loss=0.61741]\n","Step 29500   [1.813 sec/step, loss=0.60817, avg_loss=0.61732]\n","Writing summary at step: 29500\n","Saving checkpoint to: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/model.ckpt-29500\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (47700,)\n","Check wav file:  (77700,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000029500-align000.png\n","100% 1/1 [00:02<00:00,  2.25s/it]\n","Test finished for step 29500.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (63900,)\n","Check wav file:  (93900,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000029500-align000.png\n"," 25% 1/4 [00:03<00:09,  3.06s/it]Check wav file before change:  (63900,)\n","Check wav file:  (93900,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000029500-align001.png\n"," 50% 2/4 [00:06<00:06,  3.20s/it]Check wav file before change:  (63900,)\n","Check wav file:  (93900,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000029500-align002.png\n"," 75% 3/4 [00:09<00:03,  3.07s/it]Check wav file before change:  (63900,)\n","Check wav file:  (93900,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000029500-align003.png\n","100% 4/4 [00:12<00:00,  3.01s/it]\n","Test finished for step 29500.\n","Step 29501   [1.811 sec/step, loss=0.62165, avg_loss=0.61742]\n","Step 29502   [1.808 sec/step, loss=0.62544, avg_loss=0.61747]\n","Step 29503   [1.815 sec/step, loss=0.63234, avg_loss=0.61755]\n","Step 29504   [1.817 sec/step, loss=0.62507, avg_loss=0.61756]\n","Step 29505   [1.823 sec/step, loss=0.61286, avg_loss=0.61770]\n","Step 29506   [1.787 sec/step, loss=0.62135, avg_loss=0.61938]\n","Step 29507   [1.791 sec/step, loss=0.61851, avg_loss=0.61933]\n","Step 29508   [1.798 sec/step, loss=0.60377, avg_loss=0.61929]\n","Step 29509   [1.793 sec/step, loss=0.59630, avg_loss=0.61895]\n","Step 29510   [1.781 sec/step, loss=0.62432, avg_loss=0.61928]\n","Step 29511   [1.827 sec/step, loss=0.56796, avg_loss=0.61869]\n","Step 29512   [1.832 sec/step, loss=0.61055, avg_loss=0.61865]\n","Step 29513   [1.857 sec/step, loss=0.62497, avg_loss=0.61873]\n","Step 29514   [1.860 sec/step, loss=0.62826, avg_loss=0.61882]\n","Step 29515   [1.864 sec/step, loss=0.62592, avg_loss=0.61892]\n","Step 29516   [1.874 sec/step, loss=0.63190, avg_loss=0.61902]\n","Step 29517   [1.876 sec/step, loss=0.61902, avg_loss=0.61887]\n","Generated 32 batches of size 32 in 22.675 sec\n","Step 29518   [1.887 sec/step, loss=0.61623, avg_loss=0.61899]\n","Step 29519   [1.886 sec/step, loss=0.62932, avg_loss=0.61914]\n","Step 29520   [1.883 sec/step, loss=0.61525, avg_loss=0.61936]\n","Step 29521   [1.871 sec/step, loss=0.62288, avg_loss=0.61934]\n","Step 29522   [1.881 sec/step, loss=0.61905, avg_loss=0.61922]\n","Step 29523   [1.871 sec/step, loss=0.63124, avg_loss=0.61922]\n","Step 29524   [1.857 sec/step, loss=0.61808, avg_loss=0.61919]\n","Step 29525   [1.800 sec/step, loss=0.60649, avg_loss=0.61906]\n","Step 29526   [1.798 sec/step, loss=0.62114, avg_loss=0.61894]\n","Step 29527   [1.806 sec/step, loss=0.62934, avg_loss=0.61885]\n","Step 29528   [1.815 sec/step, loss=0.60414, avg_loss=0.61865]\n","Step 29529   [1.812 sec/step, loss=0.63788, avg_loss=0.61864]\n","Step 29530   [1.812 sec/step, loss=0.63155, avg_loss=0.61871]\n","Step 29531   [1.809 sec/step, loss=0.62390, avg_loss=0.61876]\n","Step 29532   [1.811 sec/step, loss=0.61826, avg_loss=0.61854]\n","Step 29533   [1.812 sec/step, loss=0.63840, avg_loss=0.61856]\n","Step 29534   [1.797 sec/step, loss=0.61795, avg_loss=0.61865]\n","Step 29535   [1.799 sec/step, loss=0.62858, avg_loss=0.61872]\n","Step 29536   [1.804 sec/step, loss=0.62885, avg_loss=0.61885]\n","Step 29537   [1.811 sec/step, loss=0.63625, avg_loss=0.61891]\n","Step 29538   [1.805 sec/step, loss=0.62785, avg_loss=0.61893]\n","Step 29539   [1.847 sec/step, loss=0.42902, avg_loss=0.61696]\n","Step 29540   [1.849 sec/step, loss=0.60755, avg_loss=0.61691]\n","Step 29541   [1.840 sec/step, loss=0.60183, avg_loss=0.61669]\n","Step 29542   [1.836 sec/step, loss=0.62695, avg_loss=0.61658]\n","Step 29543   [1.852 sec/step, loss=0.61515, avg_loss=0.61653]\n","Step 29544   [1.862 sec/step, loss=0.62704, avg_loss=0.61685]\n","Step 29545   [1.867 sec/step, loss=0.61488, avg_loss=0.61701]\n","Step 29546   [1.876 sec/step, loss=0.62090, avg_loss=0.61709]\n","Step 29547   [1.892 sec/step, loss=0.61693, avg_loss=0.61710]\n","Step 29548   [1.883 sec/step, loss=0.62507, avg_loss=0.61704]\n","Step 29549   [1.881 sec/step, loss=0.62106, avg_loss=0.61688]\n","Step 29550   [1.883 sec/step, loss=0.60108, avg_loss=0.61661]\n","Generated 32 batches of size 32 in 22.220 sec\n","Step 29551   [1.906 sec/step, loss=0.62524, avg_loss=0.61648]\n","Step 29552   [1.908 sec/step, loss=0.60326, avg_loss=0.61628]\n","Step 29553   [1.903 sec/step, loss=0.60540, avg_loss=0.61602]\n","Step 29554   [1.900 sec/step, loss=0.63527, avg_loss=0.61610]\n","Step 29555   [1.885 sec/step, loss=0.62048, avg_loss=0.61600]\n","Step 29556   [1.833 sec/step, loss=0.62137, avg_loss=0.61750]\n","Step 29557   [1.830 sec/step, loss=0.61201, avg_loss=0.61733]\n","Step 29558   [1.839 sec/step, loss=0.59081, avg_loss=0.61692]\n","Step 29559   [1.839 sec/step, loss=0.62464, avg_loss=0.61692]\n","Step 29560   [1.839 sec/step, loss=0.61811, avg_loss=0.61675]\n","Step 29561   [1.811 sec/step, loss=0.62482, avg_loss=0.61783]\n","Step 29562   [1.816 sec/step, loss=0.62797, avg_loss=0.61771]\n","Step 29563   [1.814 sec/step, loss=0.60166, avg_loss=0.61740]\n","Step 29564   [1.809 sec/step, loss=0.59369, avg_loss=0.61709]\n","Step 29565   [1.843 sec/step, loss=0.48162, avg_loss=0.61558]\n","Step 29566   [1.841 sec/step, loss=0.60859, avg_loss=0.61542]\n","Step 29567   [1.845 sec/step, loss=0.61578, avg_loss=0.61540]\n","Step 29568   [1.848 sec/step, loss=0.60538, avg_loss=0.61513]\n","Step 29569   [1.851 sec/step, loss=0.62518, avg_loss=0.61533]\n","Step 29570   [1.850 sec/step, loss=0.61283, avg_loss=0.61515]\n","Step 29571   [1.851 sec/step, loss=0.62647, avg_loss=0.61516]\n","Step 29572   [1.851 sec/step, loss=0.62197, avg_loss=0.61496]\n","Step 29573   [1.858 sec/step, loss=0.60539, avg_loss=0.61476]\n","Step 29574   [1.866 sec/step, loss=0.61975, avg_loss=0.61482]\n","Step 29575   [1.872 sec/step, loss=0.63213, avg_loss=0.61494]\n","Step 29576   [1.879 sec/step, loss=0.61927, avg_loss=0.61491]\n","Step 29577   [1.887 sec/step, loss=0.61516, avg_loss=0.61493]\n","Step 29578   [1.881 sec/step, loss=0.61784, avg_loss=0.61502]\n","Step 29579   [1.876 sec/step, loss=0.61238, avg_loss=0.61502]\n","Step 29580   [1.882 sec/step, loss=0.62486, avg_loss=0.61501]\n","Step 29581   [1.872 sec/step, loss=0.63237, avg_loss=0.61502]\n","Step 29582   [1.851 sec/step, loss=0.61407, avg_loss=0.61501]\n","Generated 32 batches of size 32 in 22.041 sec\n","Step 29583   [1.913 sec/step, loss=0.60610, avg_loss=0.61492]\n","Step 29584   [1.906 sec/step, loss=0.64276, avg_loss=0.61526]\n","Step 29585   [1.887 sec/step, loss=0.62852, avg_loss=0.61543]\n","Step 29586   [1.890 sec/step, loss=0.63696, avg_loss=0.61555]\n","Step 29587   [1.890 sec/step, loss=0.62744, avg_loss=0.61569]\n","Step 29588   [1.873 sec/step, loss=0.62579, avg_loss=0.61584]\n","Step 29589   [1.860 sec/step, loss=0.60474, avg_loss=0.61561]\n","Step 29590   [1.845 sec/step, loss=0.62153, avg_loss=0.61596]\n","Step 29591   [1.883 sec/step, loss=0.45444, avg_loss=0.61421]\n","Step 29592   [1.874 sec/step, loss=0.62132, avg_loss=0.61436]\n","Step 29593   [1.874 sec/step, loss=0.63431, avg_loss=0.61433]\n","Step 29594   [1.880 sec/step, loss=0.61855, avg_loss=0.61428]\n","Step 29595   [1.892 sec/step, loss=0.62841, avg_loss=0.61438]\n","Step 29596   [1.891 sec/step, loss=0.63606, avg_loss=0.61447]\n","Step 29597   [1.889 sec/step, loss=0.60469, avg_loss=0.61433]\n","Step 29598   [1.889 sec/step, loss=0.64072, avg_loss=0.61456]\n","Step 29599   [1.884 sec/step, loss=0.63187, avg_loss=0.61468]\n","Step 29600   [1.884 sec/step, loss=0.63217, avg_loss=0.61492]\n","Writing summary at step: 29600\n","Step 29601   [1.888 sec/step, loss=0.62799, avg_loss=0.61499]\n","Step 29602   [1.886 sec/step, loss=0.62643, avg_loss=0.61500]\n","Step 29603   [1.880 sec/step, loss=0.64124, avg_loss=0.61509]\n","Step 29604   [1.884 sec/step, loss=0.63096, avg_loss=0.61515]\n","Step 29605   [1.896 sec/step, loss=0.62870, avg_loss=0.61530]\n","Step 29606   [1.897 sec/step, loss=0.61944, avg_loss=0.61529]\n","Step 29607   [1.894 sec/step, loss=0.62981, avg_loss=0.61540]\n","Step 29608   [1.900 sec/step, loss=0.65310, avg_loss=0.61589]\n","Step 29609   [1.910 sec/step, loss=0.63640, avg_loss=0.61629]\n","Step 29610   [1.909 sec/step, loss=0.61462, avg_loss=0.61620]\n","Step 29611   [1.871 sec/step, loss=0.63809, avg_loss=0.61690]\n","Step 29612   [1.866 sec/step, loss=0.63421, avg_loss=0.61713]\n","Step 29613   [1.850 sec/step, loss=0.62959, avg_loss=0.61718]\n","Generated 32 batches of size 32 in 22.471 sec\n","Step 29614   [1.891 sec/step, loss=0.65352, avg_loss=0.61743]\n","Step 29615   [1.888 sec/step, loss=0.63192, avg_loss=0.61749]\n","Step 29616   [1.894 sec/step, loss=0.62155, avg_loss=0.61739]\n","Step 29617   [1.897 sec/step, loss=0.65024, avg_loss=0.61770]\n","Step 29618   [1.882 sec/step, loss=0.62663, avg_loss=0.61780]\n","Step 29619   [1.882 sec/step, loss=0.63145, avg_loss=0.61783]\n","Step 29620   [1.893 sec/step, loss=0.62250, avg_loss=0.61790]\n","Step 29621   [1.887 sec/step, loss=0.62072, avg_loss=0.61788]\n","Step 29622   [1.874 sec/step, loss=0.63934, avg_loss=0.61808]\n","Step 29623   [1.876 sec/step, loss=0.63807, avg_loss=0.61815]\n","Step 29624   [1.877 sec/step, loss=0.63831, avg_loss=0.61835]\n","Step 29625   [1.878 sec/step, loss=0.61010, avg_loss=0.61839]\n","Step 29626   [1.885 sec/step, loss=0.62798, avg_loss=0.61845]\n","Step 29627   [1.876 sec/step, loss=0.60851, avg_loss=0.61825]\n","Step 29628   [1.865 sec/step, loss=0.62590, avg_loss=0.61846]\n","Step 29629   [1.905 sec/step, loss=0.49688, avg_loss=0.61705]\n","Step 29630   [1.898 sec/step, loss=0.65708, avg_loss=0.61731]\n","Step 29631   [1.899 sec/step, loss=0.64713, avg_loss=0.61754]\n","Step 29632   [1.894 sec/step, loss=0.65152, avg_loss=0.61787]\n","Step 29633   [1.893 sec/step, loss=0.64275, avg_loss=0.61792]\n","Step 29634   [1.894 sec/step, loss=0.62863, avg_loss=0.61802]\n","Step 29635   [1.900 sec/step, loss=0.66584, avg_loss=0.61840]\n","Step 29636   [1.903 sec/step, loss=0.63679, avg_loss=0.61848]\n","Step 29637   [1.906 sec/step, loss=0.64021, avg_loss=0.61852]\n","Step 29638   [1.907 sec/step, loss=0.64493, avg_loss=0.61869]\n","Step 29639   [1.869 sec/step, loss=0.63356, avg_loss=0.62073]\n","Step 29640   [1.882 sec/step, loss=0.67401, avg_loss=0.62140]\n","Step 29641   [1.908 sec/step, loss=0.68547, avg_loss=0.62223]\n","Step 29642   [1.907 sec/step, loss=0.65189, avg_loss=0.62248]\n","Step 29643   [1.900 sec/step, loss=0.64859, avg_loss=0.62282]\n","Step 29644   [1.897 sec/step, loss=0.65285, avg_loss=0.62308]\n","Step 29645   [1.909 sec/step, loss=0.67402, avg_loss=0.62367]\n","Generated 32 batches of size 32 in 21.839 sec\n","Step 29646   [1.925 sec/step, loss=0.63213, avg_loss=0.62378]\n","Step 29647   [1.905 sec/step, loss=0.66716, avg_loss=0.62428]\n","Step 29648   [1.908 sec/step, loss=0.66136, avg_loss=0.62464]\n","Step 29649   [1.896 sec/step, loss=0.66155, avg_loss=0.62505]\n","Step 29650   [1.890 sec/step, loss=0.66433, avg_loss=0.62568]\n","Step 29651   [1.862 sec/step, loss=0.68079, avg_loss=0.62624]\n","Step 29652   [1.851 sec/step, loss=0.65514, avg_loss=0.62676]\n","Step 29653   [1.848 sec/step, loss=0.64682, avg_loss=0.62717]\n","Step 29654   [1.847 sec/step, loss=0.69139, avg_loss=0.62773]\n","Step 29655   [1.863 sec/step, loss=0.65443, avg_loss=0.62807]\n","Step 29656   [1.859 sec/step, loss=0.67305, avg_loss=0.62859]\n","Step 29657   [1.858 sec/step, loss=0.66412, avg_loss=0.62911]\n","Step 29658   [1.856 sec/step, loss=0.67247, avg_loss=0.62993]\n","Step 29659   [1.858 sec/step, loss=0.67941, avg_loss=0.63047]\n","Step 29660   [1.860 sec/step, loss=0.68633, avg_loss=0.63116]\n","Step 29661   [1.859 sec/step, loss=0.64458, avg_loss=0.63135]\n","Step 29662   [1.858 sec/step, loss=0.68364, avg_loss=0.63191]\n","Step 29663   [1.869 sec/step, loss=0.67316, avg_loss=0.63262]\n","Step 29664   [1.874 sec/step, loss=0.68831, avg_loss=0.63357]\n","Step 29665   [1.882 sec/step, loss=0.49466, avg_loss=0.63370]\n","Step 29666   [1.893 sec/step, loss=0.69343, avg_loss=0.63455]\n","Step 29667   [1.889 sec/step, loss=0.70896, avg_loss=0.63548]\n","Step 29668   [1.882 sec/step, loss=0.68154, avg_loss=0.63624]\n","Step 29669   [1.891 sec/step, loss=0.69869, avg_loss=0.63698]\n","Step 29670   [1.900 sec/step, loss=0.70375, avg_loss=0.63789]\n","Step 29671   [1.906 sec/step, loss=0.69944, avg_loss=0.63862]\n","Step 29672   [1.913 sec/step, loss=0.73327, avg_loss=0.63973]\n","Step 29673   [1.918 sec/step, loss=0.73099, avg_loss=0.64099]\n","Step 29674   [1.923 sec/step, loss=0.70374, avg_loss=0.64183]\n","Step 29675   [1.921 sec/step, loss=0.75284, avg_loss=0.64303]\n","Step 29676   [1.920 sec/step, loss=0.70459, avg_loss=0.64389]\n","Step 29677   [1.916 sec/step, loss=0.68804, avg_loss=0.64462]\n","Generated 32 batches of size 32 in 22.326 sec\n","Step 29678   [1.938 sec/step, loss=0.70410, avg_loss=0.64548]\n","Step 29679   [1.936 sec/step, loss=0.69145, avg_loss=0.64627]\n","Step 29680   [1.933 sec/step, loss=0.71044, avg_loss=0.64712]\n","Step 29681   [1.934 sec/step, loss=0.70965, avg_loss=0.64790]\n","Step 29682   [1.929 sec/step, loss=0.71852, avg_loss=0.64894]\n","Step 29683   [1.869 sec/step, loss=0.74021, avg_loss=0.65028]\n","Step 29684   [1.865 sec/step, loss=0.70823, avg_loss=0.65094]\n","Step 29685   [1.868 sec/step, loss=0.71437, avg_loss=0.65180]\n","Step 29686   [1.859 sec/step, loss=0.76759, avg_loss=0.65310]\n","Step 29687   [1.858 sec/step, loss=0.71678, avg_loss=0.65400]\n","Step 29688   [1.856 sec/step, loss=0.71905, avg_loss=0.65493]\n","Step 29689   [1.864 sec/step, loss=0.74729, avg_loss=0.65635]\n","Step 29690   [1.891 sec/step, loss=0.67798, avg_loss=0.65692]\n","Step 29691   [1.866 sec/step, loss=0.75405, avg_loss=0.65991]\n","Step 29692   [1.872 sec/step, loss=0.73624, avg_loss=0.66106]\n","Step 29693   [1.868 sec/step, loss=0.69508, avg_loss=0.66167]\n","Step 29694   [1.868 sec/step, loss=0.77312, avg_loss=0.66322]\n","Step 29695   [1.860 sec/step, loss=0.71123, avg_loss=0.66404]\n","Step 29696   [1.865 sec/step, loss=0.71776, avg_loss=0.66486]\n","Step 29697   [1.865 sec/step, loss=0.71982, avg_loss=0.66601]\n","Step 29698   [1.864 sec/step, loss=0.71741, avg_loss=0.66678]\n","Step 29699   [1.864 sec/step, loss=0.73511, avg_loss=0.66781]\n","Step 29700   [1.862 sec/step, loss=0.70451, avg_loss=0.66854]\n","Writing summary at step: 29700\n","Step 29701   [1.869 sec/step, loss=0.73774, avg_loss=0.66963]\n","Step 29702   [1.872 sec/step, loss=0.70322, avg_loss=0.67040]\n","Step 29703   [1.878 sec/step, loss=0.71893, avg_loss=0.67118]\n","Step 29704   [1.884 sec/step, loss=0.71977, avg_loss=0.67207]\n","Step 29705   [1.883 sec/step, loss=0.73958, avg_loss=0.67318]\n","Step 29706   [1.884 sec/step, loss=0.70597, avg_loss=0.67404]\n","Step 29707   [1.889 sec/step, loss=0.71421, avg_loss=0.67488]\n","Step 29708   [1.893 sec/step, loss=0.73977, avg_loss=0.67575]\n","Generated 32 batches of size 32 in 22.523 sec\n","Step 29709   [1.920 sec/step, loss=0.69068, avg_loss=0.67629]\n","Step 29710   [1.915 sec/step, loss=0.71609, avg_loss=0.67731]\n","Step 29711   [1.913 sec/step, loss=0.71608, avg_loss=0.67809]\n","Step 29712   [1.915 sec/step, loss=0.71657, avg_loss=0.67891]\n","Step 29713   [1.910 sec/step, loss=0.73260, avg_loss=0.67994]\n","Step 29714   [1.860 sec/step, loss=0.69857, avg_loss=0.68039]\n","Step 29715   [1.858 sec/step, loss=0.71899, avg_loss=0.68126]\n","Step 29716   [1.840 sec/step, loss=0.71286, avg_loss=0.68218]\n","Step 29717   [1.834 sec/step, loss=0.69153, avg_loss=0.68259]\n","Step 29718   [1.844 sec/step, loss=0.69853, avg_loss=0.68331]\n","Step 29719   [1.847 sec/step, loss=0.69650, avg_loss=0.68396]\n","Step 29720   [1.836 sec/step, loss=0.70056, avg_loss=0.68474]\n","Step 29721   [1.840 sec/step, loss=0.71839, avg_loss=0.68572]\n","Step 29722   [1.841 sec/step, loss=0.72328, avg_loss=0.68656]\n","Step 29723   [1.840 sec/step, loss=0.70567, avg_loss=0.68723]\n","Step 29724   [1.835 sec/step, loss=0.68184, avg_loss=0.68767]\n","Step 29725   [1.843 sec/step, loss=0.71645, avg_loss=0.68873]\n","Step 29726   [1.842 sec/step, loss=0.69474, avg_loss=0.68940]\n","Step 29727   [1.842 sec/step, loss=0.68839, avg_loss=0.69020]\n","Step 29728   [1.845 sec/step, loss=0.69837, avg_loss=0.69092]\n","Step 29729   [1.804 sec/step, loss=0.70940, avg_loss=0.69305]\n","Step 29730   [1.804 sec/step, loss=0.70288, avg_loss=0.69350]\n","Step 29731   [1.803 sec/step, loss=0.70994, avg_loss=0.69413]\n","Step 29732   [1.809 sec/step, loss=0.69875, avg_loss=0.69461]\n","Step 29733   [1.814 sec/step, loss=0.71261, avg_loss=0.69530]\n","Step 29734   [1.883 sec/step, loss=0.53196, avg_loss=0.69434]\n","Step 29735   [1.909 sec/step, loss=0.69371, avg_loss=0.69462]\n","Step 29736   [1.917 sec/step, loss=0.69290, avg_loss=0.69518]\n","Step 29737   [1.916 sec/step, loss=0.67738, avg_loss=0.69555]\n","Generated 32 batches of size 32 in 23.207 sec\n","Step 29738   [1.931 sec/step, loss=0.67716, avg_loss=0.69587]\n","Step 29739   [1.925 sec/step, loss=0.68817, avg_loss=0.69642]\n","Step 29740   [1.913 sec/step, loss=0.67791, avg_loss=0.69646]\n","Step 29741   [1.891 sec/step, loss=0.69628, avg_loss=0.69656]\n","Step 29742   [1.887 sec/step, loss=0.68328, avg_loss=0.69688]\n","Step 29743   [1.884 sec/step, loss=0.69437, avg_loss=0.69734]\n","Step 29744   [1.885 sec/step, loss=0.66943, avg_loss=0.69750]\n","Step 29745   [1.870 sec/step, loss=0.68788, avg_loss=0.69764]\n","Step 29746   [1.846 sec/step, loss=0.66810, avg_loss=0.69800]\n","Step 29747   [1.852 sec/step, loss=0.68934, avg_loss=0.69822]\n","Step 29748   [1.845 sec/step, loss=0.67235, avg_loss=0.69833]\n","Step 29749   [1.844 sec/step, loss=0.66114, avg_loss=0.69833]\n","Step 29750   [1.846 sec/step, loss=0.69752, avg_loss=0.69866]\n","Step 29751   [1.834 sec/step, loss=0.68755, avg_loss=0.69873]\n","Step 29752   [1.835 sec/step, loss=0.66747, avg_loss=0.69885]\n","Step 29753   [1.834 sec/step, loss=0.66278, avg_loss=0.69901]\n","Step 29754   [1.833 sec/step, loss=0.69779, avg_loss=0.69907]\n","Step 29755   [1.818 sec/step, loss=0.66433, avg_loss=0.69917]\n","Step 29756   [1.819 sec/step, loss=0.67330, avg_loss=0.69918]\n","Step 29757   [1.833 sec/step, loss=0.66649, avg_loss=0.69920]\n","Step 29758   [1.834 sec/step, loss=0.66917, avg_loss=0.69917]\n","Step 29759   [1.830 sec/step, loss=0.65826, avg_loss=0.69895]\n","Step 29760   [1.828 sec/step, loss=0.68483, avg_loss=0.69894]\n","Step 29761   [1.835 sec/step, loss=0.67200, avg_loss=0.69921]\n","Step 29762   [1.831 sec/step, loss=0.65708, avg_loss=0.69895]\n","Step 29763   [1.821 sec/step, loss=0.66347, avg_loss=0.69885]\n","Step 29764   [1.882 sec/step, loss=0.53632, avg_loss=0.69733]\n","Step 29765   [1.851 sec/step, loss=0.66322, avg_loss=0.69902]\n","Step 29766   [1.849 sec/step, loss=0.64993, avg_loss=0.69858]\n","Step 29767   [1.861 sec/step, loss=0.65734, avg_loss=0.69807]\n","Step 29768   [1.876 sec/step, loss=0.67110, avg_loss=0.69796]\n","Step 29769   [1.876 sec/step, loss=0.66385, avg_loss=0.69761]\n","Step 29770   [1.880 sec/step, loss=0.67757, avg_loss=0.69735]\n","Generated 32 batches of size 32 in 23.205 sec\n","Step 29771   [1.883 sec/step, loss=0.66778, avg_loss=0.69703]\n","Step 29772   [1.884 sec/step, loss=0.64127, avg_loss=0.69611]\n","Step 29773   [1.864 sec/step, loss=0.64487, avg_loss=0.69525]\n","Step 29774   [1.852 sec/step, loss=0.65377, avg_loss=0.69475]\n","Step 29775   [1.846 sec/step, loss=0.65747, avg_loss=0.69380]\n","Step 29776   [1.855 sec/step, loss=0.61428, avg_loss=0.69290]\n","Step 29777   [1.850 sec/step, loss=0.66592, avg_loss=0.69268]\n","Step 29778   [1.817 sec/step, loss=0.65908, avg_loss=0.69223]\n","Step 29779   [1.821 sec/step, loss=0.66082, avg_loss=0.69192]\n","Step 29780   [1.820 sec/step, loss=0.65924, avg_loss=0.69141]\n","Step 29781   [1.817 sec/step, loss=0.66188, avg_loss=0.69093]\n","Step 29782   [1.819 sec/step, loss=0.65587, avg_loss=0.69030]\n","Step 29783   [1.815 sec/step, loss=0.64783, avg_loss=0.68938]\n","Step 29784   [1.816 sec/step, loss=0.65979, avg_loss=0.68889]\n","Step 29785   [1.814 sec/step, loss=0.65572, avg_loss=0.68831]\n","Step 29786   [1.812 sec/step, loss=0.66970, avg_loss=0.68733]\n","Step 29787   [1.818 sec/step, loss=0.66475, avg_loss=0.68681]\n","Step 29788   [1.826 sec/step, loss=0.67388, avg_loss=0.68636]\n","Step 29789   [1.858 sec/step, loss=0.48386, avg_loss=0.68372]\n","Step 29790   [1.829 sec/step, loss=0.64883, avg_loss=0.68343]\n","Step 29791   [1.816 sec/step, loss=0.65784, avg_loss=0.68247]\n","Step 29792   [1.816 sec/step, loss=0.65608, avg_loss=0.68167]\n","Step 29793   [1.820 sec/step, loss=0.65808, avg_loss=0.68130]\n","Step 29794   [1.825 sec/step, loss=0.64634, avg_loss=0.68003]\n","Step 29795   [1.823 sec/step, loss=0.66609, avg_loss=0.67958]\n","Step 29796   [1.821 sec/step, loss=0.67016, avg_loss=0.67910]\n","Step 29797   [1.833 sec/step, loss=0.64671, avg_loss=0.67837]\n","Step 29798   [1.838 sec/step, loss=0.65277, avg_loss=0.67773]\n","Step 29799   [1.841 sec/step, loss=0.62761, avg_loss=0.67665]\n","Step 29800   [1.859 sec/step, loss=0.65986, avg_loss=0.67620]\n","Writing summary at step: 29800\n","Step 29801   [1.855 sec/step, loss=0.66625, avg_loss=0.67549]\n","Step 29802   [1.864 sec/step, loss=0.64464, avg_loss=0.67490]\n","Step 29803   [1.862 sec/step, loss=0.65287, avg_loss=0.67424]\n","Generated 32 batches of size 32 in 22.066 sec\n","Step 29804   [1.892 sec/step, loss=0.66177, avg_loss=0.67366]\n","Step 29805   [1.875 sec/step, loss=0.63094, avg_loss=0.67258]\n","Step 29806   [1.888 sec/step, loss=0.61922, avg_loss=0.67171]\n","Step 29807   [1.881 sec/step, loss=0.64604, avg_loss=0.67103]\n","Step 29808   [1.899 sec/step, loss=0.48686, avg_loss=0.66850]\n","Step 29809   [1.863 sec/step, loss=0.65264, avg_loss=0.66812]\n","Step 29810   [1.865 sec/step, loss=0.66702, avg_loss=0.66763]\n","Step 29811   [1.868 sec/step, loss=0.66444, avg_loss=0.66711]\n","Step 29812   [1.865 sec/step, loss=0.65604, avg_loss=0.66650]\n","Step 29813   [1.862 sec/step, loss=0.63714, avg_loss=0.66555]\n","Step 29814   [1.860 sec/step, loss=0.65210, avg_loss=0.66509]\n","Step 29815   [1.860 sec/step, loss=0.66305, avg_loss=0.66453]\n","Step 29816   [1.863 sec/step, loss=0.66232, avg_loss=0.66402]\n","Step 29817   [1.861 sec/step, loss=0.64887, avg_loss=0.66359]\n","Step 29818   [1.848 sec/step, loss=0.63801, avg_loss=0.66299]\n","Step 29819   [1.844 sec/step, loss=0.64673, avg_loss=0.66249]\n","Step 29820   [1.848 sec/step, loss=0.63786, avg_loss=0.66186]\n","Step 29821   [1.855 sec/step, loss=0.65398, avg_loss=0.66122]\n","Step 29822   [1.857 sec/step, loss=0.63084, avg_loss=0.66030]\n","Step 29823   [1.856 sec/step, loss=0.65831, avg_loss=0.65982]\n","Step 29824   [1.862 sec/step, loss=0.64091, avg_loss=0.65941]\n","Step 29825   [1.865 sec/step, loss=0.65460, avg_loss=0.65879]\n","Step 29826   [1.858 sec/step, loss=0.63359, avg_loss=0.65818]\n","Step 29827   [1.864 sec/step, loss=0.64646, avg_loss=0.65776]\n","Step 29828   [1.864 sec/step, loss=0.64064, avg_loss=0.65719]\n","Step 29829   [1.875 sec/step, loss=0.66803, avg_loss=0.65677]\n","Step 29830   [1.891 sec/step, loss=0.66430, avg_loss=0.65639]\n","Step 29831   [1.901 sec/step, loss=0.65692, avg_loss=0.65586]\n","Step 29832   [1.901 sec/step, loss=0.64915, avg_loss=0.65536]\n","Step 29833   [1.913 sec/step, loss=0.64056, avg_loss=0.65464]\n","Step 29834   [1.847 sec/step, loss=0.63961, avg_loss=0.65572]\n","Step 29835   [1.821 sec/step, loss=0.64062, avg_loss=0.65519]\n","Generated 32 batches of size 32 in 21.427 sec\n","Step 29836   [1.885 sec/step, loss=0.43739, avg_loss=0.65263]\n","Step 29837   [1.883 sec/step, loss=0.65879, avg_loss=0.65244]\n","Step 29838   [1.861 sec/step, loss=0.63741, avg_loss=0.65205]\n","Step 29839   [1.860 sec/step, loss=0.62957, avg_loss=0.65146]\n","Step 29840   [1.863 sec/step, loss=0.65204, avg_loss=0.65120]\n","Step 29841   [1.863 sec/step, loss=0.64135, avg_loss=0.65065]\n","Step 29842   [1.859 sec/step, loss=0.64194, avg_loss=0.65024]\n","Step 29843   [1.856 sec/step, loss=0.64878, avg_loss=0.64978]\n","Step 29844   [1.852 sec/step, loss=0.64525, avg_loss=0.64954]\n","Step 29845   [1.861 sec/step, loss=0.63823, avg_loss=0.64905]\n","Step 29846   [1.867 sec/step, loss=0.63301, avg_loss=0.64869]\n","Step 29847   [1.859 sec/step, loss=0.64060, avg_loss=0.64821]\n","Step 29848   [1.866 sec/step, loss=0.62401, avg_loss=0.64772]\n","Step 29849   [1.870 sec/step, loss=0.63822, avg_loss=0.64749]\n","Step 29850   [1.874 sec/step, loss=0.62449, avg_loss=0.64676]\n","Step 29851   [1.876 sec/step, loss=0.65413, avg_loss=0.64643]\n","Step 29852   [1.884 sec/step, loss=0.62340, avg_loss=0.64599]\n","Step 29853   [1.885 sec/step, loss=0.65492, avg_loss=0.64591]\n","Step 29854   [1.883 sec/step, loss=0.63667, avg_loss=0.64530]\n","Step 29855   [1.891 sec/step, loss=0.65469, avg_loss=0.64520]\n","Step 29856   [1.894 sec/step, loss=0.65002, avg_loss=0.64497]\n","Step 29857   [1.896 sec/step, loss=0.64096, avg_loss=0.64471]\n","Step 29858   [1.893 sec/step, loss=0.66664, avg_loss=0.64469]\n","Step 29859   [1.901 sec/step, loss=0.64688, avg_loss=0.64458]\n","Step 29860   [1.906 sec/step, loss=0.65157, avg_loss=0.64424]\n","Step 29861   [1.907 sec/step, loss=0.65060, avg_loss=0.64403]\n","Step 29862   [1.913 sec/step, loss=0.66137, avg_loss=0.64407]\n","Step 29863   [1.920 sec/step, loss=0.66004, avg_loss=0.64404]\n","Step 29864   [1.862 sec/step, loss=0.64504, avg_loss=0.64512]\n","Step 29865   [1.853 sec/step, loss=0.63292, avg_loss=0.64482]\n","Step 29866   [1.850 sec/step, loss=0.64561, avg_loss=0.64478]\n","Step 29867   [1.853 sec/step, loss=0.65464, avg_loss=0.64475]\n","Generated 32 batches of size 32 in 22.061 sec\n","Step 29868   [1.898 sec/step, loss=0.66339, avg_loss=0.64467]\n","Step 29869   [1.890 sec/step, loss=0.66675, avg_loss=0.64470]\n","Step 29870   [1.881 sec/step, loss=0.64716, avg_loss=0.64440]\n","Step 29871   [1.865 sec/step, loss=0.65361, avg_loss=0.64426]\n","Step 29872   [1.866 sec/step, loss=0.65329, avg_loss=0.64438]\n","Step 29873   [1.867 sec/step, loss=0.66578, avg_loss=0.64459]\n","Step 29874   [1.878 sec/step, loss=0.64576, avg_loss=0.64451]\n","Step 29875   [1.881 sec/step, loss=0.64763, avg_loss=0.64441]\n","Step 29876   [1.863 sec/step, loss=0.65983, avg_loss=0.64486]\n","Step 29877   [1.865 sec/step, loss=0.64238, avg_loss=0.64463]\n","Step 29878   [1.867 sec/step, loss=0.64721, avg_loss=0.64451]\n","Step 29879   [1.867 sec/step, loss=0.66057, avg_loss=0.64451]\n","Step 29880   [1.864 sec/step, loss=0.65648, avg_loss=0.64448]\n","Step 29881   [1.869 sec/step, loss=0.66499, avg_loss=0.64451]\n","Step 29882   [1.864 sec/step, loss=0.64201, avg_loss=0.64437]\n","Step 29883   [1.861 sec/step, loss=0.63217, avg_loss=0.64422]\n","Step 29884   [1.897 sec/step, loss=0.50053, avg_loss=0.64262]\n","Step 29885   [1.901 sec/step, loss=0.66304, avg_loss=0.64270]\n","Step 29886   [1.911 sec/step, loss=0.65955, avg_loss=0.64259]\n","Step 29887   [1.904 sec/step, loss=0.66292, avg_loss=0.64258]\n","Step 29888   [1.900 sec/step, loss=0.65725, avg_loss=0.64241]\n","Step 29889   [1.868 sec/step, loss=0.66357, avg_loss=0.64421]\n","Step 29890   [1.868 sec/step, loss=0.63593, avg_loss=0.64408]\n","Step 29891   [1.877 sec/step, loss=0.66482, avg_loss=0.64415]\n","Step 29892   [1.882 sec/step, loss=0.64002, avg_loss=0.64399]\n","Step 29893   [1.886 sec/step, loss=0.66514, avg_loss=0.64406]\n","Step 29894   [1.883 sec/step, loss=0.67477, avg_loss=0.64434]\n","Step 29895   [1.888 sec/step, loss=0.64298, avg_loss=0.64411]\n","Step 29896   [1.903 sec/step, loss=0.65490, avg_loss=0.64396]\n","Step 29897   [1.903 sec/step, loss=0.66740, avg_loss=0.64417]\n","Step 29898   [1.912 sec/step, loss=0.67448, avg_loss=0.64438]\n","Step 29899   [1.912 sec/step, loss=0.65037, avg_loss=0.64461]\n","Generated 32 batches of size 32 in 22.419 sec\n","Step 29900   [1.932 sec/step, loss=0.64686, avg_loss=0.64448]\n","Writing summary at step: 29900\n","Step 29901   [1.925 sec/step, loss=0.65400, avg_loss=0.64436]\n","Step 29902   [1.915 sec/step, loss=0.65187, avg_loss=0.64443]\n","Step 29903   [1.920 sec/step, loss=0.63552, avg_loss=0.64426]\n","Step 29904   [1.886 sec/step, loss=0.64055, avg_loss=0.64404]\n","Step 29905   [1.903 sec/step, loss=0.61238, avg_loss=0.64386]\n","Step 29906   [1.892 sec/step, loss=0.65231, avg_loss=0.64419]\n","Step 29907   [1.888 sec/step, loss=0.63917, avg_loss=0.64412]\n","Step 29908   [1.855 sec/step, loss=0.64374, avg_loss=0.64569]\n","Step 29909   [1.854 sec/step, loss=0.64475, avg_loss=0.64561]\n","Step 29910   [1.890 sec/step, loss=0.48473, avg_loss=0.64379]\n","Step 29911   [1.883 sec/step, loss=0.65979, avg_loss=0.64374]\n","Step 29912   [1.882 sec/step, loss=0.66615, avg_loss=0.64384]\n","Step 29913   [1.883 sec/step, loss=0.65631, avg_loss=0.64403]\n","Step 29914   [1.881 sec/step, loss=0.61800, avg_loss=0.64369]\n","Step 29915   [1.878 sec/step, loss=0.64069, avg_loss=0.64347]\n","Step 29916   [1.882 sec/step, loss=0.66406, avg_loss=0.64349]\n","Step 29917   [1.883 sec/step, loss=0.66071, avg_loss=0.64361]\n","Step 29918   [1.885 sec/step, loss=0.64078, avg_loss=0.64363]\n","Step 29919   [1.884 sec/step, loss=0.64081, avg_loss=0.64357]\n","Step 29920   [1.891 sec/step, loss=0.64442, avg_loss=0.64364]\n","Step 29921   [1.882 sec/step, loss=0.65001, avg_loss=0.64360]\n","Step 29922   [1.888 sec/step, loss=0.66209, avg_loss=0.64391]\n","Step 29923   [1.897 sec/step, loss=0.65364, avg_loss=0.64387]\n","Step 29924   [1.903 sec/step, loss=0.64539, avg_loss=0.64391]\n","Step 29925   [1.902 sec/step, loss=0.65404, avg_loss=0.64390]\n","Step 29926   [1.915 sec/step, loss=0.64517, avg_loss=0.64402]\n","Step 29927   [1.921 sec/step, loss=0.64589, avg_loss=0.64401]\n","Step 29928   [1.924 sec/step, loss=0.65273, avg_loss=0.64414]\n","Step 29929   [1.917 sec/step, loss=0.64979, avg_loss=0.64395]\n","Step 29930   [1.907 sec/step, loss=0.62492, avg_loss=0.64356]\n","Generated 32 batches of size 32 in 22.505 sec\n","Step 29931   [1.952 sec/step, loss=0.62780, avg_loss=0.64327]\n","Step 29932   [1.946 sec/step, loss=0.63313, avg_loss=0.64311]\n","Step 29933   [1.930 sec/step, loss=0.63265, avg_loss=0.64303]\n","Step 29934   [1.930 sec/step, loss=0.64444, avg_loss=0.64308]\n","Step 29935   [1.925 sec/step, loss=0.65714, avg_loss=0.64324]\n","Step 29936   [1.847 sec/step, loss=0.63150, avg_loss=0.64518]\n","Step 29937   [1.856 sec/step, loss=0.60471, avg_loss=0.64464]\n","Step 29938   [1.859 sec/step, loss=0.64392, avg_loss=0.64471]\n","Step 29939   [1.862 sec/step, loss=0.65963, avg_loss=0.64501]\n","Step 29940   [1.866 sec/step, loss=0.64440, avg_loss=0.64493]\n","Step 29941   [1.864 sec/step, loss=0.63646, avg_loss=0.64488]\n","Step 29942   [1.868 sec/step, loss=0.64964, avg_loss=0.64496]\n","Step 29943   [1.867 sec/step, loss=0.64226, avg_loss=0.64490]\n","Step 29944   [1.864 sec/step, loss=0.61960, avg_loss=0.64464]\n","Step 29945   [1.854 sec/step, loss=0.64543, avg_loss=0.64471]\n","Step 29946   [1.850 sec/step, loss=0.63498, avg_loss=0.64473]\n","Step 29947   [1.855 sec/step, loss=0.65066, avg_loss=0.64483]\n","Step 29948   [1.857 sec/step, loss=0.62728, avg_loss=0.64486]\n","Step 29949   [1.854 sec/step, loss=0.63295, avg_loss=0.64481]\n","Step 29950   [1.853 sec/step, loss=0.63784, avg_loss=0.64494]\n","Step 29951   [1.889 sec/step, loss=0.47733, avg_loss=0.64318]\n","Step 29952   [1.879 sec/step, loss=0.62674, avg_loss=0.64321]\n","Step 29953   [1.877 sec/step, loss=0.63426, avg_loss=0.64300]\n","Step 29954   [1.887 sec/step, loss=0.63452, avg_loss=0.64298]\n","Step 29955   [1.887 sec/step, loss=0.64395, avg_loss=0.64287]\n","Step 29956   [1.888 sec/step, loss=0.63180, avg_loss=0.64269]\n","Step 29957   [1.897 sec/step, loss=0.64712, avg_loss=0.64275]\n","Step 29958   [1.905 sec/step, loss=0.63582, avg_loss=0.64245]\n","Step 29959   [1.905 sec/step, loss=0.65968, avg_loss=0.64257]\n","Step 29960   [1.911 sec/step, loss=0.64280, avg_loss=0.64249]\n","Step 29961   [1.908 sec/step, loss=0.63488, avg_loss=0.64233]\n","Step 29962   [1.917 sec/step, loss=0.64665, avg_loss=0.64218]\n","Generated 32 batches of size 32 in 22.218 sec\n","Step 29963   [1.949 sec/step, loss=0.60889, avg_loss=0.64167]\n","Step 29964   [1.946 sec/step, loss=0.63935, avg_loss=0.64161]\n","Step 29965   [1.944 sec/step, loss=0.65012, avg_loss=0.64179]\n","Step 29966   [1.944 sec/step, loss=0.63343, avg_loss=0.64166]\n","Step 29967   [1.931 sec/step, loss=0.64712, avg_loss=0.64159]\n","Step 29968   [1.870 sec/step, loss=0.63393, avg_loss=0.64129]\n","Step 29969   [1.867 sec/step, loss=0.62296, avg_loss=0.64086]\n","Step 29970   [1.863 sec/step, loss=0.61612, avg_loss=0.64054]\n","Step 29971   [1.865 sec/step, loss=0.62831, avg_loss=0.64029]\n","Step 29972   [1.848 sec/step, loss=0.61989, avg_loss=0.63996]\n","Step 29973   [1.848 sec/step, loss=0.63854, avg_loss=0.63969]\n","Step 29974   [1.844 sec/step, loss=0.65074, avg_loss=0.63974]\n","Step 29975   [1.841 sec/step, loss=0.64801, avg_loss=0.63974]\n","Step 29976   [1.843 sec/step, loss=0.62508, avg_loss=0.63939]\n","Step 29977   [1.842 sec/step, loss=0.63669, avg_loss=0.63933]\n","Step 29978   [1.840 sec/step, loss=0.61878, avg_loss=0.63905]\n","Step 29979   [1.831 sec/step, loss=0.62423, avg_loss=0.63869]\n","Step 29980   [1.831 sec/step, loss=0.65257, avg_loss=0.63865]\n","Step 29981   [1.832 sec/step, loss=0.62822, avg_loss=0.63828]\n","Step 29982   [1.836 sec/step, loss=0.64940, avg_loss=0.63835]\n","Step 29983   [1.846 sec/step, loss=0.63774, avg_loss=0.63841]\n","Step 29984   [1.815 sec/step, loss=0.64018, avg_loss=0.63981]\n","Step 29985   [1.845 sec/step, loss=0.52512, avg_loss=0.63843]\n","Step 29986   [1.839 sec/step, loss=0.63073, avg_loss=0.63814]\n","Step 29987   [1.851 sec/step, loss=0.64908, avg_loss=0.63800]\n","Step 29988   [1.855 sec/step, loss=0.64348, avg_loss=0.63786]\n","Step 29989   [1.860 sec/step, loss=0.63431, avg_loss=0.63757]\n","Step 29990   [1.880 sec/step, loss=0.65115, avg_loss=0.63772]\n","Step 29991   [1.875 sec/step, loss=0.63884, avg_loss=0.63746]\n","Step 29992   [1.871 sec/step, loss=0.63102, avg_loss=0.63737]\n","Step 29993   [1.877 sec/step, loss=0.66996, avg_loss=0.63742]\n","Step 29994   [1.892 sec/step, loss=0.67690, avg_loss=0.63744]\n","Generated 32 batches of size 32 in 21.764 sec\n","Step 29995   [1.902 sec/step, loss=0.63016, avg_loss=0.63731]\n","Step 29996   [1.886 sec/step, loss=0.63037, avg_loss=0.63707]\n","Step 29997   [1.876 sec/step, loss=0.64772, avg_loss=0.63687]\n","Step 29998   [1.869 sec/step, loss=0.63725, avg_loss=0.63650]\n","Step 29999   [1.867 sec/step, loss=0.63700, avg_loss=0.63637]\n","Step 30000   [1.834 sec/step, loss=0.63241, avg_loss=0.63622]\n","Writing summary at step: 30000\n","Saving checkpoint to: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/model.ckpt-30000\n","Saving audio and alignment...\n","  0% 0/1 [00:00<?, ?it/s]Check wav file before change:  (78300,)\n","Check wav file:  (108300,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/train-step-000030000-align000.png\n","100% 1/1 [00:03<00:00,  3.48s/it]\n","Test finished for step 30000.\n","  0% 0/4 [00:00<?, ?it/s]Check wav file before change:  (66900,)\n","Check wav file:  (96900,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000030000-align000.png\n"," 25% 1/4 [00:03<00:10,  3.62s/it]Check wav file before change:  (66900,)\n","Check wav file:  (96900,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000030000-align001.png\n"," 50% 2/4 [00:06<00:06,  3.48s/it]Check wav file before change:  (66900,)\n","Check wav file:  (96900,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000030000-align002.png\n"," 75% 3/4 [00:09<00:03,  3.28s/it]Check wav file before change:  (66900,)\n","Check wav file:  (96900,)\n","Training korean : Use jamo\n"," [*] Plot saved: ./logdir-tacotron2/kss_preprocess_result+preprocess_result_2021-05-28_01-47-39/test-step-000030000-align003.png\n","100% 4/4 [00:12<00:00,  3.07s/it]\n","Test finished for step 30000.\n","Step 30001   [1.832 sec/step, loss=0.64354, avg_loss=0.63612]\n","Step 30002   [1.829 sec/step, loss=0.65078, avg_loss=0.63611]\n","Step 30003   [1.816 sec/step, loss=0.67265, avg_loss=0.63648]\n","Step 30004   [1.808 sec/step, loss=0.64079, avg_loss=0.63648]\n","Step 30005   [1.790 sec/step, loss=0.62003, avg_loss=0.63656]\n","Step 30006   [1.786 sec/step, loss=0.63962, avg_loss=0.63643]\n","Step 30007   [1.789 sec/step, loss=0.63264, avg_loss=0.63636]\n","Step 30008   [1.791 sec/step, loss=0.64714, avg_loss=0.63640]\n","Step 30009   [1.792 sec/step, loss=0.62344, avg_loss=0.63618]\n","Step 30010   [1.762 sec/step, loss=0.65869, avg_loss=0.63792]\n","Step 30011   [1.760 sec/step, loss=0.63523, avg_loss=0.63768]\n","Step 30012   [1.753 sec/step, loss=0.63163, avg_loss=0.63733]\n","Step 30013   [1.756 sec/step, loss=0.65021, avg_loss=0.63727]\n","Step 30014   [1.767 sec/step, loss=0.66071, avg_loss=0.63770]\n","Step 30015   [1.772 sec/step, loss=0.63829, avg_loss=0.63768]\n","Step 30016   [1.769 sec/step, loss=0.62401, avg_loss=0.63728]\n","Step 30017   [1.772 sec/step, loss=0.64951, avg_loss=0.63716]\n","Step 30018   [1.804 sec/step, loss=0.60050, avg_loss=0.63676]\n","Step 30019   [1.820 sec/step, loss=0.63071, avg_loss=0.63666]\n","Step 30020   [1.836 sec/step, loss=0.63795, avg_loss=0.63659]\n","Generated 32 batches of size 32 in 21.875 sec\n","Step 30021   [1.910 sec/step, loss=0.46551, avg_loss=0.63475]\n","Step 30022   [1.898 sec/step, loss=0.65327, avg_loss=0.63466]\n","Step 30023   [1.888 sec/step, loss=0.62355, avg_loss=0.63436]\n","Step 30024   [1.882 sec/step, loss=0.64639, avg_loss=0.63437]\n","Step 30025   [1.876 sec/step, loss=0.63608, avg_loss=0.63419]\n","Step 30026   [1.898 sec/step, loss=0.50302, avg_loss=0.63277]\n","Step 30027   [1.890 sec/step, loss=0.62929, avg_loss=0.63260]\n","Step 30028   [1.882 sec/step, loss=0.62765, avg_loss=0.63235]\n","Step 30029   [1.883 sec/step, loss=0.62895, avg_loss=0.63214]\n","Step 30030   [1.886 sec/step, loss=0.64498, avg_loss=0.63235]\n","Step 30031   [1.831 sec/step, loss=0.63632, avg_loss=0.63243]\n","Step 30032   [1.832 sec/step, loss=0.63754, avg_loss=0.63247]\n","Step 30033   [1.831 sec/step, loss=0.64852, avg_loss=0.63263]\n","Step 30034   [1.828 sec/step, loss=0.63438, avg_loss=0.63253]\n","Step 30035   [1.825 sec/step, loss=0.63611, avg_loss=0.63232]\n","Step 30036   [1.832 sec/step, loss=0.64596, avg_loss=0.63247]\n","Step 30037   [1.831 sec/step, loss=0.59202, avg_loss=0.63234]\n","Step 30038   [1.834 sec/step, loss=0.65191, avg_loss=0.63242]\n","Step 30039   [1.836 sec/step, loss=0.62910, avg_loss=0.63211]\n","Step 30040   [1.829 sec/step, loss=0.63060, avg_loss=0.63198]\n","Step 30041   [1.828 sec/step, loss=0.65073, avg_loss=0.63212]\n","Step 30042   [1.833 sec/step, loss=0.64797, avg_loss=0.63210]\n","Step 30043   [1.838 sec/step, loss=0.63418, avg_loss=0.63202]\n","Step 30044   [1.838 sec/step, loss=0.62409, avg_loss=0.63207]\n","Step 30045   [1.835 sec/step, loss=0.62621, avg_loss=0.63187]\n","Step 30046   [1.838 sec/step, loss=0.63437, avg_loss=0.63187]\n","Step 30047   [1.833 sec/step, loss=0.65206, avg_loss=0.63188]\n","Step 30048   [1.843 sec/step, loss=0.64078, avg_loss=0.63202]\n","Step 30049   [1.857 sec/step, loss=0.63215, avg_loss=0.63201]\n","Step 30050   [1.874 sec/step, loss=0.64010, avg_loss=0.63203]\n","Step 30051   [1.842 sec/step, loss=0.62060, avg_loss=0.63346]\n","Step 30052   [1.859 sec/step, loss=0.65597, avg_loss=0.63376]\n","Step 30053   [1.872 sec/step, loss=0.63285, avg_loss=0.63374]\n","Step 30054   [1.869 sec/step, loss=0.65409, avg_loss=0.63394]\n","Step 30055   [1.862 sec/step, loss=0.61646, avg_loss=0.63366]\n","Step 30056   [1.870 sec/step, loss=0.63406, avg_loss=0.63369]\n","Generated 32 batches of size 32 in 22.107 sec\n","Step 30057   [1.862 sec/step, loss=0.63776, avg_loss=0.63359]\n","Step 30058   [1.849 sec/step, loss=0.61794, avg_loss=0.63341]\n","Step 30059   [1.842 sec/step, loss=0.62899, avg_loss=0.63311]\n","Step 30060   [1.832 sec/step, loss=0.64446, avg_loss=0.63312]\n","Step 30061   [1.838 sec/step, loss=0.63574, avg_loss=0.63313]\n","Step 30062   [1.831 sec/step, loss=0.63387, avg_loss=0.63300]\n","Step 30063   [1.790 sec/step, loss=0.61238, avg_loss=0.63304]\n","Step 30064   [1.789 sec/step, loss=0.63615, avg_loss=0.63301]\n","Step 30065   [1.822 sec/step, loss=0.51744, avg_loss=0.63168]\n","Step 30066   [1.820 sec/step, loss=0.63579, avg_loss=0.63170]\n","Step 30067   [1.815 sec/step, loss=0.62618, avg_loss=0.63149]\n","Step 30068   [1.815 sec/step, loss=0.61187, avg_loss=0.63127]\n","Step 30069   [1.819 sec/step, loss=0.63079, avg_loss=0.63135]\n","Step 30070   [1.822 sec/step, loss=0.62813, avg_loss=0.63147]\n","Step 30071   [1.826 sec/step, loss=0.63126, avg_loss=0.63150]\n","Step 30072   [1.832 sec/step, loss=0.62036, avg_loss=0.63151]\n","Step 30073   [1.835 sec/step, loss=0.64522, avg_loss=0.63157]\n","Step 30074   [1.836 sec/step, loss=0.61787, avg_loss=0.63124]\n","Step 30075   [1.832 sec/step, loss=0.60599, avg_loss=0.63082]\n","Step 30076   [1.839 sec/step, loss=0.62549, avg_loss=0.63083]\n","Step 30077   [1.840 sec/step, loss=0.61963, avg_loss=0.63066]\n","Step 30078   [1.840 sec/step, loss=0.63278, avg_loss=0.63080]\n","Step 30079   [1.852 sec/step, loss=0.62734, avg_loss=0.63083]\n","Step 30080   [1.850 sec/step, loss=0.62241, avg_loss=0.63053]\n","Step 30081   [1.851 sec/step, loss=0.64839, avg_loss=0.63073]\n","Step 30082   [1.881 sec/step, loss=0.60909, avg_loss=0.63033]\n","Step 30083   [1.883 sec/step, loss=0.62948, avg_loss=0.63024]\n","Step 30084   [1.884 sec/step, loss=0.64211, avg_loss=0.63026]\n","Step 30085   [1.858 sec/step, loss=0.62360, avg_loss=0.63125]\n","Step 30086   [1.868 sec/step, loss=0.63101, avg_loss=0.63125]\n","Step 30087   [1.863 sec/step, loss=0.62647, avg_loss=0.63102]\n","Step 30088   [1.869 sec/step, loss=0.64294, avg_loss=0.63102]\n","Generated 32 batches of size 32 in 22.620 sec\n","Step 30089   [1.878 sec/step, loss=0.62230, avg_loss=0.63090]\n","Step 30090   [1.866 sec/step, loss=0.63706, avg_loss=0.63076]\n","Step 30091   [1.873 sec/step, loss=0.62589, avg_loss=0.63063]\n","Step 30092   [1.901 sec/step, loss=0.52263, avg_loss=0.62954]\n","Step 30093   [1.886 sec/step, loss=0.61043, avg_loss=0.62895]\n","Step 30094   [1.863 sec/step, loss=0.62523, avg_loss=0.62843]\n","Step 30095   [1.847 sec/step, loss=0.61292, avg_loss=0.62826]\n","Step 30096   [1.851 sec/step, loss=0.62411, avg_loss=0.62820]\n","Step 30097   [1.850 sec/step, loss=0.62328, avg_loss=0.62795]\n","Step 30098   [1.851 sec/step, loss=0.63222, avg_loss=0.62790]\n","Step 30099   [1.849 sec/step, loss=0.62650, avg_loss=0.62780]\n","Step 30100   [1.846 sec/step, loss=0.62822, avg_loss=0.62776]\n","Writing summary at step: 30100\n","Step 30101   [1.851 sec/step, loss=0.65112, avg_loss=0.62783]\n","Step 30102   [1.854 sec/step, loss=0.62070, avg_loss=0.62753]\n","Step 30103   [1.854 sec/step, loss=0.62058, avg_loss=0.62701]\n","Step 30104   [1.856 sec/step, loss=0.62656, avg_loss=0.62687]\n","Step 30105   [1.858 sec/step, loss=0.62716, avg_loss=0.62694]\n","Step 30106   [1.867 sec/step, loss=0.62531, avg_loss=0.62680]\n","Step 30107   [1.871 sec/step, loss=0.63866, avg_loss=0.62686]\n","Step 30108   [1.872 sec/step, loss=0.62841, avg_loss=0.62667]\n","Step 30109   [1.874 sec/step, loss=0.63669, avg_loss=0.62680]\n","Step 30110   [1.867 sec/step, loss=0.61407, avg_loss=0.62636]\n","Step 30111   [1.877 sec/step, loss=0.63677, avg_loss=0.62637]\n","Step 30112   [1.884 sec/step, loss=0.63730, avg_loss=0.62643]\n","Step 30113   [1.887 sec/step, loss=0.63218, avg_loss=0.62625]\n","Step 30114   [1.888 sec/step, loss=0.63104, avg_loss=0.62595]\n","Step 30115   [1.890 sec/step, loss=0.62911, avg_loss=0.62586]\n","Step 30116   [1.899 sec/step, loss=0.63415, avg_loss=0.62596]\n","Step 30117   [1.912 sec/step, loss=0.62317, avg_loss=0.62570]\n","Step 30118   [1.885 sec/step, loss=0.62062, avg_loss=0.62590]\n","Step 30119   [1.879 sec/step, loss=0.63218, avg_loss=0.62591]\n","Generated 32 batches of size 32 in 22.549 sec\n","Step 30120   [1.893 sec/step, loss=0.64235, avg_loss=0.62596]\n","Step 30121   [1.853 sec/step, loss=0.53237, avg_loss=0.62663]\n","Step 30122   [1.859 sec/step, loss=0.63102, avg_loss=0.62640]\n","Step 30123   [1.861 sec/step, loss=0.61586, avg_loss=0.62633]\n","Step 30124   [1.864 sec/step, loss=0.61655, avg_loss=0.62603]\n","Step 30125   [1.861 sec/step, loss=0.62329, avg_loss=0.62590]\n","Step 30126   [1.826 sec/step, loss=0.61940, avg_loss=0.62706]\n","Step 30127   [1.827 sec/step, loss=0.62678, avg_loss=0.62704]\n","Step 30128   [1.827 sec/step, loss=0.62420, avg_loss=0.62700]\n","Step 30129   [1.823 sec/step, loss=0.63914, avg_loss=0.62711]\n","Step 30130   [1.819 sec/step, loss=0.64081, avg_loss=0.62706]\n","Step 30131   [1.818 sec/step, loss=0.64106, avg_loss=0.62711]\n","Step 30132   [1.819 sec/step, loss=0.63662, avg_loss=0.62710]\n","Step 30133   [1.820 sec/step, loss=0.63492, avg_loss=0.62697]\n","Step 30134   [1.820 sec/step, loss=0.62590, avg_loss=0.62688]\n","Step 30135   [1.819 sec/step, loss=0.62383, avg_loss=0.62676]\n","Step 30136   [1.819 sec/step, loss=0.64171, avg_loss=0.62672]\n","Step 30137   [1.809 sec/step, loss=0.63579, avg_loss=0.62715]\n","Step 30138   [1.812 sec/step, loss=0.62904, avg_loss=0.62693]\n","Step 30139   [1.809 sec/step, loss=0.61903, avg_loss=0.62682]\n","Step 30140   [1.807 sec/step, loss=0.59661, avg_loss=0.62648]\n","Step 30141   [1.805 sec/step, loss=0.61156, avg_loss=0.62609]\n","Step 30142   [1.794 sec/step, loss=0.62681, avg_loss=0.62588]\n","Step 30143   [1.816 sec/step, loss=0.62624, avg_loss=0.62580]\n","Step 30144   [1.822 sec/step, loss=0.63206, avg_loss=0.62588]\n","Step 30145   [1.838 sec/step, loss=0.62763, avg_loss=0.62590]\n","Step 30146   [1.845 sec/step, loss=0.63071, avg_loss=0.62586]\n","Step 30147   [1.878 sec/step, loss=0.57083, avg_loss=0.62505]\n","Step 30148   [1.880 sec/step, loss=0.62318, avg_loss=0.62487]\n","Step 30149   [1.873 sec/step, loss=0.62578, avg_loss=0.62481]\n","Step 30150   [1.860 sec/step, loss=0.62302, avg_loss=0.62464]\n","Generated 32 batches of size 32 in 22.976 sec\n","Step 30151   [1.866 sec/step, loss=0.61635, avg_loss=0.62459]\n","Step 30152   [1.850 sec/step, loss=0.60858, avg_loss=0.62412]\n","Step 30153   [1.840 sec/step, loss=0.62394, avg_loss=0.62403]\n","Step 30154   [1.831 sec/step, loss=0.59733, avg_loss=0.62346]\n","Step 30155   [1.827 sec/step, loss=0.61794, avg_loss=0.62348]\n","Step 30156   [1.816 sec/step, loss=0.61748, avg_loss=0.62331]\n","Step 30157   [1.806 sec/step, loss=0.65182, avg_loss=0.62345]\n","Step 30158   [1.807 sec/step, loss=0.61759, avg_loss=0.62345]\n","Step 30159   [1.812 sec/step, loss=0.64029, avg_loss=0.62356]\n","Step 30160   [1.807 sec/step, loss=0.62456, avg_loss=0.62336]\n","Step 30161   [1.839 sec/step, loss=0.42944, avg_loss=0.62130]\n","Step 30162   [1.839 sec/step, loss=0.61771, avg_loss=0.62114]\n","Step 30163   [1.850 sec/step, loss=0.61732, avg_loss=0.62119]\n","Step 30164   [1.853 sec/step, loss=0.63369, avg_loss=0.62116]\n","Step 30165   [1.817 sec/step, loss=0.60882, avg_loss=0.62208]\n","Step 30166   [1.819 sec/step, loss=0.63880, avg_loss=0.62211]\n","Step 30167   [1.822 sec/step, loss=0.63228, avg_loss=0.62217]\n","Step 30168   [1.826 sec/step, loss=0.61917, avg_loss=0.62224]\n","Step 30169   [1.838 sec/step, loss=0.60889, avg_loss=0.62202]\n","Step 30170   [1.841 sec/step, loss=0.63806, avg_loss=0.62212]\n","Step 30171   [1.837 sec/step, loss=0.61541, avg_loss=0.62196]\n","Step 30172   [1.838 sec/step, loss=0.63410, avg_loss=0.62210]\n","Step 30173   [1.846 sec/step, loss=0.61025, avg_loss=0.62175]\n","Step 30174   [1.846 sec/step, loss=0.63837, avg_loss=0.62196]\n","Step 30175   [1.863 sec/step, loss=0.63670, avg_loss=0.62226]\n","Step 30176   [1.860 sec/step, loss=0.60327, avg_loss=0.62204]\n","Step 30177   [1.866 sec/step, loss=0.62940, avg_loss=0.62214]\n","Step 30178   [1.876 sec/step, loss=0.61630, avg_loss=0.62197]\n","Step 30179   [1.877 sec/step, loss=0.63734, avg_loss=0.62207]\n","Step 30180   [1.877 sec/step, loss=0.61258, avg_loss=0.62198]\n","Step 30181   [1.877 sec/step, loss=0.63061, avg_loss=0.62180]\n","Step 30182   [1.857 sec/step, loss=0.62891, avg_loss=0.62200]\n","Step 30183   [1.851 sec/step, loss=0.62944, avg_loss=0.62200]\n","Generated 32 batches of size 32 in 21.279 sec\n","Step 30184   [1.884 sec/step, loss=0.64125, avg_loss=0.62199]\n","Step 30185   [1.877 sec/step, loss=0.62548, avg_loss=0.62201]\n","Step 30186   [1.867 sec/step, loss=0.62134, avg_loss=0.62191]\n","Step 30187   [1.860 sec/step, loss=0.62837, avg_loss=0.62193]\n","Step 30188   [1.856 sec/step, loss=0.63142, avg_loss=0.62181]\n","Step 30189   [1.840 sec/step, loss=0.63271, avg_loss=0.62192]\n"],"name":"stdout"}]}]}