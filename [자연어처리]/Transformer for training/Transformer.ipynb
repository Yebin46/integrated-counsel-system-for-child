{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf9W6AqH_sVa",
        "outputId": "62240eb2-df7e-433a-b0c6-fcfb879ab1f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Nf9W6AqH_sVa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfapyUGPOZD6",
        "outputId": "1142dd5d-cf61-4754-8eca-92a188e5cbb3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "id": "WfapyUGPOZD6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  1 03:45:49 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sixth-error",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11d4ea7-f68a-4479-87e0-f549dd27adb6"
      },
      "source": [
        "! pip install tensorflow_datasets"
      ],
      "id": "sixth-error",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.12.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.12.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (21.2.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.1.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.1.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.0.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (56.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets) (3.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "built-showcase",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad978c27-556b-41c3-b390-2015dba7eedf"
      },
      "source": [
        "! pip install --upgrade pip\n",
        "\n",
        "! pip install tensorflow\n",
        "\n",
        "! pip install tensorflow_datasets"
      ],
      "id": "built-showcase",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/82/04e9aaf603fdbaecb4323b9e723f13c92c245f6ab2902195c53987848c78/pip-21.1.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 13.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.1.2\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (56.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.30.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.0.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (21.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.19.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.12.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.1.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.12.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (56.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.4 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow_datasets) (3.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inappropriate-south"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "import time\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "id": "inappropriate-south",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interracial-fitness"
      },
      "source": [
        "### 1. 데이터(csv) 로드하기"
      ],
      "id": "interracial-fitness"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "upset-rescue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ca1af5f3-e70f-40dc-8050-b80719fdc585"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/chatbot_transformer/data/cyber_after_preprocess_shuffle_0522.csv\",index_col=0)\n",
        "train_data.head()"
      ],
      "id": "upset-rescue",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>concerns</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>요즘에 여대생들도 욕하나요?</td>\n",
              "      <td>욕은 여대생뿐만이 아니라 상대에게 자신으 분노를 적절하게 표현하는 방법이기도 하세요...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>가족들이 날 안좋아하나봐. 하고 제가 그렇게 생각하는게 아니라..그냥 진짜로!!!!...</td>\n",
              "      <td>가족들이 나를 안 좋아한다 느끼는군요. 혹 이런 이야기를 상대에게 했을 때 내가 오...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>안녕하세요!저는 평소 고민이 많았던 감사 본명: 윤  입니다. 저는 아직 14세 미...</td>\n",
              "      <td>그동안 고민되는 마음을 이곳에 오셔서  이야기 나누면서 도움을 받으셨다니 다행이고 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>우울하고 죽고 싶을 정도로 외롭고 공허해요쓸쓸하고조금에 스트레스조차 이젠 몸이 못 ...</td>\n",
              "      <td>너무 힘들어 글 올려주었군요. 조금 있으면 성인이 되고.. 여러가지 마음에  지쳐가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>우울증에 걸린 것 같은데 병원에 갈 환경이 아니에요. 혼자 이겨내려고 하는데 좋은 ...</td>\n",
              "      <td>우울증 증상이면 힘든 생각도 많이 나고 굉장히 힘들고 외롭고 어떻게 해야할지 고민되...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            concerns                                              reply\n",
              "0                                    요즘에 여대생들도 욕하나요?  욕은 여대생뿐만이 아니라 상대에게 자신으 분노를 적절하게 표현하는 방법이기도 하세요...\n",
              "1  가족들이 날 안좋아하나봐. 하고 제가 그렇게 생각하는게 아니라..그냥 진짜로!!!!...  가족들이 나를 안 좋아한다 느끼는군요. 혹 이런 이야기를 상대에게 했을 때 내가 오...\n",
              "2  안녕하세요!저는 평소 고민이 많았던 감사 본명: 윤  입니다. 저는 아직 14세 미...  그동안 고민되는 마음을 이곳에 오셔서  이야기 나누면서 도움을 받으셨다니 다행이고 ...\n",
              "3  우울하고 죽고 싶을 정도로 외롭고 공허해요쓸쓸하고조금에 스트레스조차 이젠 몸이 못 ...  너무 힘들어 글 올려주었군요. 조금 있으면 성인이 되고.. 여러가지 마음에  지쳐가...\n",
              "4  우울증에 걸린 것 같은데 병원에 갈 환경이 아니에요. 혼자 이겨내려고 하는데 좋은 ...  우울증 증상이면 힘든 생각도 많이 나고 굉장히 힘들고 외롭고 어떻게 해야할지 고민되..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arctic-replica",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b18c83-5fee-4928-d9de-a0bd1855f57e"
      },
      "source": [
        "print('챗봇 샘플의 개수 :', len(train_data))"
      ],
      "id": "arctic-replica",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "챗봇 샘플의 개수 : 51575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "proper-necklace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb45290-43f8-4bc2-c89e-d4b98422bd14"
      },
      "source": [
        "# 결측값 있는지 확인\n",
        "print(train_data.isnull().sum())"
      ],
      "id": "proper-necklace",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "concerns    0\n",
            "reply       0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alive-inspector"
      },
      "source": [
        "# 결측값이 들어있는 행 전체 삭제\n",
        "train_data = train_data.dropna(axis=0) "
      ],
      "id": "alive-inspector",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dense-worst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f840e346-de0f-4621-908d-0fe5c1592339"
      },
      "source": [
        "print(train_data.isnull().sum())"
      ],
      "id": "dense-worst",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "concerns    0\n",
            "reply       0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYCbUG6ibqgp"
      },
      "source": [
        "train_data.columns = [\"concerns\", \"reply\"]"
      ],
      "id": "UYCbUG6ibqgp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhv_7HWSBz_T"
      },
      "source": [
        "train_data.rename(columns = {0: \"concerns\", 1: \"reply\"}, inplace=True)"
      ],
      "id": "Mhv_7HWSBz_T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMEP9tHNCQPr"
      },
      "source": [
        "train_data = train_data.reset_index(drop=True)"
      ],
      "id": "rMEP9tHNCQPr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMLAHOhRPYIU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "e3bddec5-5ff6-4a26-feaa-177cb7c799e2"
      },
      "source": [
        "train_data"
      ],
      "id": "ZMLAHOhRPYIU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>concerns</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>요즘에 여대생들도 욕하나요?</td>\n",
              "      <td>욕은 여대생뿐만이 아니라 상대에게 자신으 분노를 적절하게 표현하는 방법이기도 하세요...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>가족들이 날 안좋아하나봐. 하고 제가 그렇게 생각하는게 아니라..그냥 진짜로!!!!...</td>\n",
              "      <td>가족들이 나를 안 좋아한다 느끼는군요. 혹 이런 이야기를 상대에게 했을 때 내가 오...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>안녕하세요!저는 평소 고민이 많았던 감사 본명: 윤  입니다. 저는 아직 14세 미...</td>\n",
              "      <td>그동안 고민되는 마음을 이곳에 오셔서  이야기 나누면서 도움을 받으셨다니 다행이고 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>우울하고 죽고 싶을 정도로 외롭고 공허해요쓸쓸하고조금에 스트레스조차 이젠 몸이 못 ...</td>\n",
              "      <td>너무 힘들어 글 올려주었군요. 조금 있으면 성인이 되고.. 여러가지 마음에  지쳐가...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>우울증에 걸린 것 같은데 병원에 갈 환경이 아니에요. 혼자 이겨내려고 하는데 좋은 ...</td>\n",
              "      <td>우울증 증상이면 힘든 생각도 많이 나고 굉장히 힘들고 외롭고 어떻게 해야할지 고민되...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51570</th>\n",
              "      <td>쓸데없는 생각과 걱정이 많이 드는데 어떻게 하는것이 좋을까요?</td>\n",
              "      <td>사람은 누구나 벌어지지 않은 일에 대해 걱정을 하기도 한답니다. kim sw님께서도...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51571</th>\n",
              "      <td>드디어 내일이 시험이네요 두근두근!긴장도되고 떨려서 실수할까봐 걱정도 되요 후......</td>\n",
              "      <td>민트님, 내일이 중간고사라 많이 긴장이 되겠어요. 푹 자고, 아침밥 챙겨 먹고, 너...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51572</th>\n",
              "      <td>엘베올라가다 문이열리자마자 누가 있더라구요 나올려하다가요 당황을 좀했더니 바로 사장...</td>\n",
              "      <td>때로는 타이밍을 맞추지 못해 늦을 수도 있지만 다음에 만났을 때 먼저 인사하면 될 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51573</th>\n",
              "      <td>이제 고등학생이 되는데 하루하루 너무 힘들어서 정신과 상담을 받고싶어요. 부모님은 ...</td>\n",
              "      <td>대부분 정신과를 방문하는 이유는 고통을 줄이기 위해 약물처방을 받기 위해 가게 되는...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51574</th>\n",
              "      <td>오늘 하루도 잘버텼다고 한마디만 해주세여.......!</td>\n",
              "      <td>오늘 하루 정말 애썼어요.  잘 견디고 버텨온것에 토닥토닥 격려해주고싶네요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51575 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                concerns                                              reply\n",
              "0                                        요즘에 여대생들도 욕하나요?  욕은 여대생뿐만이 아니라 상대에게 자신으 분노를 적절하게 표현하는 방법이기도 하세요...\n",
              "1      가족들이 날 안좋아하나봐. 하고 제가 그렇게 생각하는게 아니라..그냥 진짜로!!!!...  가족들이 나를 안 좋아한다 느끼는군요. 혹 이런 이야기를 상대에게 했을 때 내가 오...\n",
              "2      안녕하세요!저는 평소 고민이 많았던 감사 본명: 윤  입니다. 저는 아직 14세 미...  그동안 고민되는 마음을 이곳에 오셔서  이야기 나누면서 도움을 받으셨다니 다행이고 ...\n",
              "3      우울하고 죽고 싶을 정도로 외롭고 공허해요쓸쓸하고조금에 스트레스조차 이젠 몸이 못 ...  너무 힘들어 글 올려주었군요. 조금 있으면 성인이 되고.. 여러가지 마음에  지쳐가...\n",
              "4      우울증에 걸린 것 같은데 병원에 갈 환경이 아니에요. 혼자 이겨내려고 하는데 좋은 ...  우울증 증상이면 힘든 생각도 많이 나고 굉장히 힘들고 외롭고 어떻게 해야할지 고민되...\n",
              "...                                                  ...                                                ...\n",
              "51570                 쓸데없는 생각과 걱정이 많이 드는데 어떻게 하는것이 좋을까요?  사람은 누구나 벌어지지 않은 일에 대해 걱정을 하기도 한답니다. kim sw님께서도...\n",
              "51571  드디어 내일이 시험이네요 두근두근!긴장도되고 떨려서 실수할까봐 걱정도 되요 후......  민트님, 내일이 중간고사라 많이 긴장이 되겠어요. 푹 자고, 아침밥 챙겨 먹고, 너...\n",
              "51572  엘베올라가다 문이열리자마자 누가 있더라구요 나올려하다가요 당황을 좀했더니 바로 사장...  때로는 타이밍을 맞추지 못해 늦을 수도 있지만 다음에 만났을 때 먼저 인사하면 될 ...\n",
              "51573  이제 고등학생이 되는데 하루하루 너무 힘들어서 정신과 상담을 받고싶어요. 부모님은 ...  대부분 정신과를 방문하는 이유는 고통을 줄이기 위해 약물처방을 받기 위해 가게 되는...\n",
              "51574                     오늘 하루도 잘버텼다고 한마디만 해주세여.......!       오늘 하루 정말 애썼어요.  잘 견디고 버텨온것에 토닥토닥 격려해주고싶네요.  \n",
              "\n",
              "[51575 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "proof-grill"
      },
      "source": [
        "questions = []\n",
        "for sentence in train_data['concerns']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    questions.append(sentence)"
      ],
      "id": "proof-grill",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lined-bones"
      },
      "source": [
        "answers = []\n",
        "for sentence in train_data['reply']:\n",
        "    # 구두점에 대해서 띄어쓰기\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    answers.append(sentence)"
      ],
      "id": "lined-bones",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mounted-september",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5e96e8-bec3-4a2e-a93a-4a9481d8ba6a"
      },
      "source": [
        "print(questions[:5])\n",
        "print(answers[:5])"
      ],
      "id": "mounted-september",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['요즘에 여대생들도 욕하나요 ?', '가족들이 날 안좋아하나봐 .  하고 제가 그렇게 생각하는게 아니라 .  . 그냥 진짜로 !  !  !  !  안좋아해요 .  그렇게 느끼셨군요 ?  하고 답들으면 .  . 꼭 제가 오해한다는 말처럼 느껴져서 마음이 안좋아요 .  저 안좋아해요 .  그냥 .  .  . 진짜로 .  .  . 본인들도 날 사랑할 사람 아무도 없다고 ,  다른 가족들조차 너랑 사실 살기 싫을거다 말하고 다른 친척들도 저를 보고  자기네들은 저처럼 그렇지 않아  다행이라고 말해요 .  .  .  . 저희 언니조차 절 덜 좋아한단 말에 동의해요 .  .  .  .  .   .  .  .  .  .  .  .  .  오ㅐ 절안좋아하는 걸까요', '안녕하세요 ! 저는 평소 고민이 많았던 감사 본명: 윤  입니다 .  저는 아직 14세 미만이라서 계정이 없었는데 로그인없이도 익명으로 고민글을 쓸 수 있는 청소년상담센터가 있어서 잘 이용하고 있어요 .  저의 고민을 들어주신 컴슬러 분들께 감사드립니다 !  앞으로도 로그인 없이 이용가능하면 좋겠습니다 . 성탄절 잘 보내세요', '우울하고 죽고 싶을 정도로 외롭고 공허해요쓸쓸하고조금에 스트레스조차 이젠 몸이 못 버텨요두통만 있었는데 이젠 구역질 ,  호흡곤란까지 와요이제 며칠 뒤면 성인인데 너무 무섭고 미칠 것 같아요요즘 매일 울어요그냥 눈물이 나고 멍 때리고 눈물이 나서 감정을 제어 못하겠어요초등학교 때 자살이 무엇인지 알고 그때부터자살 생각 있고 시도도 해보고 자해 ,  자학도 하는데뭐랄까 이제는 너무 지치고 포기하고 도망가고 싶어요그냥 존재가 없었던 사람이 되고 싶어요잠도 많아졌어요 학교 ,  학원 빼고는 잠만 자요이유를 모르겠어요이대로 영원히 자고 싶어요힘들다고 하면 주변 사람들 중 이해 못 하는 사람이 있어요저는 사람 한 명 대우하기도 너무 힘들어요학생이잖아요학교 다니고 있잖아요 사람이 싫은 건 아니지만 너무 지겹고 지쳐요가족조차도 대우하기 힘들어요', '우울증에 걸린 것 같은데 병원에 갈 환경이 아니에요 .  혼자 이겨내려고 하는데 좋은 방법이 있을까요 ?  혼자 할 수 있는 우울증 치료법을 알려주세요']\n",
            "['욕은 여대생뿐만이 아니라 상대에게 자신으 분노를 적절하게 표현하는 방법이기도 하세요 .  다만 그것이 상황과 상대에 따라서 문제가 되느냐 안되느냐의 차이라고 보시면 될꺼 같아요 .  그러니 여대생이어서라는 편견을 가지지 마시길 바래요', '가족들이 나를 안 좋아한다 느끼는군요 .  혹 이런 이야기를 상대에게 했을 때 내가 오해하는 것일 수도 있겠다는 반응을 보게 되면 내가 오해하는 듯하다는 말처럼 이해되어 더 답답하고왜 내 말을 믿지 못할까 속도 상하겠어요 .  이미 친척이나 언니마저 이를 인정하고 있어 내가 느끼는 감정이 합리적임을 이야기 하고 싶네요 .  맞아요 내가 그리 느껴지는데는 뭔가 근거가 있는거지요 .  그런데 그 이유에 대해서는 잘 알지 못하는군요 .  그럼 그 이유에 대해 같이 나눠보면 어떨까 싶어요 . 사람의 마음은 말과 행동으로 드러나요 .  그러니 가족들이 특정한 상황에서 하는 말과 행동을 가지고 그 사람들의 마음을 해석해볼수 있어요 .  혼자 생각하다보면 그냥 다 싫고 우울해지는 것으로 끝날때가 많아요 .  채팅방에와서 이유에 대해 같이 논의해봤으면 해요 .', '그동안 고민되는 마음을 이곳에 오셔서  이야기 나누면서 도움을 받으셨다니 다행이고 감사한일이네요 앞으로도 크고 작은 여러 고민들 여기에 오셔서  함께 이야기 나누면서 잘 풀어가면 좋겠네요', '너무 힘들어 글 올려주었군요 .  조금 있으면 성인이 되고 .  .  여러가지 마음에  지쳐가고 있다고 하였어요 .  .  학생이어서 공부 자체만으로도 부담 되고  스트레스도 컸을 것 같아요 .  이것 이외에도 일이 있었다면 .  .  힘든 일이 한 두가지가 아니네요 지치고도 더 큰 아픔이 남아있는 것 같아 .  . 힘들어 보여요 .   무슨일이 어떻게 일어나고 있는지 .  어떤 마음을 나누고 싶은지 .  .  자세하게 듣고 싶으네요 .', '우울증 증상이면 힘든 생각도 많이 나고 굉장히 힘들고 외롭고 어떻게 해야할지 고민되고 지금 상황을 벗어나고 싶은 마음이 들것 같아요 . 우울증에 벗어날 수 있도록 저는 정신건강을 상담해볼 수도 있고 또 기분을 전환하거나 좋게할 수 있는 자신만의 취미생활을 갖는 것도 필요할 거예요 . 정신건강과 관련해서 상담을 받을수 있는 곳이 있어요 .  너무 힘들때는 혼자 있는게 오히려 좋지않아요 .  청소년상담복지센터에서 상담을 받아보는 것도 도움이 되리라 생각합니다 .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "careful-marathon"
      },
      "source": [
        "### 2. 단어 집합 생성"
      ],
      "id": "careful-marathon"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auburn-presentation"
      },
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)"
      ],
      "id": "auburn-presentation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9CbujFGCdMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a84ef2c-f3e8-44ef-c46b-dd3d94c46a64"
      },
      "source": [
        "tokenizer.vocab_size"
      ],
      "id": "K9CbujFGCdMZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "attended-uzbekistan"
      },
      "source": [
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "id": "attended-uzbekistan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "returning-jefferson",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395bc632-bd59-445d-997a-be6366b94d16"
      },
      "source": [
        "print('시작 토큰 번호 :',START_TOKEN)\n",
        "print('종료 토큰 번호 :',END_TOKEN)\n",
        "print('단어 집합의 크기 :',VOCAB_SIZE)"
      ],
      "id": "returning-jefferson",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "시작 토큰 번호 : [8199]\n",
            "종료 토큰 번호 : [8200]\n",
            "단어 집합의 크기 : 8201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "residential-joining"
      },
      "source": [
        "### 3. 정수 인코딩과 패딩"
      ],
      "id": "residential-joining"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wZ3Nhsksyy6"
      },
      "source": [
        "* 샘플 1개에 대해"
      ],
      "id": "2wZ3Nhsksyy6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inappropriate-consumption",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac15f44-c0ff-4676-efdf-fc61b4f96aa5"
      },
      "source": [
        "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
      ],
      "id": "inappropriate-consumption",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "임의의 질문 샘플을 정수 인코딩 : [35, 1749, 2661, 75, 6262, 362, 3653, 3236, 7753, 2273, 5, 195, 17, 4790, 3247, 35, 84, 956, 371, 178, 217, 8177, 8123, 8101, 8179, 8119, 8117, 5159, 207, 40, 3901, 2920, 269, 45]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vanilla-cruise",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b208c0-a8ff-462b-c426-823ed60893c5"
      },
      "source": [
        "sample_string = questions[20]\n",
        "\n",
        "# encode\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# decode\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))"
      ],
      "id": "vanilla-cruise",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정수 인코딩 후의 문장 [35, 1749, 2661, 75, 6262, 362, 3653, 3236, 7753, 2273, 5, 195, 17, 4790, 3247, 35, 84, 956, 371, 178, 217, 8177, 8123, 8101, 8179, 8119, 8117, 5159, 207, 40, 3901, 2920, 269, 45]\n",
            "기존 문장: 제가 12살인데 요새 야한게 가끔식 보고싶고 그런데 너무 빠른가요 제가 기독교인인데 괞찮은거에요 ?  아님 자연스러운 거에요 ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jhWTgCos21d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e56607-a627-456e-b277-4bb7c8eb7bac"
      },
      "source": [
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "id": "5jhWTgCos21d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35 ----> 제가 \n",
            "1749 ----> 12\n",
            "2661 ----> 살인\n",
            "75 ----> 데 \n",
            "6262 ----> 요새 \n",
            "362 ----> 야\n",
            "3653 ----> 한게 \n",
            "3236 ----> 가끔\n",
            "7753 ----> 식 \n",
            "2273 ----> 보고싶\n",
            "5 ----> 고 \n",
            "195 ----> 그런데 \n",
            "17 ----> 너무 \n",
            "4790 ----> 빠른\n",
            "3247 ----> 가요 \n",
            "35 ----> 제가 \n",
            "84 ----> 기\n",
            "956 ----> 독\n",
            "371 ----> 교\n",
            "178 ----> 인\n",
            "217 ----> 인데 \n",
            "8177 ----> �\n",
            "8123 ----> �\n",
            "8101 ----> �\n",
            "8179 ----> �\n",
            "8119 ----> �\n",
            "8117 ----> �\n",
            "5159 ----> 은거\n",
            "207 ----> 에요\n",
            "40 ---->  ?  \n",
            "3901 ----> 아님 \n",
            "2920 ----> 자연스러운 \n",
            "269 ----> 거에요\n",
            "45 ---->  ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmlDve9RtFE-"
      },
      "source": [
        "* 전체 데이터에 대해"
      ],
      "id": "SmlDve9RtFE-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B1mAVrzs4Hy"
      },
      "source": [
        "MAX_LENGTH = 120\n",
        "\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "    \n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "id": "6B1mAVrzs4Hy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zvNrxFos4F7"
      },
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)"
      ],
      "id": "-zvNrxFos4F7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JRErEGas4DY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7b702d-5ad6-423a-8851-6b6fdeb97f3b"
      },
      "source": [
        "print('질문 데이터의 크기(shape) :', questions.shape)\n",
        "print('답변 데이터의 크기(shape) :', answers.shape)"
      ],
      "id": "2JRErEGas4DY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "질문 데이터의 크기(shape) : (51575, 120)\n",
            "답변 데이터의 크기(shape) : (51575, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6PT_b59s4BQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2137fe-08f6-477e-f0c0-4a9761ce50bf"
      },
      "source": [
        "print(questions[10000])\n",
        "print(answers[10000])"
      ],
      "id": "T6PT_b59s4BQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8199 4396    8 6902 7332   25 6493 5571    8 2577  580 7083  116 5408\n",
            "  424   50 1297  172 1796 6396  959 2274  195 1776   26  590 7706   46\n",
            "   77  454 1410  805  619 3930 3280 3376 2274   47 1685 5197 7975 4790\n",
            " 2436 1832  170 8200    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "[8199 4396    8 5571 3930   44 5408  162 1679  156 1039 2937 7417    7\n",
            "   12    1 4396    8  590  633   67 5571 3930    8 2044 2606    7 6711\n",
            " 7975 2332    9  164  337 4423 6144  206  225  544 1513 3295 3383   32\n",
            "    2 1425  225 2853   46 2064 3204  116 6144  206 5314    4  535  794\n",
            " 7975 5232  821 2647  339    9 1248 3383    6   18  154    7  597   13\n",
            " 8200    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI0XT_yauYrw"
      },
      "source": [
        "## 4. 인코더와 디코더의 입력, 그리고 레이블 만들기"
      ],
      "id": "SI0XT_yauYrw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byLniDros3-h"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1] \n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]  \n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "id": "byLniDros3-h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnn9ccDys37o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abba38d5-e17d-475a-f0be-559afe3f55b8"
      },
      "source": [
        "print(answers[0])\n",
        "print(answers[:1][:, :-1])\n",
        "print(answers[:1][:, 1:]) "
      ],
      "id": "Rnn9ccDys37o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8199 1030   26  136  169  428 6802    8  465 1144  258 1066  442 7975\n",
            " 4055   19 5355   94 3783 1692  167 2282    1 3306 2222  691   53 1144\n",
            "   16 2590  599  406 4308 7975  880 4308   30 2507   74 2442 6412 7975\n",
            "   12    1  325  136  169 3731 2466  226  494 3587    4  678   28 1944\n",
            "  141  158 8200    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "[[8199 1030   26  136  169  428 6802    8  465 1144  258 1066  442 7975\n",
            "  4055   19 5355   94 3783 1692  167 2282    1 3306 2222  691   53 1144\n",
            "    16 2590  599  406 4308 7975  880 4308   30 2507   74 2442 6412 7975\n",
            "    12    1  325  136  169 3731 2466  226  494 3587    4  678   28 1944\n",
            "   141  158 8200    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0]]\n",
            "[[1030   26  136  169  428 6802    8  465 1144  258 1066  442 7975 4055\n",
            "    19 5355   94 3783 1692  167 2282    1 3306 2222  691   53 1144   16\n",
            "  2590  599  406 4308 7975  880 4308   30 2507   74 2442 6412 7975   12\n",
            "     1  325  136  169 3731 2466  226  494 3587    4  678   28 1944  141\n",
            "   158 8200    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDEZBukmu2Il"
      },
      "source": [
        "## 5. 트랜스포머 만들기"
      ],
      "id": "bDEZBukmu2Il"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTS8wuqSv5nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b227b94a-1054-42a4-d240-794b833fc9d3"
      },
      "source": [
        "! pip install transformers"
      ],
      "id": "DTS8wuqSv5nv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 51.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5eqvAx5wHKK"
      },
      "source": [
        "import transformers"
      ],
      "id": "v5eqvAx5wHKK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkmXjQwuyO68"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "id": "mkmXjQwuyO68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFSdA9qIyUxQ"
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x) \n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "id": "sFSdA9qIyUxQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsWLgm9zybCY"
      },
      "source": [
        "def encoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "id": "LsWLgm9zybCY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_jRQn7wyiH5"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    angle_rads = np.zeros(angle_rads.shape)\n",
        "    angle_rads[:, 0::2] = sines\n",
        "    angle_rads[:, 1::2] = cosines\n",
        "    pos_encoding = tf.constant(angle_rads)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    print(pos_encoding.shape)\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "id": "l_jRQn7wyiH5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA0TYYQ5yniJ"
      },
      "source": [
        "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs, 'key': inputs, 'value': inputs,\n",
        "          'mask': padding_mask \n",
        "      })\n",
        "\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "id": "xA0TYYQ5yniJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDdwJB8CyoUn"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "id": "tDdwJB8CyoUn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN7AAMNVyoPD"
      },
      "source": [
        "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs, 'key': inputs, 'value': inputs, \n",
        "          'mask': look_ahead_mask \n",
        "      })\n",
        "\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
        "          'mask': padding_mask \n",
        "      })\n",
        "\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "id": "xN7AAMNVyoPD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns9a5cZZy8xW"
      },
      "source": [
        "def decoder(vocab_size, num_layers, dff,\n",
        "            d_model, num_heads, dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
        "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "id": "ns9a5cZZy8xW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4M7elskxQj6"
      },
      "source": [
        "def transformer(vocab_size, num_layers, dff,\n",
        "                d_model, num_heads, dropout,\n",
        "                name=\"transformer\"):\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask, output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask]) \n",
        "\n",
        "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
        "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "id": "D4M7elskxQj6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVJGjDRkxQZQ"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "id": "xVJGjDRkxQZQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A_4uN77xQQw"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "id": "6A_4uN77xQQw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMAj6jZAxPEq"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "id": "kMAj6jZAxPEq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTmSBM0As344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7638d80e-aceb-4309-8c5b-abad631a5245"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "D_MODEL = 256\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "DFF = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "id": "dTmSBM0As344",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 8201, 256)\n",
            "(1, 8201, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSFBP3bSm9ud"
      },
      "source": [
        "### ckeckpoint 저장"
      ],
      "id": "gSFBP3bSm9ud"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ALNBcstIBM"
      },
      "source": [
        "import os"
      ],
      "id": "H7ALNBcstIBM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQIcyfbs-r3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38fa1234-14c8-4c94-ffcc-3b655fc83fba"
      },
      "source": [
        "cd /content/drive/MyDrive/chatbot_transformer"
      ],
      "id": "DQIcyfbs-r3z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/chatbot_transformer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVERjpQJm8W5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565dbc98-81f9-4cc9-fbf1-6bc793a6f8e5"
      },
      "source": [
        "checkpoint_path = \"ckpt_0523/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    period=5)\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "id": "AVERjpQJm8W5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "(1, 8201, 256)\n",
            "(1, 8201, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a1bpDtAs31o"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "id": "-a1bpDtAs31o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVvQn-yjs3v4"
      },
      "source": [
        "EPOCHS = 150\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks=[cp_callback])"
      ],
      "id": "aVvQn-yjs3v4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vquFWCX7nWxq"
      },
      "source": [
        "### 체크포인트 복원"
      ],
      "id": "vquFWCX7nWxq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESUCpXKqncDR"
      },
      "source": [
        "* 만들어진 체크포인트 확인, 마지막 체크포인트 선택"
      ],
      "id": "ESUCpXKqncDR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzHN-SVSnWGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b343e6-edef-4065-c545-49731962679a"
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "id": "dzHN-SVSnWGW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t  cp-0075.ckpt.index\n",
            "cp-0000.ckpt.data-00000-of-00001  cp-0080.ckpt.data-00000-of-00001\n",
            "cp-0000.ckpt.index\t\t  cp-0080.ckpt.index\n",
            "cp-0005.ckpt.data-00000-of-00001  cp-0085.ckpt.data-00000-of-00001\n",
            "cp-0005.ckpt.index\t\t  cp-0085.ckpt.index\n",
            "cp-0010.ckpt.data-00000-of-00001  cp-0090.ckpt.data-00000-of-00001\n",
            "cp-0010.ckpt.index\t\t  cp-0090.ckpt.index\n",
            "cp-0015.ckpt.data-00000-of-00001  cp-0095.ckpt.data-00000-of-00001\n",
            "cp-0015.ckpt.index\t\t  cp-0095.ckpt.index\n",
            "cp-0020.ckpt.data-00000-of-00001  cp-0100.ckpt.data-00000-of-00001\n",
            "cp-0020.ckpt.index\t\t  cp-0100.ckpt.index\n",
            "cp-0025.ckpt.data-00000-of-00001  cp-0105.ckpt.data-00000-of-00001\n",
            "cp-0025.ckpt.index\t\t  cp-0105.ckpt.index\n",
            "cp-0030.ckpt.data-00000-of-00001  cp-0110.ckpt.data-00000-of-00001\n",
            "cp-0030.ckpt.index\t\t  cp-0110.ckpt.index\n",
            "cp-0035.ckpt.data-00000-of-00001  cp-0115.ckpt.data-00000-of-00001\n",
            "cp-0035.ckpt.index\t\t  cp-0115.ckpt.index\n",
            "cp-0040.ckpt.data-00000-of-00001  cp-0120.ckpt.data-00000-of-00001\n",
            "cp-0040.ckpt.index\t\t  cp-0120.ckpt.index\n",
            "cp-0045.ckpt.data-00000-of-00001  cp-0125.ckpt.data-00000-of-00001\n",
            "cp-0045.ckpt.index\t\t  cp-0125.ckpt.index\n",
            "cp-0050.ckpt.data-00000-of-00001  cp-0130.ckpt.data-00000-of-00001\n",
            "cp-0050.ckpt.index\t\t  cp-0130.ckpt.index\n",
            "cp-0055.ckpt.data-00000-of-00001  cp-0135.ckpt.data-00000-of-00001\n",
            "cp-0055.ckpt.index\t\t  cp-0135.ckpt.index\n",
            "cp-0060.ckpt.data-00000-of-00001  cp-0140.ckpt.data-00000-of-00001\n",
            "cp-0060.ckpt.index\t\t  cp-0140.ckpt.index\n",
            "cp-0065.ckpt.data-00000-of-00001  cp-0145.ckpt.data-00000-of-00001\n",
            "cp-0065.ckpt.index\t\t  cp-0145.ckpt.index\n",
            "cp-0070.ckpt.data-00000-of-00001  cp-0150.ckpt.data-00000-of-00001\n",
            "cp-0070.ckpt.index\t\t  cp-0150.ckpt.index\n",
            "cp-0075.ckpt.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19jLH37Gnk-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72774aa-c9d6-4aea-afbf-81379162ef91"
      },
      "source": [
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.load_weights('ckpt_0523/cp-0150.ckpt')"
      ],
      "id": "19jLH37Gnk-L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 8201, 256)\n",
            "(1, 8201, 256)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f554b0dced0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYBAfeUYn8TC"
      },
      "source": [
        "* 학습 완료 후, 가중치만 따로 저장"
      ],
      "id": "yYBAfeUYn8TC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu9BxDMRe-Wt"
      },
      "source": [
        "  def get_config(self):\n",
        "    config = {\n",
        "    'd_model': self.d_model,\n",
        "    'warmup_steps': self.warmup_steps,\n",
        "\n",
        "     }\n",
        "    return config"
      ],
      "id": "Qu9BxDMRe-Wt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFkO3gwszlDM"
      },
      "source": [
        "## 6. 모델 평가"
      ],
      "id": "LFkO3gwszlDM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dUOSNmWs3jY"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)"
      ],
      "id": "3dUOSNmWs3jY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62iEVbZWsRuC"
      },
      "source": [
        "import re"
      ],
      "id": "62iEVbZWsRuC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZZam9XHzowl"
      },
      "source": [
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "  \n",
        "  splited = re.split(r'[.?!]', predicted_sentence)\n",
        "  temp = []\n",
        "  for i in range(len(predicted_sentence)):\n",
        "    if predicted_sentence[i] == '.' or predicted_sentence[i] == '?' or predicted_sentence[i] == '!':\n",
        "      temp.append(predicted_sentence[i])\n",
        "  # print(splited)\n",
        "  if len(splited) > 2 :\n",
        "    predicted_sentence = splited[0]+ temp[0] + splited[-2] + '.'\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "  \n",
        "\n",
        "  return predicted_sentence"
      ],
      "id": "xZZam9XHzowl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDoB4gc4zsMM"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "id": "DDoB4gc4zsMM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlmIbgBezttG"
      },
      "source": [
        "## 7. 시현하기"
      ],
      "id": "xlmIbgBezttG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlmqHKOWrZnO",
        "outputId": "d8791b8f-c09b-4326-bb3d-2f166e39a2d4"
      },
      "source": [
        "output = predict(\"요즘 기분이 너무 안좋아\")"
      ],
      "id": "tlmqHKOWrZnO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 요즘 기분이 너무 안좋아\n",
            "Output: 무슨 일이 있는걸까요 .  스트레스가 있다면 풀 수 있는 자신만의 방법을 찾아 보는 건 어떨까요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26AYHl9ftuiW",
        "outputId": "6ded48aa-92a4-45ae-cd35-a728b5162ea5"
      },
      "source": [
        "output = predict(\"요즘 학교생활이 너무 힘드네\")"
      ],
      "id": "26AYHl9ftuiW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 요즘 학교생활이 너무 힘드네\n",
            "Output: 학교생활이 힘들군요 .  함께 이야기 나누며 힘을 얻으면 좋겠어요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzHl77R1wRE0",
        "outputId": "9829914a-745c-4fd0-e392-75d58575bb4b"
      },
      "source": [
        "output = predict(\"친구들이랑 잘 지내고 싶은데 다가가는 방법을 모르겠어\")"
      ],
      "id": "UzHl77R1wRE0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 친구들이랑 잘 지내고 싶은데 다가가는 방법을 모르겠어\n",
            "Output: 친구들과 잘 지내고 싶은 마음이 느껴지네요 .  먼저 친구들에게 다가가서 말을 걸어보면 어떨까요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tDbxvOj0wn1",
        "outputId": "808194cd-40df-4884-b4c0-b75ce041bcbe"
      },
      "source": [
        "output = predict(\"내가 말을 걸면 친구들이 불편해 할까봐 걱정이야\")"
      ],
      "id": "7tDbxvOj0wn1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 내가 말을 걸면 친구들이 불편해 할까봐 걱정이야\n",
            "Output: 말을 잘 하지 않으면 상대방도 눈치가 보일수 있어요 .  그러니 너무 긴장하지 말고 편하게 말을 건네보세요\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOHr735y4Vf5",
        "outputId": "82d3a409-d625-4c54-e72d-54d69eb0e9cb"
      },
      "source": [
        "output = predict(\"반이 바뀌었는데 친구가 하나도 없어\")"
      ],
      "id": "sOHr735y4Vf5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 반이 바뀌었는데 친구가 하나도 없어\n",
            "Output: 새학기가 되어서 친구를 사귀기 위해서는 새로운 환경에 적응하는 것이 가장 중요해요 .  학교 생활이 편해야 할 때니 너무 걱정하지 마시고 새로운 친구들과 잘 지낼 수 있도록 해보세요\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAG6CYUbAuzM",
        "outputId": "8b45ed7c-a4a4-405d-9931-830759d235be"
      },
      "source": [
        "output = predict(\"반배정 나왔는데 친한 친구가 하나도 없어\")"
      ],
      "id": "JAG6CYUbAuzM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 반배정 나왔는데 친한 친구가 하나도 없어\n",
            "Output: 반배정이 잘 되지 않아서 새학기가 걱정이 되는것 같아요 .  새학기가 되면 새로운 반에 새로운 친구를 사귀어 나가면 된답니다 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lC5LIOUGkbf",
        "outputId": "57e4bb61-6d84-46c9-cd58-d131d6d0f3cd"
      },
      "source": [
        "output = predict(\"요즘 스트레스가 많아\")"
      ],
      "id": "7lC5LIOUGkbf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 요즘 스트레스가 많아\n",
            "Output: 요즘 스트레스가 많으신가봐요 .  스트레스를 풀 수 있는 자신만의 해소법을 찾아보면 어떨까요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORyvOekz2qrn",
        "outputId": "4ec3c5f8-6db7-41ca-fcf4-8d7330369358"
      },
      "source": [
        "output = predict(\"중간고사 공부를 열심히 했는데 시험을 망쳤어\")"
      ],
      "id": "ORyvOekz2qrn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 중간고사 공부를 열심히 했는데 시험을 망쳤어\n",
            "Output: 시험을 잘 보고 싶은데 성적이 잘 나오지 않아 많이 속상했을 것 같아요 .  그래도 열심히 공부해서 좋은 결과가 있기를 응원 보낼게요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbCbb4Dur3op",
        "outputId": "d2e1a17e-0087-4a52-8ce1-62308eef04bb"
      },
      "source": [
        "output = predict(\"공부를 열심히 했는데 시험을 망쳤어\")"
      ],
      "id": "bbCbb4Dur3op",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 공부를 열심히 했는데 시험을 망쳤어\n",
            "Output: 열심히 했는데 결과가 좋지 않아 많이 속상하고 마음이 무거울것같아요 .  그래도 남은 과목도 열심히 준비하며 남은 시간동안 최선을 다해서 좋은 결과 있기를 바래요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAgyUCmgtYTo",
        "outputId": "a49d6b4d-0bc2-4a4c-a75b-859a64f5148c"
      },
      "source": [
        "output = predict(\"아 시험 망했어\")"
      ],
      "id": "hAgyUCmgtYTo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 아 시험 망했어\n",
            "Output: 시험을 망쳤다니 너무 속상하겠어요 .  다음 시험에서 좋은 결과가 있기를 바랍니다 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzW9Xj8Hr5x6",
        "outputId": "83181a3b-7499-4d80-a58a-5ad2203d882e"
      },
      "source": [
        "output = predict(\"아니 나 시험 망했어\")"
      ],
      "id": "VzW9Xj8Hr5x6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 아니 나 시험 망했어\n",
            "Output: 시험을 망쳤다니 정말 많이 속상하겠어요 .  그래도 시험에서 좋은 결과 있기를 바래요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM_4GUnUDBUQ",
        "outputId": "b2aa04df-9b11-460c-e4fb-ae2060f88344"
      },
      "source": [
        "output = predict(\"실수를 많이해서 더 속상해\")"
      ],
      "id": "qM_4GUnUDBUQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 실수를 많이해서 더 속상해\n",
            "Output: 에고 실수를 해서 너무 속상하고 마음이 아프겠어요 .  너무 자책하지 마시고 다음에는 꼭 좋은 결과가 있길 바래요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7MUZW0v8SDW",
        "outputId": "4bdc95bf-9e04-4247-d0b4-0d88fe95ec9f"
      },
      "source": [
        "output = predict(\"정말 열심히 공부했는데 성적이 떨어졌어\")"
      ],
      "id": "C7MUZW0v8SDW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 정말 열심히 공부했는데 성적이 떨어졌어\n",
            "Output: 열심히 공부해서 성적이 떨어졌다면 더 기운이 빠질 수 있을 것 같아요 .  그래도 열심히 공부해서 좋은 결과 있기를 응원할게요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3mXdGXYuyQM",
        "outputId": "43f9e5c5-20a6-4050-c7fb-4be437475d31"
      },
      "source": [
        "output = predict(\"난 쓸모없는 사람인 것 같아\")\t"
      ],
      "id": "H3mXdGXYuyQM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 난 쓸모없는 사람인 것 같아\n",
            "Output: 쓸모없는 사람이라고 생각하니 너무 힘들고 지치지요 .  조금 더 자세히 이야기를 나누어보면 좋겠어요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO7v5tpnGJN9",
        "outputId": "1a11b9d0-4adc-49ce-bd92-69a81d99ea38"
      },
      "source": [
        "output = predict(\"친구들에게 따돌림을 당하고 있어\")"
      ],
      "id": "dO7v5tpnGJN9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 친구들에게 따돌림을 당하고 있어\n",
            "Output: 따돌림을 당하고 있는 상황이라 너무 외롭고 견디기 어려웠을 듯 해요 .  혼자 끙끙 앓지 말고 누군가와 이야기를 나눠보고  도움을 청할 수 있는 사람에게 도움을 청하면 좋겠어요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU-4Vp0WFw3t",
        "outputId": "75a46956-2c75-4a09-a87a-73d7d92019cc"
      },
      "source": [
        "output = predict(\"친구들에게 괴롭힘만 당하느니 죽고 싶어\")"
      ],
      "id": "UU-4Vp0WFw3t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 친구들에게 괴롭힘만 당하느니 죽고 싶어\n",
            "Output: 괴롭힘을 당하다니 얼마나 괴롭고 힘들까요 .  혼자서 해결하기 어렵다면 부모님이나 담임선생님과 상의해서 도움을 받아보면 좋겠어요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCuQr5Irf4qE",
        "outputId": "a0ab0d7c-3ec0-4aee-9a8b-2127df019776"
      },
      "source": [
        "output = predict(\"요즘 공부에 너무 집중이 안되는데 어떻게 해야해\")"
      ],
      "id": "xCuQr5Irf4qE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 요즘 공부에 너무 집중이 안되는데 어떻게 해야해\n",
            "Output: 공부를 해야 하는 이유는 뭘까요 ?  해야 하는 이유를 알고 있다면 동기부여가 필요할 것 같아요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCjvP2SJcmtN",
        "outputId": "98844534-903c-4431-e774-e5bbed5d48a6"
      },
      "source": [
        "output = predict(\"과거에 안좋은 기억들 땜에 괴로워요\")"
      ],
      "id": "dCjvP2SJcmtN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 과거에 안좋은 기억들 땜에 괴로워요\n",
            "Output: 때론 과거의 안좋은 일이 생각나면 마음속에 남아있게 되시는것 같아요 .  과거의 안좋은 일이 생각나고 후회되고 자책을 하게 되는것 같아요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flTxJl86CCIF",
        "outputId": "37570977-235b-433c-e378-8766724b8da6"
      },
      "source": [
        "output = predict(\"날씨가 흐려서 우울해졌어요 위로받고 싶어요\")"
      ],
      "id": "flTxJl86CCIF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 날씨가 흐려서 우울해졌어요 위로받고 싶어요\n",
            "Output: 에고 .  .  얼마나 힘들고 ,  슬프고 화도 나고 기운도 없을것 같아요   이런 속상한 마음을 털어버리시고 힘내세요\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr3QK5ZvM8JM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19f94ef-9ee2-4ab2-8843-5406769f5a99"
      },
      "source": [
        "output = predict(\"좋아하는 남자친구가 있는데 고백할 용기가 나지 않아\")"
      ],
      "id": "Qr3QK5ZvM8JM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 좋아하는 남자친구가 있는데 고백할 용기가 나지 않아\n",
            "Output: 좋아하는 남자친구가 있는데 고백 중이신가봐요 .  고백은 문자나 톡 등을 통해 표현해봐도 좋을 것 같아요 .  고백하기 전에 문자로라도 꼭 해보세요\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxPOIVm-doe9",
        "outputId": "4ef66a18-831a-4e10-f0dd-c5a4bbd1c03b"
      },
      "source": [
        "output = predict(\"수면부족으로 잠을 못자서 너무 피곤해\")"
      ],
      "id": "gxPOIVm-doe9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 수면부족으로 잠을 못자서 너무 피곤해\n",
            "Output: 잠을 못자면 다음날 피곤할 것 같아요 .  잠이 안 올 때는 억지로 자려고 하지 말고 누워서 잠을 자려고 하지 말고 누워서 하루를 보내면 좋겠네요 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_TtEpLLexvw",
        "outputId": "881dc543-69c0-44a3-df59-1eb98fbf2329"
      },
      "source": [
        "output = predict(\"요즘 공부에 너무 집중이 안되는데 어떻게 해야해?\")"
      ],
      "id": "g_TtEpLLexvw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 요즘 공부에 너무 집중이 안되는데 어떻게 해야해?\n",
            "Output: 공부를 해야 하는 이유는 뭘까요 ?  해야 하는 이유를 알고 있다면 동기부여가 생기지 않을까요 ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5F_pXlgqd6D",
        "outputId": "b6b10b39-2ab6-4a69-aa6c-a466b6c80f71"
      },
      "source": [
        "output = predict(\"살고 싶지 않아 죽고싶어\")"
      ],
      "id": "R5F_pXlgqd6D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: 살고 싶지 않아 죽고싶어\n",
            "Output: 죽고싶은 마음이 들 정도로 많이 힘들어보이네요 .  죽고싶은 마음이 들 정도로 힘든 일이 있었나봐요 .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}